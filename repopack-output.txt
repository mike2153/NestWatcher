This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2025-10-08T23:14:15.147Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
.eslintignore
.eslintrc.cjs
.gitignore
.prettierignore
ccncstats
color-migration.js
docs/ARCHITECTURE.md
docs/CODEBASE_AUDIT.md
docs/INTRODUCTION.md
docs/IPC.md
docs/JOB-FLOW.md
docs/PROJECT_STRUCTURE.md
docs/stock_request.csv
docs/stock.csv
docs/STYLING.md
docs/WATCHERS.md
docs/WORKLIST.md
electron-builder.yml
package.json
packages/main/package.json
packages/main/src/db/schema.ts
packages/main/src/ipc/alarms.ts
packages/main/src/ipc/db.ts
packages/main/src/ipc/diagnostics.ts
packages/main/src/ipc/errors.ts
packages/main/src/ipc/files.ts
packages/main/src/ipc/grundner.ts
packages/main/src/ipc/history.ts
packages/main/src/ipc/hypernest.ts
packages/main/src/ipc/ipcBridge.ts
packages/main/src/ipc/jobs.ts
packages/main/src/ipc/lifecycle.ts
packages/main/src/ipc/log.ts
packages/main/src/ipc/machines.ts
packages/main/src/ipc/onDestroyed.ts
packages/main/src/ipc/result.ts
packages/main/src/ipc/router.ts
packages/main/src/ipc/settings.ts
packages/main/src/ipc/telemetry.ts
packages/main/src/ipc/ui.ts
packages/main/src/logger.ts
packages/main/src/main.ts
packages/main/src/repo/alarmsHistoryRepo.ts
packages/main/src/repo/alarmsRepo.ts
packages/main/src/repo/cncStatsRepo.ts
packages/main/src/repo/grundnerRepo.ts
packages/main/src/repo/historyRepo.ts
packages/main/src/repo/jobEventsRepo.ts
packages/main/src/repo/jobsRepo.ts
packages/main/src/repo/machinesRepo.ts
packages/main/src/repo/routerRepo.ts
packages/main/src/repo/telemetryRepo.ts
packages/main/src/security.ts
packages/main/src/services/config.ts
packages/main/src/services/db.ts
packages/main/src/services/dbWatchdog.ts
packages/main/src/services/diagnostics.ts
packages/main/src/services/grundner.ts
packages/main/src/services/ingest.ts
packages/main/src/services/readyImport.ts
packages/main/src/services/uiState.ts
packages/main/src/services/watchers.ts
packages/main/src/services/worklist.ts
packages/main/src/workers/telemetryParser.ts
packages/main/src/workers/watchersMessages.ts
packages/main/src/workers/watchersWorker.ts
packages/main/tsconfig.json
packages/preload/package.json
packages/preload/src/index.ts
packages/preload/tsconfig.json
packages/renderer/components.json
packages/renderer/index.html
packages/renderer/package.json
packages/renderer/postcss.config.cjs
packages/renderer/src/components/AppSidebar.tsx
packages/renderer/src/components/table/GlobalTable.tsx
packages/renderer/src/components/ui/badge.tsx
packages/renderer/src/components/ui/button.tsx
packages/renderer/src/components/ui/card.tsx
packages/renderer/src/components/ui/glowing-effect.tsx
packages/renderer/src/components/ui/separator.tsx
packages/renderer/src/components/ui/sheet.tsx
packages/renderer/src/components/ui/sidebar.tsx
packages/renderer/src/components/ui/skeleton.tsx
packages/renderer/src/components/ui/table.tsx
packages/renderer/src/components/ui/tooltip.tsx
packages/renderer/src/hooks/use-mobile.ts
packages/renderer/src/index.css
packages/renderer/src/lib/utils.ts
packages/renderer/src/main.tsx
packages/renderer/src/pages/CncAlarmsPage.tsx
packages/renderer/src/pages/DashboardPage.tsx
packages/renderer/src/pages/GrundnerPage.tsx
packages/renderer/src/pages/HistoryPage.tsx
packages/renderer/src/pages/JobsPage.tsx
packages/renderer/src/pages/MachinesPage.tsx
packages/renderer/src/pages/ReadyPage.tsx
packages/renderer/src/pages/RouterPage.tsx
packages/renderer/src/pages/SettingsPage.tsx
packages/renderer/src/pages/SettingsPage.tsx.tmp
packages/renderer/src/pages/TelemetryPage.tsx
packages/renderer/src/pages/Theme.tsx
packages/renderer/src/pages/ThemeShowcase.tsx
packages/renderer/src/setupLogger.ts
packages/renderer/src/shell/alarmUtils.ts
packages/renderer/src/shell/AppLayout.tsx
packages/renderer/src/styles/theme.css
packages/renderer/src/types/global.d.ts
packages/renderer/src/utils/cn.ts
packages/renderer/tailwind.config.ts
packages/renderer/tsconfig.json
packages/renderer/vite.config.ts
packages/settings.json
packages/shared/package.json
packages/shared/src/index.ts
packages/shared/src/ipc.ts
packages/shared/src/result.ts
packages/shared/tsconfig.json
playwright.config.ts
pnpm-workspace.yaml
prettier.config.cjs
settings.json
simulation/import_cnc_stats.py
simulation/README.md
simulation/requirements.txt
simulation/simulate_workflow.py
SQL_Schema.sql
test-results/.last-run.json
tests/e2e/smoke.spec.ts
tests/integration/main-ipc.test.ts
tests/setup/electronMock.ts
tests/tsconfig.json
tests/unit/alarmsRepo.test.ts
tests/unit/alarmUtils.test.ts
tests/unit/config.test.ts
tests/unit/diagnostics.test.ts
tests/unit/ipcErrors.test.ts
tests/unit/ipcResult.test.ts
tests/unit/telemetryParser.test.ts
tests/unit/watchersService.test.ts
tsconfig.base.json
vitest.config.ts

================================================================
Repository Files
================================================================

================
File: .eslintignore
================
node_modules/
packages/**/dist/

================
File: .eslintrc.cjs
================
/* eslint-env node */
module.exports = {
  root: true,
  ignorePatterns: [
    'node_modules/',
    'packages/**/dist/',
  ],
  overrides: [
    {
      files: ['packages/**/*.ts', 'packages/**/*.tsx', 'tests/**/*.ts', 'tests/**/*.tsx'],
      parser: '@typescript-eslint/parser',
      parserOptions: {
        ecmaVersion: 2021,
        sourceType: 'module'
      },
      plugins: ['@typescript-eslint'],
      extends: [
        'eslint:recommended',
        'plugin:@typescript-eslint/recommended'
      ],
      rules: {
        '@typescript-eslint/no-unused-vars': ['warn', { argsIgnorePattern: '^_', varsIgnorePattern: '^_' }],
        '@typescript-eslint/consistent-type-imports': 'warn'
      }
    },
    {
      files: ['packages/renderer/**/*.{ts,tsx}'],
      env: { browser: true },
      plugins: ['react', 'react-hooks'],
      extends: [
        'plugin:react/recommended',
        'plugin:react-hooks/recommended'
      ],
      settings: { react: { version: 'detect' } },
      rules: {
        'react/react-in-jsx-scope': 'off'
      }
    },
    {
      files: ['packages/main/**/*.ts', 'packages/preload/**/*.ts'],
      env: { node: true }
    },
    {
      files: ['tests/**/*.{ts,tsx}'],
      env: { node: true },
      globals: {
        describe: 'readonly',
        it: 'readonly',
        test: 'readonly',
        expect: 'readonly',
        beforeAll: 'readonly',
        beforeEach: 'readonly',
        afterAll: 'readonly',
        afterEach: 'readonly',
        vi: 'readonly',
        page: 'readonly',
        browser: 'readonly',
        context: 'readonly'
      }
    }
  ]
};

================
File: .gitignore
================
node_modules/
packages/*/dist/
*.log
.DS_Store
.env
.vscode/
.github/
.claude/
logs/
resources/hypernest
resources/

================
File: .prettierignore
================
node_modules
pnpm-lock.yaml
packages/*/dist
packages/*/build
packages/*/coverage
dist
coverage
resources/hypernest
*.log

================
File: ccncstats
================
"key"	"api_ip"	"status"
"2025.08.04 12:00:00"	"127.0.0.1"	"NOT READY"
"2025.08.04 11:00:00"	"127.0.0.1"	"NOT READY"
"2025.08.04 10:00:00"	"127.0.0.1"	"READY"
"2025.08.04 09:00:00"	"127.0.0.1"	"READY"
"2025.08.04 08:00:00"	"127.0.0.1"	"READY"
"2025.08.04 07:00:00"	"127.0.0.1"	"READY"
"2025.08.04 06:00:00"	"127.0.0.1"	"READY"
"2025.08.01 17:00:00"	"127.0.0.1"	"READY"
"2025.08.01 16:00:00"	"127.0.0.1"	"READY"
"2025.08.01 15:00:00"	"127.0.0.1"	"READY"
"2025.08.01 14:00:00"	"127.0.0.1"	"READY"
"2025.08.01 13:00:00"	"127.0.0.1"	"READY"
"2025.08.01 12:00:00"	"127.0.0.1"	"B-STOP"
"2025.08.01 11:00:00"	"127.0.0.1"	"B-STOP"
"2025.08.01 10:00:00"	"127.0.0.1"	"B-STOP"
"2025.08.01 08:00:00"	"127.0.0.1"	"NOT READY"
"2025.08.01 07:00:00"	"127.0.0.1"	"NOT READY"
"2025.08.01 06:00:00"	"127.0.0.1"	"NOT READY"
"2025.07.31 17:00:00"	"127.0.0.1"	"B-STOP"
"2025.07.31 16:00:00"	"127.0.0.1"	"B-STOP"

================
File: color-migration.js
================
#!/usr/bin/env node

/**
 * Automated color replacement script
 * Replaces hardcoded Tailwind colors with semantic utility classes
 */

const fs = require('fs');
const path = require('path');
const glob = require('glob');

// Color mapping rules
const replacements = [
  // Status chips
  { pattern: /bg-rose-500(?:\/\d+)?\s+(?:border\s+)?border-rose-\d+(?:\/\d+)?\s+text-rose-\d+/g, replacement: 'chip chip--error' },
  { pattern: /bg-red-500(?:\/\d+)?\s+(?:border\s+)?border-red-\d+(?:\/\d+)?\s+text-red-\d+/g, replacement: 'chip chip--error' },
  { pattern: /bg-emerald-500(?:\/\d+)?\s+(?:border\s+)?border-emerald-\d+(?:\/\d+)?\s+text-emerald-\d+/g, replacement: 'chip chip--success' },
  { pattern: /bg-green-500(?:\/\d+)?\s+(?:border\s+)?border-green-\d+(?:\/\d+)?\s+text-green-\d+/g, replacement: 'chip chip--success' },
  { pattern: /bg-amber-500(?:\/\d+)?\s+(?:border\s+)?border-amber-\d+(?:\/\d+)?\s+text-amber-\d+/g, replacement: 'chip chip--warning' },
  { pattern: /bg-yellow-500(?:\/\d+)?\s+(?:border\s+)?border-yellow-\d+(?:\/\d+)?\s+text-yellow-\d+/g, replacement: 'chip chip--warning' },

  // Individual color replacements
  { pattern: /text-rose-\d+/g, replacement: 'text-destructive' },
  { pattern: /text-red-\d+/g, replacement: 'text-destructive' },
  { pattern: /text-emerald-\d+/g, replacement: 'text-success' },
  { pattern: /text-green-\d+/g, replacement: 'text-success' },
  { pattern: /text-amber-\d+/g, replacement: 'text-warning' },
  { pattern: /text-yellow-\d+/g, replacement: 'text-warning' },

  { pattern: /bg-rose-\d+(?:\/\d+)?/g, replacement: 'bg-surface' },
  { pattern: /bg-red-\d+(?:\/\d+)?/g, replacement: 'bg-surface' },
  { pattern: /bg-white\/10/g, replacement: 'bg-surface' },
  { pattern: /bg-white\/20/g, replacement: 'bg-surface-medium' },
  { pattern: /bg-white\/30/g, replacement: 'bg-surface-strong' },

  // Border colors
  { pattern: /border-rose-\d+(?:\/\d+)?/g, replacement: 'border-light' },
  { pattern: /border-red-\d+(?:\/\d+)?/g, replacement: 'border-light' },
  { pattern: /border-white\/20/g, replacement: 'border-light' },
  { pattern: /border-white\/30/g, replacement: 'border-medium' },
  { pattern: /border-white\/50/g, replacement: 'border-strong' },

  // Text colors
  { pattern: /text-white\/70/g, replacement: 'text-secondary' },
  { pattern: /text-white\/60/g, replacement: 'text-tertiary' },
  { pattern: /text-white\/50/g, replacement: 'text-tertiary' },
  { pattern: /text-white\/40/g, replacement: 'text-disabled' },
  { pattern: /text-white\/35/g, replacement: 'text-disabled' },
  { pattern: /text-white(?!\w)/g, replacement: 'text-primary' },

  // Navigation specific
  { pattern: /hover:bg-white\/10/g, replacement: 'hover:bg-surface' },
  { pattern: /bg-white\/20.*?text-primary/g, replacement: 'nav-link--active' },

  // Buttons
  { pattern: /bg-gradient-to-r\s+from-slate-\d+\s+to-slate-\d+/g, replacement: 'btn btn--primary' },
  { pattern: /bg-white\/20\s+border\s+border-white\/30/g, replacement: 'btn btn--secondary' },
];

// File patterns to process
const filePatterns = [
  'packages/renderer/src/**/*.tsx',
  'packages/renderer/src/**/*.ts'
];

function processFile(filePath) {
  console.log(`Processing: ${filePath}`);

  let content = fs.readFileSync(filePath, 'utf8');
  let changed = false;

  replacements.forEach(({ pattern, replacement }) => {
    if (pattern.test(content)) {
      content = content.replace(pattern, replacement);
      changed = true;
    }
  });

  if (changed) {
    fs.writeFileSync(filePath, content);
    console.log(`  ✓ Updated ${filePath}`);
  } else {
    console.log(`  - No changes needed for ${filePath}`);
  }
}

function main() {
  console.log('🎨 Starting automated color migration...\n');

  filePatterns.forEach(pattern => {
    const files = glob.sync(pattern, {
      cwd: __dirname,
      absolute: true
    });

    files.forEach(processFile);
  });

  console.log('\n✨ Color migration complete!');
  console.log('\nNext steps:');
  console.log('1. Review the changes');
  console.log('2. Test the application');
  console.log('3. Make manual adjustments if needed');
}

// Check if glob is available
try {
  require.resolve('glob');
  main();
} catch (e) {
  console.log('Installing glob dependency...');
  const { execSync } = require('child_process');
  execSync('npm install glob', { stdio: 'inherit' });
  main();
}

================
File: docs/ARCHITECTURE.md
================
## Architecture: Main, Preload, Renderer (Beginner Lesson)

This document explains how the app is organized and how data flows.

### High‑Level
- Main (Node) controls windows, OS access, file IO, watchers, and DB.
- Renderer (React) displays UI and calls `window.api.*` for work.
- Preload is the safe bridge that defines `window.api`.

### Where Code Lives
- Main: `packages/main/src`
  - IPC registration: `packages/main/src/ipc/*`
  - Services: `packages/main/src/services/*` (worklist, ingest, diagnostics, etc.)
  - Repos/DB access: `packages/main/src/repo/*`
  - Background watchers worker: `packages/main/src/workers/watchersWorker.ts`
- Preload: `packages/preload/src/index.ts` (exposes `window.api`)
- Renderer: `packages/renderer/src` (pages, layout, styling)

### The Request/Response Pattern
1) Renderer calls `window.api.jobs.list(req)` (typed request)
2) Preload forwards to Main with `ipcRenderer.invoke('jobs:list', req)`
3) Main registered a handler with `registerResultHandler('jobs:list', ...)`
4) Main returns `{ ok, value | error }` envelope (neverthrow‑style ergonomic result)
5) Renderer renders the response

### Subscriptions (push from Main)
Some features stream updates (DB status, Ready‑To‑Run folder):
- Renderer subscribes → Preload attaches an IPC `on(channel)` listener
- Main sends updates with `contents.send('channel', payload)`
- Renderer unsubscribes on unmount; Main cleans up listeners

### Worker Threads
`watchersWorker.ts` runs background watchers (AutoPAC CSVs, Nestpick outputs) and telemetry sockets. It posts events back to Main over Node worker messaging, and Main forwards status into Diagnostics.

### Why the Bridge (Preload)?
- Security: Renderer doesn’t get Node APIs directly
- DX: A single `window.api` surface is easy to reason about and type

================
File: docs/CODEBASE_AUDIT.md
================
# Codebase Audit Report

Date: 2025-10-02
Repo: electron_port/electron

This report summarizes a comprehensive review of the Electron + TypeScript + React monorepo, covering architecture, security posture, correctness, tooling, performance, DX, and packaging. It includes concrete file references and prioritized actions.

## Executive Summary

- Overall architecture is solid: sandboxed renderer, contextIsolation, typed IPC, repository layout (main, preload, renderer, shared) is clean, and diagnostics/logging subsystems are thoughtful.
- Critical items: TypeScript config inconsistency causes typecheck failure; a few UI bugs (undefined icon import, garbled placeholder strings) and ESLint errors should be fixed; Electron hardening has one notable relaxation (`allow-file-access-from-files`).
- Security posture is decent with CSP and navigation guards, but consider tightening file scheme access, and be cautious with the separate Hypernest window’s relaxed CSP.
- Build/test tooling is good (pnpm, Vitest, Playwright) but typechecking fails and BrowserRouter usage may break packaged navigation.

## High-Priority Findings (P1)

- TypeScript typecheck fails in preload due to incompatible `moduleResolution: bundler` with `module: CommonJS`.
  - Evidence: `tsconfig.base.json:1` sets `"module": "CommonJS"` and `"moduleResolution": "bundler"`; `packages/preload/tsconfig.json:4` inherits CommonJS.
  - Repro: `pnpm -w typecheck` ? TS5095 in preload.
  - Recommendation: Either set root `module` to `ESNext` to use `bundler`, or override preload/main to `moduleResolution: node` (keep CJS), leaving renderer on `bundler`/`ESNext`.

- UI bug: Undefined icon component in Jobs page.
  - Evidence: `packages/renderer/src/pages/JobsPage.tsx:860` uses `<RefreshCw />` but it’s not imported; ESLint error (`react/jsx-no-undef`).
  - Fix: Add `RefreshCw` import from `lucide-react` or replace with existing icon.

- Garbled placeholder strings in AppLayout helpers.
  - Evidence: `packages/renderer/src/shell/AppLayout.tsx:13` and `:26` return `GA????A?A` for empty values (likely paste/encoding artifact).
  - Risk: User-visible garbage; a11y/readability issue.
  - Fix: Replace with safe, readable placeholders (e.g., `"-"`).

- Electron hardening: Global `allow-file-access-from-files` reduces file:// isolation.
  - Evidence: `packages/main/src/main.ts:21` appends `allow-file-access-from-files` at process level.
  - Risk: If the renderer is compromised (XSS), it can fetch arbitrary `file://` paths (still sandboxed, but leaks local content).
  - Mitigation: Remove the global switch and gate local file access via main-process IPC; if truly required for Hypernest, scope to that window only and consider a constrained scheme handler.

- Router choice in renderer: `createBrowserRouter` may break in packaged apps.
  - Evidence: `packages/renderer/src/main.tsx:3` uses BrowserRouter; packaged Electron loads `file://.../index.html` and History API deep links often 404.
  - Fix: Use `HashRouter` or `MemoryRouter` for packaged builds; keep `BrowserRouter` in dev via env flag.

## Security Review

- Electron WebPreferences (good):
  - `contextIsolation: true`, `sandbox: true`, `nodeIntegration: false` for main window; similarly for Hypernest window. `packages/main/src/main.ts:28-35`, `packages/main/src/ipc/hypernest.ts:42-51`.
- CSP:
  - Main app CSP set via `onHeadersReceived` with development relaxations (`'unsafe-inline'`, `'unsafe-eval'` only in dev): `packages/main/src/security.ts`.
  - Hypernest window uses a separate persistent session with a relaxed CSP allowing external CDNs and inline scripts: `packages/main/src/ipc/hypernest.ts:66-99`.
    - Keep it isolated (already using `partition: 'persist:hypernest'`); verify it never loads untrusted content.
- Navigation guards:
  - Internal navigation restricted; external navigations intercepted and either opened via `shell.openExternal` or blocked; allowed protocols limited to `https:`, `mailto:`, `tel:` and a small origin allowlist; see `packages/main/src/security.ts`.
- File scheme access:
  - Global `allow-file-access-from-files` increases risk; see P1 above.
- IPC surface:
  - Preload exposes a narrow, typed API returning result envelopes and validates inputs with zod on the main side (e.g., `ReadyImportReq`, `ThemePreferenceReq`): `packages/preload/src/index.ts`, `packages/main/src/ipc/*.ts`.
  - Log tailing and file listing are guarded against path traversal by comparing against known log directory and explicit allowlist: `packages/main/src/services/diagnostics.ts`.
- Secrets / credentials:
  - DB password stored in `settings.json` under `userData` (packaged) or repo root (dev). Consider supporting OS credential storage and masking in UI. `packages/main/src/services/config.ts`.
- Network / SSRF:
  - Limited: watchers and CNC telemetry use local filesystem and network (via `net`), but no arbitrary URL fetching from untrusted input was found.

## Correctness & Bugs

- Jobs page icon import missing.
  - `packages/renderer/src/pages/JobsPage.tsx:860` — `<RefreshCw />` undefined.

- Garbled strings in helpers.
  - `packages/renderer/src/shell/AppLayout.tsx:13,26` — return unreadable placeholder strings.

- ESLint errors and warnings (selection):
  - Empty blocks, `any` usage, and unused vars flagged in multiple files.
    - Example: `packages/main/src/ipc/files.ts:92,150` empty blocks; `:112-113` `any` casts.
    - `packages/main/src/workers/watchersWorker.ts:529,685` empty blocks; `:650` `any` type; several let?const suggestions.
    - `packages/renderer/src/components/ui/sidebar.tsx:50-51` `as any` to set CSS vars.
  - Run: `pnpm -w lint` (15 errors, 25 warnings observed).

- Minor UI polish:
  - Some headings and titles may be inconsistent (e.g., Router/Dashboard label seen during partial inspection). Review page titles for consistency.

## Build, Tooling, and Config

- TypeScript config mismatch (P1): `moduleResolution: bundler` with `module: CommonJS` at root breaks preload typechecking. See P1.
  - Suggested split:
    - Root: Prefer `module: ESNext`, `moduleResolution: bundler`.
    - Main/Preload tsconfigs: override to `module: CommonJS`, `moduleResolution: node` for Node/Electron contexts.
    - Renderer tsconfig: keep `module: ESNext`, `moduleResolution: bundler`.

- Linting and formatting:
  - ESLint and Prettier are configured; running `pnpm lint:fix` will repair some issues. Tighten rules if desired (e.g., forbid `any` in production code paths).

- Testing:
  - Unit/integration tests use Vitest and pg-mem; E2E uses Playwright against Vite dev server. Consider adding packaged-app E2E to validate router strategy and window hardening.

## Performance & Reliability

- Watchers worker:
  - Work is delegated to a Worker thread; good for keeping main thread responsive. The code includes backoff, stability checks for files, and hashing; review chokidar globs to ensure they do not watch unnecessary paths.

- DB watchdog:
  - Periodic ping with latency tracking and pool reset on failure: `packages/main/src/services/dbWatchdog.ts`. Consider jittering the interval slightly to avoid alignment with other periodic tasks.

- Logging:
  - Pino with daytime-rotated files and retention pruning; console stream pretty-prints via a custom writable. Reasonable defaults with env overrides (`WOODTRON_LOG_DIR`, `WOODTRON_LOG_RETENTION`).

## Developer Experience (DX)

- Diagnostics UI is robust and helpful (log tailing, machine health, watcher status).
- Shared types via zod improve IPC correctness.
- Consider adding a few codemods:
  - eliminate explicit `as any` (CSS var assignment can be wrapped in a helper that provides typed style props),
  - ensure all icons/components are imported consistently.

## Packaging & Distribution

- `electron-builder.yml` is minimal, with a placeholder updates URL. If updates are expected, integrate a real provider (or disable publish config until ready). Ensure CSP and router selection are compatible with packaged `file://` deployment.

## Recommended Actions (Prioritized)

1) Fix typechecking configuration
- Change root `tsconfig.base.json` to `module: "ESNext"` (or remove `moduleResolution: "bundler"` at root) and explicitly set `moduleResolution: "node"` in `packages/main` and `packages/preload` tsconfigs.
- Re-run `pnpm -w typecheck` until clean.

2) Address ESLint errors and key warnings
- Import `RefreshCw` in `packages/renderer/src/pages/JobsPage.tsx:860`.
- Replace garbled strings in `packages/renderer/src/shell/AppLayout.tsx:13,26`.
- Remove empty blocks and `any` casts where flagged (e.g., `packages/main/src/ipc/files.ts`, `packages/main/src/workers/watchersWorker.ts`).

3) Electron hardening
- Remove global `allow-file-access-from-files`. If Hypernest requires file access, consider scoping a custom protocol or using targeted IPC.
- Confirm CSP is applied for `file://` loads as intended; otherwise, consider templating meta CSP for app pages.

4) Router strategy for packaged app
- Swap to `HashRouter`/`MemoryRouter` in packaged builds or add a custom file protocol handler to emulate proper history routing.

5) Secrets handling
- Offer an option to store DB credentials via OS keychain and redact/mask password in settings UI. At minimum, ensure the settings file path and permissions are safe by default.

6) Tests
- Add a packaged app smoke test (window launches, navigation works under `file://`, main security flags verified) and a quick security harness (validate `webPreferences`, CSP, navigation guards).

7) Polish and DX
- Replace ASCII control characters used as sort indicators with accessible icons or arrows in `GlobalTable`.
- Encapsulate CSS variable assignment to avoid `any` casts in `SidebarProvider`.

## File References

- packages/preload/tsconfig.json:1
- tsconfig.base.json:1
- packages/renderer/src/pages/JobsPage.tsx:860
- packages/renderer/src/shell/AppLayout.tsx:13
- packages/renderer/src/shell/AppLayout.tsx:26
- packages/main/src/main.ts:21
- packages/main/src/security.ts:1
- packages/main/src/ipc/hypernest.ts:42
- packages/main/src/ipc/hypernest.ts:66
- packages/preload/src/index.ts:1
- packages/main/src/ipc/files.ts:92
- packages/main/src/ipc/files.ts:112
- packages/main/src/ipc/files.ts:113
- packages/main/src/workers/watchersWorker.ts:529
- packages/main/src/workers/watchersWorker.ts:685
- packages/renderer/src/components/ui/sidebar.tsx:50
- packages/renderer/src/components/ui/sidebar.tsx:51
- packages/renderer/src/main.tsx:3
- packages/main/src/services/diagnostics.ts:199

## Notes

- Lint summary at the time of audit: 15 errors, 25 warnings (`pnpm -w lint`).
- Typecheck failed in preload with TS5095 (`pnpm -w typecheck`).
- No AGENTS.md files were found.

================
File: docs/INTRODUCTION.md
================
## Welcome: Electron + TypeScript + Tailwind (Beginner Lesson)

This project is an Electron desktop app written in TypeScript with a Tailwind-assisted UI. If you are brand new to Electron or desktop development, start here.

### What Electron Is (and is not)
- Electron lets you build desktop apps using web technologies (HTML, CSS, JavaScript).
- It bundles two major pieces: Chromium (for the UI) and Node.js (for system access).
- Your code runs in separate processes that talk over a bridge called IPC.
- Electron is not a browser and not a web server; it is a desktop runtime that ships with your app.

### Big Picture: Main, Preload, Renderer
- Main process (Node.js): Starts your app, creates windows, talks to the OS, reads files, and owns powerful APIs.
- Renderer process (Chromium): Runs your UI (e.g., React). It is like a browser tab for your app window.
- Preload script (bridge): Runs before the Renderer loads. It safely exposes a small, controlled API (`window.api`) so your UI can ask Main to do work.

---

## Deep Dive: The Key Components (Beginner Friendly)

### What is Node.js?
- Node.js is a JavaScript runtime built on the V8 engine (the same engine used by Chrome). It lets JavaScript run outside the browser.
- It provides access to the filesystem, network, processes, and many operating system features.
- In Electron, the Main process is a Node.js process. That is why the Main can read files, spawn processes, and manage windows.
- Why it matters: Your Renderer (UI) should avoid direct system access. Instead, ask the Main process (Node.js) to do privileged work through IPC. This separation keeps your app safer and easier to reason about.

### What is Chromium?
- Chromium is an open-source browser engine (the core of Google Chrome). Electron embeds Chromium to render your app's UI.
- It understands HTML, CSS, and modern Web APIs, and it gives you familiar tools like DevTools for debugging.
- Every BrowserWindow in Electron is effectively a Chromium-powered page dedicated to your app.

### What is a Renderer?
- A Renderer process is a Chromium page that displays and updates your UI.
- It runs your front-end code (e.g., React, plain JS) and handles user interactions.
- By default (with context isolation enabled), it does NOT have direct access to Node.js or the filesystem. That's on purpose for security.
- If the UI needs data from disk or needs to perform an OS-level task, it asks the Main process via the Preload bridge and IPC.

### What is the Main process?
- The Main process is the 'brain' of an Electron app. It runs first, creates windows, registers IPC handlers, and can call OS APIs.
- It decides when to show a window, what preload script to load, and how to respond to requests from the UI.
- Treat it like a backend that lives inside your desktop app.

### What is the Preload script?
- The Preload script runs in a special, isolated context that can see both the Renderer and limited Electron APIs (e.g., `ipcRenderer`, `contextBridge`).
- Its job is to expose a safe, minimal API into the Renderer with `contextBridge.exposeInMainWorld()`.
- Example: expose `window.api.readTextFile(path)` that internally calls the Main process to actually read from disk.
- The Preload keeps your UI safe by not leaking Node.js or powerful APIs directly into the page.

### What is IPC (Inter-Process Communication)?
- IPC is how the Main and Renderer processes send messages to each other.
- Think of it as a request/response pipeline and event stream between UI and backend.
- Common patterns you will use:
  - Request/response (recommended): Renderer calls `ipcRenderer.invoke(channel, request)`; Main handles with `ipcMain.handle(channel, handler)` and returns a result.
  - One-way events: Renderer sends `ipcRenderer.send(channel, payload)`; Main listens with `ipcMain.on(channel, listener)` (and vice versa with `webContents.send`).
- Why IPC exists: Main and Renderer run in separate processes for stability and security. They must communicate by sending messages, not by sharing memory or direct references.
- Safety first:
  - Only expose the minimum set of channels and functions your UI needs.
  - Validate and sanitize all data in Main before using it (never trust the Renderer input blindly).
  - Keep Node integration disabled in the Renderer; use Preload and `contextIsolation: true`.

---

## How Everything Works Together (Lifecycle)
- App starts: Electron launches the Main process (Node.js).
- Main creates a `BrowserWindow` and points it at your UI's HTML/URL.
- Main attaches a Preload script to that window.
- Preload runs before the page loads and exposes `window.api`.
- Renderer loads and can now call `window.api.*` to request work from Main via IPC.
- Main performs privileged work (file I/O, OS calls), returns results, and Renderer updates the UI.

---

## Example: A Tiny IPC Call

Below is a minimal, end-to-end example you can compare with this repo's structure. The idea: the UI asks for the app version.

- Main (Node): register a handler
```
// main.ts
import { app, ipcMain } from 'electron'

ipcMain.handle('app:getVersion', async () => {
  return app.getVersion()
})
```

- Preload (bridge): expose a safe function
```
// preload.ts
import { contextBridge, ipcRenderer } from 'electron'

contextBridge.exposeInMainWorld('api', {
  getAppVersion: () => ipcRenderer.invoke('app:getVersion')
})
```

- Renderer (UI): call the exposed API
```
// renderer.tsx
const version = await window.api.getAppVersion()
console.log('App version:', version)
```

Key points:
- Renderer never touches Node APIs directly.
- Preload exposes a single, typed surface (`window.api`).
- Main owns the privileged logic and returns results.

---

## Project Layout in This Repo
- Main: `packages/main/src` (creates windows, registers IPC handlers, services)
- Preload: `packages/preload/src/index.ts` (exposes `window.api`)
- Renderer: `packages/renderer/src` (React UI and styling)

## TypeScript in This Project
- TypeScript adds types to JavaScript to catch mistakes early.
- It improves autocomplete, refactoring, and cross-file consistency.
- In Electron, it's especially helpful to keep IPC request/response types aligned between Main, Preload, and Renderer.

## Tailwind CSS in This Project
- Tailwind is a utility-first CSS framework (e.g., `px-2`, `rounded`, `text-sm`).
- It helps you style quickly without writing lots of custom CSS.
- This repo uses a small set of custom variables/utilities for theming and glass effects.

## Security Basics (Must-Know)
- Keep `contextIsolation: true` and do not enable `nodeIntegration` in the Renderer.
- Expose only what you need via Preload; avoid dumping Node APIs into `window`.
- Validate all IPC inputs in Main and prefer `ipcMain.handle`/`ipcRenderer.invoke` for clear request/response flows.

## Glossary
- Main process: Node.js runtime managing the app and windows.
- Renderer process: Chromium page that runs your UI.
- Preload: a small script that exposes a safe API from Main to Renderer.
- IPC: Inter-Process Communication (messages between Main and Renderer).
- ContextIsolation: Electron setting that isolates the Renderer from Node.

## Next Steps
- Read `docs/ARCHITECTURE.md` for a deeper tour of how code is organized.
- Read `docs/IPC.md` for more IPC patterns (requests, subscriptions, streaming).
- Read `docs/STYLING.md` to see how Tailwind and theming work here.

================
File: docs/IPC.md
================
## IPC Guide: Calling Main From Renderer (Beginner Lesson)

IPC (Inter‑Process Communication) is how the React UI (Renderer) asks the Node side (Main) to do work. This project uses a consistent, type‑safe pattern.

### The Pattern
1) Preload defines `window.api.*` methods that wrap `ipcRenderer.invoke(channel, args...)`
2) Main registers `registerResultHandler(channel, handler)` that returns `{ ok, value | error }`
3) Renderer calls `await window.api.something.method(args)` and gets an envelope back

### Typed Result Envelope
Every call resolves to `{ ok: true, value }` or `{ ok: false, error }` so the UI never deals with thrown exceptions across the boundary.

### Example: Listing Router Jobs (DB View)
- Renderer: `window.api.router.list({ limit, machineId?, statusIn? })`
- Preload: wires `router:list`
- Main: `packages/main/src/ipc/router.ts` calls into `routerRepo.listMachineJobs`

### Example: Ready‑To‑Run Files (Filesystem View)
- Renderer: `window.api.files.listReady(machineId)`
- Main: `packages/main/src/ipc/files.ts` walks the machine’s folder and enriches each `.nc` with DB details

### Push Updates (Subscriptions)
Some features push data from Main to Renderer over channels:
- DB status: `db:status:update`
- Diagnostics: `diagnostics:update`
- Ready‑To‑Run files: `files:ready:update`

Flow:
1) Renderer subscribes → Preload attaches `.on(channel, handler)` and sends a subscribe request
2) Main keeps a map of subscribers (by `WebContents.id`) and `.send(...)`s updates
3) Renderer unsubscribes → Main removes listeners and cleans up

### Good Practices
- Don’t pass DOM objects or class instances over IPC; send plain data
- Always handle `{ ok: false, error }` in the UI to inform the user
- Unsubscribe on unmount to avoid leaks

================
File: docs/JOB-FLOW.md
================
# Job Processing Flow

Quick reference for how jobs move through the system from ingestion to completion.

## Flow Diagram

```
1. PENDING       → Job ingested from processedJobsRoot folder
                   (ingest.ts scans .nc files, reads metadata)

2. STAGED        → Operator adds job to worklist for a machine
                   (worklist.ts copies files to machine's ap_jobfolder)

3. LOAD_FINISH   → AutoPAC signals material loaded
                   (load_finish<machine>.csv → autoPacCsvDir)

4. LABEL_FINISH  → AutoPAC signals labeling complete
                   (label_finish<machine>.csv → autoPacCsvDir)

5. CNC_FINISH    → AutoPAC signals CNC cutting complete
                   (cnc_finish<machine>.csv → autoPacCsvDir)
                   → Auto-forwards CSV to Nestpick folder

6. FORWARDED_TO_NESTPICK → CSV written to Nestpick.csv
                           (watchersWorker forwards parts CSV)

7. NESTPICK_COMPLETE → Nestpick writes "processed" CSV
                       (nestpickFolder/processed/*.csv detected)
```

## File Structure Requirements

### 1. Ingestion (PENDING)
**Location**: `processedJobsRoot` (configured in Settings)

**Structure**:
```
processedJobsRoot/
  └─ JobFolderName/
      ├─ JobName.nc        (required - CNC program)
      ├─ JobName.lpt       (optional - Planit label file)
      ├─ JobName.pts       (optional - Alphacam parts file)
      ├─ JobName.csv       (optional - per-file parts CSV)
      ├─ RJT.csv           (optional - Planit family CSV, first 3 chars)
      └─ images/           (optional - .bmp, .jpg, .jpeg files)
```

**Metadata Extracted** from `.nc` file:
- `ID=<material>` → material field
- `G100 X<x> Y<y> Z<z>` → size (XxY), thickness (Z)
- Parts count from `.lpt` or `.pts` file

### 2. Staging (STAGED)
**Trigger**: Operator clicks "Add To Worklist" in Jobs page

**Destination**: Machine's `ap_jobfolder` (e.g., `\\Machine1\ReadyToRun`)

**Files Copied**:
- **Always**: `.nc`, `.lpt`, `.pts`, exact-match `.csv` (JobName.csv)
- **Planit mode** (has `.lpt`, no `.pts`): Also copy family CSV (`RJT.csv`)
- **Alphacam mode** (has `.pts`): Copy all `JobName*.bmp|jpg|jpeg`
- **Images**: Resolved via Planit family CSV or Alphacam wildcard

**CSV Rules**:
- `JobName.csv` = per-file parts CSV (forwarded to Nestpick later)
- `RJT.csv` = family CSV (first 3 letters, Planit only, for image mapping)

### 3. Processing Events (LOAD_FINISH, LABEL_FINISH, CNC_FINISH)
**Location**: `autoPacCsvDir` (configured in Settings)

**File Naming** (strict):
- `load_finish<machine>.csv`
- `label_finish<machine>.csv`
- `cnc_finish<machine>.csv`

Where `<machine>` = machine name or ID (e.g., `load_finish_Machine1.csv` or `load_finish_1.csv`)

**CSV Format**:
```csv
JobName1
JobName2
Machine1
```
- First column = NC base name (with or without `.nc` extension)
- CSV must contain matching machine identifier somewhere in content

**Processing**:
- Watcher detects file in `autoPacCsvDir`
- Updates job status to `LOAD_FINISH`, `LABEL_FINISH`, or `CNC_FINISH`
- On `CNC_FINISH`: Auto-forwards parts CSV to Nestpick folder
- Deletes source CSV after successful processing

### 4. Nestpick Forwarding (FORWARDED_TO_NESTPICK)
**Automatic** after `CNC_FINISH` if machine has Nestpick enabled

**Process**:
1. Finds `JobName.csv` in staged folder (`ap_jobfolder/JobFolderName/`)
2. Rewrites CSV with machine columns (destination=99, source=machineId)
3. Waits for `Nestpick.csv` slot to be available (5min timeout)
4. Writes to `machine.nestpickFolder/Nestpick.csv`
5. Deletes source CSV from staged folder

### 5. Nestpick Completion (NESTPICK_COMPLETE)
**Location**: `machine.nestpickFolder/processed/`

**Trigger**: Watcher detects any `.csv` file in processed folder

**Processing**:
- Reads CSV, extracts NC base names
- Updates job status to `NESTPICK_COMPLETE`
- Archives CSV to `machine.nestpickFolder/archive/`

### 6. Pallet Assignment (Optional)
**Location**: `machine.nestpickFolder/Report_FullNestpickUnstack.csv`

**Format**:
```csv
JobName,SourcePlace,Dest,...
RJT123,Pallet_A05,...
```
- Column 0 = Job name
- Column 1 = Pallet (e.g., `Pallet_A05`)

**Processing**:
- Updates `pallet` field on job record
- Archives CSV after processing

## Status Transitions

**Allowed Transitions** (enforced in `jobsRepo.ts`):
- `PENDING` → `PENDING` only (reingestion)
- `STAGED` → from `PENDING`, `STAGED`
- `LOAD_FINISH` → from `PENDING`, `STAGED`, `LOAD_FINISH`
- `LABEL_FINISH` → from `STAGED`, `LOAD_FINISH`, `LABEL_FINISH`
- `CNC_FINISH` → from `STAGED`, `LOAD_FINISH`, `LABEL_FINISH`, `CNC_FINISH`
- `FORWARDED_TO_NESTPICK` → from `CNC_FINISH`, `FORWARDED_TO_NESTPICK`
- `NESTPICK_COMPLETE` → from `FORWARDED_TO_NESTPICK`, `NESTPICK_COMPLETE`

Invalid transitions are rejected (e.g., cannot jump from `PENDING` to `CNC_FINISH`).

## Key Configuration Paths

Set these in **Settings** page:

| Setting | Purpose | Example |
|---------|---------|---------|
| `processedJobsRoot` | Source folder for job ingestion | `C:\Jobs\Processed` |
| `autoPacCsvDir` | Where AutoPAC writes status CSVs | `C:\AutoPAC\CSV` |
| `machines[].apJobfolder` | Machine's ready-to-run folder | `\\Machine1\ReadyToRun` |
| `machines[].nestpickFolder` | Nestpick input/output folder | `\\Machine1\Nestpick` |
| `machines[].nestpickEnabled` | Enable Nestpick forwarding | `true` |

## Quick Troubleshooting

**Job stuck in PENDING?**
- Check if `processedJobsRoot` is set and folder exists
- Verify `.nc` file is present
- Check Diagnostics panel for watcher errors

**Job not staging?**
- Verify `ap_jobfolder` is accessible (network share permissions)
- Check for folder name collisions (timestamped folders created automatically)

**AutoPAC CSV not processing?**
- File must be named `load_finish<machine>.csv` (exact format)
- CSV must contain machine identifier in content
- Check `autoPacCsvDir` setting and file permissions

**Nestpick not forwarding?**
- Machine must have `nestpickEnabled=true`
- `nestpickFolder` must be set and accessible
- `JobName.csv` must exist in staged folder
- Check for `Nestpick.csv` lock/busy timeout (5min)

**Nestpick completion not detected?**
- Check watcher is running (Diagnostics panel)
- Verify files appear in `nestpickFolder/processed/`
- CSV must contain recognizable NC base names

================
File: docs/PROJECT_STRUCTURE.md
================
## Project Structure (Beginner Lesson)

This guide introduces how the repository is laid out and what each part does. It’s aimed at someone new to Electron, web dev, and TypeScript.

### Big Picture

The repo is a monorepo with separate packages for the Electron Main process, the Preload bridge, the Renderer UI, and shared types. You will mostly touch the Renderer (UI) and sometimes Preload/Main for new features.

### Top‑Level Files and Folders

- package.json — workspace metadata
- pnpm‑workspace.yaml — tells pnpm which folders are in the workspace
- docs/ — developer docs (start with INTRODUCTION.md)
- packages/
  - main/ — Electron Main process (Node side)
  - preload/ — the secure bridge exposing `window.api` to the UI
  - renderer/ — the React + Tailwind UI (Chromium side)
  - shared/ — shared TypeScript types and IPC schemas
- resources/ — app resources (e.g., static bundles used by features)
- tests/ — unit and integration tests

### The Four Packages

1) packages/main (Electron Main)
- Entry: `packages/main/src/main.ts` — creates the BrowserWindow and initializes app services
- IPC handlers: `packages/main/src/ipc/*.ts` — define what Main can do on request
- Services: `packages/main/src/services/*.ts` — business logic (worklist, ingest, diagnostics, etc.)
- Repo (DB): `packages/main/src/repo/*.ts` — DB queries and lifecycle transitions
- Workers: `packages/main/src/workers/watchersWorker.ts` — background watchers (AutoPAC, Nestpick, telemetry)
- Security/Logger: `packages/main/src/security.ts`, `packages/main/src/logger.ts`

2) packages/preload (Bridge)
- `packages/preload/src/index.ts` defines `window.api` using `contextBridge.exposeInMainWorld`
- Each method wraps `ipcRenderer.invoke(channel, args)` and returns a typed `{ ok, value | error }` envelope
- This keeps Renderer safe (no raw Node access) and strongly typed

3) packages/renderer (UI)
- Pages live in `packages/renderer/src/pages/*.tsx` (e.g., JobsPage, RouterPage)
- Shell layout: `packages/renderer/src/shell/AppLayout.tsx` (nav, header, theme application)
- Styling: `packages/renderer/src/index.css` (CSS variables + a few custom utilities) and Tailwind config
- Renderer calls `window.api.*` to talk to Main; renders results with React

4) packages/shared (Types)
- IPC schemas and types: `packages/shared/src/ipc.ts`
- Result envelope helpers: `packages/shared/src/result.ts`
- Shared enums and Zod schemas keep Main/Renderer in sync

### Typical Feature Flow (Add a new IPC)

1) Define the request/response types in `packages/shared/src/ipc.ts`
   - e.g., `MyFeatureReq`, `MyFeatureRes`, and add to `window.api` typings if needed

2) Implement the handler in Main under `packages/main/src/ipc/myFeature.ts`
   - Use `registerResultHandler('myFeature:doThing', async (_e, req) => ok(value))`
   - Put heavy logic in a `packages/main/src/services/*.ts` file

3) Expose it in Preload (`packages/preload/src/index.ts`)
   - Add `myFeature: { doThing: (req) => invokeResult('myFeature:doThing', req) }`

4) Call it from the Renderer
   - `const res = await window.api.myFeature.doThing(req)` and render `res.value` or show `res.error`

5) (Optional) Add a streaming update (subscription)
   - Main: `contents.send('myFeature:update', payload)` to push
   - Preload: helper subscribe/unsubscribe wrappers
   - Renderer: attach/detach listeners on mount/unmount

### Styling and Theming

Read `docs/STYLING.md`. In short:
- CSS variables on `:root` define color tokens and table font size
- Glass (frosted) panels are controllable per section (cards/nav/header) with presets
- Settings page updates localStorage and applies CSS variables immediately

### File Watchers & Job Flow

Read `docs/WATCHERS.md` and `docs/WORKLIST.md` for how AutoPAC CSVs and Worklist staging operate, including Nestpick forwarding.

### Tests

- `tests/unit/` — fast tests for small pieces
- `tests/integration/` — orchestrated tests across IPC/services
- You can follow existing tests to see usage patterns of IPC and services

### Running & Building (general guidance)

- Dev servers and scripts are defined in the root `package.json`
- Typical tasks:
  - Start UI/Main in dev mode (depends on project scripts)
  - Build main and renderer bundles for production
- Check existing scripts (without running anything you don’t intend to) to learn the flow

### Conventions to Follow

- Keep Main thin; put logic in `services/` and `repo/`
- Only expose safe, typed functions via Preload
- Renderer never uses Node APIs directly; use `window.api`
- Use the result envelope `{ ok, value | error }` and handle errors
- For subscriptions, always unsubscribe on unmount
- Use existing CSS variables and classes; extend via `docs/STYLING.md`

### Where to Start Reading Code

1) `packages/renderer/src/shell/AppLayout.tsx` — app structure & theme application
2) `packages/renderer/src/pages/JobsPage.tsx` — typical list+filters+IPC
3) `packages/preload/src/index.ts` — see what `window.api` contains
4) `packages/main/src/ipc/*` — IPC handlers and their services
5) `packages/shared/src/ipc.ts` — the shape of all IPC requests/responses

As you make changes, keep the flow in mind: Renderer (React) → Preload (`window.api`) → Main (IPC) → Service/Repo logic → back to Renderer.

================
File: docs/stock_request.csv
================
0
!E

================
File: docs/stock.csv
================
type_data,customer_id,NA,length_mm,width_mm,thickness_mm,NA,stock,stock_available,NA,NA,NA,NA,NA,NA,reserved_stock,NA,NA,NA

================
File: docs/STYLING.md
================
Styling Guide (Themes & Tokens)

Overview
- One global theme file controls all colors: `packages/renderer/src/styles/theme.css`.
- Exactly three themes are supported: light (default), dark (`.dark`), and modern (`.modern`).
- All colors are hex values so you can edit them directly.
- Tailwind is wired to CSS variables, so utility classes like `bg-primary-600` still work.

Where To Edit Colors
- File: `packages/renderer/src/styles/theme.css`
- Scopes:
  - `:root` → light
  - `.dark` → dark
  - `.modern` → modern
- Change semantic tokens to update the whole app:
  - `--background`, `--foreground`, `--card`, `--border`, `--input`, `--ring`
  - `--primary`, `--secondary`, `--muted`, `--accent`, `--destructive`
  - Table tokens: `--table-bg`, `--table-header-bg`, `--table-text`
- Adjust full color scales if needed (for Tailwind shades):
  - `--primary-50…950`, `--secondary-50…900`, `--neutral-50…950`
  - Status: `--success-*`, `--warning-*`, `--error-*`

Alpha/Transparency
- Use 8‑digit hex variables already defined in `theme.css` (no HSL triplets):
  - Example: `--muted-a50` (50%), `--primary-a20` (20%), `--border-a10` (10%).
- If you need a new transparency, add a new token, e.g. `--accent-a15: #RRGGBB26`.

Using Colors In Code
- Prefer Tailwind with variables:
  - Backgrounds: `bg-[var(--table-bg)]`, `bg-primary-600`, `bg-card`
  - Text: `text-[var(--table-text)]`, `text-primary-foreground`, `text-muted-foreground`
  - Borders: `border-border`, arbitrary: `border-[var(--border-a30)]`
- Avoid hardcoded `#hex` or `rgb(...)` in TSX/CSS. If needed for special effects, add a new `--fx-*` token to `theme.css` and reference it.

Theme Switching
- Theme is applied by adding a class to `<html>` (`document.documentElement`):
  - Light: no class (default)
  - Dark: `.dark`
  - Modern: `.modern`
- Code: `packages/renderer/src/shell/AppLayout.tsx` manages applying these classes based on user preference.

Glass and Effects
- `.glass-card` is supported and uses the theme’s alpha tokens for subtle blur/opacity.
- If you need different tints in effects, update the `--fx-*` tokens in `theme.css`.

Do’s and Don’ts
- Do: change only variables in `theme.css` to recolor the app.
- Do: use Tailwind classes that map to variables.
- Don’t: add new hex/hsl literals directly in components.
- Don’t: reintroduce per-component color definitions.

Adding Another Theme (optional)
- Create a new scope in `theme.css` like `[data-theme="brandx"] { ... }`.
- Copy the semantic tokens from `:root`, then change the hex values.
- Toggle it by setting `document.documentElement.dataset.theme = 'brandx'`.

================
File: docs/WATCHERS.md
================
## File Watchers, AutoPAC, and Nestpick (Beginner Lesson)

This app watches machine folders and CSVs to update job status and forward to Nestpick.

### Where the Logic Runs
- Worker: `packages/main/src/workers/watchersWorker.ts`
  - AutoPAC CSV watcher
  - Nestpick processed/unstack watchers
  - Telemetry TCP clients

### AutoPAC CSV Files
- Naming must include machine: `load_finishWT1.csv`, `label_finishWT2.csv`, `cnc_finishWT1.csv` (separators `_`/`-` allowed)
- CSV rows must have NC name in the first column (either `base` or `base.nc` only)
- We also require the CSV content to contain the machine token (e.g., `WT1`) somewhere in the file; mismatch → warning, file left untouched

Flow:
1) Watcher sees a file, waits briefly for writes to stabilize
2) Extract process (LOAD/LABEL/CNC) and machine from filename
3) Validate CSV contains same machine token
4) Extract bases from the first column and find matching DB jobs by `ncfile` (only `base` or `base.nc`)
5) Update lifecycle (e.g., `LOAD_FINISH`, `CNC_FINISH`), append history events
6) On success, delete the CSV
7) If `CNC_FINISH` and machine supports Nestpick, forward per‑file parts CSV to Nestpick folder

### Nestpick Forwarding
Triggered on `CNC_FINISH` if `machine.nestpickEnabled` and `nestpickFolder` are set.
- Finds the job’s parts CSV in Ready‑To‑Run
- Rewrites `Destination=99`, `SourceMachine=<machineId>`
- Writes `Nestpick.csv` atomically to the Nestpick share (waits if busy)
- Appends job events and updates lifecycle to `FORWARDED_TO_NESTPICK`

### Diagnostics & Health
The worker posts messages back; Main turns them into Diagnostics snapshot entries visible in the UI.
- Issues like “missing parts CSV”, “Nestpick share unreachable”, or copy failures appear as machine health pills.

### Tuning Watchers
- Stability and debounce times are configured in `watchersWorker.ts` (we use low latencies for responsiveness).

================
File: docs/WORKLIST.md
================
## Worklist: Staging Jobs to Ready‑To‑Run (Beginner Lesson)

When an operator chooses “Add To Worklist”, we copy a job’s files from the processed jobs root into the machine’s Ready‑To‑Run folder with the correct associated assets.

### Where the Logic Lives
- `packages/main/src/services/worklist.ts`
  - File walking and copy planning
  - NC/CSV/LPT/PTS/image resolution rules
  - Lifecycle updates + job events

### Two Modes: Alphacam vs Planit
- Alphacam: detected when a `.pts` exists for the same base as the NC
  - Copy NC and exact companions
  - Also copy all wildcard images `base*.bmp|jpg|jpeg` from the job root and subfolders
- Planit: detected when an `.lpt` exists (and no `.pts`)
  - Copy NC, per‑file CSV `base.csv`, and family CSV `prefix.csv` (first three letters)
  - Image mapping uses the family CSV only (labels → image tokens)

### CSV Copy Rules
- If `base.csv` exists, copy it (this is the parts CSV forwarded to Nestpick)
- For Planit, also copy `prefix.csv` (e.g., `RJT.csv`) alongside
  - Image mapping uses `prefix.csv` (never the per‑file CSV)

### Image Rules
- Alphacam: wildcard all images starting with `base`
- Planit: image tokens resolved via family CSV + LPT label numbers

### Overwrite Semantics
- Some files (e.g., CSV/NC/LPT/PTS/images) can be overwritten; existing destination files may be skipped if not in the overwrite list

### Lifecycle and Events
- On success, lifecycle transitions to `STAGED` and we append a `worklist:staged` job event with details (copied/skipped counts)

================
File: electron-builder.yml
================
appId: com.woodtron.app
productName: WoodtronApp
files:
  - "packages/**/dist/**"
  - "resources/**"
win:
  target: nsis
mac:
  target: dmg
linux:
  target: AppImage
publish:
  - provider: generic
    url: https://example.com/updates

================
File: package.json
================
{
    "name":  "woodtron-electron",
    "version":  "0.1.0",
    "private":  true,
    "description":  "Electron + TypeScript + React + shadcn/ui desktop app",
    "license":  "UNLICENSED",
    "packageManager":  "pnpm@9.0.0",
    "engines":  {
                    "node":  "\u003e=20",
                    "pnpm":  "\u003e=9"
                },
    "workspaces":  [
                       "packages/*"
                   ],
    "scripts":  {
                    "dev":  "concurrently -k -n RENDERER,MAIN,PRELOAD,ELECTRON \"pnpm:dev:renderer\" \"pnpm:dev:main\" \"pnpm:dev:preload\" \"pnpm:dev:electron\"",
                    "dev:renderer":  "pnpm -C packages/renderer dev",
                    "dev:main":  "esbuild packages/main/src/main.ts packages/main/src/workers/watchersWorker.ts --bundle --platform=node --format=cjs --target=node20 --external:electron --external:fsevents --outdir=packages/main/dist --sourcemap --watch",
                    "dev:preload":  "esbuild packages/preload/src/index.ts --bundle --platform=node --format=cjs --target=node20 --external:electron --outfile=packages/preload/dist/index.js --sourcemap --watch",
                    "dev:electron":  "wait-on http-get://localhost:5180 packages/preload/dist/index.js packages/main/dist/main.js packages/main/dist/workers/watchersWorker.js \u0026\u0026 cross-env VITE_DEV_SERVER_URL=http://localhost:5180 pnpm -C packages/main exec electron dist/main.js",
                    "build":  "pnpm build:preload \u0026\u0026 pnpm build:main \u0026\u0026 pnpm -C packages/renderer build",
                    "build:main":  "esbuild packages/main/src/main.ts packages/main/src/workers/watchersWorker.ts --bundle --platform=node --format=cjs --target=node20 --external:electron --external:fsevents --outdir=packages/main/dist --sourcemap",
                    "build:preload":  "esbuild packages/preload/src/index.ts --bundle --platform=node --format=cjs --target=node20 --external:electron --outfile=packages/preload/dist/index.js --sourcemap",
                    "lint":  "eslint \"packages/**/*.{ts,tsx}\" \"tests/**/*.{ts,tsx}\"",
                    "lint:fix":  "eslint --fix \"packages/**/*.{ts,tsx}\" \"tests/**/*.{ts,tsx}\"",
                    "typecheck":  "pnpm -r run typecheck \u0026\u0026 tsc -p tests/tsconfig.json",
                    "test":  "vitest run --coverage",
                    "test:watch":  "vitest",
                    "format":  "pnpm dlx prettier --config prettier.config.cjs --ignore-path .prettierignore --write .",
                    "format:check":  "pnpm dlx prettier --config prettier.config.cjs --ignore-path .prettierignore --check .",
                    "e2e":  "playwright test"
                },
    "devDependencies":  {
                            "@playwright/test":  "^1.48.2",
                            "@types/node":  "^20.12.12",
                            "@typescript-eslint/eslint-plugin":  "^7.16.0",
                            "@typescript-eslint/parser":  "^7.16.0",
                            "@vitest/coverage-v8":  "^2.1.1",
                            "concurrently":  "^9.0.1",
                            "cross-env":  "^7.0.3",
                            "esbuild":  "^0.21.5",
                            "eslint":  "^8.57.0",
                            "eslint-plugin-react":  "^7.35.0",
                            "eslint-plugin-react-hooks":  "^4.6.2",
                            "pg-mem":  "^3.0.5",
                            "typescript":  "^5.4.5",
                            "vitest":  "^2.1.1",
                            "wait-on":  "^7.2.0"
                        },
    "dependencies":  {
                         "drizzle-orm":  "^0.44.5",
                         "neverthrow":  "^7.1.0"
                     }
}

================
File: packages/main/package.json
================
{
  "name": "@app/main",
  "version": "0.1.0",
  "private": true,
  "main": "dist/main.js",
  "type": "commonjs",
  "scripts": {
    "build": "tsc -p tsconfig.json",
    "dev": "echo Run via root dev runner once set up",
    "typecheck": "tsc -p tsconfig.json --noEmit"
  },
  "dependencies": {
    "chokidar": "^3.6.0",
    "drizzle-orm": "^0.44.5",
    "electron": "^31.0.0",
    "neverthrow": "^7.1.0",
    "pg": "^8.11.5",
    "pino": "^9.3.2",
    "pino-pretty": "^11.2.2",
    "zod": "^3.23.8"
  },
  "devDependencies": {
    "@types/node": "^20.12.12",
    "@types/pg": "^8.11.6",
    "typescript": "^5.4.5"
  }
}

================
File: packages/main/src/db/schema.ts
================
import {
  bigserial,
  boolean,
  inet,
  integer,
  jsonb,
  pgEnum,
  pgTable,
  serial,
  text,
  timestamp,
  varchar
} from 'drizzle-orm/pg-core';

export const jobStatusEnum = pgEnum('job_status', [
  'PENDING',
  'STAGED',
  'LOAD_FINISH',
  'LABEL_FINISH',
  'CNC_FINISH',
  'FORWARDED_TO_NESTPICK',
  'NESTPICK_COMPLETE'
]);

export const machines = pgTable('machines', {
  machineId: serial('machine_id').primaryKey(),
  name: text('name').notNull(),
  pcIp: inet('pc_ip'),
  cncIp: inet('cnc_ip'),
  cncPort: integer('cnc_port'),
  apJobfolder: text('ap_jobfolder').notNull(),
  nestpickFolder: text('nestpick_folder').notNull(),
  nestpickEnabled: boolean('nestpick_enabled').default(true).notNull(),
  createdAt: timestamp('created_at', { withTimezone: true }).defaultNow().notNull(),
  updatedAt: timestamp('updated_at', { withTimezone: true }).defaultNow().notNull(),
  pcPort: integer('pc_port').default(5000).notNull()
});

export const jobs = pgTable('jobs', {
  key: varchar('key', { length: 100 }).primaryKey(),
  folder: varchar('folder', { length: 255 }),
  ncfile: varchar('ncfile', { length: 255 }),
  material: varchar('material', { length: 255 }),
  parts: varchar('parts', { length: 255 }),
  size: varchar('size', { length: 255 }),
  thickness: varchar('thickness', { length: 255 }),
  isReserved: boolean('is_reserved').default(false).notNull(),
  machineId: integer('machine_id').references(() => machines.machineId, { onDelete: 'set null' }),
  dateAdded: timestamp('dateadded', { withTimezone: true }),
  stagedAt: timestamp('staged_at', { withTimezone: true }),
  cutAt: timestamp('cut_at', { withTimezone: true }),
  nestpickCompletedAt: timestamp('nestpick_completed_at', { withTimezone: true }),
  updatedAt: timestamp('updated_at', { withTimezone: true }).defaultNow().notNull(),
  pallet: varchar('pallet', { length: 50 }),
  lastError: text('last_error'),
  status: jobStatusEnum('status').default('PENDING').notNull()
});

export const jobEvents = pgTable('job_events', {
  eventId: bigserial('event_id', { mode: 'number' }).primaryKey(),
  key: varchar('key', { length: 100 })
    .notNull()
    .references(() => jobs.key, { onDelete: 'cascade' }),
  machineId: integer('machine_id').references(() => machines.machineId, { onDelete: 'set null' }),
  eventType: text('event_type').notNull(),
  payload: jsonb('payload').$type<unknown | null>(),
  createdAt: timestamp('created_at', { withTimezone: true }).defaultNow().notNull()
});

export const grundner = pgTable('grundner', {
  id: serial('id').primaryKey(),
  typeData: integer('type_data').notNull(),
  customerId: varchar('customer_id', { length: 50 }),
  lengthMm: integer('length_mm'),
  widthMm: integer('width_mm'),
  thicknessMm: integer('thickness_mm'),
  stock: integer('stock'),
  stockAvailable: integer('stock_available'),
  lastUpdated: varchar('last_updated', { length: 50 }),
  reservedStock: integer('reserved_stock').default(0)
});

export const schema = {
  jobs,
  machines,
  jobEvents,
  grundner,
  jobStatusEnum
};

export type JobStatus = (typeof jobStatusEnum.enumValues)[number];

================
File: packages/main/src/ipc/alarms.ts
================
import type { WebContents } from 'electron';
import { ok } from 'neverthrow';
import type { AlarmsHistoryReq, AlarmsHistoryRes, AppError } from '../../../shared/src';
import { AlarmsHistoryReq as AlarmsHistoryReqSchema } from '../../../shared/src';
import { listActiveAlarms } from '../repo/alarmsRepo';
import { logger } from '../logger';
import { registerResultHandler } from './result';
import { onContentsDestroyed } from './onDestroyed';
import { listAlarmIntervals } from '../repo/alarmsHistoryRepo';

type AlarmSubscription = {
  timer: NodeJS.Timeout;
  refCount: number;
};

const POLL_INTERVAL_MS = 7500;
const subscribers = new Map<number, AlarmSubscription>();

async function pushAlarms(contents: WebContents) {
  try {
    const alarms = await listActiveAlarms();
    if (!contents.isDestroyed()) {
      contents.send('alarms:update', alarms);
    }
  } catch (err) {
    logger.error({ err }, 'alarms-ipc: failed to fetch alarms');
  }
}

function ensureSubscription(contents: WebContents) {
  const id = contents.id;
  const existing = subscribers.get(id);
  if (existing) {
    existing.refCount += 1;
    return;
  }

  const timer = setInterval(() => {
    void pushAlarms(contents);
  }, POLL_INTERVAL_MS);

  const subscription: AlarmSubscription = { timer, refCount: 1 };
  subscribers.set(id, subscription);

  onContentsDestroyed(contents, () => releaseSubscription(contents));
  void pushAlarms(contents);
}

function releaseSubscription(contents: WebContents) {
  const id = contents.id;
  const entry = subscribers.get(id);
  if (!entry) return;
  entry.refCount -= 1;
  if (entry.refCount <= 0) {
    clearInterval(entry.timer);
    subscribers.delete(id);
  }
}

export function registerAlarmsIpc() {
  registerResultHandler('alarms:list', async () => ok(await listActiveAlarms()));

  registerResultHandler('alarms:subscribe', async (event) => {
    ensureSubscription(event.sender);
    return ok<null, AppError>(null);
  });

  registerResultHandler('alarms:unsubscribe', async (event) => {
    releaseSubscription(event.sender);
    return ok<null, AppError>(null);
  });

  registerResultHandler('alarms:history', async (_e, raw) => {
    const req = AlarmsHistoryReqSchema.parse(raw ?? {} as AlarmsHistoryReq);
    const items = await listAlarmIntervals(req);
    const res: AlarmsHistoryRes = { items };
    return ok<AlarmsHistoryRes, AppError>(res);
  });
}

================
File: packages/main/src/ipc/db.ts
================
import type { WebContents } from 'electron';
import type { AppError, DbStatus } from '../../../shared/src';
import { ok } from 'neverthrow';
import { withClient } from '../services/db';
import { getDbStatus, subscribeDbStatus } from '../services/dbWatchdog';
import { registerResultHandler } from './result';
import { onContentsDestroyed } from './onDestroyed';

const statusSubscribers = new Map<number, { unsubscribe: () => void; count: number }>();

function ensureSubscription(contents: WebContents): DbStatus {
  const id = contents.id;
  const existing = statusSubscribers.get(id);
  if (existing) {
    existing.count += 1;
    return getDbStatus();
  }

  const send = (next: DbStatus) => {
    if (!contents.isDestroyed()) {
      contents.send('db:status:update', next);
    }
  };

  const unsubscribe = subscribeDbStatus(send);
  
  // Register destroyed cleanup BEFORE adding to map to prevent race condition
  onContentsDestroyed(contents, () => {
    const entry = statusSubscribers.get(id);
    if (!entry) return; // nil-guard if entry is already absent

    // Use reference counting instead of unconditional cleanup
    entry.count -= 1;
    if (entry.count <= 0) {
      entry.unsubscribe();
      statusSubscribers.delete(id);
    }
  });

  // Check if destroyed after handler registration
  if (contents.isDestroyed()) {
    unsubscribe(); // Clean up immediately if already destroyed
    return getDbStatus();
  }

  statusSubscribers.set(id, { unsubscribe, count: 1 });

  return getDbStatus();
}

function releaseSubscription(contents: WebContents) {
  const id = contents.id;
  const entry = statusSubscribers.get(id);
  if (!entry) return;
  entry.count -= 1;
  if (entry.count <= 0) {
    entry.unsubscribe();
    statusSubscribers.delete(id);
  }
}

export function registerDbIpc() {
  registerResultHandler('db:ping', async () => {
    await withClient((c) => c.query('SELECT 1'));
    return ok<null, AppError>(null);
  });

  registerResultHandler('db:status:get', async () => ok<DbStatus, AppError>(getDbStatus()));

  registerResultHandler('db:status:subscribe', async (event) =>
    ok<DbStatus, AppError>(ensureSubscription(event.sender))
  );

  registerResultHandler('db:status:unsubscribe', async (event) => {
    releaseSubscription(event.sender);
    return ok<null, AppError>(null);
  });
}

================
File: packages/main/src/ipc/diagnostics.ts
================
import { clipboard, type WebContents } from 'electron';
import { ok, err } from 'neverthrow';
import type { AppError, CopyDiagnosticsResult, DiagnosticsLogSummary, DiagnosticsLogTailRes, DiagnosticsLogStreamReq } from '../../../shared/src';
import { DiagnosticsLogTailReq, DiagnosticsLogStreamReq as DiagnosticsLogStreamReqSchema } from '../../../shared/src';
import { getDiagnosticsSnapshot, subscribeDiagnostics, buildDiagnosticsCopyPayload, listDiagnosticsLogs, getDiagnosticsLogTail, subscribeLogStream } from '../services/diagnostics';
import { logger } from '../logger';
import { createAppError } from './errors';
import { registerResultHandler } from './result';
import { onContentsDestroyed } from './onDestroyed';

type DiagnosticsSubscription = {
  unsubscribe: () => void;
  count: number;
};

const subscribers = new Map<number, DiagnosticsSubscription>();
const logSubscribers = new Map<number, { file: string; unsubscribe: () => void }>();

function pushSnapshot(contents: WebContents) {
  if (contents.isDestroyed()) return;
  contents.send('diagnostics:update', getDiagnosticsSnapshot());
}

function ensureSubscription(contents: WebContents) {
  const id = contents.id;
  const existing = subscribers.get(id);
  if (existing) {
    existing.count += 1;
    return;
  }

  const handler = () => pushSnapshot(contents);
  const unsubscribe = subscribeDiagnostics(handler);

  subscribers.set(id, { unsubscribe, count: 1 });

  onContentsDestroyed(contents, () => releaseSubscription(contents));
  handler();
}

function releaseSubscription(contents: WebContents) {
  const id = contents.id;
  const entry = subscribers.get(id);
  if (!entry) return;
  entry.count -= 1;
  if (entry.count <= 0) {
    entry.unsubscribe();
    subscribers.delete(id);
  }
}

export function registerDiagnosticsIpc() {
  registerResultHandler('diagnostics:get', async () => ok(getDiagnosticsSnapshot()));

  registerResultHandler('diagnostics:subscribe', async (event) => {
    ensureSubscription(event.sender);
    return ok<null, AppError>(null);
  });

  registerResultHandler('diagnostics:unsubscribe', async (event) => {
    releaseSubscription(event.sender);
    return ok<null, AppError>(null);
  });

  registerResultHandler('diagnostics:logs:list', async () => {
    try {
      const items = await listDiagnosticsLogs();
      return ok<{ items: DiagnosticsLogSummary[] }, AppError>({ items });
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      logger.error({ error }, 'diagnostics: failed to list log files');
      return err(createAppError('DIAGNOSTICS_LOGS_LIST_FAILED', message));
    }
  });

  registerResultHandler('diagnostics:logs:tail', async (_event, raw) => {
    try {
      const req = DiagnosticsLogTailReq.parse(raw ?? {});
      const log = await getDiagnosticsLogTail(req.file, req.limit);
      return ok<DiagnosticsLogTailRes, AppError>(log);
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      logger.error({ error, raw }, 'diagnostics: failed to read log file');
      return err(createAppError('DIAGNOSTICS_LOG_TAIL_FAILED', message));
    }
  });

  registerResultHandler('diagnostics:copy', async () => {
    try {
      const { snapshot, logs } = await buildDiagnosticsCopyPayload();
      const payload = {
        copiedAt: new Date().toISOString(),
        snapshot,
        logs
      };
      const serialized = JSON.stringify(payload, null, 2);
      clipboard.writeText(serialized);
      const result: CopyDiagnosticsResult = {
        ok: true,
        copiedAt: payload.copiedAt,
        bytes: Buffer.byteLength(serialized, 'utf8'),
        logCount: logs.length,
        logs,
        snapshot
      };
      return ok<CopyDiagnosticsResult, AppError>(result);
    } catch (error) {
      logger.error({ error }, 'diagnostics: failed to copy diagnostics bundle');
      const message = error instanceof Error ? error.message : String(error);
      return err(createAppError('diagnostics.copyFailed', message));
    }
  });

  registerResultHandler('diagnostics:log:subscribe', async (event, raw) => {
    try {
      const req = DiagnosticsLogStreamReqSchema.parse(raw ?? {}) as DiagnosticsLogStreamReq;
      const file = String(req.file ?? '');
      if (!file) throw new Error('file is required');
      const contents = event.sender;
      const id = contents.id;

      // Clean up previous subscription for this contents
      const prev = logSubscribers.get(id);
      if (prev) {
        try { prev.unsubscribe(); } catch { /* noop */ void 0; }
        logSubscribers.delete(id);
      }

      const unsubscribe = subscribeLogStream(file, (lines) => {
        if (!contents.isDestroyed()) contents.send('diagnostics:log:update', { file, lines });
      });
      logSubscribers.set(id, { file, unsubscribe });

      onContentsDestroyed(contents, () => {
        const entry = logSubscribers.get(id);
        if (entry) {
          try { entry.unsubscribe(); } catch { /* noop */ void 0; }
          logSubscribers.delete(id);
        }
      });
      return ok<null, AppError>(null);
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      return err({ code: 'DIAGNOSTICS_LOG_SUBSCRIBE_FAILED', message } as AppError);
    }
  });

  registerResultHandler('diagnostics:log:unsubscribe', async (event) => {
    const contents = event.sender;
    const id = contents.id;
    const entry = logSubscribers.get(id);
    if (entry) {
      try { entry.unsubscribe(); } catch { /* noop */ void 0; }
      logSubscribers.delete(id);
    }
    return ok<null, AppError>(null);
  });
}

================
File: packages/main/src/ipc/errors.ts
================
import { AppErrorSchema, type AppError } from '../../../shared/src';
import type { DatabaseError } from 'pg';

function pickDetails(error: DatabaseError) {
  const details: Record<string, unknown> = {};
  if (error.detail) details.detail = error.detail;
  if (error.schema) details.schema = error.schema;
  if (error.table) details.table = error.table;
  if (error.constraint) details.constraint = error.constraint;
  const column = (error as unknown as { column?: unknown }).column;
  if (column !== undefined) {
    details.column = column;
  }
  return Object.keys(details).length ? details : undefined;
}

const PG_ERROR_MAPPERS: Record<string, (error: DatabaseError) => AppError> = {
  '23505': (error) => ({
    code: 'db.uniqueViolation',
    message: 'A record with the same value already exists.',
    details: pickDetails(error)
  }),
  '23503': (error) => ({
    code: 'db.foreignKeyViolation',
    message: 'The requested record references missing related data.',
    details: pickDetails(error)
  }),
  '23502': (error) => ({
    code: 'db.notNullViolation',
    message: 'A required column was missing.',
    details: pickDetails(error)
  }),
  '22001': (error) => ({
    code: 'db.stringTooLong',
    message: 'Input was too long for the target column.',
    details: pickDetails(error)
  })
};

function defaultPgError(error: DatabaseError): AppError {
  return {
    code: 'db.error',
    message: error.message,
    details: pickDetails(error)
  };
}

function isDatabaseError(error: unknown): error is DatabaseError {
  return (
    typeof error === 'object' &&
    error !== null &&
    typeof (error as { code?: unknown }).code === 'string'
  );
}

export function toAppError(error: unknown): AppError {
  if (!(error instanceof Error) && AppErrorSchema.safeParse(error).success) {
    return error as AppError;
  }

  if (isDatabaseError(error)) {
    const mapper = PG_ERROR_MAPPERS[error.code ?? ''];
    return mapper ? mapper(error) : defaultPgError(error);
  }

  if (error instanceof Error) {
    return {
      code: 'unknown',
      message: error.message,
      details: error.stack ? { stack: error.stack } : undefined
    };
  }

  return {
    code: 'unknown',
    message: 'An unknown error occurred.',
    details: { raw: error }
  };
}

export function createAppError(code: string, message: string, details?: unknown): AppError {
  return { code, message, details };
}

================
File: packages/main/src/ipc/files.ts
================
import { readdirSync, statSync, promises as fsp } from 'fs';
import { join, relative, dirname, extname, basename, resolve } from 'path';
import chokidar, { type FSWatcher } from 'chokidar';
import { ok, err } from 'neverthrow';
import type { AppError, Machine, ReadyImportRes, ReadyFile, ReadyDeleteRes } from '../../../shared/src';
import { ReadyImportReq, ReadyDeleteReq } from '../../../shared/src';
import { listMachines } from '../repo/machinesRepo';
import { importReadyFile } from '../services/readyImport';
import { findJobDetailsByNcBase } from '../repo/jobsRepo';
import { createAppError } from './errors';
import { registerResultHandler } from './result';
import { onContentsDestroyed } from './onDestroyed';

function collectFiles(root: string, current: string = root) {
  const entries = readdirSync(current, { withFileTypes: true });
  const out: { fullPath: string; relativePath: string; name: string }[] = [];
  for (const entry of entries) {
    const fullPath = join(current, entry.name);
    if (entry.isDirectory()) {
      out.push(...collectFiles(root, fullPath));
    } else if (entry.isFile()) {
      const rel = relative(root, fullPath).split('\\').join('/');
      if (/\.nc$/i.test(entry.name)) {
        out.push({ fullPath, relativePath: rel, name: entry.name });
      }
    }
  }
  return out;
}

function baseFromName(name: string) {
  const idx = name.lastIndexOf('.');
  const withoutExt = idx >= 0 ? name.slice(0, idx) : name;
  return withoutExt.replace(/\s+/g, '');
}

// File types to remove when cleaning up a sheet's artifacts in Ready-To-Run.
// Includes .csv per updated requirements.
const DELETE_EXTENSIONS = new Set(['.bmp', '.jpg', '.jpeg', '.png', '.pts', '.lpt', '.nc', '.csv']);

function normalizeRelativePath(input: string) {
  return input.split('\\').join('/');
}

export function registerFilesIpc() {
  const isWindows = process.platform === 'win32';
  const samePath = (a: string, b: string) => (isWindows ? a.toLowerCase() === b.toLowerCase() : a === b);

  async function removeEmptyDirsUpToRoot(root: string, startDir: string) {
    const rootResolved = resolve(root);
    let current = resolve(startDir);
    const IGNORABLE = new Set(['thumbs.db', 'desktop.ini', '.ds_store']);

    async function pruneEmptyDir(dir: string): Promise<boolean> {
      if (samePath(dir, rootResolved)) return false; // never delete the root
      let dirents: Array<{ name: string; isFile: () => boolean; isDirectory: () => boolean }>;
      try {
        dirents = await fsp.readdir(dir, { withFileTypes: true } as unknown as { withFileTypes: true }) as unknown as Array<{
          name: string; isFile: () => boolean; isDirectory: () => boolean;
        }>;
      } catch {
        // Can't read dir; treat as non-removable
        return false;
      }

      // Remove ignorable OS noise files
      for (const d of dirents) {
        if (d.isFile && d.isFile()) {
          const nm = d.name.toLowerCase();
          if (IGNORABLE.has(nm) || nm.startsWith('._')) {
            try { await fsp.unlink(join(dir, d.name)); } catch { /* ignore */ }
          }
        }
      }

      // Re-read with types and prune child directories first (bottom-up)
      try {
        dirents = await fsp.readdir(dir, { withFileTypes: true } as unknown as { withFileTypes: true }) as unknown as Array<{
          name: string; isFile: () => boolean; isDirectory: () => boolean;
        }>;
      } catch {
        return false;
      }
      for (const d of dirents) {
        if (d.isDirectory && d.isDirectory()) {
          await pruneEmptyDir(join(dir, d.name));
        }
      }

      // After pruning children and noise files, check if empty
      let remaining: string[];
      try {
        remaining = await fsp.readdir(dir);
      } catch {
        return false;
      }
      if (remaining.length > 0) return false;
      try {
        await fsp.rmdir(dir);
        return true;
      } catch {
        return false;
      }
    }

    // Walk upward from the starting directory, pruning empties on each ancestor
    while (!samePath(current, rootResolved)) {
      await pruneEmptyDir(current);
      const parent = dirname(current);
      if (parent === current) break;
      current = parent;
    }
  }
  async function buildReadyList(machineId: number): Promise<{ machineId: number; files: ReadyFile[] }> {
    const machines = await listMachines();
    const machine = machines.find((m: Machine) => m.machineId === machineId);
    if (!machine || !machine.apJobfolder) return { machineId, files: [] };
    const root = machine.apJobfolder;
    const fileEntries = collectFiles(root);
    const files: ReadyFile[] = await Promise.all(
      fileEntries.map(async ({ fullPath, relativePath, name }) => {
        const stats = statSync(fullPath);
        const base = baseFromName(name);
        const job = base ? await findJobDetailsByNcBase(base) : null;
        return {
          name,
          relativePath,
          size: stats.size,
          mtimeMs: stats.mtimeMs,
          inDatabase: !!job,
          jobKey: job?.key ?? null,
          status: job?.status ?? null,
          jobMaterial: job?.material ?? null,
          jobSize: job?.size ?? null,
          jobParts: job?.parts ?? null,
          jobThickness: job?.thickness ?? null,
          jobDateadded: job?.dateadded ?? null,
          addedAtR2R: new Date(stats.mtimeMs).toISOString()
        } satisfies ReadyFile;
      })
    );
    files.sort((a, b) => a.relativePath.localeCompare(b.relativePath));
    return { machineId, files };
  }

  registerResultHandler('files:listReady', async (_e, rawMachineId) => {
    const machineId = typeof rawMachineId === 'number' ? rawMachineId : Number(rawMachineId);
    if (!Number.isFinite(machineId)) {
      return err(createAppError('files.invalidMachineId', 'Machine id must be a number'));
    }
    const { files, machineId: mid } = await buildReadyList(machineId);
    return ok<{ machineId: number; files: ReadyFile[] }, AppError>({ machineId: mid, files });
  });

  // Live subscription for Ready-To-Run folder changes
  const readyWatchers = new Map<number, FSWatcher>(); // keyed by WebContents.id

  registerResultHandler('files:ready:subscribe', async (event, rawMachineId) => {
    const contents = event.sender;
    const webId = contents.id;
    const machineId = typeof rawMachineId === 'number' ? rawMachineId : Number(rawMachineId);
    if (!Number.isFinite(machineId)) {
      return err(createAppError('files.invalidMachineId', 'Machine id must be a number'));
    }
    // Cleanup an existing watcher for this WebContents, if any
    const existing = readyWatchers.get(webId);
    if (existing) {
      try { await existing.close(); } catch (e) { void e; }
      readyWatchers.delete(webId);
    }

    const machines = await listMachines();
    const machine = machines.find((m: Machine) => m.machineId === machineId);
    if (!machine || !machine.apJobfolder) {
      return err(createAppError('files.machineNotFound', 'Machine not found or ap_jobfolder not set'));
    }
    const root = machine.apJobfolder;

    let timer: NodeJS.Timeout | null = null;
    const scheduleUpdate = () => {
      if (timer) clearTimeout(timer);
      timer = setTimeout(async () => {
        const { files } = await buildReadyList(machineId);
        if (!contents.isDestroyed()) {
          contents.send('files:ready:update', { machineId, files });
        }
      }, 200) as unknown as NodeJS.Timeout;
      if (timer && typeof timer.unref === 'function') {
        timer.unref();
      }
    };

    const watcher = chokidar.watch(root, {
      ignoreInitial: false,
      depth: 5,
      awaitWriteFinish: { stabilityThreshold: 500, pollInterval: 100 }
    });
    watcher.on('add', (p) => { if (/\.nc$/i.test(p)) scheduleUpdate(); });
    watcher.on('unlink', (p) => { if (/\.nc$/i.test(p)) scheduleUpdate(); });
    watcher.on('change', (p) => { if (/\.nc$/i.test(p)) scheduleUpdate(); });
    watcher.on('error', () => scheduleUpdate());

    readyWatchers.set(webId, watcher);

    onContentsDestroyed(contents, () => {
      const w = readyWatchers.get(webId);
      if (w) {
        w.close().catch((err) => { void err; });
        readyWatchers.delete(webId);
      }
    });

    // Send initial snapshot
    const { files } = await buildReadyList(machineId);
    if (!contents.isDestroyed()) {
      contents.send('files:ready:update', { machineId, files });
    }

    return ok<null, AppError>(null);
  });

  registerResultHandler('files:ready:unsubscribe', async (event) => {
    const webId = event.sender.id;
    const w = readyWatchers.get(webId);
    if (w) {
      try { await w.close(); } catch (e) { void e; }
      readyWatchers.delete(webId);
    }
    return ok<null, AppError>(null);
  });

  registerResultHandler('files:ready:delete', async (_event, raw) => {
    const parsed = ReadyDeleteReq.safeParse(raw ?? {});
    if (!parsed.success) {
      return err(createAppError('files.invalidArguments', parsed.error.message));
    }

    const { machineId, relativePaths } = parsed.data;
    const machines = await listMachines();
    const machine = machines.find((m: Machine) => m.machineId === machineId);
    if (!machine || !machine.apJobfolder) {
      return err(createAppError('files.machineNotFound', 'Machine not found or ap_jobfolder not set'));
    }
    const root = machine.apJobfolder;

    const uniquePaths = Array.from(new Set(relativePaths.map(normalizeRelativePath)));
    const errors: ReadyDeleteRes['errors'] = [];
    const targets = new Set<string>();
    const candidateDirs = new Set<string>();

    for (const rel of uniquePaths) {
      if (rel.includes('..') || rel.startsWith('/') || /^[a-zA-Z]:\//.test(rel)) {
        errors.push({ file: rel, message: 'Relative path cannot contain ..' });
        continue;
      }
      const fileName = basename(rel);
      const ext = extname(fileName);
      const stemExact = fileName.slice(0, fileName.length - ext.length);
      const stemLower = stemExact.toLowerCase();
      const stemNoSpacesLower = stemLower.replace(/\s+/g, '');

      const absoluteNc = join(root, rel);
      const containingDir = dirname(absoluteNc);
      candidateDirs.add(containingDir);
      let dirEntries: string[];
      try {
        dirEntries = await fsp.readdir(containingDir);
      } catch (error) {
        const errObj = error as NodeJS.ErrnoException;
        if (errObj?.code !== 'ENOENT') {
          errors.push({ file: rel, message: error instanceof Error ? error.message : String(error) });
        }
        continue;
      }
      // Always include the exact .nc file if present
      targets.add(absoluteNc);
      for (const entry of dirEntries) {
        const entryLower = entry.toLowerCase();
        const extension = extname(entryLower);
        if (!DELETE_EXTENSIONS.has(extension)) continue;
        const entryStemLower = entryLower.slice(0, entryLower.length - extension.length);
        if (
          entryStemLower === stemLower ||
          entryStemLower === stemNoSpacesLower ||
          entryStemLower.startsWith(stemLower) ||
          entryStemLower.startsWith(stemNoSpacesLower)
        ) {
          targets.add(join(containingDir, entry));
        }
      }
    }

    const deletedFiles: string[] = [];
    let deletedCount = 0;
    for (const absolute of targets) {
      try {
        await fsp.unlink(absolute);
        deletedCount += 1;
        deletedFiles.push(normalizeRelativePath(relative(root, absolute)));
      } catch (error) {
        const errObj = error as NodeJS.ErrnoException;
        if (errObj?.code === 'ENOENT') {
          continue;
        }
        errors.push({
          file: normalizeRelativePath(relative(root, absolute)),
          message: error instanceof Error ? error.message : String(error)
        });
      }
    }

    // Attempt to remove empty directories for each affected job folder, up to but not including the root
    for (const dir of candidateDirs) {
      try {
        await removeEmptyDirsUpToRoot(root, dir);
      } catch {
        // ignore cleanup errors; file deletions are primary concern
      }
    }

    return ok<ReadyDeleteRes, AppError>({ deleted: deletedCount, files: deletedFiles, errors });
  });

  registerResultHandler('files:importReady', async (_event, raw) => {
    const parsed = ReadyImportReq.safeParse(raw ?? {});
    if (!parsed.success) {
      return err(createAppError('files.invalidArguments', parsed.error.message));
    }
    try {
      const result = await importReadyFile(parsed.data.machineId, parsed.data.relativePath);
      return ok<ReadyImportRes, AppError>(result);
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      return err(createAppError('files.importFailed', message));
    }
  });
}

================
File: packages/main/src/ipc/grundner.ts
================
import { ok } from 'neverthrow';
import type { AppError } from '../../../shared/src';
import { GrundnerListReq, GrundnerUpdateReq, GrundnerResyncReq } from '../../../shared/src';
import { listGrundner, updateGrundnerRow, resyncGrundnerReserved } from '../repo/grundnerRepo';
import { registerResultHandler } from './result';

export function registerGrundnerIpc() {
  registerResultHandler('grundner:list', async (_e, raw) => {
    const req = GrundnerListReq.parse(raw ?? {});
    const items = await listGrundner(req);
    return ok({ items });
  });

  registerResultHandler('grundner:update', async (_e, raw) => {
    const req = GrundnerUpdateReq.parse(raw);
    const res = await updateGrundnerRow(req);
    return ok(res);
  });

  registerResultHandler('grundner:resync', async (_e, raw) => {
    const req = GrundnerResyncReq.parse(raw ?? {});
    const updated = await resyncGrundnerReserved(req.id);
    return ok<{ updated: number }, AppError>({ updated });
  });
}

================
File: packages/main/src/ipc/history.ts
================
import { ok, err } from 'neverthrow';
import type { AppError } from '../../../shared/src';
import { HistoryListReq } from '../../../shared/src';
import { getJobTimeline, listHistory } from '../repo/historyRepo';
import { createAppError } from './errors';
import { registerResultHandler } from './result';

export function registerHistoryIpc() {
  registerResultHandler('history:list', async (_event, raw) => {
    const req = HistoryListReq.parse(raw ?? {});
    const items = await listHistory(req);
    return ok({ items });
  });

  registerResultHandler('history:timeline', async (_event, raw) => {
    const key = typeof raw === 'string'
      ? raw
      : typeof raw === 'object' && raw !== null && 'key' in raw
        ? (raw as { key: unknown }).key
        : undefined;
    if (typeof key !== 'string') {
      return err(createAppError('history.invalidRequest', 'Invalid history timeline request'));
    }
    const data = await getJobTimeline(key);
    return ok<typeof data, AppError>(data);
  });
}

================
File: packages/main/src/ipc/hypernest.ts
================
import { app, BrowserWindow, session } from 'electron';
import { existsSync } from 'fs';
import { join, resolve } from 'path';
import { ok } from 'neverthrow';
import type { AppError } from '../../../shared/src';
import { applyWindowNavigationGuards, applyCustomContentSecurityPolicy } from '../security';
import { registerResultHandler } from './result';

let hypernestWin: BrowserWindow | null = null;

function resolveHypernestIndex(): string {
  const entry = process.env.HYPERNEST_ENTRY || 'index.html';

  // Prefer a dev working copy when provided
  const devDir = process.env.HYPERNEST_DEV_DIR;
  if (devDir && existsSync(devDir)) {
    return join(resolve(devDir), entry);
  }

  // Packaged: <App>/resources/hypernest
  // Dev:      ../../../resources/hypernest relative to compiled dist
  const base = app.isPackaged
    ? join(process.resourcesPath, 'hypernest')
    : resolve(__dirname, '../../../resources/hypernest');

  return join(base, entry);
}

export function openHypernestWindow() {
  if (hypernestWin && !hypernestWin.isDestroyed()) {
    hypernestWin.focus();
    return;
  }

  const indexFile = resolveHypernestIndex();

  hypernestWin = new BrowserWindow({
    width: 1400,
    height: 900,
    show: false,
    autoHideMenuBar: true,
    webPreferences: {
      // Use a separate session so we can apply a relaxed CSP without affecting the main app
      partition: 'persist:hypernest',
      contextIsolation: true,
      sandbox: true,
      nodeIntegration: false,
      webSecurity: true
    }
  });

  applyWindowNavigationGuards(hypernestWin.webContents, { allowExternal: false });

  hypernestWin.on('ready-to-show', () => hypernestWin?.show());
  hypernestWin.on('closed', () => {
    hypernestWin = null;
  });
  hypernestWin.webContents.on('did-finish-load', () => {
    // Hypernest UI is designed for a browser viewport; scale it slightly for the desktop window
    hypernestWin?.webContents.setZoomFactor(0.9);
  });

  // Relaxed CSP for Hypernest: allow required CDNs and inline handlers in this session only
  const hnSession = session.fromPartition('persist:hypernest');
  const hnPolicy = [
    "default-src 'self' https: data:",
    // Inline handlers + Tailwind CDN runtime rely on relaxed script execution
    "script-src 'self' 'unsafe-inline' 'unsafe-eval' https://cdn.tailwindcss.com https://cdn.babylonjs.com",
    // Tailwind + Google Fonts stylesheet
    "style-src 'self' 'unsafe-inline' https://fonts.googleapis.com",
    // Google Fonts assets
    "font-src 'self' https://fonts.gstatic.com",
    // Images from local and possible https
    "img-src 'self' data: blob: https:",
    "connect-src 'self'",
    "object-src 'none'",
    "frame-ancestors 'none'",
    "base-uri 'self'",
    "form-action 'self'"
  ].join('; ');
  applyCustomContentSecurityPolicy(hnSession, hnPolicy);

  hypernestWin.loadFile(indexFile).catch((err) => {
    console.error('Failed to load Hypernest', { err, indexFile });
  });
}

export function registerHypernestIpc() {
  registerResultHandler('hypernest:open', async () => {
    openHypernestWindow();
    return ok<null, AppError>(null);
  });
}

================
File: packages/main/src/ipc/ipcBridge.ts
================
import { ipcMain as electronIpcMain } from 'electron';

type IpcMainLike = typeof electronIpcMain;

let currentIpcMain: IpcMainLike = electronIpcMain;

export function getIpcMain(): IpcMainLike {
  return currentIpcMain;
}

export function __setIpcMain(mock: IpcMainLike) {
  currentIpcMain = mock;
}

================
File: packages/main/src/ipc/jobs.ts
================
import { ok, err } from 'neverthrow';
import type { AppError, WorklistAddResult } from '../../../shared/src';
import { JobEventsReq, JobsListReq, ReserveReq, UnreserveReq } from '../../../shared/src';
import { getJobEvents } from '../repo/jobEventsRepo';
import { listJobFilters, listJobs, reserveJob, unreserveJob } from '../repo/jobsRepo';
import { addJobToWorklist } from '../services/worklist';
import { ingestProcessedJobsRoot } from '../services/ingest';
import { createAppError } from './errors';
import { registerResultHandler } from './result';

export function registerJobsIpc() {
  // Return filters wrapped in an { options } object to match JobsFiltersRes
  registerResultHandler('jobs:filters', async () =>
    ok({ options: await listJobFilters() })
  );

  registerResultHandler('jobs:events', async (_e, raw) => {
    const req = JobEventsReq.parse(raw);
    const events = await getJobEvents(req.key, req.limit ?? 50);
    // Wrap in an object to match JobEventsRes shape expected by the renderer
    return ok({ events });
  });

  registerResultHandler('jobs:list', async (_e, raw) => {
    const req = JobsListReq.parse(raw);
    const res = await listJobs(req);
    return ok(res);
  });

  registerResultHandler('jobs:reserve', async (_e, raw) => {
    const req = ReserveReq.parse(raw);
    const success = await reserveJob(req.key);
    if (!success) {
      return err(createAppError('jobs.alreadyReserved', 'Job is already reserved.'));
    }
    return ok<null, AppError>(null);
  });

  registerResultHandler('jobs:unreserve', async (_e, raw) => {
    const req = UnreserveReq.parse(raw);
    const success = await unreserveJob(req.key);
    if (!success) {
      return err(createAppError('jobs.notReserved', 'Job is not currently reserved.'));
    }
    return ok<null, AppError>(null);
  });

  registerResultHandler('jobs:addToWorklist', async (_e, raw) => {
    if (typeof raw !== 'object' || raw === null) {
      return err(createAppError('jobs.invalidArguments', 'Invalid arguments supplied.'));
    }
    const { key, machineId } = raw as { key?: unknown; machineId?: unknown };
    if (typeof key !== 'string' || typeof machineId !== 'number') {
      return err(createAppError('jobs.invalidArguments', 'Invalid arguments supplied.'));
    }
    const result = await addJobToWorklist(key, machineId);
    return ok<WorklistAddResult, AppError>(result);
  });

  registerResultHandler('jobs:resync', async () => ok(await ingestProcessedJobsRoot()));
}

================
File: packages/main/src/ipc/lifecycle.ts
================
import { ok } from 'neverthrow';
import type { AppError } from '../../../shared/src';
import { LifecycleReq } from '../../../shared/src';
import { updateLifecycle } from '../repo/jobsRepo';
import { registerResultHandler } from './result';

export function registerLifecycleIpc() {
  registerResultHandler('jobs:lifecycle', async (_e, raw) => {
    const req = LifecycleReq.parse(raw);
    const options: { machineId?: number | null; source?: string; payload?: unknown } = {};
    if (Object.prototype.hasOwnProperty.call(req, 'machineId')) {
      options.machineId = req.machineId ?? null;
    }
    if (req.source) {
      options.source = req.source;
    }
    if (Object.prototype.hasOwnProperty.call(req, 'payload')) {
      options.payload = req.payload;
    }
    const result = await updateLifecycle(req.key, req.to, options);
    return ok<typeof result, AppError>(result);
  });
}

================
File: packages/main/src/ipc/log.ts
================
import { ok } from 'neverthrow';
import type { AppError, LogWriteReq } from '../../../shared/src';
import { LogWriteReq as LogWriteReqSchema } from '../../../shared/src';
import { logger } from '../logger';
import { registerResultHandler } from './result';

export function registerLogIpc() {
  registerResultHandler<null>('log:write', async (_event, raw) => {
    const parsed = LogWriteReqSchema.parse(raw ?? {});
    const { level, msg, context } = parsed as LogWriteReq;
    const safeMsg = `renderer: ${msg}`;
    try {
      switch (level) {
        case 'trace':
          logger.trace({ proc: 'Renderer', source: 'renderer', ...context }, safeMsg);
          break;
        case 'debug':
          logger.debug({ proc: 'Renderer', source: 'renderer', ...context }, safeMsg);
          break;
        case 'info':
          logger.info({ proc: 'Renderer', source: 'renderer', ...context }, safeMsg);
          break;
        case 'warn':
          logger.warn({ proc: 'Renderer', source: 'renderer', ...context }, safeMsg);
          break;
        case 'error':
          logger.error({ proc: 'Renderer', source: 'renderer', ...context }, safeMsg);
          break;
        case 'fatal':
          logger.fatal({ proc: 'Renderer', source: 'renderer', ...context }, safeMsg);
          break;
        default:
          logger.info({ proc: 'Renderer', source: 'renderer', ...context }, safeMsg);
      }
    } catch (err) {
      // Last resort: avoid throwing across IPC
      try { logger.warn({ err }, 'log:write failed'); } catch { /* noop */ void 0; }
    }
    return ok<null, AppError>(null);
  });
}

================
File: packages/main/src/ipc/machines.ts
================
import { dialog, BrowserWindow } from 'electron';
import { ok, err } from 'neverthrow';
import type { AppError, MachinesListRes } from '../../../shared/src';
import { SaveMachineReq } from '../../../shared/src';
import { listMachines, saveMachine, deleteMachine } from '../repo/machinesRepo';
import { createAppError } from './errors';
import { registerResultHandler } from './result';

export function registerMachinesIpc() {
  registerResultHandler('machines:list', async () => {
    const items = await listMachines();
    const res: MachinesListRes = { items };
    return ok<MachinesListRes, AppError>(res);
  });

  registerResultHandler('machines:save', async (_e, raw) => {
    const req = SaveMachineReq.parse(raw);
    const saved = await saveMachine(req);
    return ok(saved);
  });

  registerResultHandler('machines:delete', async (_e, rawMachineId) => {
    const machineId = typeof rawMachineId === 'number' ? rawMachineId : Number(rawMachineId);
    if (!Number.isFinite(machineId)) {
      return err(createAppError('machines.invalidId', 'Machine id must be a number'));
    }
    await deleteMachine(machineId);
    return ok<null, AppError>(null);
  });

  registerResultHandler('dialog:pickFolder', async (e) => {
    const parent = BrowserWindow.fromWebContents(e.sender);
    const props = { properties: ['openDirectory', 'createDirectory'] as Array<'openDirectory' | 'createDirectory'> };
    const res = parent ? await dialog.showOpenDialog(parent, props) : await dialog.showOpenDialog(props);
    if (res.canceled || res.filePaths.length === 0) {
      return ok<null, AppError>(null);
    }
    return ok<string, AppError>(res.filePaths[0]);
  });
}

================
File: packages/main/src/ipc/onDestroyed.ts
================
import type { WebContents } from 'electron';
import { logger } from '../logger';

type Cleanup = () => void;

const destroyedCleanups = new WeakMap<WebContents, Set<Cleanup>>();

function attachOnce(contents: WebContents, cleanups: Set<Cleanup>) {
  contents.once('destroyed', () => {
    destroyedCleanups.delete(contents);
    for (const cleanup of cleanups) {
      try {
        cleanup();
      } catch (error) {
        logger.warn({ error }, 'onDestroyed: cleanup threw');
      }
    }
    cleanups.clear();
  });
}

export function onContentsDestroyed(contents: WebContents, cleanup: Cleanup) {
  let cleanups = destroyedCleanups.get(contents);
  if (!cleanups) {
    cleanups = new Set();
    destroyedCleanups.set(contents, cleanups);
    attachOnce(contents, cleanups);
  }
  cleanups.add(cleanup);
}

export function offContentsDestroyed(contents: WebContents, cleanup: Cleanup) {
  const cleanups = destroyedCleanups.get(contents);
  if (!cleanups) {
    return;
  }
  cleanups.delete(cleanup);
  if (cleanups.size === 0) {
    destroyedCleanups.delete(contents);
  }
}

================
File: packages/main/src/ipc/result.ts
================
import type { IpcMainInvokeEvent } from 'electron';
import { ResultAsync, type Result } from 'neverthrow';
import type { AppError } from '../../../shared/src';
import { makeOk, makeErr, toEnvelope, type ResultEnvelope } from '../../../shared/src';
import { toAppError } from './errors';
import { getIpcMain } from './ipcBridge';

export function fromResult<T>(result: Result<T, AppError>): ResultEnvelope<T> {
  return toEnvelope(result);
}

export async function fromPromise<T>(resolver: () => Promise<T>): Promise<ResultEnvelope<T>> {
  const result = await ResultAsync.fromPromise(resolver(), toAppError);
  return toEnvelope(result);
}

export function success<T>(value: T): ResultEnvelope<T> {
  return makeOk(value);
}

export function failure<T>(error: AppError): ResultEnvelope<T> {
  return makeErr<T>(error);
}

export function registerResultHandler<T>(
  channel: string,
  handler: (event: IpcMainInvokeEvent, ...args: unknown[]) => Promise<Result<T, AppError>> | Result<T, AppError>
) {
  const ipcMain = getIpcMain();
  ipcMain.handle(channel, async (event, ...args) => {
    try {
      const result = await handler(event, ...args);
      return fromResult(result);
    } catch (error) {
      return failure<T>(toAppError(error));
    }
  });
}

================
File: packages/main/src/ipc/router.ts
================
import { ok } from 'neverthrow';
import type { AppError } from '../../../shared/src';
import { RouterListReq } from '../../../shared/src';
import { listMachineJobs } from '../repo/routerRepo';
import { registerResultHandler } from './result';

export function registerRouterIpc() {
  registerResultHandler('router:list', async (_e, raw) => {
    const req = RouterListReq.parse(raw ?? {});
    const items = await listMachineJobs(req);
    return ok<{ items: typeof items }, AppError>({ items });
  });
}

================
File: packages/main/src/ipc/settings.ts
================
import { ok } from 'neverthrow';
import type { PathValidationRes, Settings } from '../../../shared/src';
import { promises as fsp } from 'fs';
import { resolve } from 'path';
import { DbSettingsSchema, PathValidationReq } from '../../../shared/src';
import { getConfigPath, loadConfig, mergeSettings, overwriteConfig } from '../services/config';
import { testConnection, resetPool } from '../services/db';
import { triggerDbStatusCheck } from '../services/dbWatchdog';
import { registerResultHandler } from './result';

export function registerSettingsIpc() {
  registerResultHandler('settings:get', async () => ok(loadConfig()));

  // Expose the resolved on-disk path of the settings file for display in UI
  registerResultHandler('settings:path', async () => ok(getConfigPath()));

  registerResultHandler('settings:save', async (_e, next) => {
    const update = (typeof next === 'object' && next !== null ? (next as Partial<Settings>) : {}) ?? {};
    const resolved = mergeSettings({ ...update });
    overwriteConfig(resolved);
    await resetPool();
    triggerDbStatusCheck();
    return ok(resolved);
  });

  registerResultHandler('settings:validatePath', async (_event, raw) => {
    const req = PathValidationReq.parse(raw);
    const input = req.path.trim();
    const resolved = resolve(input);
    try {
      const stats = await fsp.stat(resolved);
      const result: PathValidationRes = {
        path: resolved,
        exists: true,
        isDirectory: stats.isDirectory(),
        isFile: stats.isFile(),
        error: null
      };
      return ok(result);
    } catch (err) {
      const message = err instanceof Error ? err.message : String(err);
      const result: PathValidationRes = {
        path: resolved,
        exists: false,
        isDirectory: false,
        isFile: false,
        error: message
      };
      return ok(result);
    }
  });

  registerResultHandler('db:test', async (_e, dbSettings) => {
    const cfg = DbSettingsSchema.parse(dbSettings);
    const current = loadConfig();
    const effective = {
      ...cfg,
      password: cfg.password === '********' ? current.db.password : cfg.password
    };
    const res = await testConnection(effective);
    return ok(res);
  });
}

================
File: packages/main/src/ipc/telemetry.ts
================
import { ok } from 'neverthrow';
import type { AppError, TelemetrySummaryReq, TelemetrySummaryRes } from '../../../shared/src';
import { TelemetrySummaryReq as TelemetrySummaryReqSchema } from '../../../shared/src';
import { registerResultHandler } from './result';
import { summarizeTelemetry } from '../repo/telemetryRepo';
import type { WebContents } from 'electron';
import { onContentsDestroyed } from './onDestroyed';
import { logger } from '../logger';

export function registerTelemetryIpc() {
  registerResultHandler('telemetry:summary', async (_e, raw) => {
    const req = TelemetrySummaryReqSchema.parse(raw ?? {} as TelemetrySummaryReq);
    const items = await summarizeTelemetry(req);
    const res: TelemetrySummaryRes = { items };
    return ok<TelemetrySummaryRes, AppError>(res);
  });

  type Sub = { timer: NodeJS.Timeout; req: TelemetrySummaryReq; lastHash: string | null };
  const POLL_MS = 5000;
  const subs = new Map<number, Sub>();

  async function push(contents: WebContents, entry: Sub) {
    try {
      const items = await summarizeTelemetry(entry.req);
      const res: TelemetrySummaryRes = { items };
      const hash = JSON.stringify(res);
      if (entry.lastHash !== hash) {
        entry.lastHash = hash;
        if (!contents.isDestroyed()) contents.send('telemetry:update', res);
        logger.debug({ items: items.length }, 'telemetry: pushed update');
      }
    } catch (err) {
      logger.error({ err }, 'telemetry: push failed');
    }
  }

  function ensure(contents: WebContents, req: TelemetrySummaryReq) {
    const id = contents.id;
    const existing = subs.get(id);
    if (existing) {
      existing.req = req;
      existing.lastHash = null;
      void push(contents, existing);
      return;
    }
    const entry: Sub = { req, lastHash: null, timer: setInterval(() => void push(contents, entry), POLL_MS) };
    subs.set(id, entry);
    onContentsDestroyed(contents, () => release(contents));
    void push(contents, entry);
  }

  function release(contents: WebContents) {
    const id = contents.id;
    const entry = subs.get(id);
    if (!entry) return;
    clearInterval(entry.timer);
    subs.delete(id);
  }

  registerResultHandler('telemetry:subscribe', async (event, raw) => {
    const req = TelemetrySummaryReqSchema.parse(raw ?? {} as TelemetrySummaryReq);
    logger.debug({ req }, 'telemetry: subscribe');
    ensure(event.sender, req);
    return ok<null, AppError>(null);
  });

  registerResultHandler('telemetry:unsubscribe', async (event) => {
    logger.debug('telemetry: unsubscribe');
    release(event.sender);
    return ok<null, AppError>(null);
  });
}

================
File: packages/main/src/ipc/ui.ts
================
import { ok, err } from 'neverthrow';
import type { AppError } from '../../../shared/src';
import { ThemePreferenceReq } from '../../../shared/src';
import type { ThemePreferenceRes } from '../../../shared/src';
import { getThemePreference, setThemePreference } from '../services/uiState';
import { createAppError } from './errors';
import { registerResultHandler } from './result';

export function registerUiIpc() {
  registerResultHandler('ui:theme:get', async () => ok<ThemePreferenceRes, AppError>({ preference: getThemePreference() }));

  registerResultHandler('ui:theme:set', async (_event, raw) => {
    try {
      const req = ThemePreferenceReq.parse(raw ?? {});
      setThemePreference(req.preference);
      return ok<ThemePreferenceRes, AppError>({ preference: req.preference });
    } catch (error) {
      return err(createAppError('UI_THEME_SET_FAILED', error instanceof Error ? error.message : String(error)));
    }
  });
}

================
File: packages/main/src/logger.ts
================
import { app } from 'electron';
import { createWriteStream, existsSync, mkdirSync, readdirSync, unlinkSync, type WriteStream } from 'fs';
import { join } from 'path';
import { Writable } from 'stream';
import pino, { multistream, type Level, type StreamEntry } from 'pino';
import { isMainThread, parentPort } from 'worker_threads';

const FALLBACK_LOG_DIR = join(process.cwd(), 'logs');
const DEFAULT_RETENTION_DAYS = 14;

function resolveLogDirectory(): string {
  const envDir = process.env.WOODTRON_LOG_DIR?.trim();
  if (envDir) return envDir;
  try {
    return join(app.getPath('userData'), 'logs');
  } catch {
    return FALLBACK_LOG_DIR;
  }
}

function resolveRetentionDays(): number {
  const fromEnv = Number.parseInt(process.env.WOODTRON_LOG_RETENTION ?? '', 10);
  if (Number.isFinite(fromEnv) && fromEnv > 0) return fromEnv;
  return DEFAULT_RETENTION_DAYS;
}

const logDir = resolveLogDirectory();
if (!existsSync(logDir)) {
  mkdirSync(logDir, { recursive: true });
}

const retentionDays = resolveRetentionDays();
const VALID_LEVELS: Level[] = ['fatal', 'error', 'warn', 'info', 'debug', 'trace'];

function resolveLogLevel(): Level {
  const requested = (process.env.LOG_LEVEL ?? '').toLowerCase();
  if (VALID_LEVELS.includes(requested as Level)) {
    return requested as Level;
  }
  return process.env.NODE_ENV === 'development' ? 'debug' : 'info';
}

// Avoid empty catch blocks: provide resilient fallbacks for warnings/logging
function safeWarn(...args: unknown[]) {
  try {
    // eslint-disable-next-line no-console
    console.warn(...args);
  } catch {
    try {
      const text = args.map((a) => (a instanceof Error ? a.stack || a.message : String(a))).join(' ');
      process.stderr.write(`[WARN] ${text}\n`);
    } catch {
      /* noop */
    }
  }
}

function safeLog(...args: unknown[]) {
  try {
    // eslint-disable-next-line no-console
    console.log(...args);
  } catch {
    try {
      const text = args.map((a) => (a instanceof Error ? a.stack || a.message : String(a))).join(' ');
      process.stdout.write(`${text}\n`);
    } catch {
      /* noop */
    }
  }
}

class RotatingFileStream extends Writable {
  private currentDate: string | null = null;
  private stream: WriteStream | null = null;
  private cleanupScheduled = false;
  private pending: Buffer[] = [];
  private opening = false;

  constructor(private readonly directory: string, private readonly retention: number) {
    super();
  }

  private formatDateKey(epochMs: number) {
    const date = new Date(epochMs);
    const yyyy = date.getFullYear();
    const mm = String(date.getMonth() + 1).padStart(2, '0');
    const dd = String(date.getDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  }

  private scheduleCleanup() {
    if (this.cleanupScheduled) return;
    this.cleanupScheduled = true;
    const timer = setTimeout(() => {
      this.cleanupScheduled = false;
      try {
        const entries = readdirSync(this.directory)
          .filter((name) => name.endsWith('.log'))
          .sort();
        const allowed = Math.max(this.retention, 1);
        if (entries.length > allowed) {
          const excess = entries.slice(0, entries.length - allowed);
          for (const file of excess) {
            try {
              unlinkSync(join(this.directory, file));
            } catch (err) {
              console.warn('logger: failed to prune log file', err);
            }
          }
        }
      } catch (err) {
        safeWarn('logger: failed to enumerate log directory', err);
      }
    }, 1_000);
    if (typeof timer.unref === 'function') timer.unref();
  }

  private attachStreamHandlers(target: WriteStream) {
    target.on('error', (err) => {
      safeWarn('logger: file stream error; attempting reopen', err);
      this.stream = null;
      this.opening = false;
    });
  }

  private openStream(dateKey: string) {
    if (this.opening) return;
    this.opening = true;
    try {
      const destination = join(this.directory, `${dateKey}.log`);
      const s = createWriteStream(destination, { flags: 'a' });
      this.attachStreamHandlers(s);
      this.stream = s;
      this.currentDate = dateKey;
      this.scheduleCleanup();
    } catch (err) {
      safeWarn('logger: failed to open log file', err);
      this.stream = null;
    } finally {
      this.opening = false;
    }
  }

  private rotateIfNeeded(dateKey: string) {
    if (this.currentDate === dateKey && this.stream) return;
    try {
      this.stream?.end();
    } catch (err) {
      safeWarn('logger: failed to close previous log stream', err);
    }
    this.openStream(dateKey);
  }

  override _write(chunk: Buffer | string, encoding: BufferEncoding, callback: (error?: Error | null) => void) {
    try {
      const buffer = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);
      let time = Date.now();
      let line: string | null = null;
      try {
        const parsed = JSON.parse(buffer.toString('utf8')) as {
          time?: number;
          level?: number;
          msg?: string;
          err?: { message?: string } | unknown;
          pid?: number;
          proc?: string;
          [key: string]: unknown;
        };
        if (typeof parsed?.time === 'number') time = parsed.time;
        const levelMap: Record<number, string> = {
          10: 'TRACE',
          20: 'DEBUG',
          30: 'INFO',
          40: 'WARN',
          50: 'ERROR',
          60: 'FATAL'
        };
        const date = new Date(time);
        const hhmmss = date.toLocaleTimeString('en-GB', { hour12: false });
        const day = String(date.getDate()).padStart(2, '0');
        const mon = date.toLocaleString('en-GB', { month: 'short' });
      const levelLabel = typeof parsed?.level === 'number' ? (levelMap[parsed.level] || 'INFO') : 'INFO';
      const proc = typeof parsed?.proc === 'string' ? parsed.proc : (isMainThread ? 'Main' : 'Watchers');
        const message = parsed?.msg ?? '';
        const e = parsed?.err;
        const errMsg = (e && typeof e === 'object' && 'message' in (e as Record<string, unknown>) && typeof (e as { message?: unknown }).message === 'string')
          ? ` - ${(e as { message: string }).message}`
          : '';
        line = `${levelLabel} ${proc} | ${hhmmss} ${day} ${mon} | ${message}${errMsg}`;
      } catch {
        // Fallback: write raw text if parsing fails
        line = buffer.toString('utf8');
      }
      const dateKey = this.formatDateKey(time);
      this.rotateIfNeeded(dateKey);
      if (!this.stream) {
        this.openStream(dateKey);
      }
      const toWrite = Buffer.from((line ?? '') + (line?.endsWith('\n') ? '' : '\n'), 'utf8');
      const writeOrBuffer = (buf: Buffer) => {
        if (this.stream) {
          const ok = this.stream.write(buf);
          if (!ok) this.stream.once('drain', () => this.flushPending());
        } else {
          this.pending.push(buf);
        }
      };
      writeOrBuffer(toWrite);
      this.flushPending();
      callback();
    } catch (err) {
      callback(err as Error);
    }
  }

  override _final(callback: (error?: Error | null) => void) {
    try {
      this.flushPending();
      if (this.stream) {
        this.stream.end(callback);
      } else {
        callback();
      }
    } catch (err) {
      callback(err as Error);
    }
  }

  private flushPending() {
    if (!this.stream || this.pending.length === 0) return;
    try {
      while (this.pending.length > 0 && this.stream) {
        const buf = this.pending.shift()!;
        const ok = this.stream.write(buf);
        if (!ok) {
          this.stream.once('drain', () => this.flushPending());
          break;
        }
      }
    } catch (err) {
      safeWarn('logger: flush failed', err);
    }
  }
}

const level = resolveLogLevel();

class CleanConsoleStream extends Writable {
  override _write(chunk: Buffer | string, encoding: BufferEncoding, callback: (error?: Error | null) => void) {
    try {
      const buffer = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);
      const logEntry = JSON.parse(buffer.toString('utf8')) as {
        level: number;
        time: number;
        msg: string;
        err?: { message?: string };
        proc?: string;
        [key: string]: unknown;
      };

      const levelMap: Record<number, string> = {
        10: 'TRACE',
        20: 'DEBUG',
        30: 'INFO',
        40: 'WARN',
        50: 'ERROR',
        60: 'FATAL'
      };

      const date = new Date(logEntry.time);
      const hhmmss = date.toLocaleTimeString('en-GB', { hour12: false });
      const day = String(date.getDate()).padStart(2, '0');
      const mon = date.toLocaleString('en-GB', { month: 'short' });
      const levelLabel = levelMap[logEntry.level] || 'INFO';
      const proc = typeof logEntry?.proc === 'string' ? logEntry.proc : (isMainThread ? 'Main' : 'Watchers');

      let message = `${proc} | ${hhmmss} ${day} ${mon} | ${logEntry.msg}`;
      if (logEntry.err?.message) {
        message += ` - ${logEntry.err.message}`;
      }
      // Include level prefix for console visibility
      console.log(`${levelLabel} ${message}`);
      callback();
    } catch (err) {
      callback(err as Error);
    }
  }
}

const streams: StreamEntry[] = [
  { stream: new CleanConsoleStream(), level },
  { stream: new RotatingFileStream(logDir, retentionDays), level }
];

// In worker threads, proxy logs to main via parentPort so all logs go through unified writer
function makeWorkerProxyLogger() {
  const post = (lvl: Level, msg: string, context?: Record<string, unknown>) => {
    try {
      parentPort?.postMessage({ type: 'log', level: lvl, msg, context });
    } catch {
      // Fallback if parentPort is missing
      safeLog(`[${lvl.toUpperCase()}] ${msg}`);
    }
  };
  const asCtx = (v: unknown): Record<string, unknown> | undefined =>
    v && typeof v === 'object' ? (v as Record<string, unknown>) : undefined;
  const emit = (lvl: Level, a: unknown, b?: unknown) => {
    if (typeof a === 'string' && typeof b === 'undefined') return post(lvl, a);
    if (typeof b === 'string') return post(lvl, b, asCtx(a));
    return post(lvl, String(b ?? a ?? ''));
  };
  return {
    trace: (a: unknown, b?: unknown) => emit('trace', a, b),
    debug: (a: unknown, b?: unknown) => emit('debug', a, b),
    info: (a: unknown, b?: unknown) => emit('info', a, b),
    warn: (a: unknown, b?: unknown) => emit('warn', a, b),
    error: (a: unknown, b?: unknown) => emit('error', a, b),
    fatal: (a: unknown, b?: unknown) => emit('fatal', a, b)
  } as unknown as ReturnType<typeof pino>;
}

export const logger = isMainThread ? pino({ level }, multistream(streams)) : makeWorkerProxyLogger();

export function getLogDirectory() {
  return logDir;
}

export function listLogFiles(): string[] {
  try {
    return readdirSync(logDir)
      .filter((name) => name.endsWith('.log'))
      .map((name) => join(logDir, name))
      .sort();
  } catch {
    return [];
  }
}

================
File: packages/main/src/main.ts
================
import { app, BrowserWindow } from 'electron';
import { join } from 'path';
import { registerSettingsIpc } from './ipc/settings';
import { registerJobsIpc } from './ipc/jobs';
import { registerDbIpc } from './ipc/db';
import { registerMachinesIpc } from './ipc/machines';
import { registerFilesIpc } from './ipc/files';
import { registerRouterIpc } from './ipc/router';
import { registerLifecycleIpc } from './ipc/lifecycle';
import { registerHypernestIpc } from './ipc/hypernest';
import { registerHistoryIpc } from './ipc/history';
import { registerAlarmsIpc } from './ipc/alarms';
import { registerDiagnosticsIpc } from './ipc/diagnostics';
import { registerLogIpc } from './ipc/log';
import { registerTelemetryIpc } from './ipc/telemetry';
import { registerUiIpc } from './ipc/ui';
import { registerGrundnerIpc } from './ipc/grundner';
import { initWatchers, shutdownWatchers } from './services/watchers';
import { startDbWatchdog, stopDbWatchdog } from './services/dbWatchdog';
import { logger } from './logger';
import { initializeDiagnostics } from './services/diagnostics';
import { applyStoredThemePreference, getStoredWindowState, monitorWindowState } from './services/uiState';
import {
  applyWindowNavigationGuards,
  ensureContentSecurityPolicy,
  logSecurityConfigurationSummary
} from './security';

let win: BrowserWindow | null = null;

// Allow local file XHR/fetch when loading Hypernest via file://
// If you prefer to keep WebSecurity strict, remove this and instead
// read any needed files via an explicit IPC from main.
app.commandLine.appendSwitch('allow-file-access-from-files');

function createWindow() {
  const state = getStoredWindowState();
  const options: Electron.BrowserWindowConstructorOptions = {
    width: state.width,
    height: state.height,
    webPreferences: {
      preload: join(__dirname, '../../preload/dist/index.js'),
      contextIsolation: true,
      sandbox: true,
      nodeIntegration: false,
      webSecurity: true
    },
    show: false
  };
  if (state.x != null && state.y != null) {
    options.x = state.x;
    options.y = state.y;
  }

  win = new BrowserWindow(options);
  monitorWindowState(win);

  applyWindowNavigationGuards(win.webContents);

  win.on('ready-to-show', () => {
    if (!win) return;
    if (state.maximized) {
      win.maximize();
    }
    win.show();
  });

  if (process.env.VITE_DEV_SERVER_URL) {
    win.loadURL(process.env.VITE_DEV_SERVER_URL);
  } else {
    win.loadFile(join(__dirname, '../../renderer/dist/index.html'));
  }
}

app.whenReady().then(async () => {
  const userDataPath = app.getPath('userData');
  process.env.WOODTRON_USER_DATA_PATH = userDataPath;
  process.env.WOODTRON_CONFIG_PATH = join(userDataPath, 'settings.json');

  applyStoredThemePreference();

  ensureContentSecurityPolicy();
  logSecurityConfigurationSummary();

  registerSettingsIpc();
  registerDbIpc();
  registerJobsIpc();
  registerMachinesIpc();
  registerFilesIpc();
  registerRouterIpc();
  registerLifecycleIpc();
  registerHypernestIpc();
  registerHistoryIpc();
  registerAlarmsIpc();
  registerDiagnosticsIpc();
  registerUiIpc();
  registerTelemetryIpc();
  registerLogIpc();
  registerGrundnerIpc();

  try {
    await initializeDiagnostics();
  } catch (error) {
    logger.warn({ error }, 'Failed to initialize diagnostics subsystem');
  }

  try {
    startDbWatchdog();
  } catch (error) {
    logger.error({ error }, 'Failed to start database watchdog');
  }

  initWatchers();
  createWindow();

  app.on('activate', () => {
    if (BrowserWindow.getAllWindows().length === 0) {
      createWindow();
    }
  });
});

app.on('window-all-closed', () => {
  if (process.platform !== 'darwin') app.quit();
});

process.on('uncaughtException', (err) => logger.error({ err }, 'Uncaught exception'));
process.on('unhandledRejection', (err) => logger.error({ err }, 'Unhandled rejection'));

app.on('will-quit', async () => {
  try {
    await shutdownWatchers();
  } catch (err) {
    logger.error({ err }, 'Failed to stop watchers worker');
  }

  try {
    stopDbWatchdog();
  } catch (err) {
    logger.error({ err }, 'Failed to stop DB watchdog');
  }
});

================
File: packages/main/src/repo/alarmsHistoryRepo.ts
================
import { withClient } from '../services/db';
import { logger } from '../logger';
import type { AlarmIntervalRow, AlarmsHistoryReq } from '../../../shared/src';

type SeriesRow = {
  machine_id: number | null;
  machine_name: string | null;
  ts: string; // ISO timestamp from SQL
  alarm: string | null;
};

function toIsoOrNull(value: unknown): string | null {
  if (typeof value === 'string') return value;
  if (value instanceof Date) return value.toISOString();
  return null;
}

function toDate(value: string): Date {
  return new Date(value);
}

function dayKey(d: Date): string {
  const y = d.getFullYear();
  const m = String(d.getMonth() + 1).padStart(2, '0');
  const day = String(d.getDate()).padStart(2, '0');
  return `${y}-${m}-${day}`;
}

function normalizeAlarmText(value: string | null | undefined): string | null {
  if (value == null) return null;
  const trimmed = value.trim();
  if (trimmed.length === 0) return null;
  if (trimmed === '****') return null; // explicitly ignore only ****
  return trimmed;
}

function parseAlarmIdAndDesc(alarm: string): { id: string | null; description: string } {
  const m = alarm.match(/^\s*\(([^)]+)\)\s*(.*)$/);
  if (m) {
    const id = m[1].trim();
    const desc = (m[2] ?? '').trim();
    return { id: id.length ? id : null, description: desc.length ? desc : alarm };
  }
  return { id: null, description: alarm.trim() };
}

export async function listAlarmIntervals(req: AlarmsHistoryReq): Promise<AlarmIntervalRow[]> {
  const fromIso = req.from ?? null;
  const toIso = req.to ?? null;

  logger.debug({ fromIso, toIso, machineIds: req.machineIds }, 'alarms: history summarize');

  const params: unknown[] = [];
  let idx = 1;
  let where = 'WHERE 1=1';

  if (fromIso) {
    where += ` AND to_timestamp(cs.key, 'YYYY.MM.DD HH24:MI:SS') >= $${idx++}`;
    params.push(new Date(fromIso));
  }
  if (toIso) {
    where += ` AND to_timestamp(cs.key, 'YYYY.MM.DD HH24:MI:SS') <= $${idx++}`;
    params.push(new Date(toIso));
  }
  if (req.machineIds && req.machineIds.length) {
    where += ` AND m.machine_id = ANY($${idx++})`;
    params.push(req.machineIds);
  }

  const sql = `
    SELECT
      m.machine_id,
      m.name AS machine_name,
      to_timestamp(cs.key, 'YYYY.MM.DD HH24:MI:SS') AS ts,
      cs.alarm
    FROM public.cncstats cs
    LEFT JOIN public.machines m
      ON lower(btrim(m.pc_ip::text)) = split_part(split_part(regexp_replace(lower(btrim(cs.api_ip)), '^https?://', ''), '/', 1), ':', 1)
    ${where}
    ORDER BY m.machine_id NULLS LAST, ts ASC
  `;

  logger.debug({ sql, params }, 'alarms: executing SQL');

  const rows = await withClient<SeriesRow[]>((client) =>
    client.query(sql, params).then((r) => {
      logger.debug({ rowCount: r.rowCount }, 'alarms: SQL returned rows');
      return r.rows.map((row) => ({
        machine_id: row.machine_id == null ? null : Number(row.machine_id),
        machine_name: row.machine_name ?? null,
        alarm: row.alarm ?? null,
        ts: toIsoOrNull(row.ts) ?? new Date(row.ts as unknown as string).toISOString()
      }));
    })
  );

  // group by machine (string key to allow null)
  const byMachine = new Map<string, SeriesRow[]>();
  for (const r of rows) {
    const k = r.machine_id == null ? 'null' : String(r.machine_id);
    if (!byMachine.has(k)) byMachine.set(k, []);
    byMachine.get(k)!.push(r);
  }

  const intervals: AlarmIntervalRow[] = [];

  for (const [, series] of byMachine.entries()) {
    const machineId = series[0]?.machine_id ?? null;
    const machineName = series[0]?.machine_name ?? null;
    // split by day
    const byDay = new Map<string, SeriesRow[]>();
    for (const p of series) {
      const k = dayKey(toDate(p.ts));
      if (!byDay.has(k)) byDay.set(k, []);
      byDay.get(k)!.push(p);
    }

    for (const [, points] of byDay.entries()) {
      if (!points.length) continue;
      // walk alarm changes within the day
      let current: string | null = null;
      let startAt: Date | null = null;
      for (let i = 0; i < points.length - 1; i++) {
        const curr = points[i];
        const next = points[i + 1];
        const alarm = normalizeAlarmText(curr.alarm);
        if (current == null && alarm != null) {
          current = alarm;
          startAt = toDate(curr.ts);
          continue;
        }
        if (current != null) {
          const thisAlarm = alarm;
          if (thisAlarm !== current) {
            // alarm changed or cleared at next point => close interval at next.ts
            const endAt = toDate(next.ts);
            const minutes = Math.max(0, Math.round((endAt.getTime() - (startAt ?? toDate(curr.ts)).getTime()) / 60000));
            const { id, description } = parseAlarmIdAndDesc(current);
            intervals.push({
              startAt: (startAt ?? toDate(curr.ts)).toISOString(),
              endAt: endAt.toISOString(),
              durationMinutes: minutes,
              machineId,
              machineName,
              alarmId: id,
              description
            });
            current = thisAlarm;
            startAt = thisAlarm ? toDate(next.ts) : null;
          }
        }
      }
      // End of day handling: if last point still in alarm, assign 1 minute
      const last = points[points.length - 1];
      const lastAlarm = current ?? normalizeAlarmText(last.alarm);
      if (lastAlarm) {
        const { id, description } = parseAlarmIdAndDesc(lastAlarm);
        const endStart = startAt ?? toDate(last.ts);
        intervals.push({
          startAt: endStart.toISOString(),
          endAt: null,
          durationMinutes: 1,
          machineId,
          machineName,
          alarmId: id,
          description
        });
      }
    }
  }

  logger.debug({ intervals: intervals.length }, 'alarms: summarized intervals');
  return intervals;
}

================
File: packages/main/src/repo/alarmsRepo.ts
================
import { withClient } from '../services/db';
import { logger } from '../logger';
import type { AlarmEntry } from '../../../shared/src';

type RawAlarmRow = {
  key: string;
  api_ip: string | null;
  alarm: string | null;
  status: string | null;
  mode: string | null;
  currentprogram: string | null;
  alarmhistory: string | null;
};

const INACTIVE_VALUES = new Set<string>(['', 'ok', 'ready', 'none', 'no alarm', '0']);

function normalizeAlarm(value: string | null | undefined): string | null {
  if (!value) return null;
  const trimmed = value.trim();
  if (!trimmed) return null;
  if (INACTIVE_VALUES.has(trimmed.toLowerCase())) return null;
  return trimmed;
}

function inferSeverity(alarmText: string): AlarmEntry['severity'] {
  const lowered = alarmText.toLowerCase();
  if (lowered.includes('emergency') || lowered.includes('fault') || lowered.includes('alarm')) {
    return 'critical';
  }
  if (lowered.includes('warning') || lowered.includes('warn')) {
    return 'warning';
  }
  return 'info';
}

export async function listActiveAlarms(): Promise<AlarmEntry[]> {
  // Select the most recent row per machine IP (api_ip) using the timestamp stored in `key`.
  // The `key` has format: YYYY.MM.DD HH24:MI:SS (e.g., 2025.04.16 12:58:06).
  // We filter obvious inactive alarms at the DB level to reduce payload.
  const sql = `
    SELECT DISTINCT ON (lower(api_ip))
      key, api_ip, alarm, status, mode, currentprogram, alarmhistory
    FROM public.cncstats
    WHERE api_ip IS NOT NULL AND btrim(api_ip) <> ''
      AND alarm IS NOT NULL AND btrim(alarm) <> ''
      AND lower(alarm) NOT IN ('ok','ready','none','no alarm','0')
    ORDER BY lower(api_ip), to_timestamp(key, 'YYYY.MM.DD HH24:MI:SS') DESC NULLS LAST
  `;
  try {
    const rows = await withClient<RawAlarmRow[]>((client) =>
      client.query<RawAlarmRow>(sql).then((result) => result.rows)
    );

    const nowIso = new Date().toISOString();

    const active: AlarmEntry[] = [];
    for (const row of rows) {
      const alarm = normalizeAlarm(row.alarm);
      if (!alarm) continue;
      const machineKey = (row.api_ip && row.api_ip.trim()) ? row.api_ip.trim().toLowerCase() : row.key;
      const id = `${machineKey}:${alarm}`;
      const severity = inferSeverity(alarm);
      active.push({
        id,
        key: machineKey,
        alarm,
        status: row.status ?? null,
        mode: row.mode ?? null,
        currentProgram: row.currentprogram ?? null,
        alarmHistory: row.alarmhistory ?? null,
        lastSeenAt: nowIso,
        severity
      });
    }
    return active;
  } catch (err) {
    logger.error({ err }, 'alarmRepo: failed to list active alarms');
    return [];
  }
}

================
File: packages/main/src/repo/cncStatsRepo.ts
================
import { withClient } from '../services/db';
import type { PoolClient } from 'pg';

export interface CncStatsUpsert {
  key: string;
  apiIp: string | null;
  currentProgram: string | null;
  mode: string | null;
  status: string | null;
  alarm: string | null;
  emg: string | null;
  powerOnTime: string | null;
  cuttingTime: string | null;
  alarmHistory: string | null;
  vacuumTime: string | null;
  drillHeadTime: string | null;
  spindleTime: string | null;
  conveyorTime: string | null;
  greaseTime: string | null;
}

function sanitize(value: string | null | undefined, limit: number): string | null {
  if (value == null) return null;
  const trimmed = value.trim();
  if (!trimmed) return null;
  if (trimmed.length <= limit) return trimmed;
  return trimmed.slice(0, limit);
}

export async function upsertCncStats(row: CncStatsUpsert, client?: PoolClient): Promise<void> {
  const key = sanitize(row.key, 100);
  if (!key) {
    throw new Error('CNC telemetry key cannot be empty');
  }
  const sql = `
    INSERT INTO public.cncstats(
      key, api_ip, currentprogram, mode, status, alarm, emg, powerontime, cuttingtime,
      alarmhistory, vacuumtime, drillheadtime, spindletime, conveyortime, greasetime
    ) VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15)
    ON CONFLICT (key) DO UPDATE SET
      api_ip = EXCLUDED.api_ip,
      currentprogram = EXCLUDED.currentprogram,
      mode = EXCLUDED.mode,
      status = EXCLUDED.status,
      alarm = EXCLUDED.alarm,
      emg = EXCLUDED.emg,
      powerontime = EXCLUDED.powerontime,
      cuttingtime = EXCLUDED.cuttingtime,
      alarmhistory = EXCLUDED.alarmhistory,
      vacuumtime = EXCLUDED.vacuumtime,
      drillheadtime = EXCLUDED.drillheadtime,
      spindletime = EXCLUDED.spindletime,
      conveyortime = EXCLUDED.conveyortime,
      greasetime = EXCLUDED.greasetime
  `;
  const params = [
    key,
    sanitize(row.apiIp, 100),
    sanitize(row.currentProgram, 50),
    sanitize(row.mode, 50),
    sanitize(row.status, 50),
    sanitize(row.alarm, 50),
    sanitize(row.emg, 50),
    sanitize(row.powerOnTime, 50),
    sanitize(row.cuttingTime, 50),
    sanitize(row.alarmHistory, 50),
    sanitize(row.vacuumTime, 50),
    sanitize(row.drillHeadTime, 50),
    sanitize(row.spindleTime, 50),
    sanitize(row.conveyorTime, 50),
    sanitize(row.greaseTime, 50)
  ];
  if (client) {
    await client.query({ name: 'upsert_cncstats_v1', text: sql, values: params });
  } else {
    await withClient((c) => c.query({ name: 'upsert_cncstats_v1', text: sql, values: params }));
  }
}

================
File: packages/main/src/repo/grundnerRepo.ts
================
import type { QueryResult } from "pg";
import { withClient } from '../services/db';
import { getGrundnerLookupColumn, resolveMaterialKey } from '../services/grundner';
import type { GrundnerListReq, GrundnerUpdateReq, GrundnerRow } from '../../../shared/src';

type SqlParam = string | number | boolean | null | Date;

type GrundnerRowDb = {
  id: number;
  type_data: number | null;
  customer_id: string | null;
  length_mm: number | null;
  width_mm: number | null;
  thickness_mm: number | null;
  stock: number | null;
  stock_available: number | null;
  reserved_stock: number | null;
  last_updated: string | null;
};

type GrundnerKeyRow = {
  id: number;
  type_data: number | null;
  customer_id: string | null;
};

function mapRow(row: GrundnerRowDb): GrundnerRow {
  return {
    id: row.id,
    typeData: row.type_data,
    customerId: row.customer_id,
    lengthMm: row.length_mm,
    widthMm: row.width_mm,
    thicknessMm: row.thickness_mm,
    stock: row.stock,
    stockAvailable: row.stock_available,
    reservedStock: row.reserved_stock,
    lastUpdated: row.last_updated
  };
}

export async function listGrundner(req: GrundnerListReq) {
  const { limit, filter } = req;
  const params: SqlParam[] = [];
  const where: string[] = [];

  if (filter.search && filter.search.trim()) {
    const search = `%${filter.search.trim()}%`;
    params.push(search, search);
    where.push(`(CAST(type_data AS TEXT) ILIKE $${params.length - 1} OR customer_id ILIKE $${params.length})`);
  }
  if (filter.onlyAvailable) {
    where.push('COALESCE(stock_available, 0) > 0');
  }
  if (filter.onlyReserved) {
    where.push('COALESCE(reserved_stock, 0) > 0');
  }
  if (filter.thicknessMin != null) {
    params.push(filter.thicknessMin);
    where.push(`thickness_mm >= $${params.length}`);
  }
  if (filter.thicknessMax != null) {
    params.push(filter.thicknessMax);
    where.push(`thickness_mm <= $${params.length}`);
  }

  params.push(Math.min(Math.max(limit, 1), 500));

  const sql = `
    SELECT id, type_data, customer_id, length_mm, width_mm, thickness_mm,
           stock, stock_available, reserved_stock, last_updated
    FROM public.grundner
    ${where.length ? 'WHERE ' + where.join(' AND ') : ''}
    ORDER BY type_data ASC, customer_id ASC NULLS LAST
    LIMIT $${params.length}
  `;

  const rows = await withClient<GrundnerRowDb[]>((c) =>
    c.query<GrundnerRowDb>(sql, params).then((r: QueryResult<GrundnerRowDb>) => r.rows)
  );
  return rows.map(mapRow);
}

export async function updateGrundnerRow(input: GrundnerUpdateReq) {
  const sets: string[] = [];
  const params: SqlParam[] = [];

  if (Object.prototype.hasOwnProperty.call(input, 'stock')) {
    params.push(input.stock ?? null);
    sets.push(`stock = $${params.length}`);
  }
  if (Object.prototype.hasOwnProperty.call(input, 'stockAvailable')) {
    params.push(input.stockAvailable ?? null);
    sets.push(`stock_available = $${params.length}`);
  }
  if (Object.prototype.hasOwnProperty.call(input, 'reservedStock')) {
    params.push(input.reservedStock ?? null);
    sets.push(`reserved_stock = $${params.length}`);
  }
  if (!sets.length) return { ok: false as const, updated: 0 };

  params.push(input.id);
  const sql = `UPDATE public.grundner
               SET ${sets.join(', ')}, last_updated = now()
               WHERE id = $${params.length}`;
  const res = await withClient((c) => c.query(sql, params));
  return { ok: true as const, updated: res.rowCount ?? 0 };
}

export async function resyncGrundnerReserved(id?: number) {
  return withClient(async (c) => {
    const column = getGrundnerLookupColumn();
    let rows: GrundnerKeyRow[];
    if (id != null) {
      const single = await c.query<GrundnerKeyRow>('SELECT id, type_data, customer_id FROM public.grundner WHERE id = $1', [id]);
      rows = single.rows;
    } else {
      const all = await c.query<GrundnerKeyRow>('SELECT id, type_data, customer_id FROM public.grundner');
      rows = all.rows;
    }

    let updated = 0;
    for (const row of rows) {
      const material = resolveMaterialKey(column, { typeData: row.type_data, customerId: row.customer_id });
      if (!material) continue;
      const res = await c.query(
        `UPDATE public.grundner
           SET reserved_stock = (
             SELECT COUNT(*) FROM public.jobs WHERE material = $1 AND is_reserved = TRUE
           ), last_updated = now()
         WHERE id = $2`,
        [material, row.id]
      );
      updated += res.rowCount ?? 0;
    }
    return updated;
  });
}

// Rows parsed from Grundner stock.csv
export type GrundnerCsvRow = {
  typeData: number | null;
  customerId: string | null;
  lengthMm: number | null;
  widthMm: number | null;
  thicknessMm: number | null;
  stock: number | null;
  stockAvailable: number | null;
};

export async function upsertGrundnerInventory(rows: GrundnerCsvRow[]): Promise<{ inserted: number; updated: number }> {
  if (!rows.length) return { inserted: 0, updated: 0 };
  const columns = ['type_data', 'customer_id', 'length_mm', 'width_mm', 'thickness_mm', 'stock', 'stock_available'] as const;
  const chunkSize = 200; // avoid huge single statements
  let inserted = 0;
  let updated = 0;

  await withClient(async (c) => {
    for (let i = 0; i < rows.length; i += chunkSize) {
      const batch = rows.slice(i, i + chunkSize);
      const params: Array<string | number | null> = [];
      const tuples = batch.map((r, idx) => {
        const base = idx * columns.length;
        params.push(
          r.typeData,
          r.customerId,
          r.lengthMm,
          r.widthMm,
          r.thicknessMm,
          r.stock,
          r.stockAvailable
        );
        const ph = columns.map((_, j) => `$${base + j + 1}`).join(',');
        return `(${ph}, now())`;
      }).join(',');

      const sql = `
        INSERT INTO public.grundner (${columns.join(', ')}, last_updated)
        VALUES ${tuples}
        ON CONFLICT (type_data, customer_id) DO UPDATE SET
          length_mm = EXCLUDED.length_mm,
          width_mm = EXCLUDED.width_mm,
          thickness_mm = EXCLUDED.thickness_mm,
          stock = EXCLUDED.stock,
          stock_available = EXCLUDED.stock_available,
          last_updated = now()
        WHERE (
          COALESCE(grundner.length_mm, -1) IS DISTINCT FROM EXCLUDED.length_mm OR
          COALESCE(grundner.width_mm, -1) IS DISTINCT FROM EXCLUDED.width_mm OR
          COALESCE(grundner.thickness_mm, -1) IS DISTINCT FROM EXCLUDED.thickness_mm OR
          COALESCE(grundner.stock, -1) IS DISTINCT FROM EXCLUDED.stock OR
          COALESCE(grundner.stock_available, -1) IS DISTINCT FROM EXCLUDED.stock_available
        )
        RETURNING (xmax = 0) AS inserted;
      `;

      const res = await c.query<{ inserted: boolean }>(sql, params);
      for (const row of res.rows ?? []) {
        if (row.inserted) inserted += 1; else updated += 1;
      }
    }
  });

  return { inserted, updated };
}

================
File: packages/main/src/repo/historyRepo.ts
================
import { and, asc, eq, sql, type SQL } from 'drizzle-orm';
import { jobEvents, jobs, machines } from '../db/schema';
import { withDb } from '../services/db';
import type { HistoryListReq, HistoryRow, JobTimelineEvent, JobTimelineRes } from '../../../shared/src';

type SqlExpression = NonNullable<SQL>;

const FINISH_EXPR = sql<Date | null>`CASE WHEN COALESCE(${machines.nestpickEnabled}, FALSE) THEN ${jobs.nestpickCompletedAt} ELSE ${jobs.cutAt} END`;

type HistoryRowDb = {
  key: string;
  folder: string | null;
  ncfile: string | null;
  material: string | null;
  machineId: number | null;
  machineName: string | null;
  machineNestpickEnabled: boolean | null;
  status: string;
  stagedAt: Date | null;
  cutAt: Date | null;
  nestpickCompletedAt: Date | null;
  finishAtRaw: Date | null;
  pallet: string | null;
  updatedAt: Date | null;
  dateAdded: Date | null;
};

type JobDetailRowDb = {
  key: string;
  folder: string | null;
  ncfile: string | null;
  material: string | null;
  machineId: number | null;
  machineName: string | null;
  machineNestpickEnabled: boolean | null;
  status: string;
  dateAdded: Date | null;
  stagedAt: Date | null;
  cutAt: Date | null;
  nestpickCompletedAt: Date | null;
  finishAtRaw: Date | null;
  pallet: string | null;
  updatedAt: Date | null;
};

type JobEventRowDb = {
  eventType: string;
  createdAt: Date | null;
  machineId: number | null;
  machineName: string | null;
  payload: unknown | null;
};

function toIso(value: Date | string | null | undefined): string | null {
  if (!value) return null;
  const date = value instanceof Date ? value : new Date(value);
  if (Number.isNaN(date.getTime())) return null;
  return date.toISOString();
}

function combineClauses(clauses: SqlExpression[]): SqlExpression {
  if (clauses.length === 0) return sql`true`;
  if (clauses.length === 1) return clauses[0];
  const [first, second, ...rest] = clauses as [SqlExpression, SqlExpression, ...SqlExpression[]];
  const initial = and(first, second) as SqlExpression;
  return rest.reduce<SqlExpression>((acc, clause) => and(acc, clause) as SqlExpression, initial);
}

export async function listHistory(req: HistoryListReq): Promise<HistoryRow[]> {
  const { limit, machineId, search, from, to } = req;
  const safeLimit = Math.max(1, Math.min(limit ?? 100, 200));

  const conditions: SqlExpression[] = [];

  if (machineId != null) {
    conditions.push(eq(jobs.machineId, machineId));
  }

  if (search && search.trim()) {
    const term = `%${search.trim()}%`;
    conditions.push(
      sql`(${jobs.key} ILIKE ${term} OR ${jobs.ncfile} ILIKE ${term} OR ${jobs.folder} ILIKE ${term} OR ${jobs.material} ILIKE ${term})`
    );
  }

  if (from) {
    const fromDate = new Date(from);
    if (!Number.isNaN(fromDate.getTime())) {
      conditions.push(sql`${FINISH_EXPR} >= ${fromDate.toISOString()}`);
    }
  }

  if (to) {
    const toDate = new Date(to);
    if (!Number.isNaN(toDate.getTime())) {
      conditions.push(sql`${FINISH_EXPR} <= ${toDate.toISOString()}`);
    }
  }

  const rows = await withDb((db) => {
    const baseQuery = db
      .select({
        key: jobs.key,
        folder: jobs.folder,
        ncfile: jobs.ncfile,
        material: jobs.material,
        machineId: jobs.machineId,
        machineName: machines.name,
        machineNestpickEnabled: machines.nestpickEnabled,
        status: jobs.status,
        stagedAt: jobs.stagedAt,
        cutAt: jobs.cutAt,
        nestpickCompletedAt: jobs.nestpickCompletedAt,
        pallet: jobs.pallet,
        updatedAt: jobs.updatedAt,
        dateAdded: jobs.dateAdded,
        finishAtRaw: FINISH_EXPR
      })
      .from(jobs)
      .leftJoin(machines, eq(jobs.machineId, machines.machineId));

    const whereClause = combineClauses([sql`${FINISH_EXPR} IS NOT NULL`, ...conditions]);

    const filteredQuery = baseQuery.where(whereClause);

    return filteredQuery.orderBy(sql`${FINISH_EXPR} DESC`).limit(safeLimit);
  }) as HistoryRowDb[];

  return rows.map((row: HistoryRowDb) => {
    const finishAtIso = toIso(row.finishAtRaw);
    if (!finishAtIso) {
      throw new Error(`History row missing finish timestamp for job ${row.key}`);
    }
    const machineNestpickEnabled = row.machineNestpickEnabled ?? null;
    const finishSource: HistoryRow['finishSource'] = machineNestpickEnabled ? 'nestpick' : 'cut';
    return {
      key: row.key,
      folder: row.folder,
      ncfile: row.ncfile,
      material: row.material,
      machineId: row.machineId,
      machineName: row.machineName,
      machineNestpickEnabled,
      status: row.status as HistoryRow['status'],
      stagedAt: toIso(row.stagedAt),
      cutAt: toIso(row.cutAt),
      nestpickCompletedAt: toIso(row.nestpickCompletedAt),
      finishAt: finishAtIso,
      finishSource,
      pallet: row.pallet,
      updatedAt: toIso(row.updatedAt)
    };
  });
}

export async function getJobTimeline(key: string): Promise<JobTimelineRes | null> {
  const jobRow = (await withDb((db) =>
    db
      .select({
        key: jobs.key,
        folder: jobs.folder,
        ncfile: jobs.ncfile,
        material: jobs.material,
        machineId: jobs.machineId,
        machineName: machines.name,
        machineNestpickEnabled: machines.nestpickEnabled,
        status: jobs.status,
        dateAdded: jobs.dateAdded,
        stagedAt: jobs.stagedAt,
        cutAt: jobs.cutAt,
        nestpickCompletedAt: jobs.nestpickCompletedAt,
        finishAtRaw: FINISH_EXPR,
        pallet: jobs.pallet,
        updatedAt: jobs.updatedAt
      })
      .from(jobs)
      .leftJoin(machines, eq(jobs.machineId, machines.machineId))
      .where(eq(jobs.key, key))
      .limit(1)
  )) as JobDetailRowDb[];

  if (!jobRow.length) return null;

  const detail: JobDetailRowDb = jobRow[0];

  const eventRows = (await withDb((db) =>
    db
      .select({
        eventType: jobEvents.eventType,
        createdAt: jobEvents.createdAt,
        machineId: jobEvents.machineId,
        machineName: machines.name,
        payload: jobEvents.payload
      })
      .from(jobEvents)
      .leftJoin(machines, eq(jobEvents.machineId, machines.machineId))
      .where(eq(jobEvents.key, key))
      .orderBy(asc(jobEvents.createdAt), asc(jobEvents.eventId))
  )) as JobEventRowDb[];

  const machineNestpickEnabled = detail.machineNestpickEnabled ?? null;
  const finishAtIso = toIso(detail.finishAtRaw);
  const usedNestpick = Boolean(machineNestpickEnabled && detail.nestpickCompletedAt);
  const finishSource: JobTimelineRes['job']['finishSource'] = finishAtIso
    ? usedNestpick ? 'nestpick' : 'cut'
    : 'pending';

  const events: JobTimelineEvent[] = eventRows.map((row, index) => ({
    id: `${key}:${row.eventType}:${row.createdAt ? toIso(row.createdAt) : index}`,
    eventType: row.eventType,
    createdAt: toIso(row.createdAt),
    machineId: row.machineId,
    machineName: row.machineName,
    payload: row.payload ?? null
  }));

  return {
    job: {
      key: detail.key,
      folder: detail.folder,
      ncfile: detail.ncfile,
      material: detail.material,
      machineId: detail.machineId,
      machineName: detail.machineName,
      machineNestpickEnabled,
      status: detail.status as JobTimelineRes['job']['status'],
      dateadded: toIso(detail.dateAdded),
      stagedAt: toIso(detail.stagedAt),
      cutAt: toIso(detail.cutAt),
      nestpickCompletedAt: toIso(detail.nestpickCompletedAt),
      finishAt: finishAtIso,
      finishSource,
      pallet: detail.pallet,
      updatedAt: toIso(detail.updatedAt)
    },
    events
  };
}

================
File: packages/main/src/repo/jobEventsRepo.ts
================
import type { AppDb } from '../services/db';
import { withDb } from '../services/db';
import { jobEvents } from '../db/schema';
import { desc, eq } from 'drizzle-orm';
import type { JobEvent } from '../../../shared/src';

export async function appendJobEvent(
  key: string,
  eventType: string,
  payload?: unknown,
  machineId?: number | null,
  db?: AppDb
) {
  const values = {
    key,
    eventType,
    payload: payload ?? null,
    machineId: machineId ?? null
  };

  if (db) {
    await db.insert(jobEvents).values(values);
    return;
  }

  await withDb(async (innerDb) => {
    await innerDb.insert(jobEvents).values(values);
  });
}

export async function getJobEvents(key: string, limit: number): Promise<JobEvent[]> {
  const safeLimit = Math.max(1, Math.min(limit, 200));
  const rows = await withDb((db) =>
    db
      .select({
        id: jobEvents.eventId,
        key: jobEvents.key,
        eventType: jobEvents.eventType,
        payload: jobEvents.payload,
        machineId: jobEvents.machineId,
        createdAt: jobEvents.createdAt
      })
      .from(jobEvents)
      .where(eq(jobEvents.key, key))
      .orderBy(desc(jobEvents.createdAt), desc(jobEvents.eventId))
      .limit(safeLimit)
  );

  return rows.map((row) => ({
    id: Number(row.id),
    key: row.key,
    eventType: row.eventType,
    payload: row.payload ?? null,
    machineId: row.machineId ?? null,
    createdAt: row.createdAt ? row.createdAt.toISOString() : new Date().toISOString()
  }));
}

================
File: packages/main/src/repo/jobsRepo.ts
================
import { and, asc, desc, eq, inArray, lt, or, sql, type SQL } from 'drizzle-orm';
import type { JobStatus, JobsFilterOptions, JobsListReq } from '../../../shared/src';
import { appendJobEvent } from './jobEventsRepo';
import { getGrundnerLookupColumn, getGrundnerMode } from '../services/grundner';
import { withDb, type AppDb } from '../services/db';
import { grundner, jobs, jobEvents } from '../db/schema';

type SqlExpression = NonNullable<SQL>;

type LifecycleUpdateOptions = {
  machineId?: number | null;
  source?: string;
  payload?: unknown;
};

type LifecycleUpdateResult =
  | {
      ok: true;
      status: JobStatus;
      previousStatus: JobStatus;
      machineId: number | null;
      stagedAt: string | null;
      cutAt: string | null;
      nestpickCompletedAt: string | null;
      updatedAt: string | null;
    }
  | { ok: false; reason: 'NOT_FOUND' }
  | { ok: false; reason: 'INVALID_TRANSITION'; previousStatus: JobStatus }
  | {
      ok: false;
      reason: 'NO_CHANGE';
      previousStatus: JobStatus;
      stagedAt: string | null;
      cutAt: string | null;
      nestpickCompletedAt: string | null;
      updatedAt: string | null;
    };

type JobLookupRow = {
  key: string;
  folder: string | null;
  ncfile: string | null;
  machineId: number | null;
  status: JobStatus;
};

const ALLOWED_TRANSITIONS: Record<JobStatus, JobStatus[]> = {
  PENDING: ['PENDING'],
  STAGED: ['PENDING', 'STAGED'],
  LOAD_FINISH: ['PENDING', 'STAGED', 'LOAD_FINISH'],
  LABEL_FINISH: ['STAGED', 'LOAD_FINISH', 'LABEL_FINISH'],
  CNC_FINISH: ['STAGED', 'LOAD_FINISH', 'LABEL_FINISH', 'CNC_FINISH'],
  FORWARDED_TO_NESTPICK: ['CNC_FINISH', 'FORWARDED_TO_NESTPICK'],
  NESTPICK_COMPLETE: ['FORWARDED_TO_NESTPICK', 'NESTPICK_COMPLETE']
};

const RESETTABLE_STATUSES: JobStatus[] = ['CNC_FINISH', 'FORWARDED_TO_NESTPICK', 'NESTPICK_COMPLETE'];

function toIso(value: Date | string | null | undefined): string | null {
  if (!value) return null;
  const date = value instanceof Date ? value : new Date(value);
  if (Number.isNaN(date.getTime())) return null;
  return date.toISOString();
}

function combineClauses(clauses: SqlExpression[]): SqlExpression {
  if (clauses.length === 0) return sql`true`;
  if (clauses.length === 1) return clauses[0];
  const [first, second, ...rest] = clauses as [SqlExpression, SqlExpression, ...SqlExpression[]];
  const initial = and(first, second) as SqlExpression;
  return rest.reduce<SqlExpression>((acc, clause) => and(acc, clause) as SqlExpression, initial);
}

async function syncGrundnerReservedStock(db: AppDb, material: string | null, delta: number) {
  const trimmed = material?.trim();
  if (!trimmed) return;

  const lookupColumn = getGrundnerLookupColumn();
  const mode = getGrundnerMode();

  let condition: SQL | null = null;
  if (lookupColumn === 'customer_id') {
    condition = eq(grundner.customerId, trimmed);
  } else {
    const numeric = Number(trimmed);
    if (Number.isNaN(numeric)) {
      return;
    }
    condition = eq(grundner.typeData, numeric);
  }

  if (!condition) return;

  if (mode === 'delta') {
    const updated = await db
      .update(grundner)
      .set({
        reservedStock: sql<number>`GREATEST(COALESCE(${grundner.reservedStock}, 0) + ${delta}, 0)`
      })
      .where(condition)
      .returning({ id: grundner.id });

    if (updated.length > 0) {
      return;
    }
  }

  const [{ count }] = await db
    .select({ count: sql<number>`COUNT(*)` })
    .from(jobs)
    .where(and(eq(jobs.material, trimmed), eq(jobs.isReserved, true)));

  await db
    .update(grundner)
    .set({ reservedStock: count })
    .where(condition);
}

export async function listJobFilters(): Promise<JobsFilterOptions> {
  return withDb(async (db) => {
    const materialsRes = await db
      .selectDistinct({ material: jobs.material })
      .from(jobs)
      .where(sql`TRIM(COALESCE(${jobs.material}, '')) <> ''`)
      .orderBy(asc(jobs.material));

    const statusesRes = await db
      .selectDistinct({ status: jobs.status })
      .from(jobs)
      .orderBy(asc(jobs.status));

    const materials = materialsRes
      .map((row) => row.material?.trim())
      .filter((value): value is string => !!value);

    const statuses = statusesRes.map((row) => row.status as JobStatus);

    return { materials, statuses };
  });
}

export async function listJobs(req: JobsListReq) {
  const { search, sortBy, sortDir, limit, cursor, filter } = req;
  const safeLimit = Math.max(1, Math.min(limit ?? 50, 200));

  const conditions: SqlExpression[] = [];

  if (filter.folder) {
    conditions.push(eq(jobs.folder, filter.folder));
  }
  if (filter.material) {
    conditions.push(eq(jobs.material, filter.material));
  }
  if (filter.materialIn && filter.materialIn.length) {
    conditions.push(inArray(jobs.material, filter.materialIn));
  }
  if (filter.size) {
    conditions.push(eq(jobs.size, filter.size));
  }
  if (filter.thickness) {
    conditions.push(eq(jobs.thickness, filter.thickness));
  }
  if (filter.status && filter.status !== 'all') {
    if (filter.status === 'cut') conditions.push(sql`${jobs.cutAt} IS NOT NULL`);
    if (filter.status === 'uncut') conditions.push(sql`${jobs.cutAt} IS NULL`);
  }
  if (filter.statusIn && filter.statusIn.length) {
    conditions.push(inArray(jobs.status, filter.statusIn as JobStatus[]));
  }
  if (filter.machineId != null) {
    conditions.push(eq(jobs.machineId, filter.machineId));
  }
  if (search && search.trim()) {
    const term = `%${search.trim()}%`;
    conditions.push(
      sql`(${jobs.folder} ILIKE ${term} OR ${jobs.ncfile} ILIKE ${term} OR ${jobs.material} ILIKE ${term} OR ${jobs.parts} ILIKE ${term} OR ${jobs.size} ILIKE ${term} OR ${jobs.thickness} ILIKE ${term} OR ${jobs.dateAdded}::text ILIKE ${term})`
    );
  }
  if (cursor) {
    conditions.push(lt(jobs.key, cursor));
  }

  const orderColumn = (() => {
    switch (sortBy) {
      case 'folder':
        return jobs.folder;
      case 'ncfile':
        return jobs.ncfile;
      case 'material':
        return jobs.material;
      case 'parts':
        return jobs.parts;
      case 'size':
        return jobs.size;
      case 'thickness':
        return jobs.thickness;
      case 'reserved':
        return jobs.isReserved;
      case 'dateadded':
      default:
        return jobs.dateAdded;
    }
  })();

  const orderFn = sortDir === 'asc' ? asc : desc;

  const rows = await withDb((db) => {
    const baseQuery = db
      .select({
        key: jobs.key,
        folder: jobs.folder,
        ncfile: jobs.ncfile,
        material: jobs.material,
        parts: jobs.parts,
        size: jobs.size,
        thickness: jobs.thickness,
        dateAdded: jobs.dateAdded,
        isReserved: jobs.isReserved,
        status: jobs.status,
        machineId: jobs.machineId,
        processingSeconds: sql<number | null>`CASE 
          WHEN ${jobs.nestpickCompletedAt} IS NULL OR ${jobs.stagedAt} IS NULL THEN NULL
          ELSE EXTRACT(EPOCH FROM (${jobs.nestpickCompletedAt} - ${jobs.stagedAt}))::int
        END`
      })
      .from(jobs);

    const whereClause = combineClauses(conditions);

    const filteredQuery = baseQuery.where(whereClause);

    return filteredQuery.orderBy(orderFn(orderColumn), desc(jobs.key)).limit(safeLimit + 1);
  });

  const items = rows.slice(0, safeLimit).map((row) => ({
    key: row.key,
    folder: row.folder,
    ncfile: row.ncfile,
    material: row.material,
    parts: row.parts,
    size: row.size,
    thickness: row.thickness,
    dateadded: row.dateAdded ? row.dateAdded.toISOString() : null,
    reserved: !!row.isReserved,
    status: row.status as JobStatus,
    machineId: row.machineId ?? null,
    processingSeconds: row.processingSeconds ?? null
  }));

  const nextCursor = rows.length > safeLimit ? rows[safeLimit].key : null;
  return { items, nextCursor };
}

export async function reserveJob(key: string) {
  return withDb((db) =>
    db.transaction(async (tx) => {
    const updated = await tx
      .update(jobs)
      .set({ isReserved: true, updatedAt: sql<Date>`now()` as unknown as Date })
        .where(and(eq(jobs.key, key), eq(jobs.isReserved, false)))
        .returning({ material: jobs.material });

      if (!updated.length) {
        return false;
      }

      await syncGrundnerReservedStock(tx, updated[0].material ?? null, 1);
      return true;
    })
  );
}

export async function unreserveJob(key: string) {
  return withDb((db) =>
    db.transaction(async (tx) => {
    const updated = await tx
      .update(jobs)
      .set({ isReserved: false, updatedAt: sql<Date>`now()` as unknown as Date })
        .where(and(eq(jobs.key, key), eq(jobs.isReserved, true)))
        .returning({ material: jobs.material });

      if (!updated.length) {
        return false;
      }

      await syncGrundnerReservedStock(tx, updated[0].material ?? null, -1);
      return true;
    })
  );
}

export async function findJobByNcBase(base: string): Promise<JobLookupRow | null> {
  // Accept only two case-insensitive variants: "sheet1" or "sheet1.nc"
  const baseLower = base.trim().toLowerCase();
  const withoutExt = baseLower.replace(/\.nc$/i, '');

  const selectCols = {
    key: jobs.key,
    folder: jobs.folder,
    ncfile: jobs.ncfile,
    machineId: jobs.machineId,
    status: jobs.status
  };

  const rows = await withDb((db) =>
    db
      .select(selectCols)
      .from(jobs)
      .where(
        or(
          sql`LOWER(${jobs.ncfile}) = ${withoutExt}`,
          sql`LOWER(${jobs.ncfile}) = ${withoutExt} || '.nc'`
        )
      )
      .orderBy(desc(jobs.updatedAt))
      .limit(1)
  );

  if (!rows.length) return null;
  const row = rows[0];
  return {
    key: row.key,
    folder: row.folder,
    ncfile: row.ncfile,
    machineId: row.machineId ?? null,
    status: row.status as JobStatus
  };
}

export async function findJobByNcBasePreferStatus(base: string, preferred: string[]): Promise<JobLookupRow | null> {
  const baseLower = base.toLowerCase();
  const withoutExt = baseLower.replace(/\.nc$/i, '');

  const selectCols = {
    key: jobs.key,
    folder: jobs.folder,
    ncfile: jobs.ncfile,
    machineId: jobs.machineId,
    status: jobs.status
  };

  // First try: only jobs whose status is in preferred list
  if (preferred.length > 0) {
    const preferredTyped = preferred as readonly JobStatus[];
    const rows = await withDb((db) =>
      db
        .select(selectCols)
        .from(jobs)
        .where(
          and(
            inArray(jobs.status, preferredTyped),
            or(sql`LOWER(${jobs.ncfile}) = ${withoutExt}`, sql`LOWER(${jobs.ncfile}) = ${withoutExt} || '.nc'`)
          )
        )
        .orderBy(desc(jobs.updatedAt))
        .limit(1)
    );
    if (rows.length) {
      const row = rows[0];
      return {
        key: row.key,
        folder: row.folder,
        ncfile: row.ncfile,
        machineId: row.machineId ?? null,
        status: row.status as JobStatus
      };
    }
  }

  // Fallback to the generic lookup
  return findJobByNcBase(base);
}

export type JobDetails = {
  key: string;
  status: JobStatus;
  material: string | null;
  size: string | null;
  parts: string | null;
  thickness: string | null;
  dateadded: string | null; // ISO
};

export async function findJobDetailsByNcBase(base: string): Promise<JobDetails | null> {
  const normalized = base.replace(/\.nc$/i, '');
  const selectCols = {
    key: jobs.key,
    status: jobs.status,
    material: jobs.material,
    size: jobs.size,
    parts: jobs.parts,
    thickness: jobs.thickness,
    dateAdded: jobs.dateAdded
  };

  const rows = await withDb((db) =>
    db
      .select(selectCols)
      .from(jobs)
      .where(
        or(
          sql`LOWER(${jobs.ncfile}) = LOWER(${normalized})`,
          sql`LOWER(${jobs.key}) = LOWER(${normalized})`,
          sql`LOWER(${jobs.key}) = LOWER(${normalized} || '.nc')`
        )
      )
      .orderBy(desc(jobs.updatedAt))
      .limit(1)
  );

  if (!rows.length) return null;
  const row = rows[0];
  return {
    key: row.key,
    status: row.status as JobStatus,
    material: row.material ?? null,
    size: row.size ?? null,
    parts: row.parts ?? null,
    thickness: row.thickness ?? null,
    dateadded: row.dateAdded ? row.dateAdded.toISOString() : null
  };
}

export async function resetJobForRestage(
  key: string
): Promise<{ reset: boolean; iteration?: number; previousStatus?: JobStatus }> {
  return withDb((db) =>
    db.transaction(async (tx) => {
      const rows = await tx
        .select({
          status: jobs.status,
          machineId: jobs.machineId,
          stagedAt: jobs.stagedAt,
          cutAt: jobs.cutAt,
          nestpickCompletedAt: jobs.nestpickCompletedAt,
          pallet: jobs.pallet
        })
        .from(jobs)
        .where(eq(jobs.key, key))
        .for('update')
        .limit(1);

      if (!rows.length) {
        return { reset: false };
      }

      const current = rows[0];
      const currentStatus = current.status as JobStatus;
      if (!RESETTABLE_STATUSES.includes(currentStatus)) {
        return { reset: false };
      }

      const dbNow = sql<Date>`now()`;
      await tx
        .update(jobs)
        .set({
          status: 'PENDING',
          machineId: null,
          stagedAt: null,
          cutAt: null,
          nestpickCompletedAt: null,
          pallet: null,
          updatedAt: dbNow as unknown as Date
        })
        .where(eq(jobs.key, key));

      const resetCountRows = await tx
        .select({ count: sql<number>`count(*)` })
        .from(jobEvents)
        .where(and(eq(jobEvents.key, key), eq(jobEvents.eventType, 'job:restage:reset')));

      const previousResets = Number(resetCountRows[0]?.count ?? 0);
      const iteration = previousResets + 1;

      await appendJobEvent(
        key,
        'job:restage:reset',
        {
          iteration,
          previousStatus: currentStatus,
          previousMachineId: current.machineId ?? null,
          previousStagedAt: toIso(current.stagedAt),
          previousCutAt: toIso(current.cutAt),
          previousNestpickCompletedAt: toIso(current.nestpickCompletedAt),
          previousPallet: current.pallet ?? null
        },
        current.machineId ?? null,
        tx
      );

      return { reset: true, iteration, previousStatus: currentStatus };
    })
  );
}

export async function updateLifecycle(
  key: string,
  to: JobStatus,
  options: LifecycleUpdateOptions = {}
): Promise<LifecycleUpdateResult> {
  return withDb((db) =>
    db.transaction(async (tx) => {
      const currentRows = await tx
        .select({
          status: jobs.status,
          machineId: jobs.machineId,
          stagedAt: jobs.stagedAt,
          cutAt: jobs.cutAt,
          nestpickCompletedAt: jobs.nestpickCompletedAt,
          updatedAt: jobs.updatedAt
        })
        .from(jobs)
        .where(eq(jobs.key, key))
        .for('update')
        .limit(1);

      if (!currentRows.length) {
        return { ok: false, reason: 'NOT_FOUND' };
      }

      const current = currentRows[0];
      const previousStatus = current.status as JobStatus;
      const currentStagedAt = toIso(current.stagedAt);
      const currentCutAt = toIso(current.cutAt);
      const currentNestpickAt = toIso(current.nestpickCompletedAt);
      const currentUpdatedAt = toIso(current.updatedAt);

      if (!ALLOWED_TRANSITIONS[to].includes(previousStatus)) {
        return { ok: false, reason: 'INVALID_TRANSITION', previousStatus };
      }

      const patch: Partial<typeof jobs.$inferInsert> = {};
      const dbNow = sql<Date>`now()`;
      let touched = false;

      if (previousStatus !== to) {
        patch.status = to;
        touched = true;
      }

      if ((to === 'STAGED' || to === 'LOAD_FINISH' || to === 'LABEL_FINISH') && !current.stagedAt) {
        patch.stagedAt = dbNow as unknown as Date;
        touched = true;
      }

      if (to === 'CNC_FINISH' && !current.cutAt) {
        patch.cutAt = dbNow as unknown as Date;
        touched = true;
      }

      if (to === 'NESTPICK_COMPLETE' && !current.nestpickCompletedAt) {
        patch.nestpickCompletedAt = dbNow as unknown as Date;
        touched = true;
      }

      let nextMachineId = current.machineId ?? null;
      if (Object.prototype.hasOwnProperty.call(options, 'machineId') && options.machineId !== current.machineId) {
        nextMachineId = options.machineId ?? null;
        patch.machineId = nextMachineId;
        touched = true;
      }

      if (!touched) {
        return {
          ok: false,
          reason: 'NO_CHANGE',
          previousStatus,
          stagedAt: currentStagedAt,
          cutAt: currentCutAt,
          nestpickCompletedAt: currentNestpickAt,
          updatedAt: currentUpdatedAt
        };
      }

      patch.updatedAt = dbNow as unknown as Date;

      const updatedRows = await tx
        .update(jobs)
        .set(patch)
        .where(eq(jobs.key, key))
        .returning({
          status: jobs.status,
          machineId: jobs.machineId,
          stagedAt: jobs.stagedAt,
          cutAt: jobs.cutAt,
          nestpickCompletedAt: jobs.nestpickCompletedAt,
          updatedAt: jobs.updatedAt
        });

      if (!updatedRows.length) {
        return { ok: false, reason: 'NOT_FOUND' };
      }

      const updated = updatedRows[0];
      const newStatus = updated.status as JobStatus;
      const machineId = updated.machineId ?? null;
      const stagedAtIso = toIso(updated.stagedAt);
      const cutAtIso = toIso(updated.cutAt);
      const nestpickCompletedAtIso = toIso(updated.nestpickCompletedAt);
      const updatedAtIso = toIso(updated.updatedAt);

      const eventPayload: Record<string, unknown> = {
        from: previousStatus,
        to: newStatus
      };
      if (machineId !== null) {
        eventPayload.machineId = machineId;
      }
      if (options.source) {
        eventPayload.source = options.source;
      }
      if (options.payload !== undefined) {
        eventPayload.payload = options.payload;
      }

      await appendJobEvent(key, `status:${newStatus}`, eventPayload, machineId, tx);

      return {
        ok: true,
        status: newStatus,
        previousStatus,
        machineId,
        stagedAt: stagedAtIso,
        cutAt: cutAtIso,
        nestpickCompletedAt: nestpickCompletedAtIso,
        updatedAt: updatedAtIso
      };
    })
  );
}

export async function updateJobPallet(key: string, pallet: string | null) {
  const updated = await withDb((db) =>
    db
      .update(jobs)
      .set({ pallet, updatedAt: sql<Date>`now()` as unknown as Date })
      .where(eq(jobs.key, key))
      .returning({ key: jobs.key })
  );

  return updated.length > 0;
}

================
File: packages/main/src/repo/machinesRepo.ts
================
import { asc, eq, sql } from 'drizzle-orm';
import type { SaveMachineReq, Machine } from '../../../shared/src';
import { machines } from '../db/schema';
import { withDb } from '../services/db';

const MACHINE_FIELDS = {
  machineId: machines.machineId,
  name: machines.name,
  pcIp: machines.pcIp,
  cncIp: machines.cncIp,
  cncPort: machines.cncPort,
  apJobfolder: machines.apJobfolder,
  nestpickFolder: machines.nestpickFolder,
  nestpickEnabled: machines.nestpickEnabled,
  pcPort: machines.pcPort
};

type MachineRow = Pick<typeof machines.$inferSelect, keyof typeof MACHINE_FIELDS>;

function toMachine(row: MachineRow): Machine {
  return {
    machineId: row.machineId,
    name: row.name,
    pcIp: row.pcIp ?? null,
    cncIp: row.cncIp ?? null,
    cncPort: row.cncPort ?? null,
    apJobfolder: row.apJobfolder,
    nestpickFolder: row.nestpickFolder,
    nestpickEnabled: row.nestpickEnabled,
    pcPort: row.pcPort
  };
}

export async function listMachines(): Promise<Machine[]> {
  const rows = await withDb((db) =>
    db.select(MACHINE_FIELDS).from(machines).orderBy(asc(machines.machineId))
  );

  return rows.map(toMachine);
}

export async function saveMachine(input: SaveMachineReq) {
  if (input.machineId != null) {
    const machineId = input.machineId;
    const [row] = await withDb((db) =>
      db
        .update(machines)
        .set({
          name: input.name ?? 'New Machine',
          pcIp: input.pcIp ?? null,
          cncIp: input.cncIp ?? null,
          cncPort: input.cncPort ?? null,
          apJobfolder: input.apJobfolder ?? '',
          nestpickFolder: input.nestpickFolder ?? '',
          nestpickEnabled: input.nestpickEnabled ?? true,
          pcPort: input.pcPort ?? 5000,
          updatedAt: sql`now()`
        })
        .where(eq(machines.machineId, machineId))
        .returning(MACHINE_FIELDS)
    );

    if (!row) {
      throw new Error(`Machine ${input.machineId} not found`);
    }

    return toMachine(row);
  }

  const [inserted] = await withDb((db) =>
    db
      .insert(machines)
      .values({
        name: input.name ?? 'New Machine',
        pcIp: input.pcIp ?? null,
        cncIp: input.cncIp ?? null,
        cncPort: input.cncPort ?? null,
        apJobfolder: input.apJobfolder ?? '',
        nestpickFolder: input.nestpickFolder ?? '',
        nestpickEnabled: input.nestpickEnabled ?? true,
        pcPort: input.pcPort ?? 5000
      })
      .returning(MACHINE_FIELDS)
  );

  if (!inserted) {
    throw new Error('Failed to insert machine');
  }

  return toMachine(inserted);
}

export async function deleteMachine(machineId: number) {
  await withDb((db) => db.delete(machines).where(eq(machines.machineId, machineId)));
  return true;
}

export async function getMachine(machineId: number): Promise<Machine | null> {
  const rows = await withDb((db) =>
    db.select(MACHINE_FIELDS).from(machines).where(eq(machines.machineId, machineId)).limit(1)
  );
  const row = rows[0];
  return row ? toMachine(row) : null;
}

================
File: packages/main/src/repo/routerRepo.ts
================
import { withClient } from '../services/db';
import type { QueryResult } from 'pg';

type SqlParam = string | number | boolean | null | Date;

type RouterJobRowDb = {
  key: string;
  folder: string | null;
  ncfile: string | null;
  material: string | null;
  status: string;
  machineId: number | null;
  stagedAt: Date | null;
  cutAt: Date | null;
  nestpickCompletedAt: Date | null;
  updatedAt: Date | null;
  pallet: string | null;
  lastError: string | null;
};

export async function listMachineJobs(options: { machineId?: number; statusIn?: string[]; limit?: number } = {}) {
  const params: SqlParam[] = [];
  const where: string[] = [];

  if (options.machineId != null) {
    params.push(options.machineId);
    where.push(`machine_id = $${params.length}`);
  }
  if (options.statusIn && options.statusIn.length) {
    const idxStart = params.length + 1;
    const placeholders = options.statusIn.map((_, i) => `$${idxStart + i}`).join(',');
    params.push(...options.statusIn);
    where.push(`status IN (${placeholders})`);
  }

  const limit = Math.min(Math.max(options.limit ?? 200, 1), 500);
  params.push(limit);

  const sql = `
    SELECT key,
           folder,
           ncfile,
           material,
           status,
           machine_id AS "machineId",
           staged_at AS "stagedAt",
           cut_at AS "cutAt",
           nestpick_completed_at AS "nestpickCompletedAt",
           updated_at AS "updatedAt",
           pallet,
           last_error AS "lastError"
    FROM public.machine_jobs
    ${where.length ? 'WHERE ' + where.join(' AND ') : ''}
    ORDER BY updated_at DESC NULLS LAST, key DESC
    LIMIT $${params.length}
  `;
  const rows = await withClient<RouterJobRowDb[]>((c) =>
    c.query<RouterJobRowDb>(sql, params).then((r: QueryResult<RouterJobRowDb>) => r.rows)
  );

  return rows.map((row) => ({
    key: row.key,
    folder: row.folder,
    ncfile: row.ncfile,
    material: row.material,
    status: row.status,
    machineId: row.machineId,
    stagedAt: row.stagedAt ? new Date(row.stagedAt).toISOString() : null,
    cutAt: row.cutAt ? new Date(row.cutAt).toISOString() : null,
    nestpickCompletedAt: row.nestpickCompletedAt ? new Date(row.nestpickCompletedAt).toISOString() : null,
    updatedAt: row.updatedAt ? new Date(row.updatedAt).toISOString() : null,
    pallet: row.pallet,
    lastError: row.lastError
  }));
}

================
File: packages/main/src/repo/telemetryRepo.ts
================
import { withClient } from '../services/db';
import { logger } from '../logger';
import type { TelemetryMachineSummary, TelemetrySummaryReq, TelemetrySeconds } from '../../../shared/src';

const API_HOST_EXPR = `split_part(split_part(regexp_replace(lower(btrim(cs.api_ip)), '^https?://', ''), '/', 1), ':', 1)`;
const API_HOST_NORM_EXPR = `regexp_replace(${API_HOST_EXPR}, '\\s+', '', 'g')`;
const MACHINE_HOST_EXPR = 'host(m.pc_ip)';
const MACHINE_HOST_NORM_EXPR = `regexp_replace(lower(${MACHINE_HOST_EXPR}), '\\s+', '', 'g')`;

type SeriesRow = {
  machine_id: number | null;
  machine_name: string | null;
  ts: string; // ISO timestamp from SQL
  status: string | null;
  api_ip_raw: string | null;
  api_ip_host: string | null;
  api_ip_host_norm: string | null;
};

function toIsoOrNull(value: unknown): string | null {
  if (typeof value === 'string') return value;
  if (value instanceof Date) return value.toISOString();
  return null;
}

function toDate(value: string): Date {
  return new Date(value);
}

function normalizeStatus(raw: string | null): keyof TelemetrySeconds | 'OTHER' {
  if (!raw) return 'OTHER';
  const v = raw.trim().toUpperCase();
  if (v === 'READY') return 'READY';
  if (v === 'B-STOP' || v === 'BSTOP' || v === 'B_STOP') return 'B-STOP';
  if (v === 'BUSY' || v === 'RUNNING') return 'BUSY';
  if (v === 'ALARM') return 'ALARM';
  if (v === 'EMG' || v === 'EMERGENCY') return 'EMG';
  return 'OTHER';
}

export async function summarizeTelemetry(req: TelemetrySummaryReq): Promise<TelemetryMachineSummary[]> {
  const fromIso = req.from ?? null;
  const toIso = req.to ?? null;

  logger.debug({ fromIso, toIso, machineIds: req.machineIds }, 'telemetry: summarizing');

  const params: unknown[] = [];
  let idx = 1;
  let where = 'WHERE 1=1';

  if (fromIso) {
    where += ` AND to_timestamp(cs.key, 'YYYY.MM.DD HH24:MI:SS') >= $${idx++}`;
    params.push(new Date(fromIso));
  }
  if (toIso) {
    where += ` AND to_timestamp(cs.key, 'YYYY.MM.DD HH24:MI:SS') <= $${idx++}`;
    params.push(new Date(toIso));
  }
  if (req.machineIds && req.machineIds.length) {
    where += ` AND m.machine_id = ANY($${idx++})`;
    params.push(req.machineIds);
  }

  // Note on JOIN:
  // We normalize both sides to lowercase, strip protocol from cs.api_ip, extract just the host,
  // and remove whitespace so we can match against machines.pc_ip (stored as inet) regardless of formatting.
  const sql = `
    SELECT
      m.machine_id,
      m.name AS machine_name,
      to_timestamp(cs.key, 'YYYY.MM.DD HH24:MI:SS') AS ts,
      cs.status,
      cs.api_ip,
      ${API_HOST_EXPR} AS api_ip_host,
      ${API_HOST_NORM_EXPR} AS api_ip_host_norm,
      ${MACHINE_HOST_EXPR} AS machine_host
    FROM public.cncstats cs
    LEFT JOIN public.machines m
      ON ${MACHINE_HOST_NORM_EXPR} = ${API_HOST_NORM_EXPR}
    ${where}
    ORDER BY m.machine_id NULLS LAST, ts ASC
  `;

  logger.debug({ sql, params }, 'telemetry: executing SQL');

  const rows = await withClient<SeriesRow[]>((client) =>
    client.query(sql, params).then((r) => {
      logger.debug({ rowCount: r.rowCount }, 'telemetry: SQL returned rows');
      return r.rows.map((row) => ({
        machine_id: row.machine_id == null ? null : Number(row.machine_id),
        machine_name: row.machine_name ?? null,
        status: row.status ?? null,
        ts: toIsoOrNull(row.ts) ?? new Date(row.ts as unknown as string).toISOString(),
        api_ip_raw: row.api_ip ?? null,
        api_ip_host: row.api_ip_host ?? null,
        api_ip_host_norm: row.api_ip_host_norm ?? null
      }));
    })
  );

  // Debugging: inspect join behavior and IP normalization results using a small sample
  try {
    const sampleSql = `
      SELECT
        cs.api_ip,
        ${API_HOST_EXPR} AS api_ip_host,
        ${API_HOST_NORM_EXPR} AS api_ip_host_norm,
        m.pc_ip::text AS pc_ip_raw,
        ${MACHINE_HOST_EXPR} AS machine_host,
        ${MACHINE_HOST_NORM_EXPR} AS machine_host_norm,
        m.machine_id,
        m.name
      FROM public.cncstats cs
      LEFT JOIN public.machines m
        ON ${MACHINE_HOST_NORM_EXPR} = ${API_HOST_NORM_EXPR}
      ${where}
      ORDER BY m.machine_id NULLS LAST, cs.key ASC
      LIMIT 50
    `;
    await withClient((client) =>
      client.query(sampleSql, params).then((r) => {
        const sample = r.rows.map((x) => ({
          api_ip: x.api_ip,
          api_ip_host: x.api_ip_host,
          api_ip_host_norm: x.api_ip_host_norm,
          pc_ip_raw: x.pc_ip_raw,
          machine_host: x.machine_host,
          machine_host_norm: x.machine_host_norm,
          machine_id: x.machine_id,
          machine_name: x.name
        }));
        logger.debug({ sampleCount: sample.length, sample }, 'telemetry: join debug sample');
      })
    );
  } catch (err) {
    logger.warn({ err }, 'telemetry: failed to fetch join debug sample');
  }

  // group by machine
  const byMachine = new Map<number, SeriesRow[]>();
  const unmatchedHosts = new Map<string, number>();
  let unmatchedExists = false;
  for (const r of rows) {
    if (r.machine_id == null) {
      unmatchedExists = true;
      const hostKey = r.api_ip_host_norm ?? r.api_ip_host ?? r.api_ip_raw ?? '(unknown)';
      unmatchedHosts.set(hostKey, (unmatchedHosts.get(hostKey) ?? 0) + 1);
      continue; // skip unmatched for grouping
    }
    if (!byMachine.has(r.machine_id)) byMachine.set(r.machine_id, []);
    byMachine.get(r.machine_id)!.push(r);
  }

  const result: TelemetryMachineSummary[] = [];

  for (const [machineId, series] of byMachine.entries()) {
    // Aggregate across the full requested range (no per-day reset), still using consecutive points.
    const seconds: TelemetrySeconds = { READY: 0, 'B-STOP': 0, BUSY: 0, ALARM: 0, EMG: 0, OTHER: 0 };

    if (series.length < 2) {
      logger.debug({ machineId, points: series.length }, 'telemetry: insufficient points for intervals');
    } else {
      for (let i = 0; i < series.length - 1; i++) {
        const curr = series[i];
        const next = series[i + 1];
        const dt = Math.max(0, (toDate(next.ts).getTime() - toDate(curr.ts).getTime()) / 1000);
        const key = normalizeStatus(curr.status);
        if ((key as keyof TelemetrySeconds) in seconds) {
          const k = key as keyof TelemetrySeconds;
          seconds[k] += Math.floor(dt);
        } else {
          seconds.OTHER += Math.floor(dt);
        }
      }
    }

    result.push({ machineId, machineName: series[0]?.machine_name ?? null, seconds });
    logger.debug({ machineId, machineName: series[0]?.machine_name ?? null, seconds }, 'telemetry: machine summary');
  }

  if (unmatchedExists && unmatchedHosts.size) {
    const hostSummary = Array.from(unmatchedHosts.entries()).map(([host, count]) => ({ host, count }));
    const rawSamples = Array.from(new Set(rows.filter((r) => r.machine_id == null).map((r) => r.api_ip_raw ?? '(null)'))).slice(0, 5);
    logger.info({ hosts: hostSummary, rawSamples }, 'telemetry: unmatched machine hosts');
  }

  if (result.length === 0 && unmatchedExists) {
    const zero: TelemetrySeconds = { READY: 0, 'B-STOP': 0, BUSY: 0, ALARM: 0, EMG: 0, OTHER: 0 };
    result.push({ machineId: null, machineName: null, seconds: zero });
  }

  logger.debug({ items: result.length }, 'telemetry: summarize done');
  return result;
}

================
File: packages/main/src/security.ts
================
import { app, session, shell, type WebContents } from 'electron';
import { logger } from './logger';
import type { Session } from 'electron';

const DEFAULT_EXTERNAL_ORIGINS = ['https://woodtron.com', 'https://www.woodtron.com'];
const ALLOWED_EXTERNAL_PROTOCOLS = new Set(['https:', 'mailto:', 'tel:']);
const ALLOWED_EXTERNAL_ORIGINS = new Set<string>([
  ...DEFAULT_EXTERNAL_ORIGINS,
  ...((process.env.APP_ALLOWED_EXTERNAL_ORIGINS ?? '')
    .split(',')
    .map((value) => value.trim())
    .filter((value) => value.length > 0))
]);

function getInternalOrigins(): Set<string> {
  const origins = new Set<string>();
  origins.add('file://');
  const devServer = process.env.VITE_DEV_SERVER_URL;
  if (devServer) {
    try {
      origins.add(new URL(devServer).origin);
    } catch (err) {
      logger.warn({ devServer, err }, 'Invalid VITE_DEV_SERVER_URL; falling back to packaged CSP');
    }
  }
  return origins;
}

function isInternalNavigation(url: string): boolean {
  try {
    const parsed = new URL(url);
    if (parsed.protocol === 'file:') return true;
    const allowedOrigins = getInternalOrigins();
    const origin = `${parsed.protocol}//${parsed.host}`;
    return allowedOrigins.has(origin);
  } catch {
    return false;
  }
}

function isAllowedExternal(url: string): boolean {
  try {
    const parsed = new URL(url);
    if (!ALLOWED_EXTERNAL_PROTOCOLS.has(parsed.protocol)) return false;
    if (parsed.protocol === 'mailto:' || parsed.protocol === 'tel:') return true;
    const origin = `${parsed.protocol}//${parsed.host}`;
    return ALLOWED_EXTERNAL_ORIGINS.has(origin);
  } catch {
    return false;
  }
}

export function applyWindowNavigationGuards(contents: WebContents, options?: { allowExternal?: boolean }) {
  const allowExternal = options?.allowExternal ?? true;

  contents.setWindowOpenHandler(({ url }) => {
    if (allowExternal && isAllowedExternal(url)) {
      shell
        .openExternal(url)
        .catch((err) => logger.error({ err, url }, 'Failed to open external URL'));
    } else {
      logger.warn({ url }, 'Blocked window.open navigation');
    }
    return { action: 'deny' };
  });

  const handleNavigation = (event: Electron.Event, url: string) => {
    if (isInternalNavigation(url)) return;
    event.preventDefault();
    if (allowExternal && isAllowedExternal(url)) {
      shell
        .openExternal(url)
        .catch((err) => logger.error({ err, url }, 'Failed to open external URL'));
    } else {
      logger.warn({ url }, 'Blocked navigation attempt');
    }
  };

  contents.on('will-navigate', handleNavigation);
  contents.on('will-redirect', handleNavigation);
}

let cspConfigured = false;

function buildContentSecurityPolicy(): string {
  const directives: Record<string, Set<string>> = {
    'default-src': new Set(["'self'"]),
    'script-src': new Set(["'self'"]),
    'style-src': new Set(["'self'", "'unsafe-inline'"]),
    'img-src': new Set(["'self'", 'data:']),
    'font-src': new Set(["'self'"]),
    'connect-src': new Set(["'self'"]),
    'object-src': new Set(["'none'"]),
    'frame-ancestors': new Set(["'none'"]),
    'base-uri': new Set(["'self'"]),
    'form-action': new Set(["'self'"])
  };

  const devServer = process.env.VITE_DEV_SERVER_URL;
  const isDevelopment = !app.isPackaged;
  if (devServer) {
    try {
      const devUrl = new URL(devServer);
      directives['connect-src'].add(devUrl.origin);
      directives['connect-src'].add(`ws://${devUrl.host}`);
      directives['script-src'].add(devUrl.origin);
      if (isDevelopment) {
        directives['script-src'].add(`ws://${devUrl.host}`);
      }
    } catch (err) {
      logger.warn({ devServer, err }, 'Invalid dev server URL; skipping dev CSP extras');
    }
  }

  if (isDevelopment) {
    directives['script-src'].add("'unsafe-inline'");
    directives['script-src'].add("'unsafe-eval'");
    directives['connect-src'].add('ws://localhost:*');
  }

  return Object.entries(directives)
    .map(([key, values]) => `${key} ${Array.from(values).join(' ')}`)
    .join('; ');
}

export function ensureContentSecurityPolicy() {
  if (cspConfigured) return;
  const policy = buildContentSecurityPolicy();
  const targetSession = session.defaultSession;

  targetSession.webRequest.onHeadersReceived((details, callback) => {
    const responseHeaders = { ...details.responseHeaders };
    responseHeaders['Content-Security-Policy'] = [policy];
    callback({ responseHeaders });
  });

  cspConfigured = true;
  logger.info({ policy }, 'Content Security Policy applied');
}

// Apply a custom CSP to a specific session (e.g., Hypernest window)
export function applyCustomContentSecurityPolicy(targetSession: Session, policy: string) {
  targetSession.webRequest.onHeadersReceived((details, callback) => {
    const responseHeaders = { ...details.responseHeaders };
    responseHeaders['Content-Security-Policy'] = [policy];
    callback({ responseHeaders });
  });
  logger.info({ policy }, 'Custom Content Security Policy applied to session');
}

export function logSecurityConfigurationSummary() {
  logger.info(
    {
      allowedExternalOrigins: Array.from(ALLOWED_EXTERNAL_ORIGINS),
      allowedExternalProtocols: Array.from(ALLOWED_EXTERNAL_PROTOCOLS),
      internalOrigins: Array.from(getInternalOrigins()),
      packaged: app.isPackaged
    },
    'Navigation security configuration'
  );
}

================
File: packages/main/src/services/config.ts
================
import { app } from 'electron';
import { existsSync, mkdirSync, readFileSync, writeFileSync } from 'fs';
import { dirname, join } from 'path';
import { DbSettingsSchema, CURRENT_SETTINGS_VERSION } from '../../../shared/src';
import type { Settings } from '../../../shared/src';
import { logger } from '../logger';

const DEFAULT_SETTINGS: Settings = {
  version: CURRENT_SETTINGS_VERSION,
  db: {
    host: 'localhost',
    port: 5432,
    database: 'woodtron',
    user: 'woodtron_user',
    password: '',
    sslMode: 'disable',
    statementTimeoutMs: 30000
  },
  paths: { processedJobsRoot: '', autoPacCsvDir: '', grundnerFolderPath: '' },
  test: { testDataFolderPath: '', useTestDataMode: false, sheetIdMode: 'type_data' },
  grundner: { reservedAdjustmentMode: 'delta' }
};

let cache: Settings | null = null;

type MaybeSettings = Partial<Settings> | undefined | null | { [key: string]: unknown };

function cloneDefaults(): Settings {
  return {
    version: CURRENT_SETTINGS_VERSION,
    db: { ...DEFAULT_SETTINGS.db },
    paths: { ...DEFAULT_SETTINGS.paths },
    test: { ...DEFAULT_SETTINGS.test },
    grundner: { ...DEFAULT_SETTINGS.grundner }
  };
}

function normalizeSettings(input: MaybeSettings): Settings {
  const base = (typeof input === 'object' && input !== null ? input : {}) as Partial<Settings>;
  const db: Settings['db'] = { ...DEFAULT_SETTINGS.db, ...(base.db ?? {}) } as Settings['db'];
  // Coerce password to a string to avoid pg errors when null/number are provided
  db.password = typeof db.password === 'string' ? db.password : (db.password == null ? '' : String(db.password));
  return {
    version: typeof base.version === 'number' && base.version > 0 ? base.version : CURRENT_SETTINGS_VERSION,
    db,
    paths: { ...DEFAULT_SETTINGS.paths, ...(base.paths ?? {}) },
    test: { ...DEFAULT_SETTINGS.test, ...(base.test ?? {}) },
    grundner: { ...DEFAULT_SETTINGS.grundner, ...(base.grundner ?? {}) }
  };
}

function mergeSettingsInternal(base: Settings, update: MaybeSettings): Settings {
  const partial = (typeof update === 'object' && update !== null ? update : {}) as Partial<Settings>;
  return normalizeSettings({
    version: partial.version ?? base.version,
    db: { ...base.db, ...(partial.db ?? {}) },
    paths: { ...base.paths, ...(partial.paths ?? {}) },
    test: { ...base.test, ...(partial.test ?? {}) },
    grundner: { ...base.grundner, ...(partial.grundner ?? {}) }
  });
}

// Strict config path policy:
// - Dev: settings.json at repo root (relative to compiled main at packages/main/dist)
// - Prod: settings.json next to the .exe (dirname(process.execPath))
export function getConfigPath() {
  const override = process.env.WOODTRON_CONFIG_PATH?.trim();
  if (override) {
    return override;
  }

  const isPackaged = app?.isPackaged ?? false;
  if (isPackaged) {
    return join(dirname(process.execPath), 'settings.json');
  }

  return join(__dirname, '../../../settings.json');
}

export function loadConfig(): Settings {
  if (cache) return cache;
  const file = getConfigPath();
  try {
    if (!existsSync(file)) {
      const defaults = cloneDefaults();
      writeConfig(defaults);
      logger.info({ file }, 'Config created with defaults');
      return defaults;
    }
    const raw = readFileSync(file, 'utf8');
    const parsedJson = JSON.parse(raw);
    const normalized = normalizeSettings(parsedJson);
    cache = normalized;
    logger.info({ file }, 'Config loaded');
    // Do not rewrite automatically; only write on explicit save
    return normalized;
  } catch (err) {
    logger.warn({ err }, 'Failed to load config, falling back to defaults');
    throw err instanceof Error ? err : new Error(String(err));
  }
}

function writeConfig(settings: Settings) {
  const file = getConfigPath();
  const dir = dirname(file);
  const normalized = normalizeSettings(settings);
  if (!existsSync(dir)) mkdirSync(dir, { recursive: true });
  writeFileSync(file, JSON.stringify(normalized, null, 2), 'utf8');
  cache = normalized;
  logger.info({ file }, 'Config saved');
}

export function saveConfig(next: Settings | Partial<Settings>) {
  const file = getConfigPath();
  const current = cache ?? (existsSync(file) ? normalizeSettings(JSON.parse(readFileSync(file, 'utf8'))) : cloneDefaults());
  const merged = mergeSettingsInternal(current, next as MaybeSettings);
  writeConfig(merged);
}

export function mergeSettings(update: Partial<Settings>): Settings {
  const current = loadConfig();
  return mergeSettingsInternal(current, update);
}

export function overwriteConfig(settings: Settings) {
  writeConfig(settings);
}

export function redactSettings(settings: Settings): Settings {
  return {
    ...settings,
    db: { ...settings.db, password: settings.db.password ? '********' : '' }
  };
}

export function validateDbSettings(partial: Partial<Settings['db']>) {
  return DbSettingsSchema.partial().parse(partial);
}

================
File: packages/main/src/services/db.ts
================
import { Pool } from 'pg';
import type { PoolClient, PoolConfig } from 'pg';
import { drizzle, type NodePgDatabase } from 'drizzle-orm/node-postgres';
import { loadConfig } from './config';
import { logger } from '../logger';
import { schema } from '../db/schema';


function resolvePassword(password: string | undefined): string | undefined {
  return process.env.WOODTRON_TEST_DISABLE_PASSWORD === '1' ? undefined : password;
}

let pool: Pool | null = null;
let poolMutex = Promise.resolve();

export type AppDb = NodePgDatabase<typeof schema>;

export function getPool() {
  if (pool) return pool;
  
  // Wait for any ongoing pool reset to complete before creating a new pool
  poolMutex = poolMutex.then(async () => {
    if (pool) return; // Double-check after waiting
    
    const cfg = loadConfig();
    // Password is validated as non-empty by schema before reaching this function
    const baseConfig: PoolConfig = {
      host: cfg.db.host,
      port: cfg.db.port,
      user: cfg.db.user,
      database: cfg.db.database,
      max: 10,
      idleTimeoutMillis: 30000,
      connectionTimeoutMillis: 10000,
      ssl: cfg.db.sslMode === 'disable' ? false : { rejectUnauthorized: cfg.db.sslMode === 'verify-full' }
    };
    const password = resolvePassword(cfg.db.password);
    if (password !== undefined) {
      baseConfig.password = password; // Non-empty password required by schema validation (can be suppressed in tests)
    }
    pool = new Pool(baseConfig);
    pool.on('error', (err: unknown) => logger.error({ err }, 'PG pool error'));
  });
  
  // For synchronous callers, return the pool if it exists, otherwise return null
  // The pool will be created asynchronously and subsequent calls will get it
  return pool;
}

export async function resetPool() {
  if (!pool) return;
  
  // Wait for any ongoing pool operations to complete before resetting
  await poolMutex;
  
  const current = pool;
  pool = null;
  try {
    await current.end();
  } catch (err) {
    logger.warn({ err }, 'Failed to close PG pool');
  }
}

export async function testConnection(settings = loadConfig().db): Promise<{ ok: true } | { ok: false; error: string }>{
  // Password is validated as non-empty by schema before reaching this function
  const baseConfig: PoolConfig = {
    host: settings.host,
    port: settings.port,
    user: settings.user,
    database: settings.database,
    max: 1,
    connectionTimeoutMillis: 8000,
    ssl: settings.sslMode === 'disable' ? false : { rejectUnauthorized: settings.sslMode === 'verify-full' }
  };
  const password = resolvePassword(settings.password);
  if (password !== undefined) {
    baseConfig.password = password; // Non-empty password required by schema validation (can be suppressed in tests)
  }
  const tmp = new Pool(baseConfig);
  try {
    const c = await tmp.connect();
    try {
      await c.query('SELECT 1');
    } finally {
      c.release();
    }
    await tmp.end();
    return { ok: true };
  } catch (e: unknown) {
    await tmp.end().catch(() => {});
    const msg = e instanceof Error ? e.message : String(e);
    return { ok: false, error: msg };
  }
}

function shouldResetPoolForError(err: unknown): boolean {
  const msg = err instanceof Error ? err.message : String(err);
  const lowered = msg.toLowerCase();
  // Common transient connection issues worth a quick reset+retry
  return (
    lowered.includes('connection terminated unexpectedly') ||
    lowered.includes('connection terminated due to connection timeout') ||
    lowered.includes('terminating connection due to administrator command') ||
    lowered.includes('timeout') ||
    lowered.includes('ecconnreset') ||
    lowered.includes('econnrefused')
  );
}

export async function withClient<T>(fn: (c: PoolClient) => Promise<T>): Promise<T> {
  // Up to two attempts to handle transient connection failures
  let attempt = 0;
  // eslint-disable-next-line no-constant-condition
  while (true) {
    attempt += 1;
    // Wait for pool to be available (handles async pool creation)
    let currentPool = getPool();
    if (!currentPool) {
      // Pool is being created asynchronously, wait for it
      await poolMutex;
      currentPool = getPool();
      if (!currentPool) {
        throw new Error('Failed to create database pool');
      }
    }

    try {
      const c = await currentPool.connect();
      try {
        await c.query(`SET statement_timeout TO ${loadConfig().db.statementTimeoutMs}`);
        // Ensure queries target the expected schema regardless of cluster defaults
        await c.query('SET search_path TO public');
        return await fn(c);
      } finally {
        c.release();
      }
    } catch (err) {
      if (attempt >= 2 || !shouldResetPoolForError(err)) {
        throw err;
      }
      // Reset pool and try once more after a short delay
      logger.warn({ err, attempt }, 'PG connect failed; resetting pool and retrying');
      await resetPool();
      await new Promise((r) => setTimeout(r, 200));
    }
  }
}

export async function withDb<T>(fn: (db: AppDb, client: PoolClient) => Promise<T>): Promise<T> {
  return withClient(async (client) => {
    const db = drizzle(client, { schema });
    return fn(db, client);
  });
}

================
File: packages/main/src/services/dbWatchdog.ts
================
import { logger } from '../logger';
import type { DbStatus } from '../../../shared/src';
import { resetPool, withClient } from './db';

const listeners = new Set<(status: DbStatus) => void>();

let status: DbStatus = {
  online: false,
  checkedAt: new Date(0).toISOString(),
  latencyMs: null,
  error: null
};

let timer: NodeJS.Timeout | null = null;
let running = false;
let rerun = false;

function emit(next: DbStatus) {
  status = next;
  for (const listener of [...listeners]) {
    try {
      listener(status);
    } catch (err) {
      logger.warn({ err }, 'db status listener threw');
    }
  }
}

async function runCheck() {
  if (running) {
    rerun = true;
    return;
  }
  running = true;
  do {
    rerun = false;
    const started = Date.now();
    try {
      await withClient((client) => client.query('SELECT 1'));
      const latencyMs = Date.now() - started;
      emit({
        online: true,
        checkedAt: new Date().toISOString(),
        latencyMs,
        error: null
      });
    } catch (err) {
      const message = err instanceof Error ? err.message : String(err);
      logger.warn({ err: message }, 'Database connectivity check failed');
      await resetPool();
      emit({
        online: false,
        checkedAt: new Date().toISOString(),
        latencyMs: null,
        error: message
      });
    }
  } while (rerun);
  running = false;
}

export function getDbStatus(): DbStatus {
  return status;
}

export function subscribeDbStatus(listener: (status: DbStatus) => void): () => void {
  listeners.add(listener);
  listener(status);
  return () => listeners.delete(listener);
}

export function triggerDbStatusCheck() {
  void runCheck();
}

export function startDbWatchdog(intervalMs = 15000) {
  if (timer) return;
  
  const scheduleNext = async () => {
    await runCheck();
    timer = setTimeout(scheduleNext, intervalMs);
  };
  
  void scheduleNext();
}

export function stopDbWatchdog() {
  if (timer) {
    clearTimeout(timer);
    timer = null;
  }
}

================
File: packages/main/src/services/diagnostics.ts
================
import { EventEmitter } from 'events';
import { randomUUID } from 'crypto';
import { app } from 'electron';
import { promises as fsp } from 'fs';
import type { Stats } from 'fs';
import { basename, dirname, isAbsolute, join, resolve } from 'path';
import type {
  CopyDiagnosticsLog,
  DiagnosticsLogSummary,
  DiagnosticsLogTailRes,
  DiagnosticsSnapshot,
  MachineHealthCode,
  MachineHealthEntry,
  WatcherStatus,
  WorkerErrorEntry
} from '../../../shared/src';

import { getDbStatus } from './dbWatchdog';
import { getLogDirectory, listLogFiles, logger } from '../logger';

type InternalWatcherStatus = WatcherStatus;

const emitter = new EventEmitter();
const watchers = new Map<string, InternalWatcherStatus>();
const MAX_ERRORS = 200;
const DEFAULT_COPY_LOGS = 3;
const DEFAULT_COPY_LINES = 200;

let recentErrors: WorkerErrorEntry[] = [];
let storePath: string | null = null;
let initialized = false;
const machineHealth = new Map<string, MachineHealthEntry>();

// Live log tailers (push updates)
type LogListener = (lines: string[]) => void;
type Tailer = {
  file: string;
  timer: NodeJS.Timeout | null;
  lastSize: number;
  buf: string; // carry partial line across reads
  listeners: Set<LogListener>;
};

const tailers = new Map<string, Tailer>();

function emitLogLines(file: string, lines: string[]) {
  const t = tailers.get(file);
  if (!t || lines.length === 0) return;
  for (const fn of t.listeners) {
    try { fn(lines); } catch { /* noop */ void 0; }
  }
}

async function pollTailer(t: Tailer) {
  try {
    const stats = await fsp.stat(t.file);
    const size = stats.size;
    if (size < t.lastSize) {
      // rotation or truncate
      t.lastSize = 0;
      t.buf = '';
    }
    if (size > t.lastSize) {
      const fd = await fsp.open(t.file, 'r');
      try {
        const toRead = size - t.lastSize;
        const buffer = Buffer.allocUnsafe(Math.min(toRead, 1024 * 1024)); // cap read chunk
        let offset = t.lastSize;
        let remaining = toRead;
        let acc = '';
        while (remaining > 0) {
          const len = Math.min(buffer.length, remaining);
          const { bytesRead } = await fd.read({ buffer, position: offset, length: len });
          if (bytesRead <= 0) break;
          acc += buffer.subarray(0, bytesRead).toString('utf8');
          offset += bytesRead;
          remaining -= bytesRead;
        }
        t.lastSize = size;
        const combined = t.buf + acc;
        const parts = combined.split(/\r?\n/);
        t.buf = parts.pop() ?? '';
        const lines = parts.filter((s) => s.length > 0);
        if (lines.length) emitLogLines(t.file, lines);
      } finally {
        await fd.close();
      }
    }
  } catch (err) {
    const code = (err as NodeJS.ErrnoException)?.code;
    if (code !== 'ENOENT') {
      try { logger.warn({ err, file: t.file }, 'diagnostics: log tailer poll failed'); } catch { /* noop */ void 0; }
    }
  }
}

function startTailer(file: string) {
  let t = tailers.get(file);
  if (!t) {
    t = { file, timer: null, lastSize: 0, buf: '', listeners: new Set() };
    tailers.set(file, t);
  }
  if (!t.timer) {
    // Initialize lastSize to current file size to only stream new lines
    fsp.stat(file).then((st) => { t!.lastSize = st.size; }).catch(() => { t!.lastSize = 0; });
    const id = setInterval(() => { void pollTailer(t!); }, 1000);
    if (typeof id.unref === 'function') id.unref();
    t.timer = id;
  }
  return t;
}

function stopTailerIfIdle(file: string) {
  const t = tailers.get(file);
  if (!t) return;
  if (t.listeners.size === 0) {
    if (t.timer) {
      clearInterval(t.timer);
      t.timer = null;
    }
    tailers.delete(file);
  }
}

export function subscribeLogStream(file: string, listener: (lines: string[]) => void): () => void {
  const t = startTailer(file);
  t.listeners.add(listener);
  return () => {
    t.listeners.delete(listener);
    stopTailerIfIdle(file);
  };
}

function emitUpdate() {
  emitter.emit('update');
}

function makeHealthKey(machineId: number | null, code: MachineHealthCode) {
  return `${machineId ?? 'global'}:${code}`;
}

function sortMachineHealthEntries(entries: MachineHealthEntry[]) {
  const severityWeight = { critical: 3, warning: 2, info: 1 } as const;
  return entries.sort((a, b) => {
    const severityDelta = severityWeight[b.severity] - severityWeight[a.severity];
    if (severityDelta !== 0) return severityDelta;
    if (a.machineId == null && b.machineId != null) return 1;
    if (a.machineId != null && b.machineId == null) return -1;
    if (a.machineId != null && b.machineId != null && a.machineId !== b.machineId) {
      return a.machineId - b.machineId;
    }
    return b.lastUpdatedAt.localeCompare(a.lastUpdatedAt);
  });
}

function getMachineHealthEntries(): MachineHealthEntry[] {
  return sortMachineHealthEntries(Array.from(machineHealth.values()));
}

function ensureWatcher(name: string, label?: string): InternalWatcherStatus {
  const existing = watchers.get(name);
  if (existing) {
    if (label && existing.label !== label) existing.label = label;
    return existing;
  }
  const created: InternalWatcherStatus = {
    name,
    label: label ?? name,
    status: 'idle',
    lastEventAt: null,
    lastEvent: null,
    lastErrorAt: null,
    lastError: null
  };
  watchers.set(name, created);
  return created;
}

async function loadExistingErrors() {
  if (!storePath) return;
  try {
    const raw = await fsp.readFile(storePath, 'utf8');
    const lines = raw
      .split(/\r?\n/)
      .map((line) => line.trim())
      .filter(Boolean)
      .slice(-MAX_ERRORS);
    const parsed: WorkerErrorEntry[] = [];
    for (const line of lines) {
      try {
        const entry = JSON.parse(line) as WorkerErrorEntry;
        if (entry && typeof entry.id === 'string' && typeof entry.timestamp === 'string') {
          parsed.push({
            id: entry.id,
            source: entry.source,
            message: entry.message,
            timestamp: entry.timestamp,
            stack: entry.stack ?? undefined,
            context: entry.context
          });
        }
      } catch (err) {
        logger.warn({ err, line }, 'diagnostics: failed to parse stored error entry');
      }
    }
    parsed.sort((a, b) => b.timestamp.localeCompare(a.timestamp));
    recentErrors = parsed.slice(0, MAX_ERRORS);
  } catch (err) {
    const code = (err as NodeJS.ErrnoException).code;
    if (code === 'ENOENT') {
      await fsp.writeFile(storePath, '');
    } else {
      logger.warn({ err }, 'diagnostics: failed to read worker error log');
    }
  }
}

export async function initializeDiagnostics(customDir?: string) {
  if (initialized) return;
  initialized = true;
  try {
    const base = customDir ?? (app.isReady() ? app.getPath('userData') : process.cwd());
    storePath = join(base, 'worker-errors.jsonl');
    await fsp.mkdir(dirname(storePath), { recursive: true });
    await loadExistingErrors();
  } catch (err) {
    logger.warn({ err }, 'diagnostics: failed to initialize persistent error store');
    storePath = null;
  }
}

function serializeErrorEntry(entry: WorkerErrorEntry) {
  return JSON.stringify(entry) + '\n';
}

function toMessage(error: unknown): { message: string; stack?: string } {
  if (error instanceof Error) {
    return { message: error.message, stack: error.stack ?? undefined };
  }
  if (typeof error === 'string') {
    return { message: error };
  }
  try {
    return { message: JSON.stringify(error) };
  } catch {
    return { message: String(error) };
  }
}

export function watcherReady(name: string, label?: string) {
  const watcher = ensureWatcher(name, label);
  watcher.status = 'watching';
  try {
    const lbl = watcher.label ?? name;
    logger.info({ watcher: name, label: lbl }, `watcher: ready - ${lbl}`);
  } catch { /* noop */ void 0; }
  emitUpdate();
}

export function recordWatcherEvent(
  name: string,
  info?: { label?: string; message?: string; context?: unknown }
) {
  const watcher = ensureWatcher(name, info?.label);
  watcher.status = 'watching';
  watcher.lastEventAt = new Date().toISOString();
  watcher.lastEvent = info?.message ?? null;
  try {
    const lbl = watcher.label ?? name;
    const msg = info?.message ?? 'event';
    logger.info({ watcher: name, label: lbl, context: info?.context }, `watcher:event - ${lbl}: ${msg}`);
  } catch { /* noop */ void 0; }
  emitUpdate();
}

export function recordWatcherError(
  name: string,
  error: unknown,
  context?: Record<string, unknown> & { label?: string }
) {
  const { label, ...rest } = context ?? {};
  const watcher = ensureWatcher(name, label as string | undefined);
  const { message } = toMessage(error);
  watcher.status = 'error';
  watcher.lastErrorAt = new Date().toISOString();
  watcher.lastError = message;
  try {
    const lbl = watcher.label ?? name;
    logger.error({ watcher: name, label: lbl, err: error, context: rest }, `watcher:error - ${lbl}: ${message}`);
  } catch { /* noop */ void 0; }
  recordWorkerError(name, error, rest);
}

export function getDiagnosticsSnapshot(): DiagnosticsSnapshot {
  return {
    dbStatus: getDbStatus(),
    watchers: Array.from(watchers.values()).sort((a, b) => a.label.localeCompare(b.label)),
    recentErrors: recentErrors.slice(0, 50),
    machineHealth: getMachineHealthEntries(),
    lastUpdatedAt: new Date().toISOString()
  };
}

export function subscribeDiagnostics(listener: (snapshot: DiagnosticsSnapshot) => void): () => void {
  const handler = () => listener(getDiagnosticsSnapshot());
  emitter.on('update', handler);
  return () => emitter.off('update', handler);
}

export function registerWatcher(name: string, label: string) {
  ensureWatcher(name, label);
  try {
    logger.info({ watcher: name, label }, `watcher: register - ${label}`);
  } catch { /* noop */ void 0; }
  emitUpdate();
}

export function recordWorkerError(
  source: string,
  error: unknown,
  context?: Record<string, unknown>
): WorkerErrorEntry {
  const { message, stack } = toMessage(error);
  const entry: WorkerErrorEntry = {
    id: randomUUID(),
    source,
    message,
    timestamp: new Date().toISOString(),
    stack: stack ?? undefined,
    context
  };

  recentErrors = [entry, ...recentErrors].slice(0, MAX_ERRORS);

  if (storePath) {
    fsp.appendFile(storePath, serializeErrorEntry(entry)).catch((err) => {
      logger.warn({ err }, 'diagnostics: failed to append worker error entry');
    });
  }

  emitUpdate();
  return entry;
}

async function readLogTail(path: string, maxLines: number): Promise<{ lines: string[]; total: number }> {
  try {
    const raw = await fsp.readFile(path, "utf8");
    const lines = raw.split(/\r?\n/);
    const filtered = lines.filter((line) => line.length > 0);
    const total = filtered.length;
    if (total <= maxLines) {
      return { lines: filtered, total };
    }
    return { lines: filtered.slice(total - maxLines), total };
  } catch (err) {
    const message = err instanceof Error ? err.message : String(err);
    logger.warn({ err: message, path }, "diagnostics: failed to read log file");
    return { lines: [`[failed to read ${path}: ${message}]`], total: 0 };
  }
}
async function statsForLog(path: string): Promise<Stats | null> {
  try {
    return await fsp.stat(path);
  } catch (err) {
    const code = (err as NodeJS.ErrnoException).code;
    if (code !== 'ENOENT') {
      logger.warn({ err, path }, "diagnostics: failed to stat log file");
    }
    return null;
  }
}

function toLogSummary(file: string, stats: Stats | null): DiagnosticsLogSummary {
  return {
    file,
    name: basename(file),
    size: stats ? stats.size : null,
    updatedAt: stats ? stats.mtime.toISOString() : null
  };
}

function resolveLogFilePath(input: string): string {
  const logDir = getLogDirectory();
  const base = resolve(logDir);
  const candidate = resolve(isAbsolute(input) ? input : join(logDir, input));
  if (!candidate.startsWith(base)) {
    throw new Error("Invalid log file path");
  }
  return candidate;
}

function ensureKnownLog(file: string): string {
  const candidate = resolveLogFilePath(file);
  const allowed = new Set(listLogFiles().map((entry) => resolve(entry)));
  if (!allowed.has(candidate)) {
    throw new Error(`Log file not found: ${file}`);
  }
  return candidate;
}




export async function buildDiagnosticsCopyPayload(options?: {
  maxLogs?: number;
  maxLines?: number;
}): Promise<{ snapshot: DiagnosticsSnapshot; logs: CopyDiagnosticsLog[] }> {
  const limitLogs = Math.max(1, options?.maxLogs ?? DEFAULT_COPY_LOGS);
  const limitLines = Math.max(1, options?.maxLines ?? DEFAULT_COPY_LINES);
  const snapshot = getDiagnosticsSnapshot();
  const files = listLogFiles();
  const selected = files.slice(-limitLogs);
  const logs: CopyDiagnosticsLog[] = [];
  for (const file of selected.reverse()) {
    const stats = await statsForLog(file);
    const { lines, total } = await readLogTail(file, limitLines);
    const summary = toLogSummary(file, stats);
    logs.push({ ...summary, lines, available: total });
  }
  return { snapshot, logs };
}

export async function listDiagnosticsLogs(): Promise<DiagnosticsLogSummary[]> {
  const files = listLogFiles();
  const summaries: DiagnosticsLogSummary[] = [];
  for (const file of files) {
    const stats = await statsForLog(file);
    summaries.push(toLogSummary(file, stats));
  }
  return summaries.sort((a, b) => {
    if (a.updatedAt && b.updatedAt && a.updatedAt !== b.updatedAt) {
      return b.updatedAt.localeCompare(a.updatedAt);
    }
    if (a.size != null && b.size != null && a.size !== b.size) {
      return b.size - a.size;
    }
    return b.name.localeCompare(a.name);
  });
}

export async function getDiagnosticsLogTail(file: string, limit: number): Promise<DiagnosticsLogTailRes> {
  const safeLimit = Math.max(10, Math.min(limit, 2000));
  const target = ensureKnownLog(file);
  const stats = await statsForLog(target);
  const { lines, total } = await readLogTail(target, safeLimit);
  return {
    ...toLogSummary(target, stats),
    lines,
    limit: safeLimit,
    available: total
  };
}

export function setMachineHealthIssue(params: {
  machineId: number | null;
  code: MachineHealthCode;
  message: string;
  severity?: MachineHealthEntry['severity'];
  context?: Record<string, unknown>;
}): MachineHealthEntry {
  const key = makeHealthKey(params.machineId, params.code);
  const previous = machineHealth.get(key);
  const entry: MachineHealthEntry = {
    id: key,
    machineId: params.machineId,
    code: params.code,
    severity: params.severity ?? previous?.severity ?? 'warning',
    message: params.message,
    lastUpdatedAt: new Date().toISOString(),
    context: params.context
      ? { ...(previous?.context ?? {}), ...params.context }
      : previous?.context
  };
  machineHealth.set(key, entry);
  emitUpdate();
  return entry;
}

export function clearMachineHealthIssue(machineId: number | null, code: MachineHealthCode) {
  const key = makeHealthKey(machineId, code);
  if (machineHealth.delete(key)) {
    emitUpdate();
  }
}

export function getMachineHealthSummary(): MachineHealthEntry[] {
  return getMachineHealthEntries();
}

================
File: packages/main/src/services/grundner.ts
================
import { loadConfig } from './config';

export type ReservedSyncMode = 'delta' | 'absolute';

type GrundnerColumn = 'type_data' | 'customer_id';

export function getGrundnerLookupColumn(): GrundnerColumn {
  const cfg = loadConfig();
  return cfg.test.sheetIdMode === 'customer_id' ? 'customer_id' : 'type_data';
}

export function getGrundnerMode(): ReservedSyncMode {
  const cfg = loadConfig();
  return cfg.grundner?.reservedAdjustmentMode ?? 'delta';
}

export function resolveMaterialKey(column: GrundnerColumn, row: { typeData: number | null; customerId: string | null }): string | null {
  if (column === 'customer_id') {
    return row.customerId?.trim() ?? null;
  }
  if (row.typeData == null) return null;
  return String(row.typeData);
}

================
File: packages/main/src/services/ingest.ts
================
import { readdirSync, readFileSync, existsSync } from 'fs';
import { join, extname, basename, relative, dirname } from 'path';
import { withClient } from './db';
import { loadConfig } from './config';
import { logger } from '../logger';

function walkDir(dir: string): string[] {
  const out: string[] = [];
  try {
    const entries = readdirSync(dir, { withFileTypes: true });
    for (const e of entries) {
      const p = join(dir, e.name);
      if (e.isDirectory()) out.push(...walkDir(p));
      else if (e.isFile()) out.push(p);
    }
  } catch (err) {
    logger.warn({ err, dir }, 'Failed to read directory during walkDir');
  }
  return out;
}

function toBaseNoExt(p: string) {
  const b = basename(p);
  const i = b.lastIndexOf('.');
  return i >= 0 ? b.substring(0, i) : b;
}

function parseNc(ncPath: string): { material?: string; size?: string; thickness?: string } {
  try {
    const txt = readFileSync(ncPath, 'utf8');
    const lines = txt.split(/\r?\n/);
    let material: string | undefined;
    let size: string | undefined;
    let thickness: string | undefined;
    for (const ln of lines) {
      const l = ln.trim();
      const m = l.match(/ID\s*=\s*([A-Za-z0-9_.-]+)/i);
      if (m && !material) material = m[1];
      const g = l.match(/G100\s+X([0-9]+(?:\.[0-9]+)?)\s+Y([0-9]+(?:\.[0-9]+)?)\s+Z([0-9]+(?:\.[0-9]+)?)/i);
      if (g && !size) {
        const x = Number.parseFloat(g[1]);
        const y = Number.parseFloat(g[2]);
        const z = g[3];
        const xInt = Number.isNaN(x) ? null : Math.round(x);
        const yInt = Number.isNaN(y) ? null : Math.round(y);
        if (xInt != null && yInt != null) {
          size = `${xInt}x${yInt}`;
        }
        thickness = z;
      }
    }
    return { material, size, thickness };
  } catch {
    return {};
  }
}

function countParts(dir: string, base: string): string | undefined {
  const entries = readdirSync(dir, { withFileTypes: true });
  let target: string | null = null;
  for (const e of entries) {
    if (!e.isFile()) continue;
    const nm = e.name.toLowerCase();
    if (nm === `${base.toLowerCase()}.pts` || nm === `${base.toLowerCase()}.lpt`) {
      target = join(dir, e.name);
      break;
    }
  }
  if (!target) return undefined;
  try {
    const txt = readFileSync(target, 'utf8');
    const lines = txt.split(/\r?\n/).map(s => s.trim()).filter(Boolean);
    return String(lines.length);
  } catch {
    return undefined;
  }
}

export async function ingestProcessedJobsRoot(): Promise<{ inserted: number; updated: number }> {
  const cfg = loadConfig();
  const root = cfg.paths.processedJobsRoot;
  if (!root) {
    logger.warn('No processedJobsRoot configured, skipping ingest');
    return { inserted: 0, updated: 0 };
  }
  if (!existsSync(root)) {
    logger.error({ root }, 'processedJobsRoot path does not exist');
    return { inserted: 0, updated: 0 };
  }
  let inserted = 0, updated = 0;
  const files = walkDir(root).filter(p => extname(p).toLowerCase() === '.nc');
  for (const nc of files) {
    const dir = dirname(nc);
    const base = toBaseNoExt(nc);
    const baseNoExt = basename(base);
    const relFolder = relative(root, dir).split('\\').join('/');
    const folderLeaf = basename(dir);
    const key = `${relFolder}/${baseNoExt}`.replace(/^\//, '').slice(0, 100);
    const { material, size, thickness } = parseNc(nc);
    const parts = countParts(dir, baseNoExt);
    const sql = `INSERT INTO public.jobs(key, folder, ncfile, material, parts, size, thickness, dateadded, updated_at)
                   VALUES($1,$2,$3,$4,$5,$6,$7, now(), now())
                   ON CONFLICT (key) DO UPDATE SET
                     folder=EXCLUDED.folder,
                     ncfile=EXCLUDED.ncfile,
                     material=COALESCE(EXCLUDED.material, jobs.material),
                     parts=COALESCE(EXCLUDED.parts, jobs.parts),
                     size=COALESCE(EXCLUDED.size, jobs.size),
                     thickness=COALESCE(EXCLUDED.thickness, jobs.thickness),
                     updated_at=now()
                   RETURNING (xmax = 0) AS inserted`;
    try {
      const res = await withClient(c => c.query<{ inserted: boolean }>(sql, [
        key,
        folderLeaf,
        baseNoExt,
        material ?? null,
        parts ?? null,
        size ?? null,
        thickness ?? null
      ]));
      const wasInserted = (res.rows?.[0]?.inserted ?? false) as boolean;
      if (wasInserted) inserted++; else updated++;
    } catch (e) {
      logger.warn({ err: e }, 'ingest upsert failed');
      // Keep counters stable; treat failures as neither inserted nor updated
    }
  }
  return { inserted, updated };
}

================
File: packages/main/src/services/readyImport.ts
================
import { promises as fsp } from 'fs';
import { basename, dirname, extname, join, relative, resolve } from 'path';
import { eq } from 'drizzle-orm';
import type { JobStatus, ReadyImportRes } from '../../../shared/src';
import { jobs } from '../db/schema';
import { appendJobEvent } from '../repo/jobEventsRepo';
import { getMachine } from '../repo/machinesRepo';
import { withDb } from './db';

function toPosix(path: string): string {
  return path.split('\\').join('/');
}

async function parseNcMetadata(filePath: string): Promise<{
  material: string | null;
  size: string | null;
  thickness: string | null;
}> {
  try {
    const raw = await fsp.readFile(filePath, 'utf8');
    const lines = raw.split(/\r?\n/);
    let material: string | null = null;
    let size: string | null = null;
    let thickness: string | null = null;
    for (const line of lines) {
      const trimmed = line.trim();
      if (!material) {
        const match = trimmed.match(/ID\s*=\s*([A-Za-z0-9_.-]+)/i);
        if (match) {
          material = match[1];
        }
      }
      if (!size || !thickness) {
        const match = trimmed.match(
          /G100\s+X([0-9]+(?:\.[0-9]+)?)\s+Y([0-9]+(?:\.[0-9]+)?)\s+Z([0-9]+(?:\.[0-9]+)?)/i
        );
        if (match) {
          size = `${match[1]}x${match[2]}`;
          thickness = match[3];
        }
      }
      if (material && size && thickness) {
        break;
      }
    }
    return { material, size, thickness };
  } catch (err) {
    const message = err instanceof Error ? err.message : String(err);
    throw new Error(`Failed to read NC file: ${message}`);
  }
}

async function countParts(directory: string, base: string): Promise<string | null> {
  try {
    const entries = await fsp.readdir(directory, { withFileTypes: true });
    const lowerBase = base.toLowerCase();
    const target = entries.find((entry) => {
      if (!entry.isFile()) return false;
      const name = entry.name.toLowerCase();
      return name === `${lowerBase}.pts` || name === `${lowerBase}.lpt`;
    });
    if (!target) {
      return null;
    }
    const file = join(directory, target.name);
    const raw = await fsp.readFile(file, 'utf8');
    const lines = raw
      .split(/\r?\n/)
      .map((line) => line.trim())
      .filter((line) => line.length > 0);
    return String(lines.length);
  } catch {
    return null;
  }
}

function buildJobKey(relativePath: string): { key: string; baseName: string } {
  const normalized = toPosix(relativePath).replace(/^\/+/, '');
  const lastSlash = normalized.lastIndexOf('/');
  const folderRelative = lastSlash >= 0 ? normalized.slice(0, lastSlash) : '';
  const fileName = lastSlash >= 0 ? normalized.slice(lastSlash + 1) : normalized;
  const baseName = fileName.replace(/\.[^./]+$/, '') || fileName;
  const key = (folderRelative ? `${folderRelative}/${baseName}` : baseName).slice(0, 100);
  return { key, baseName };
}

export async function importReadyFile(machineId: number, relativePath: string): Promise<ReadyImportRes> {
  const machine = await getMachine(machineId);
  if (!machine) {
    throw new Error(`Machine ${machineId} not found`);
  }
  const root = machine.apJobfolder?.trim();
  if (!root) {
    throw new Error('Machine ap_jobfolder is not configured');
  }
  if (!relativePath) {
    throw new Error('relativePath is required');
  }

  const rootResolved = resolve(root);
  const normalizedRelative = toPosix(relativePath).replace(/^\/+/, '');
  const absolutePath = resolve(rootResolved, normalizedRelative);
  const relativeCheck = relative(rootResolved, absolutePath);
  if (relativeCheck.startsWith('..')) {
    throw new Error('Resolved path escapes machine job folder');
  }
  if (extname(absolutePath).toLowerCase() !== '.nc') {
    throw new Error('Only NC files can be imported');
  }

  const stats = await fsp.stat(absolutePath).catch((err) => {
    const message = err instanceof Error ? err.message : String(err);
    throw new Error(`Failed to access NC file: ${message}`);
  });
  if (!stats.isFile()) {
    throw new Error('Provided path does not point to a file');
  }

  const { key, baseName } = buildJobKey(relativePath);
  const folderAbsolute = dirname(absolutePath);
  const folderLeaf = basename(folderAbsolute);
  const metadata = await parseNcMetadata(absolutePath);
  const parts = await countParts(folderAbsolute, baseName);
  const now = new Date();

  return withDb(async (db) => {
    const existing = await db
      .select({
        status: jobs.status,
        material: jobs.material,
        size: jobs.size,
        thickness: jobs.thickness,
        parts: jobs.parts
      })
      .from(jobs)
      .where(eq(jobs.key, key))
      .limit(1);

    const nextMaterial = metadata.material ?? existing[0]?.material ?? null;
    const nextSize = metadata.size ?? existing[0]?.size ?? null;
    const nextThickness = metadata.thickness ?? existing[0]?.thickness ?? null;
    const nextParts = parts ?? existing[0]?.parts ?? null;

    if (existing.length) {
      await db
        .update(jobs)
        .set({
          folder: folderLeaf,
          ncfile: baseName,
          material: nextMaterial,
          size: nextSize,
          thickness: nextThickness,
          parts: nextParts,
          machineId,
          updatedAt: now
        })
        .where(eq(jobs.key, key));

      await appendJobEvent(
        key,
        'manual-import:updated',
        { relativePath: toPosix(relativePath), machineId },
        machineId,
        db
      );

      return {
        jobKey: key,
        created: false,
        status: existing[0].status as JobStatus,
        folder: folderLeaf,
        ncfile: baseName,
        material: nextMaterial,
        size: nextSize,
        thickness: nextThickness,
        parts: nextParts
      };
    }

    const status: JobStatus = 'PENDING';
    await db.insert(jobs).values({
      key,
      folder: folderLeaf,
      ncfile: baseName,
      material: metadata.material,
      size: metadata.size,
      thickness: metadata.thickness,
      parts,
      machineId,
      status,
      dateAdded: now,
      updatedAt: now
    });

    await appendJobEvent(
      key,
      'manual-import:created',
      { relativePath: toPosix(relativePath), machineId },
      machineId,
      db
    );

    return {
      jobKey: key,
      created: true,
      status,
      folder: folderLeaf,
      ncfile: baseName,
      material: metadata.material,
      size: metadata.size,
      thickness: metadata.thickness,
      parts
    };
  });
}

================
File: packages/main/src/services/uiState.ts
================
import { app, nativeTheme } from 'electron';
import type { BrowserWindow } from 'electron';
import { existsSync, mkdirSync, readFileSync, writeFileSync } from 'fs';
import { dirname, join } from 'path';
import { logger } from '../logger';

export type ThemePreference = 'system' | 'light' | 'dark' | 'modern';

export type WindowState = {
  x?: number;
  y?: number;
  width: number;
  height: number;
  maximized?: boolean;
};

type UiState = {
  window?: WindowState;
  theme?: ThemePreference;
};

const DEFAULT_WINDOW: WindowState = { width: 1280, height: 800 };
let cachedState: UiState | null = null;

function getStatePath() {
  const base = app.getPath('userData');
  return join(base, 'ui-state.json');
}

function loadState(): UiState {
  if (cachedState) return cachedState;
  const file = getStatePath();
  try {
    if (!existsSync(file)) {
      cachedState = {};
      return cachedState;
    }
    const raw = readFileSync(file, 'utf8');
    cachedState = JSON.parse(raw) as UiState;
    return cachedState ?? {};
  } catch (error) {
    logger.warn({ error }, 'Failed to load UI state');
    cachedState = {};
    return cachedState;
  }
}

function persistState(next: UiState) {
  const file = getStatePath();
  const dir = dirname(file);
  if (!existsSync(dir)) mkdirSync(dir, { recursive: true });
  try {
    writeFileSync(file, JSON.stringify(next, null, 2), 'utf8');
    cachedState = next;
  } catch (error) {
    logger.warn({ error }, 'Failed to persist UI state');
  }
}

function clampWindowBounds(bounds: Partial<WindowState>): WindowState {
  const width = Math.max(bounds.width ?? DEFAULT_WINDOW.width, 960);
  const height = Math.max(bounds.height ?? DEFAULT_WINDOW.height, 600);
  const x = Number.isFinite(bounds.x) ? bounds.x : undefined;
  const y = Number.isFinite(bounds.y) ? bounds.y : undefined;
  return { width, height, x, y, maximized: bounds.maximized ?? false };
}

export function getStoredWindowState(): WindowState {
  const state = loadState();
  return clampWindowBounds(state.window ?? DEFAULT_WINDOW);
}

function captureWindowState(win: BrowserWindow) {
  if (win.isDestroyed()) return;
  const isFullScreen = win.isFullScreen();
  const isMaximized = win.isMaximized() || isFullScreen;
  const bounds = isMaximized ? win.getNormalBounds() : win.getBounds();
  const next: UiState = {
    ...loadState(),
    window: clampWindowBounds({
      x: bounds.x,
      y: bounds.y,
      width: bounds.width,
      height: bounds.height,
      maximized: isMaximized
    })
  };
  persistState(next);
}

export function monitorWindowState(win: BrowserWindow) {
  let timer: NodeJS.Timeout | null = null;
  const schedule = () => {
    if (timer) clearTimeout(timer);
    timer = setTimeout(() => {
      timer = null;
      captureWindowState(win);
    }, 500);
  };
  win.on('move', schedule);
  win.on('resize', schedule);
  win.on('maximize', schedule);
  win.on('unmaximize', schedule);
  win.on('close', () => {
    if (timer) {
      clearTimeout(timer);
      timer = null;
    }
    captureWindowState(win);
  });
}

export function getThemePreference(): ThemePreference {
  const state = loadState();
  const pref = state.theme;
  if (pref === 'light' || pref === 'dark' || pref === 'system' || pref === 'modern') {
    return pref;
  }
  return 'system';
}

export function applyStoredThemePreference(): ThemePreference {
  const preference = getThemePreference();
  // Electron supports 'system' | 'light' | 'dark' for themeSource.
  nativeTheme.themeSource = preference === 'modern' ? 'dark' : preference;
  return preference;
}

export function setThemePreference(preference: ThemePreference) {
  nativeTheme.themeSource = preference === 'modern' ? 'dark' : preference;
  const next: UiState = { ...loadState(), theme: preference };
  persistState(next);
}

================
File: packages/main/src/services/watchers.ts
================
import { existsSync } from 'fs';
import { join } from 'path';
import { dialog } from 'electron';
import { Worker } from 'worker_threads';
import { logger } from '../logger';
import {
  registerWatcher,
  watcherReady,
  recordWatcherEvent,
  recordWatcherError,
  recordWorkerError,
  setMachineHealthIssue,
  clearMachineHealthIssue
} from './diagnostics';
import type {
  WatcherWorkerToMainMessage,
  MainToWatcherMessage,
  SerializableError
} from '../workers/watchersMessages';

let worker: Worker | null = null;
let shuttingDown = false;
let restartTimer: NodeJS.Timeout | null = null;

function resolveWorkerPath() {
  const override = process.env.WOODTRON_WATCHERS_WORKER_PATH?.trim();
  if (override) {
    return override;
  }
  const candidates = [
    join(__dirname, 'workers', 'watchersWorker.js'),
    join(__dirname, '..', 'dist', 'workers', 'watchersWorker.js'),
    join(__dirname, '..', 'workers', 'watchersWorker.js')
  ];
  const existing = candidates.find((candidate) => existsSync(candidate));
  return existing ?? candidates[0];
}

function toError(serialized: SerializableError): Error {
  const err = new Error(serialized.message);
  if (serialized.stack) {
    err.stack = serialized.stack;
  }
  return err;
}

function handleWorkerMessage(message: WatcherWorkerToMainMessage) {
  switch (message.type) {
    case 'log': {
      const base = { ...message.context, proc: 'Watchers' };
      const m = String(message.msg ?? '');
      switch (message.level) {
        case 'trace':
          logger.trace(base, m);
          break;
        case 'debug':
          logger.debug(base, m);
          break;
        case 'info':
          logger.info(base, m);
          break;
        case 'warn':
          logger.warn(base, m);
          break;
        case 'error':
          logger.error(base, m);
          break;
        case 'fatal':
          logger.fatal(base, m);
          break;
        default:
          logger.info(base, m);
      }
      break;
    }
    case 'registerWatcher':
      registerWatcher(message.name, message.label);
      break;
    case 'watcherReady':
      watcherReady(message.name, message.label ?? message.name);
      break;
    case 'watcherEvent':
      recordWatcherEvent(message.name, {
        label: message.label ?? message.name,
        message: message.message,
        context: message.context
      });
      break;
    case 'watcherError': {
      const context = {
        ...(message.context ?? {}),
        label: message.label ?? message.name
      };
      recordWatcherError(message.name, toError(message.error), context);
      break;
    }
    case 'userAlert': {
      const { title, message: body } = message;
      void dialog.showMessageBox({ type: 'warning', title, message: body, buttons: ['OK'], defaultId: 0 });
      break;
    }
    case 'workerError':
      recordWorkerError(message.source, toError(message.error), message.context);
      break;
    case 'machineHealthSet':
      setMachineHealthIssue(message.payload);
      break;
    case 'machineHealthClear':
      clearMachineHealthIssue(message.payload.machineId, message.payload.code);
      break;
    default:
      logger.warn({ message }, 'watchers: received unknown worker message');
  }
}

function scheduleRestart() {
  if (restartTimer || shuttingDown) return;
  restartTimer = setTimeout(() => {
    restartTimer = null;
    logger.info('watchers: restarting worker after unexpected exit');
    spawnWorker();
  }, 2_000);
  if (typeof restartTimer.unref === 'function') {
    restartTimer.unref();
  }
}

function spawnWorker() {
  try {
    const script = resolveWorkerPath();
    const instance = new Worker(script);
    worker = instance;
    instance.on('message', handleWorkerMessage);
    instance.on('error', (err) => {
      recordWorkerError('watchers-worker', err);
      logger.error({ err }, 'watchers: worker thread error');
    });
    instance.on('exit', (code) => {
      worker = null;
      if (shuttingDown) {
        return;
      }
      if (code !== 0) {
        const err = new Error(`Watchers worker exited with code ${code}`);
        recordWorkerError('watchers-worker', err);
        logger.error({ code }, 'watchers: worker exited unexpectedly');
        scheduleRestart();
      }
    });
    logger.info('watchers: worker thread started');
  } catch (err) {
    recordWorkerError('watchers-worker', err);
    logger.error({ err }, 'watchers: failed to start worker thread');
  }
}

export function initWatchers() {
  if (worker || shuttingDown) {
    return;
  }
  spawnWorker();
}

export async function shutdownWatchers(): Promise<void> {
  if (shuttingDown) {
    return;
  }
  shuttingDown = true;
  if (restartTimer) {
    clearTimeout(restartTimer);
    restartTimer = null;
  }
  const current = worker;
  if (!current) {
    return;
  }
  worker = null;

  return new Promise((resolve) => {
    let finished = false;
    const finish = () => {
      if (finished) return;
      finished = true;
      resolve();
    };

    const timeout = setTimeout(() => {
      current.terminate().then(finish, finish);
    }, 5_000);

    current.once('exit', () => {
      clearTimeout(timeout);
      finish();
    });

    try {
      const message: MainToWatcherMessage = { type: 'shutdown', reason: 'app-quit' };
      current.postMessage(message);
    } catch (err) {
      recordWorkerError('watchers-worker', err);
      clearTimeout(timeout);
      current.terminate().then(finish, finish);
    }
  });
}

================
File: packages/main/src/services/worklist.ts
================
import type { Dirent } from 'fs';
import { existsSync, mkdirSync, copyFileSync, readdirSync, statSync, readFileSync } from 'fs';
import { basename, dirname, extname, isAbsolute, join, normalize, relative, resolve, sep } from 'path';
import type { WorklistAddResult, WorklistCollisionInfo, WorklistSkippedFile } from '../../../shared/src';
import { appendJobEvent } from '../repo/jobEventsRepo';
import { listMachines } from '../repo/machinesRepo';
import { resetJobForRestage, updateLifecycle } from '../repo/jobsRepo';
import { logger } from '../logger';
import { loadConfig } from './config';
import { withClient } from './db';

const OVERWRITE_PATTERNS: RegExp[] = [
  /^planit.*\.csv$/i,
  /\.csv$/i,
  /\.nc$/i,
  /\.lpt$/i,
  /\.pts$/i,
  /\.(bmp|jpg|jpeg|png|gif)$/i
];

function walk(dir: string): string[] {
  let entries: Dirent[] = [];
  try {
    entries = readdirSync(dir, { withFileTypes: true });
  } catch (err) {
    logger.warn({ err, dir }, 'worklist: failed to read directory');
    return [];
  }

  const out: string[] = [];
  for (const e of entries) {
    const p = join(dir, e.name);
    if (e.isDirectory()) out.push(...walk(p));
    else if (e.isFile()) out.push(p);
  }
  return out;
}

function isDir(path: string) {
  try {
    return statSync(path).isDirectory();
  } catch {
    return false;
  }
}

function resolveSourceRoot(rawFolder: string | null, processedRoot: string, jobKey: string): string | null {
  const trimmed = rawFolder?.trim() ?? '';
  if (trimmed) {
    const normalized = normalize(trimmed);

    if (isAbsolute(normalized) && isDir(normalized)) {
      return normalized;
    }

    if (isDir(normalized)) {
      return normalize(normalized);
    }

    if (processedRoot) {
      const candidate = resolve(processedRoot, normalized);
      const rel = relative(resolve(processedRoot), candidate);
      if (!rel.startsWith('..') && !rel.includes(`..${sep}`) && isDir(candidate)) {
        return candidate;
      }
    }
  }

  if (!processedRoot) return null;

  const slashIndex = jobKey.lastIndexOf('/');
  const keyFolder = slashIndex >= 0 ? jobKey.slice(0, slashIndex) : '';
  const candidateFromKey = keyFolder
    ? resolve(processedRoot, keyFolder.split('/').join(sep))
    : processedRoot;

  const relFromKey = relative(resolve(processedRoot), candidateFromKey);
  if (relFromKey.startsWith('..') || relFromKey.includes(`..${sep}`)) {
    return null;
  }
  return isDir(candidateFromKey) ? candidateFromKey : null;
}

function formatTimestampForDir(date: Date) {
  const pad = (value: number) => value.toString().padStart(2, '0');
  const year = date.getFullYear();
  const month = pad(date.getMonth() + 1);
  const day = pad(date.getDate());
  const hours = pad(date.getHours());
  const minutes = pad(date.getMinutes());
  const seconds = pad(date.getSeconds());
  return `${year}${month}${day}-${hours}${minutes}${seconds}`;
}

function toPosixRelative(path: string) {
  return path.split('\\').join('/');
}

function canOverwrite(name: string) {
  return OVERWRITE_PATTERNS.some((pattern) => pattern.test(name));
}

function chooseDestination(baseDir: string): { path: string; collision?: WorklistCollisionInfo } {
  if (!existsSync(baseDir)) {
    return { path: baseDir };
  }

  const parent = dirname(baseDir);
  const leaf = basename(baseDir);
  const timestamp = formatTimestampForDir(new Date());
  let candidate = join(parent, `${leaf}_${timestamp}`);
  let suffix = 1;
  while (existsSync(candidate)) {
    candidate = join(parent, `${leaf}_${timestamp}_${suffix}`);
    suffix += 1;
  }

  const collision: WorklistCollisionInfo = {
    originalPath: baseDir,
    redirectedPath: candidate
  };
  logger.info({ baseDir, redirectedPath: candidate }, 'worklist: collision detected, staging into timestamped directory');
  return { path: candidate, collision };
}

export async function addJobToWorklist(key: string, machineId: number): Promise<WorklistAddResult> {
  const job = await withClient(async (c) => {
    const r = await c.query(
      `SELECT key, folder, ncfile FROM public.jobs WHERE key = $1`,
      [key]
    );
    return r.rows[0] as { key: string; folder: string | null; ncfile: string | null } | undefined;
  });
  if (!job) return { ok: false, error: 'Job not found' };

  const machines = await listMachines();
  const m = machines.find((x) => x.machineId === machineId);
  if (!m) return { ok: false, error: 'Machine not found' };
  const destDir = m.apJobfolder;
  if (!destDir) return { ok: false, error: 'Machine ap_jobfolder is empty' };

  if (!job.ncfile) return { ok: false, error: 'Job ncfile missing' };

  const resetResult = await resetJobForRestage(job.key);
  if (resetResult.reset) {
    logger.info(
      {
        jobKey: job.key,
        iteration: resetResult.iteration,
        previousStatus: resetResult.previousStatus,
        machineId
      },
      'worklist: lifecycle reset for restaging'
    );
  }

  const cfg = loadConfig();
  const sourceRoot = resolveSourceRoot(job.folder, cfg.paths.processedJobsRoot || '', job.key);
  if (!sourceRoot) {
    logger.warn({ folder: job.folder, jobKey: job.key, processedRoot: cfg.paths.processedJobsRoot }, 'worklist: source folder unresolved');
    return { ok: false, error: 'Source folder not found' };
  }

  const leaf = basename(sourceRoot) || 'job';
  const destBaseDir = join(destDir, leaf);
  const { path: finalDestBaseDir, collision } = chooseDestination(destBaseDir);
  if (!existsSync(finalDestBaseDir)) mkdirSync(finalDestBaseDir, { recursive: true });

  const files = walk(sourceRoot);
  if (!files.length) {
    return { ok: false, error: 'No files found in source folder' };
  }

  const filesByName = new Map<string, string[]>();
  const filesByRelLower = new Map<string, string>();
  const csvFiles: string[] = [];
  for (const filePath of files) {
    const nameLower = basename(filePath).toLowerCase();
    const list = filesByName.get(nameLower) ?? [];
    list.push(filePath);
    filesByName.set(nameLower, list);
    if (nameLower.endsWith('.csv')) {
      csvFiles.push(filePath);
    }
    const rel = relative(sourceRoot, filePath).replace(/^[\\/]+/, '');
    filesByRelLower.set(rel.toLowerCase(), filePath);
  }

  const ncFileName = job.ncfile.trim();
  const ncFileNameLower = ncFileName.toLowerCase();

  const pickFileByName = (nameLower: string, preferredDirLower?: string): string | null => {
    const candidates = filesByName.get(nameLower);
    if (!candidates?.length) return null;
    if (!preferredDirLower) return candidates[0];
    const normalizedPreferred = normalize(preferredDirLower).toLowerCase();
    const sorted = [...candidates].sort((a, b) => {
      const weight = (p: string) => {
        const dirLower = normalize(dirname(p)).toLowerCase();
        return dirLower === normalizedPreferred ? 0 : 1;
      };
      const diff = weight(a) - weight(b);
      if (diff !== 0) return diff;
      return a.localeCompare(b);
    });
    return sorted[0] ?? null;
  };

  const resolveTokenToFile = (token: string, preferredDirLower?: string): string | null => {
    if (!token) return null;
    const normalizedToken = token.replace(/^["']|["']$/g, '').trim();
    if (!normalizedToken) return null;
    let tokenLower = normalizedToken.toLowerCase();

    const direct = filesByRelLower.get(tokenLower);
    if (direct) return direct;

    tokenLower = tokenLower.replace(/^\.\/?/, '').replace(/^\\/, '');
    const trimmed = filesByRelLower.get(tokenLower);
    if (trimmed) return trimmed;

    const base = basename(normalizedToken);
    if (base) {
      const baseLower = base.toLowerCase();
      const resolved = pickFileByName(baseLower, preferredDirLower);
      if (resolved) return resolved;
    }

    return null;
  };

  let ncPath = pickFileByName(ncFileNameLower);
  // Fallback: if DB value omitted extension, try appending .nc (case-insensitive)
  if (!ncPath) {
    const hasExt = !!extname(ncFileNameLower);
    if (!hasExt) {
      const withNc = `${ncFileNameLower}.nc`;
      ncPath = pickFileByName(withNc);
    }
  }
  if (!ncPath) {
    logger.warn({ ncfile: job.ncfile, sourceRoot }, 'worklist: nc file not found');
    return { ok: false, error: `NC file ${job.ncfile} not found` };
  }

  const preferredDirLower = normalize(dirname(ncPath)).toLowerCase();

  const filesToCopy = new Map<string, string>();
  const addCopyTarget = (filePath: string) => {
    const relPath = relative(sourceRoot, filePath);
    if (relPath.startsWith('..')) {
      logger.debug({ filePath, sourceRoot }, 'worklist: candidate outside source root, skipping');
      return;
    }
    const normalizedRel = relPath.replace(/^[\\/]+/, '');
    filesToCopy.set(filePath, normalizedRel);
  };

  addCopyTarget(ncPath);

  const removeExtension = (value: string) => {
    const ext = extname(value);
    return ext ? value.slice(0, -ext.length) : value;
  };

  const ncBaseName = removeExtension(ncFileName);
  const ncBaseLower = ncBaseName.toLowerCase();

  const associatedExtensions = ['.lpt', '.pts', '.bmp', '.jpg', '.jpeg'];
  let lptPath: string | null = null;
  let hasPtsForAlphaCam = false;
  for (const ext of associatedExtensions) {
    const candidate = pickFileByName(`${ncBaseLower}${ext}`, preferredDirLower);
    if (candidate) {
      addCopyTarget(candidate);
      if (ext === '.lpt') lptPath = candidate;
      if (ext === '.pts') hasPtsForAlphaCam = true;
    } else {
      logger.debug({ key: job.key, file: `${ncBaseName}${ext}` }, 'worklist: associated file not found');
    }
  }

  const exactCsv = pickFileByName(`${ncBaseLower}.csv`, preferredDirLower);
  if (exactCsv) {
    addCopyTarget(exactCsv);
  }

  // Decide scanning mode
  const mode: 'alphacam' | 'planit' | 'generic' = hasPtsForAlphaCam ? 'alphacam' : (lptPath ? 'planit' : 'generic');

  const prefix = ncBaseLower.slice(0, 3);
  let planitCsvPath: string | null = null;
  let planitPrefixCsvPath: string | null = null;
  if (mode === 'planit' && prefix.length === 3) {
    // Copy the exact per-file CSV (already handled via exactCsv above)
    // Additionally, copy the family CSV: first three chars only (e.g., RJT.csv)
    const familyCsvName = `${prefix}.csv`;
    planitPrefixCsvPath = pickFileByName(familyCsvName, preferredDirLower);
    if (planitPrefixCsvPath) {
      addCopyTarget(planitPrefixCsvPath);
    } else {
      logger.debug({ key: job.key, prefix }, 'worklist: family CSV (prefix.csv) not found');
    }
    // Image mapping must use the family CSV (prefix.csv), not the per-file CSV
    planitCsvPath = planitPrefixCsvPath ?? null;
  }

  // Planit-only image mapping via LPT/CSV
  if (mode === 'planit' && lptPath) {
    let lptContent = '';
    try {
      lptContent = readFileSync(lptPath, 'utf8');
    } catch (err) {
      logger.warn({ err, lptPath }, 'worklist: failed to read LPT file');
    }

    if (lptContent) {
      const labelNumbers = new Set<number>();
      for (const line of lptContent.split(/\r?\n/)) {
        const trimmed = line.trim();
        if (!trimmed) continue;
        const cols = trimmed.split(',');
        if (cols.length < 3) continue;
        const value = parseInt(cols[2].trim(), 10);
        if (!Number.isNaN(value)) labelNumbers.add(value);
      }

      if (labelNumbers.size > 0) {
        const imageTokensByLabel = new Map<number, string[]>();
        if (planitCsvPath) {
          try {
            const mapContent = readFileSync(planitCsvPath, 'utf8');
            for (const row of mapContent.split(/\r?\n/)) {
              if (!row.trim()) continue;
              const cols = row.split(',');
              if (!cols.length) continue;
              const label = parseInt(cols[0].trim(), 10);
              if (Number.isNaN(label)) continue;
              const tokens: string[] = [];
              for (const raw of cols) {
                const token = raw.trim();
                if (!token) continue;
                const lower = token.toLowerCase();
                if (lower.endsWith('.bmp') || lower.endsWith('.jpg') || lower.endsWith('.jpeg')) {
                  tokens.push(token);
                }
              }
              if (tokens.length) {
                const existing = imageTokensByLabel.get(label) ?? [];
                imageTokensByLabel.set(label, existing.concat(tokens));
              }
            }
          } catch (err) {
            logger.warn({ err, planitCsvPath }, 'worklist: failed to read Planit CSV');
          }
        }

        const seenImages = new Set<string>();
        const tryAddImage = (token: string) => {
          const resolved = resolveTokenToFile(token, preferredDirLower);
          if (resolved) {
            const keyLower = resolved.toLowerCase();
            if (!seenImages.has(keyLower)) {
              addCopyTarget(resolved);
              seenImages.add(keyLower);
            }
            return true;
          }
          const base = basename(token);
          if (base) {
            const bmp = resolveTokenToFile(`${base}.bmp`, preferredDirLower);
            if (bmp && !seenImages.has(bmp.toLowerCase())) {
              addCopyTarget(bmp);
              seenImages.add(bmp.toLowerCase());
              return true;
            }
            const jpg = resolveTokenToFile(`${base}.jpg`, preferredDirLower);
            if (jpg && !seenImages.has(jpg.toLowerCase())) {
              addCopyTarget(jpg);
              seenImages.add(jpg.toLowerCase());
              return true;
            }
          }
          return false;
        };

        for (const label of labelNumbers) {
          const tokens = imageTokensByLabel.get(label) ?? [];
          let copiedImage = false;
          for (const token of tokens) {
            if (tryAddImage(token)) {
              copiedImage = true;
              break;
            }
          }
          if (!copiedImage && tokens.length) {
            logger.debug({ key: job.key, label }, 'worklist: unable to resolve image token for label');
          }
          if (!tokens.length) {
            logger.debug({ key: job.key, label }, 'worklist: no image mapping for label in Planit CSV');
          }
        }
      }
    }
  }

  // Alphacam-only: if a .pts exists for the same base name, copy all images matching
  // `${ncBase}*.bmp|jpg|jpeg` from job root and subfolders
  if (mode === 'alphacam') {
    for (const filePath of files) {
      const nameLower = basename(filePath).toLowerCase();
      if (nameLower.endsWith('.bmp') || nameLower.endsWith('.jpg') || nameLower.endsWith('.jpeg')) {
        const baseNoExt = removeExtension(nameLower);
        if (baseNoExt.startsWith(ncBaseLower)) {
          addCopyTarget(filePath);
        }
      }
    }
  }

  const skipped: WorklistSkippedFile[] = [];
  let copied = 0;

  for (const [src, rel] of filesToCopy.entries()) {
    const relPosix = toPosixRelative(rel);
    const dest = join(finalDestBaseDir, rel);
    const destParent = dirname(dest);
    if (!existsSync(destParent)) mkdirSync(destParent, { recursive: true });

    const fileName = basename(src);
    if (existsSync(dest) && !canOverwrite(fileName)) {
      skipped.push({ relativePath: relPosix, reason: 'exists', message: 'Destination file already exists' });
      logger.debug({ src, dest }, 'worklist: skipped existing file');
      continue;
    }

    try {
      copyFileSync(src, dest);
      copied++;
    } catch (err) {
      const message = err instanceof Error ? err.message : String(err);
      skipped.push({ relativePath: relPosix, reason: 'error', message });
      logger.warn({ err, src, dest }, 'worklist: copy failed');
    }
  }

  if (copied === 0) {
    return { ok: false, error: 'No files copied (all skipped or failed)', skipped };
  }

  let stagedAt: string | null = null;
  let alreadyStaged = false;

  try {
    const lifecycle = await updateLifecycle(job.key, 'STAGED', {
      machineId,
      source: 'worklist',
      payload: { dest: finalDestBaseDir, copied, skipped }
    });

    if (lifecycle.ok) {
      stagedAt = lifecycle.stagedAt ?? null;
      alreadyStaged = lifecycle.previousStatus === 'STAGED';
    } else if (lifecycle.reason === 'NO_CHANGE') {
      stagedAt = lifecycle.stagedAt ?? null;
      alreadyStaged = true;
    } else {
      logger.warn({ key: job.key, lifecycle }, 'worklist: lifecycle update failed');
      return { ok: false, error: `Lifecycle update failed: ${lifecycle.reason}`, skipped };
    }
  } catch (err) {
    logger.warn({ err, key: job.key }, 'worklist: lifecycle update threw');
    return { ok: false, error: 'Lifecycle update threw an exception', skipped };
  }

  try {
    await appendJobEvent(job.key, 'worklist:staged', { dest: finalDestBaseDir, copied, skipped }, machineId);
  } catch (err) {
    logger.warn({ err, key: job.key }, 'worklist: failed to append job event');
  }

  return {
    ok: true,
    path: finalDestBaseDir,
    copied,
    skipped,
    stagedAt,
    alreadyStaged,
    ...(collision ? { collision } : {})
  };
}

================
File: packages/main/src/workers/telemetryParser.ts
================
import type { Machine } from '../../../shared/src';
import type { CncStatsUpsert } from '../repo/cncStatsRepo';

type FlatMap = Map<string, unknown>;

function normalizeKey(key: string): string {
  return key.toLowerCase().replace(/[^a-z0-9]/g, '');
}

function flattenTelemetry(value: unknown, map: FlatMap = new Map(), prefix = ''): FlatMap {
  if (value && typeof value === 'object' && !Array.isArray(value)) {
    for (const [rawKey, rawValue] of Object.entries(value as Record<string, unknown>)) {
      const path = prefix ? `${prefix}.${rawKey}` : rawKey;
      if (rawValue && typeof rawValue === 'object' && !Array.isArray(rawValue)) {
        flattenTelemetry(rawValue, map, path);
      } else {
        map.set(normalizeKey(path), rawValue ?? null);
      }
    }
  }
  return map;
}

function coerceToString(value: unknown): string | null {
  if (value == null) return null;
  if (typeof value === 'string') {
    const trimmed = value.trim();
    return trimmed.length > 0 ? trimmed : null;
  }
  if (typeof value === 'number' || typeof value === 'bigint') {
    return String(value);
  }
  if (typeof value === 'boolean') {
    return value ? 'true' : 'false';
  }
  if (value instanceof Date) {
    return value.toISOString();
  }
  try {
    return JSON.stringify(value);
  } catch {
    return String(value);
  }
}

function pick(flat: FlatMap, candidates: string[]): string | null {
  for (const candidate of candidates) {
    const normalized = normalizeKey(candidate);
    if (flat.has(normalized)) {
      const coerced = coerceToString(flat.get(normalized));
      if (coerced != null) return coerced;
    }
  }
  return null;
}

function fallbackKey(machine: Machine, flat: FlatMap): string {
  const explicit = pick(flat, ['key', 'machine', 'machinename', 'name']);
  if (explicit) return explicit;
  if (machine.name && machine.name.trim().length > 0) return machine.name;
  return `Machine ${machine.machineId}`;
}

export function normalizeTelemetryPayload(machine: Machine, payload: unknown): CncStatsUpsert {
  const flat = flattenTelemetry(payload);
  const result: CncStatsUpsert = {
    key: fallbackKey(machine, flat),
    // Normalize API IP to the configured machine PC IP to ensure DB join works
    // regardless of what the telemetry payload reports (URL, hostname, localhost, etc.).
    apiIp: machine.pcIp ?? pick(flat, ['apiIp', 'api_ip', 'ip']),
    currentProgram: pick(flat, ['currentProgram', 'current_program', 'program', 'activeProgram', 'prog']),
    mode: pick(flat, ['mode', 'machineMode', 'operatingMode']),
    status: pick(flat, ['status', 'state', 'machineStatus']),
    alarm: pick(flat, ['alarm', 'alarmMessage', 'alarm_text']),
    emg: pick(flat, ['emg', 'emergency', 'emergencyStop', 'emergency_stop']),
    powerOnTime: pick(flat, ['powerOnTime', 'power_on', 'timers.powerOn', 'timers.power_on', 'timers.power']),
    cuttingTime: pick(flat, ['cuttingTime', 'cutting_time', 'timers.cuttingTime', 'timers.cutting_time', 'timers.cuttime']),
    alarmHistory: pick(flat, ['alarmHistory', 'alarm_history', 'alarms.history']),
    vacuumTime: pick(flat, ['vacuumTime', 'vacuum_time']),
    drillHeadTime: pick(flat, ['drillHeadTime', 'drill_head_time', 'timers.drillHead']),
    spindleTime: pick(flat, ['spindleTime', 'spindle_time', 'timers.spindle']),
    conveyorTime: pick(flat, ['conveyorTime', 'conveyor_time']),
    greaseTime: pick(flat, ['greaseTime', 'grease_time'])
  };
  return result;
}

================
File: packages/main/src/workers/watchersMessages.ts
================
import type { MachineHealthCode } from '../../../shared/src';

export type SerializableError = {
  message: string;
  stack?: string | null;
};

export type WatcherWorkerToMainMessage =
  | { type: 'registerWatcher'; name: string; label: string }
  | { type: 'watcherReady'; name: string; label?: string }
  | {
      type: 'log';
      level: 'trace' | 'debug' | 'info' | 'warn' | 'error' | 'fatal';
      msg: string;
      context?: Record<string, unknown>;
    }
  | {
      type: 'watcherEvent';
      name: string;
      label?: string;
      message: string;
      context?: Record<string, unknown>;
    }
  | {
      type: 'userAlert';
      title: string;
      message: string;
    }
  | {
      type: 'watcherError';
      name: string;
      label?: string;
      error: SerializableError;
      context?: Record<string, unknown>;
    }
  | {
      type: 'workerError';
      source: string;
      error: SerializableError;
      context?: Record<string, unknown>;
    }
  | {
      type: 'machineHealthSet';
      payload: {
        machineId: number | null;
        code: MachineHealthCode;
        message: string;
        severity?: 'info' | 'warning' | 'critical';
        context?: Record<string, unknown>;
      };
    }
  | {
      type: 'machineHealthClear';
      payload: {
        machineId: number | null;
        code: MachineHealthCode;
      };
    };

export type MainToWatcherMessage = { type: 'shutdown'; reason?: string };

================
File: packages/main/src/workers/watchersWorker.ts
================
import chokidar, { type FSWatcher } from 'chokidar';
import { createHash } from 'crypto';
import { existsSync, mkdirSync } from 'fs';
import { promises as fsp } from 'fs';
import type { Dirent } from 'fs';
import net from 'net';
import { basename, dirname, extname, join, normalize } from 'path';
import type { PoolClient } from 'pg';
import { parentPort } from 'worker_threads';
import type { Machine, MachineHealthCode } from '../../../shared/src';
import { loadConfig } from '../services/config';
import { logger } from '../logger';
import { testConnection, withClient } from '../services/db';
import { appendJobEvent } from '../repo/jobEventsRepo';
import { upsertGrundnerInventory, type GrundnerCsvRow } from '../repo/grundnerRepo';
import { listMachines } from '../repo/machinesRepo';
import { findJobByNcBase, findJobByNcBasePreferStatus, updateJobPallet, updateLifecycle } from '../repo/jobsRepo';
import { upsertCncStats } from '../repo/cncStatsRepo';
import type { CncStatsUpsert } from '../repo/cncStatsRepo';
import { normalizeTelemetryPayload } from './telemetryParser';
import type { WatcherWorkerToMainMessage, MainToWatcherMessage } from './watchersMessages';
import { ingestProcessedJobsRoot } from '../services/ingest';

const { access, copyFile, readFile, readdir, rename, stat, unlink } = fsp;

const channel = parentPort;
const fsWatchers = new Set<FSWatcher>();

function postMessageToMain(message: WatcherWorkerToMainMessage) {
  if (!channel) {
    logger.debug({ messageType: message?.type }, 'watchersWorker: parentPort unavailable; skipping message');
    return;
  }
  try {
    channel.postMessage(message);
  } catch (err) {
    logger.warn({ err }, 'watchersWorker: failed to post message');
  }
}

function serializeError(error: unknown): { message: string; stack?: string | null } {
  if (error instanceof Error) {
    return { message: error.message, stack: error.stack ?? null };
  }
  if (typeof error === 'string') {
    return { message: error };
  }
  try {
    return { message: JSON.stringify(error) };
  } catch {
    return { message: String(error) };
  }
}

function registerWatcher(name: string, label: string) {
  postMessageToMain({ type: 'registerWatcher', name, label });
}

function watcherReady(name: string, label: string) {
  postMessageToMain({ type: 'watcherReady', name, label });
}

function recordWatcherEvent(
  name: string,
  event: { label?: string; message: string; context?: Record<string, unknown> }
) {
  postMessageToMain({ type: 'watcherEvent', name, label: event.label, message: event.message, context: event.context });
}

function recordWatcherError(
  name: string,
  error: unknown,
  context?: Record<string, unknown> & { label?: string }
) {
  const { label, ...rest } = context ?? {};
  postMessageToMain({
    type: 'watcherError',
    name,
    label: label as string | undefined,
    error: serializeError(error),
    context: rest && Object.keys(rest).length ? rest : undefined
  });
}

function recordWorkerError(source: string, error: unknown, context?: Record<string, unknown>) {
  postMessageToMain({ type: 'workerError', source, error: serializeError(error), context });
}

function setMachineHealthIssue(params: {
  machineId: number | null;
  code: MachineHealthCode;
  message: string;
  severity?: 'info' | 'warning' | 'critical';
  context?: Record<string, unknown>;
}) {
  postMessageToMain({ type: 'machineHealthSet', payload: params });
}

function clearMachineHealthIssue(machineId: number | null, code: MachineHealthCode) {
  postMessageToMain({ type: 'machineHealthClear', payload: { machineId, code } });
}

function trackWatcher(watcher: FSWatcher) {
  fsWatchers.add(watcher);
  watcher.on('close', () => fsWatchers.delete(watcher));
}

let shuttingDown = false;
let jobsIngestInterval: NodeJS.Timeout | null = null;

const autoPacHashes = new Map<string, string>();

const NESTPICK_UNSTACK_FILENAME = 'Report_FullNestpickUnstack.csv';

const AUTOPAC_WATCHER_NAME = 'watcher:autopac';
const AUTOPAC_WATCHER_LABEL = 'AutoPAC CSV Watcher';
const HEALTH_CODES: Record<'noParts' | 'nestpickShare' | 'copyFailure', MachineHealthCode> = {
  noParts: 'NO_PARTS_CSV',
  nestpickShare: 'NESTPICK_SHARE_UNREACHABLE',
  copyFailure: 'COPY_FAILURE'
};

const TESTDATA_WATCHER_NAME = 'watcher:testdata';
const TESTDATA_WATCHER_LABEL = 'Test Data Telemetry';
const TESTDATA_PROCESSED_DIR = 'processed';
const TESTDATA_FAILED_DIR = 'failed';
const TESTDATA_SKIP_DIRS = new Set([TESTDATA_PROCESSED_DIR, TESTDATA_FAILED_DIR]);

// Serial processing queue for test data files
const testDataQueue: string[] = [];
const testDataQueued = new Set<string>();
let testDataProcessing = false;
// testDataRoot tracks the configured root for test data files
let testDataRoot: string | null = null;
let testDataIndex: string[] = [];
let testDataIndexPos = 0;
let testDataIndexBuilt = false;

// Grundner poller
const GRUNDNER_WATCHER_NAME = 'watcher:grundner';
const GRUNDNER_WATCHER_LABEL = 'Grundner Stock Poller';
let grundnerTimer: NodeJS.Timeout | null = null;
let grundnerLastHash: string | null = null;

function machineLabel(machine: Machine) {
  return machine.name ? `${machine.name} (#${machine.machineId})` : `Machine ${machine.machineId}`;
}

function nestpickProcessedWatcherName(machine: Machine) {
  return `watcher:nestpick-processed:${machine.machineId}`;
}

function nestpickProcessedWatcherLabel(machine: Machine) {
  return `Nestpick Processed (${machineLabel(machine)})`;
}

function nestpickUnstackWatcherName(machine: Machine) {
  return `watcher:nestpick-unstack:${machine.machineId}`;
}

function nestpickUnstackWatcherLabel(machine: Machine) {
  return `Nestpick Unstack (${machineLabel(machine)})`;
}

function delay(ms: number) {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

async function waitForDbReady(maxAttempts = 10, initialDelayMs = 500) {
  const maxDelay = 5000;
  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      const result = await testConnection();
      if (result.ok) {
        if (attempt > 1) {
          logger.info({ attempt }, 'watchers: database connection established after retries');
        }
        return;
      }
      throw new Error(result.error);
    } catch (err) {
      const delayMs = Math.min(initialDelayMs * Math.pow(2, attempt - 1), maxDelay);
      logger.warn({ err, attempt, maxAttempts, delayMs }, 'watchers: database not ready, retrying');
      await delay(delayMs);
    }
  }
  throw new Error('watchers: database not ready after maximum retries');
}

async function fileExists(path: string) {
  try {
    await access(path);
    return true;
  } catch {
    return false;
  }
}

async function waitForStableFile(path: string, attempts = 5, intervalMs = 1000) {
  let lastSize = -1;
  let lastMtime = -1;
  for (let i = 0; i < attempts; i++) {
    const info = await stat(path);
    if (info.size === lastSize && info.mtimeMs === lastMtime) {
      return info;
    }
    lastSize = info.size;
    lastMtime = info.mtimeMs;
    await delay(intervalMs);
  }
  return stat(path);
}

async function hashFile(path: string) {
  const buffer = await readFile(path);
  return createHash('sha1').update(buffer).digest('hex');
}

function splitCsvLine(line: string): string[] {
  const out: string[] = [];
  let current = '';
  let inQuotes = false;
  for (let i = 0; i < line.length; i++) {
    const ch = line[i];
    if (ch === '"') {
      if (inQuotes && line[i + 1] === '"') {
        current += '"';
        i++;
      } else {
        inQuotes = !inQuotes;
      }
    } else if ((ch === ',' || ch === ';' || ch === '\t') && !inQuotes) {
      out.push(current);
      current = '';
    } else {
      current += ch;
    }
  }
  out.push(current);
  return out.map((cell) => cell.trim());
}

async function unlinkWithRetry(path: string, attempts = 3, waitMs = 200) {
  for (let attempt = 1; attempt <= attempts; attempt++) {
    try {
      await unlink(path);
      if (attempt > 1) {
        logger.warn({ path, attempts: attempt }, 'watcher: unlink succeeded after retries');
      }
      return true;
    } catch (err) {
      if (attempt === attempts) {
        logger.error({ err, path, attempts }, 'watcher: failed to delete file after retries');
        return false;
      }
      await delay(waitMs * attempt);
    }
  }
  return false;
}

function parseCsvContent(content: string) {
  return content
    .split(/\r?\n/)
    .map((line) => line.trimEnd())
    .filter((line) => line.trim().length > 0)
    .map(splitCsvLine);
}

function extractBases(rows: string[][], fallback: string) {
  const bases = new Set<string>();
  for (const row of rows) {
    for (const raw of row) {
      const cell = raw.replace(/^"|"$/g, '').trim();
      if (!cell) continue;
      const match = cell.match(/^([A-Za-z0-9_.-]+)(?:\.nc)?$/);
      if (!match) continue;
      const candidate = match[1];
      if (candidate.length < 3) continue;
      bases.add(candidate);
      break;
    }
  }
  if (bases.size === 0 && fallback) {
    const fileBase = fallback.toLowerCase().split('_')[0]?.replace(/\.csv$/i, '').replace(/\.nc$/i, '');
    if (fileBase) bases.add(fileBase);
  }
  return Array.from(bases);
}

function toPosixLower(path: string) {
  return path.replace(/\\/g, '/').toLowerCase();
}

function isTestDataInternalPath(path: string) {
  const lower = toPosixLower(path);
  for (const segment of TESTDATA_SKIP_DIRS) {
    if (lower.includes(`/${segment}/`) || lower.endsWith(`/${segment}`)) {
      return true;
    }
  }
  return false;
}

function isTestDataFileName(filePath: string) {
  const name = basename(filePath).toLowerCase();
  if (!name.startsWith('cnc_data') && !name.startsWith('cnc_stats')) return false;
  const extension = extname(name);
  if (!extension) return true;
  return extension === '.csv' || extension === '.json' || extension === '.ndjson' || extension === '.txt';
}

function toRecord(value: unknown): Record<string, unknown> | null {
  if (!value || typeof value !== 'object' || Array.isArray(value)) return null;
  return value as Record<string, unknown>;
}

function pickCaseInsensitive(source: Record<string, unknown> | null, candidates: string[]): unknown {
  if (!source) return undefined;
  for (const candidate of candidates) {
    const lower = candidate.toLowerCase();
    for (const [key, val] of Object.entries(source)) {
      if (key.toLowerCase() === lower) {
        return val;
      }
    }
  }
  return undefined;
}

function toStringOrNull(value: unknown): string | null {
  if (value == null) return null;
  if (typeof value === 'string') {
    const trimmed = value.trim();
    return trimmed.length > 0 ? trimmed : null;
  }
  if (typeof value === 'number' || typeof value === 'bigint') {
    return Number.isFinite(Number(value)) ? String(value) : null;
  }
  if (typeof value === 'boolean') {
    return value ? 'true' : 'false';
  }
  return null;
}

function inferTimestampFromFileName(fileName: string): string | null {
  const match = fileName.match(/(\d{4})[._-]?(\d{2})[._-]?(\d{2})[T_\- ]?(\d{2})[._-]?(\d{2})[._-]?(\d{2})/);
  if (!match) return null;
  return `${match[1]}.${match[2]}.${match[3]} ${match[4]}:${match[5]}:${match[6]}`;
}

function stripCsvCell(value: string | undefined): string {
  if (typeof value !== 'string') return '';
  return value.replace(/^"|"$/g, '').trim();
}

function normalizeHeaderName(name: string, index: number, seen: Map<string, number>): string {
  let base = stripCsvCell(name)
    .toLowerCase()
    .replace(/[^a-z0-9]+/g, '_')
    .replace(/^_+|_+$/g, '');
  if (!base) {
    base = `column_${index + 1}`;
  }
  const count = (seen.get(base) ?? 0) + 1;
  seen.set(base, count);
  if (count > 1) {
    return `${base}_${count}`;
  }
  return base;
}

function parseTestDataCsv(raw: string): Record<string, unknown>[] {
  const rows = parseCsvContent(raw);
  if (rows.length <= 1) return [];
  const headers = rows[0];
  const seen = new Map<string, number>();
  const keys = headers.map((header, idx) => normalizeHeaderName(header, idx, seen));
  const records: Record<string, unknown>[] = [];
  for (let i = 1; i < rows.length; i++) {
    const row = rows[i];
    const record: Record<string, unknown> = {};
    let hasValue = false;
    for (let j = 0; j < keys.length; j++) {
      const key = keys[j];
      const rawCell = row[j] ?? '';
      const value = stripCsvCell(rawCell);
      if (value.length === 0) continue;
      record[key] = value;
      hasValue = true;
    }
    if (hasValue) records.push(record);
  }
  return records;
}

function parseTestDataPayloads(raw: string, fileName: string): unknown[] {
  const trimmed = raw.trim();
  if (!trimmed) {
    return [];
  }
  const normalized = trimmed.replace(/^\uFEFF/, '');
  try {
    const parsed = JSON.parse(normalized);
    return Array.isArray(parsed) ? parsed : [parsed];
  } catch {
    const lines = normalized.split(/\r?\n/).map((line) => line.trim()).filter(Boolean);
    const out: unknown[] = [];
    for (const line of lines) {
      try {
        out.push(JSON.parse(line));
      } catch {
        /* ignore non-JSON lines */
      }
    }
    if (out.length) return out;
  }
  const csvRecords = parseTestDataCsv(raw);
  if (csvRecords.length) return csvRecords;
  throw new Error(`Unable to parse test data file ${fileName}; expected JSON, NDJSON, or CSV payload`);
}

function pickString(sources: Array<Record<string, unknown> | null>, candidates: string[]): string | null {
  for (const source of sources) {
    if (!source) continue;
    const value = toStringOrNull(pickCaseInsensitive(source, candidates));
    if (value != null) return value;
  }
  return null;
}

function buildTestDataUpsert(entry: unknown, fileName: string): CncStatsUpsert | null {
  const record = toRecord(entry);
  if (!record) {
    logger.warn({ file: fileName }, 'test-data: payload is not an object, skipping');
    return null;
  }

  const machineStatus = toRecord(pickCaseInsensitive(record, ['MachineStatus', 'machineStatus', 'machine_status']));
  const timers = toRecord(pickCaseInsensitive(record, ['Timers', 'timers', 'timer']));

  let timestampValue =
    pickString([record], ['timestamp', 'time', 'ts', 'key']) ??
    inferTimestampFromFileName(basename(fileName));
  if (!timestampValue) {
    timestampValue = new Date().toISOString();
    logger.info({ file: fileName, timestamp: timestampValue }, 'test-data: missing timestamp; using current time');
  }

  const apiIp = pickString(
    [record, machineStatus],
    ['CNC_IP', 'cnc_ip', 'api_ip', 'ip']
  );
  // Key is timestamp only (no IP component)
  const key = timestampValue;

  const alarmHistoryRaw = pickCaseInsensitive(record, ['AlarmHistoryDictionary', 'alarmHistory', 'AlarmHistory']);
  const alarmHistory =
    alarmHistoryRaw && typeof alarmHistoryRaw === 'object' && Object.keys(alarmHistoryRaw as Record<string, unknown>).length
      ? JSON.stringify(alarmHistoryRaw)
      : null;

  const upsert: CncStatsUpsert = {
    key,
    apiIp,
    currentProgram: pickString(
      [machineStatus, record],
      ['CurrentProgram', 'currentProgram', 'Program', 'program', 'MainProgram']
    ),
    mode: pickString([machineStatus, record], ['Mode', 'mode', 'OperatingMode']),
    status: pickString([machineStatus, record], ['Status', 'status', 'MachineStatus', 'state']),
    alarm: pickString([machineStatus, record], ['Alarm', 'alarm']),
    emg: pickString([machineStatus, record], ['EMG', 'emg', 'Emergency', 'emergency']),
    powerOnTime: pickString(
      [timers, record],
      ['PowerOnTime_sec', 'powerOnTime', 'power_on', 'PowerOn', 'powerontime']
    ),
    cuttingTime: pickString(
      [timers, record],
      ['CycleCuttingTime_sec', 'cycleCuttingTime', 'AccumulatedCuttingTime_sec', 'cuttingTime', 'cut_time']
    ),
    alarmHistory,
    vacuumTime: pickString([timers, record], ['VacTime_sec', 'vacTime', 'VacuumTime']),
    drillHeadTime: pickString([timers, record], ['DrillTime_sec', 'drillTime', 'DrillHeadTime']),
    spindleTime: pickString([timers, record], ['SpindleTime_sec', 'spindleTime']),
    conveyorTime: pickString([timers, record], ['ConveyorTime_sec', 'conveyorTime']),
    greaseTime: pickString([timers, record], ['GreaseTime_sec', 'greaseTime'])
  };
  logger.info(
    {
      file: fileName,
      key: upsert.key,
      apiIp: upsert.apiIp ?? undefined,
      mode: upsert.mode ?? undefined,
      status: upsert.status ?? undefined,
      currentProgram: upsert.currentProgram ?? undefined
    },
    'test-data: built upsert payload'
  );
  return upsert;
}

function sanitizeToken(input: string | null | undefined) {
  return (input ?? '').toLowerCase().replace(/[^a-z0-9]/g, '');
}

function isAutoPacCsvFileName(fileName: string) {
  const lower = fileName.toLowerCase();
  if (!lower.endsWith('.csv')) return false;
  return (
    lower.startsWith('load_finish') ||
    lower.startsWith('label_finish') ||
    lower.startsWith('cnc_finish')
  );
}

function _inferMachineFromPath(path: string, machines: Machine[]): Machine | undefined {
  const normalizedPath = sanitizeToken(path);
  for (const machine of machines) {
    const candidates = [String(machine.machineId), machine.name];
    for (const candidate of candidates) {
      const token = sanitizeToken(candidate);
      if (token && normalizedPath.includes(token)) return machine;
    }
  }
  return undefined;
}

function deriveJobLeaf(folder: string | null, ncfile: string | null, key: string) {
  if (folder) {
    const parts = folder.split(/[\\/]/).filter(Boolean);
    if (parts.length) return parts[parts.length - 1];
  }
  if (ncfile) return ncfile.replace(/\.nc$/i, '');
  return key.replace(/\.nc$/i, '');
}

async function findMatchingCsv(root: string, base: string, depth = 0, maxDepth = 3): Promise<string | null> {
  try {
    const entries = await readdir(root, { withFileTypes: true });
    const targetLower = base.toLowerCase();
    for (const entry of entries) {
      const entryPath = join(root, entry.name);
      if (entry.isFile()) {
        const nameLower = entry.name.toLowerCase();
        if (nameLower === `${targetLower}.csv` || (nameLower.startsWith(targetLower) && nameLower.endsWith('.csv'))) {
          return entryPath;
        }
      }
    }
    if (depth >= maxDepth) return null;
    for (const entry of entries) {
      if (!entry.isDirectory()) continue;
      const entryPath = join(root, entry.name);
      const result = await findMatchingCsv(entryPath, base, depth + 1, maxDepth);
      if (result) return result;
    }
  } catch (err) {
    logger.debug({ err, root }, 'watcher: failed listing directory');
  }
  return null;
}

async function ensureDir(path: string) {
  if (existsSync(path)) return;
  mkdirSync(path, { recursive: true });
}

async function waitForNestpickSlot(path: string, timeoutMs = 5 * 60 * 1000) {
  const start = Date.now();
  while (await fileExists(path)) {
    if (Date.now() - start > timeoutMs) throw new Error('Nestpick.csv busy timeout');
    await delay(1000);
  }
}

function serializeCsv(rows: string[][]) {
  return rows
    .map((columns) =>
      columns
        .map((cell) => {
          if (cell.includes('"')) cell = cell.replace(/"/g, '""');
          if (cell.includes(',') || cell.includes('"')) return `"${cell}"`;
          return cell;
        })
        .join(',')
    )
    .join('\n');
}

function rewriteNestpickRows(rows: string[][], machineId: number) {
  if (rows.length === 0) return [];
  let destIndex = -1;
  let srcIndex = -1;
  const headerRow = rows[0];
  const isHeader = headerRow.some((cell) => /[A-Za-z]/.test(cell));

  if (isHeader) {
    destIndex = headerRow.findIndex((cell) => cell.toLowerCase() === 'destination');
    srcIndex = headerRow.findIndex((cell) => cell.toLowerCase() === 'sourcemachine');
    if (destIndex === -1) {
      headerRow.push('Destination');
      destIndex = headerRow.length - 1;
    } else {
      headerRow[destIndex] = 'Destination';
    }
    if (srcIndex === -1) {
      headerRow.push('SourceMachine');
      srcIndex = headerRow.length - 1;
    } else {
      headerRow[srcIndex] = 'SourceMachine';
    }
  } else {
    destIndex = headerRow.length;
    srcIndex = destIndex + 1;
    headerRow[destIndex] = '99';
    headerRow[srcIndex] = String(machineId);
  }

  const maxIndex = Math.max(destIndex, srcIndex);
  const dataStart = isHeader ? 1 : 0;
  for (let i = dataStart; i < rows.length; i++) {
    const row = rows[i];
    while (row.length <= maxIndex) row.push('');
    row[destIndex] = '99';
    row[srcIndex] = String(machineId);
  }
  return rows;
}

async function forwardToNestpick(base: string, job: Awaited<ReturnType<typeof findJobByNcBase>>, machine: Machine | undefined, machines: Machine[]) {
  if (!job) return;
  const resolvedMachine = machine ?? machines.find((m) => job.machineId != null && m.machineId === job.machineId);
  if (!resolvedMachine || !resolvedMachine.nestpickEnabled || !resolvedMachine.nestpickFolder) {
    logger.debug({ job: job.key }, 'watcher: nestpick forwarding skipped (no machine/folder)');
    return;
  }

  const apRoot = resolvedMachine.apJobfolder;
  if (!apRoot) {
    logger.warn({ machineId: resolvedMachine.machineId }, 'watcher: machine missing ap_jobfolder for nestpick forwarding');
    return;
  }

  const baseLower = base.toLowerCase();
  const leaf = deriveJobLeaf(job.folder, job.ncfile, job.key);
  const preferredDir = join(apRoot, leaf);
  let sourceCsv: string | null = null;
  if (await fileExists(preferredDir)) {
    sourceCsv = await findMatchingCsv(preferredDir, baseLower, 0, 2);
  }
  if (!sourceCsv) {
    sourceCsv = await findMatchingCsv(apRoot, baseLower, 0, 2);
  }
  if (!sourceCsv) {
    logger.warn({ job: job.key, apRoot, leaf }, 'watcher: staged CSV not found for nestpick forwarding');
    return;
  }

  try {
    await waitForStableFile(sourceCsv);
    const raw = await readFile(sourceCsv, 'utf8');
    const rows = parseCsvContent(raw);
    const rewritten = rewriteNestpickRows(rows, resolvedMachine.machineId);
    if (rewritten.length === 0) {
      logger.warn({ job: job.key, sourceCsv }, 'watcher: nestpick CSV empty after rewrite');
      return;
    }

    const outDir = resolvedMachine.nestpickFolder;
    await ensureDir(outDir);
    const outPath = join(outDir, 'Nestpick.csv');
    await waitForNestpickSlot(outPath);

    const tempPath = `${outPath}.tmp-${Date.now()}`;
    await fsp.writeFile(tempPath, `${serializeCsv(rewritten)}\n`, 'utf8');
    await rename(tempPath, outPath);

    await appendJobEvent(job.key, 'nestpick:forwarded', { source: sourceCsv, dest: outPath }, resolvedMachine.machineId);
    await updateLifecycle(job.key, 'FORWARDED_TO_NESTPICK', { machineId: resolvedMachine.machineId, source: 'nestpick-forward', payload: { source: sourceCsv, dest: outPath } });

    await unlink(sourceCsv).catch(() => {});
    clearMachineHealthIssue(resolvedMachine.machineId ?? null, HEALTH_CODES.copyFailure);
  } catch (err) {
    setMachineHealthIssue({
      machineId: resolvedMachine?.machineId ?? null,
      code: HEALTH_CODES.copyFailure,
      message: `Failed to forward Nestpick CSV for ${job?.key ?? base}`,
      severity: 'warning',
      context: {
        jobKey: job?.key,
        sourceCsv,
        destinationFolder: resolvedMachine?.nestpickFolder
      }
    });
    recordWorkerError('nestpick:forward', err, {
      jobKey: job.key,
      machineId: resolvedMachine?.machineId,
      sourceCsv,
      destinationFolder: resolvedMachine?.nestpickFolder
    });
    logger.error({ err, job: job.key }, 'watcher: nestpick forward failed');
  }
}

async function handleAutoPacCsv(path: string) {
  const fileName = basename(path);
  // Enforce naming: load_finish<machine>.csv, label_finish<machine>.csv, cnc_finish<machine>.csv
  const lower = fileName.toLowerCase();
  if (!lower.endsWith('.csv')) {
    logger.debug({ file: path }, 'watcher: ignoring non-CSV AutoPAC file');
    return;
  }
  let to: 'LOAD_FINISH' | 'LABEL_FINISH' | 'CNC_FINISH' | null = null;
  let machineToken = '';
  if (lower.startsWith('load_finish')) { to = 'LOAD_FINISH'; machineToken = fileName.slice('load_finish'.length); }
  else if (lower.startsWith('label_finish')) { to = 'LABEL_FINISH'; machineToken = fileName.slice('label_finish'.length); }
  else if (lower.startsWith('cnc_finish')) { to = 'CNC_FINISH'; machineToken = fileName.slice('cnc_finish'.length); }
  if (!to) return;
  machineToken = machineToken.replace(/^[-_\s]+/, '');
  const csvSuffix = machineToken.toLowerCase().indexOf('.csv');
  if (csvSuffix !== -1) {
    machineToken = machineToken.slice(0, csvSuffix);
  }
  machineToken = machineToken.trim();
  if (!machineToken) return; // machine must be specified

  try {
    await waitForStableFile(path);
    const hash = await hashFile(path);
    if (autoPacHashes.get(path) === hash) return;
    autoPacHashes.set(path, hash);
    if (autoPacHashes.size > 200) {
      const firstKey = autoPacHashes.keys().next().value;
      if (firstKey) autoPacHashes.delete(firstKey);
    }

    const raw = await readFile(path, 'utf8');

    // Validate CSV format before parsing
    const lines = raw.split(/\r?\n/).filter(line => line.trim().length > 0);
    if (lines.length === 0) {
      logger.warn({ file: path, machineToken }, 'watcher: autopac CSV file is empty');
      postMessageToMain({
        type: 'userAlert',
        title: 'AutoPAC CSV Format Error',
        message: `AutoPAC CSV ${machineToken} has incorrect format: file is empty`
      });
      recordWatcherError(AUTOPAC_WATCHER_NAME, new Error('Empty CSV file'), {
        path,
        machineToken,
        label: AUTOPAC_WATCHER_LABEL
      });
      await unlinkWithRetry(path);
      autoPacHashes.delete(path);
      logger.info({ file: path, machineToken }, 'watcher: deleted empty autopac CSV file');
      return;
    }

    // Check if CSV has proper delimiter (comma or semicolon)
    const hasDelimiters = lines.some(line => line.includes(',') || line.includes(';'));
    if (!hasDelimiters) {
      logger.warn({ file: path, machineToken, lineCount: lines.length, sampleLine: lines[0]?.slice(0, 100) }, 'watcher: autopac CSV has no delimiters (comma or semicolon)');
      postMessageToMain({
        type: 'userAlert',
        title: 'AutoPAC CSV Format Error',
        message: `AutoPAC CSV ${machineToken} has incorrect format: no comma or semicolon delimiters found`
      });
      recordWatcherError(AUTOPAC_WATCHER_NAME, new Error('Invalid CSV format: no delimiters'), {
        path,
        machineToken,
        label: AUTOPAC_WATCHER_LABEL
      });
      await unlinkWithRetry(path);
      autoPacHashes.delete(path);
      logger.info({ file: path, machineToken }, 'watcher: deleted autopac CSV with no delimiters');
      return;
    }

    const rows = parseCsvContent(raw);

    // Validate parsed rows have multiple columns
    const validRows = rows.filter(row => row.length > 1);
    if (validRows.length === 0) {
      logger.warn({ file: path, machineToken, totalRows: rows.length, sampleRow: rows[0] }, 'watcher: autopac CSV has no multi-column rows');
      postMessageToMain({
        type: 'userAlert',
        title: 'AutoPAC CSV Format Error',
        message: `AutoPAC CSV ${machineToken} has incorrect format: no valid multi-column rows found`
      });
      recordWatcherError(AUTOPAC_WATCHER_NAME, new Error('Invalid CSV format: single column only'), {
        path,
        machineToken,
        label: AUTOPAC_WATCHER_LABEL
      });
      await unlinkWithRetry(path);
      autoPacHashes.delete(path);
      logger.info({ file: path, machineToken }, 'watcher: deleted autopac CSV with single column only');
      return;
    }
    // Enforce machine token appears in CSV and matches filename
    const wantedToken = sanitizeToken(machineToken);
    const csvHasMachine = rows.some((row) =>
      row.some((cell) => {
        const token = sanitizeToken(cell);
        return token === wantedToken;
      })
    );
    if (!csvHasMachine) {
      logger.warn({ file: path, machineToken, wantedToken, fileName }, 'watcher: autopac CSV machine token not found in file content');
      postMessageToMain({
        type: 'userAlert',
        title: 'AutoPAC CSV Format Error',
        message: `AutoPAC CSV ${machineToken} has incorrect format: machine name mismatch`
      });
      setMachineHealthIssue({
        machineId: null,
        code: HEALTH_CODES.copyFailure,
        message: `AutoPAC machine mismatch: file=${fileName} expects '${machineToken}', CSV does not contain matching machine`,
        severity: 'warning',
        context: { file: path, expected: machineToken }
      });
      recordWatcherError(AUTOPAC_WATCHER_NAME, new Error('AutoPAC machine mismatch'), {
        path,
        expected: machineToken,
        label: AUTOPAC_WATCHER_LABEL
      });
      await unlinkWithRetry(path);
      autoPacHashes.delete(path);
      logger.info({ file: path, machineToken }, 'watcher: deleted autopac CSV with machine mismatch');
      return;
    }
    // Strict: first column is NC, only accept base or base.nc
    const bases = (() => {
      const set = new Set<string>();
      for (const row of rows) {
        if (!row.length) continue;
        const cell = row[0]?.trim() ?? '';
        if (!cell) continue;
        const m = cell.match(/^([A-Za-z0-9_.-]+)(?:\.nc)?$/i);
        if (m && m[1]) set.add(m[1]);
      }
      return Array.from(set);
    })();
    if (!bases.length) {
      logger.warn({ file: path, machineToken, rowCount: rows.length, sampleFirstColumn: rows.slice(0, 3).map(r => r[0]) }, 'watcher: autopac file had no identifiable bases');
      postMessageToMain({
        type: 'userAlert',
        title: 'AutoPAC CSV Format Error',
        message: `AutoPAC CSV ${machineToken} has incorrect format: no parts found`
      });
      setMachineHealthIssue({
        machineId: null,
        code: HEALTH_CODES.noParts,
        message: `No parts found in AutoPAC CSV ${basename(path)}`,
        severity: 'warning',
        context: { file: path }
      });
      recordWatcherError(AUTOPAC_WATCHER_NAME, new Error('No parts found'), {
        path,
        machineToken,
        label: AUTOPAC_WATCHER_LABEL
      });
      await unlinkWithRetry(path);
      autoPacHashes.delete(path);
      logger.info({ file: path, machineToken }, 'watcher: deleted autopac CSV with no identifiable parts');
      return;
    }

    const machines = await listMachines();
    // Resolve machine strictly from filename token (matches by name or numeric id)
    const wanted = sanitizeToken(machineToken);
    const machine = machines.find((m) => sanitizeToken(m.name) === wanted || sanitizeToken(String(m.machineId)) === wanted);
    if (!machine) {
      logger.warn({ file: path, machineToken }, 'watcher: autopac file specifies unknown machine');
      return;
    }
    let processedAny = false;

    for (const base of bases) {
      const job = await findJobByNcBase(base);
      if (!job) {
        logger.warn({ base, file: path }, 'watcher: job not found for AutoPAC CSV');
        continue;
      }
      const machineForJob = machine;
      const machineId = machineForJob.machineId;

      const lifecycle = await updateLifecycle(job.key, to, {
        machineId,
        source: 'autopac',
        payload: { file: path, base }
      });
      await appendJobEvent(job.key, `autopac:${to.toLowerCase()}`, { file: path, base }, machineId);

      if (lifecycle.ok && to === 'CNC_FINISH') {
        await forwardToNestpick(base, job, machineForJob, machines);
      }
      if (lifecycle.ok) {
        processedAny = true;
        const healthMachine = machineId ?? null;
        clearMachineHealthIssue(healthMachine, HEALTH_CODES.noParts);
      }
    }
    recordWatcherEvent(AUTOPAC_WATCHER_NAME, {
      label: AUTOPAC_WATCHER_LABEL,
      message: `Processed ${basename(path)}`
    });
    if (processedAny) {
      clearMachineHealthIssue(null, HEALTH_CODES.noParts);
      // Delete the source CSV after successful processing
      try {
        await unlinkWithRetry(path);
      } finally {
        autoPacHashes.delete(path);
      }
    }
  } catch (err) {
    autoPacHashes.delete(path);
    recordWatcherError(AUTOPAC_WATCHER_NAME, err, { path, label: AUTOPAC_WATCHER_LABEL });
    logger.error({ err, file: path }, 'watcher: AutoPAC processing failed');
  }
}

async function moveToArchive(source: string, archiveDir: string) {
  await ensureDir(archiveDir);
  const base = basename(source);
  let target = join(archiveDir, base);
  if (await fileExists(target)) {
    target = join(archiveDir, `${Date.now()}-${base}`);
  }
  try {
    await rename(source, target);
  } catch (err) {
    await copyFile(source, target);
    await unlink(source).catch((err) => { void err; });
    logger.debug({ err }, 'watcher: archive rename fallback to copy');
  }
  return target;
}

async function handleNestpickProcessed(machine: Machine, path: string) {
  try {
    await waitForStableFile(path);
    const raw = await readFile(path, 'utf8');
    const rows = parseCsvContent(raw);
    const bases = extractBases(rows, basename(path));
    let processedAny = false;
    for (const base of bases) {
      const job = await findJobByNcBase(base);
      if (!job) {
        logger.warn({ base, file: path }, 'watcher: nestpick processed job not found');
        continue;
      }
      const lifecycle = await updateLifecycle(job.key, 'NESTPICK_COMPLETE', { machineId: machine.machineId, source: 'nestpick-processed', payload: { file: path } });
      if (lifecycle.ok) {
        await appendJobEvent(job.key, 'nestpick:complete', { file: path }, machine.machineId);
        processedAny = true;
      }
    }
    await moveToArchive(path, join(machine.nestpickFolder, 'archive'));
    recordWatcherEvent(nestpickProcessedWatcherName(machine), {
      label: nestpickProcessedWatcherLabel(machine),
      message: `Processed ${basename(path)}`
    });
    if (processedAny) {
      clearMachineHealthIssue(machine.machineId ?? null, HEALTH_CODES.copyFailure);
    }
  } catch (err) {
    setMachineHealthIssue({
      machineId: machine.machineId ?? null,
      code: HEALTH_CODES.copyFailure,
      message: `Failed to archive Nestpick processed file ${basename(path)}`,
      severity: 'warning',
      context: { file: path, machineId: machine.machineId }
    });
    recordWatcherError(nestpickProcessedWatcherName(machine), err, {
      path,
      machineId: machine.machineId,
      label: nestpickProcessedWatcherLabel(machine)
    });
    logger.error({ err, file: path }, 'watcher: nestpick processed handling failed');
  }
}

async function handleNestpickUnstack(machine: Machine, path: string) {
  try {
    await waitForStableFile(path);
    logger.info({ file: path, machineId: machine.machineId }, 'watcher: unstack processing started');
    const raw = await readFile(path, 'utf8');
    const rows = parseCsvContent(raw);
    if (!rows.length) {
      logger.warn({ file: path }, 'watcher: unstack csv empty');
      await moveToArchive(path, join(machine.nestpickFolder, 'archive'));
      return;
    }

    const jobIdx = 0;
    const sourcePlaceIdx = 1;
    let processedAny = false;
    const unmatched: string[] = [];
    for (let i = 0; i < rows.length; i++) {
      const row = rows[i];
      if (row.length <= jobIdx || row.length <= sourcePlaceIdx) {
        logger.warn({ file: path, row: i + 1 }, 'watcher: unstack row missing expected columns');
        continue;
      }

      const rawJob = (row[jobIdx] ?? '').trim().replace(/^"|"$/g, '');
      if (!rawJob) continue;

      const base = rawJob;
      const job = await findJobByNcBasePreferStatus(base, ['FORWARDED_TO_NESTPICK']);
      if (!job) {
        logger.warn({ base }, 'watcher: unstack no matching job in FORWARDED_TO_NESTPICK');
        unmatched.push(base);
        continue; // alert later; do not update any job
      }

      const sourcePlaceValue = (row[sourcePlaceIdx] ?? '').trim().replace(/^"|"$/g, '') || null;
      logger.debug({ jobKey: job.key, base, sourcePlace: sourcePlaceValue, row: i + 1 }, 'watcher: unstack updating pallet');
      const ok = await updateJobPallet(job.key, sourcePlaceValue);
      if (ok) {
        await appendJobEvent(
          job.key,
          'nestpick:unstack',
          { sourcePlace: sourcePlaceValue, pallet: sourcePlaceValue, file: path },
          null
        );
        logger.info({ jobKey: job.key, base, sourcePlace: sourcePlaceValue, row: i + 1 }, 'watcher: unstack row processed');
        // Progress lifecycle to NESTPICK_COMPLETE when unstack is recorded
        // Do NOT override machine assignment here. Unstack is reported by the Nestpick system
        // and does not identify the CNC machine. Leaving machineId unspecified preserves any
        // previously determined CNC machine (from AutoPAC or forwarding) for History display.
        const lifecycle = await updateLifecycle(job.key, 'NESTPICK_COMPLETE', {
          source: 'nestpick-unstack',
          payload: { file: path, sourcePlace: sourcePlaceValue }
        });
        if (!lifecycle.ok) {
          const previous = 'previousStatus' in lifecycle ? lifecycle.previousStatus : undefined;
          logger.warn({ jobKey: job.key, base, previousStatus: previous }, 'watcher: unstack lifecycle not progressed');
        }
        processedAny = true;
      } else {
        logger.warn({ jobKey: job.key, base, sourcePlace: sourcePlaceValue, row: i + 1 }, 'watcher: unstack pallet update failed');
      }
    }
    const archiveDir = join(machine.nestpickFolder, 'archive');
    await moveToArchive(path, archiveDir);
    logger.info({ file: path, archiveDir, processedAny }, 'watcher: unstack archived');

    if (unmatched.length) {
      postMessageToMain({
        type: 'userAlert',
        title: 'Nestpick Unstack: No Matching Job',
        message: `No job in FORWARDED_TO_NESTPICK for: ${unmatched.join(', ')}`
      });
    }
    recordWatcherEvent(nestpickUnstackWatcherName(machine), {
      label: nestpickUnstackWatcherLabel(machine),
      message: `Processed ${basename(path)}`
    });
    if (processedAny) {
      clearMachineHealthIssue(machine.machineId ?? null, HEALTH_CODES.copyFailure);
    }
  } catch (err) {
    setMachineHealthIssue({
      machineId: machine.machineId ?? null,
      code: HEALTH_CODES.copyFailure,
      message: `Failed to process Nestpick unstack report ${basename(path)}`,
      severity: 'warning',
      context: { file: path, machineId: machine.machineId }
    });
    try {
      await moveToArchive(path, join(machine.nestpickFolder, 'archive'));
    } catch (e) { void e; }
    recordWatcherError(nestpickUnstackWatcherName(machine), err, {
      path,
      machineId: machine.machineId,
      label: nestpickUnstackWatcherLabel(machine)
    });
    logger.error({ err, file: path }, 'watcher: nestpick unstack handling failed');
  }
}

function stableProcess(
  fn: (path: string) => Promise<void>,
  delayMs = 1000,
  options?: { watcherName?: string; watcherLabel?: string }
) {
  const pending = new Map<string, NodeJS.Timeout>();
  return (path: string) => {
    const normalizedPath = normalize(path);
    const watcher = options?.watcherName ?? 'watcher';
    const label = options?.watcherLabel ?? watcher;
    logger.info({ path: normalizedPath, watcher, label }, 'watcher: scan queued');
    if (pending.has(normalizedPath)) clearTimeout(pending.get(normalizedPath)!);
    pending.set(
      normalizedPath,
      setTimeout(() => {
        pending.delete(normalizedPath);
        fn(normalizedPath)
          .then(() => {
            logger.info({ path: normalizedPath, watcher, label }, 'watcher: scan complete');
          })
          .catch((err) => {
            if (options?.watcherName) {
              recordWatcherError(options.watcherName, err, {
                path: normalizedPath,
                label: options.watcherLabel ?? options.watcherName
              });
            } else {
              recordWorkerError('watcher', err, { path: normalizedPath });
            }
            logger.error({ err, path: normalizedPath, watcher, label }, 'watcher error');
          });
      }, delayMs)
    );
  };
}

class TelemetryClient {
  private socket: net.Socket | null = null;
  private buffer = '';
  private reconnectTimer: NodeJS.Timeout | null = null;
  private attempt = 0;
  private stopped = false;
  private lastSignature: string | null = null;
  private readonly watcherName: string;
  private readonly watcherLabel: string;

  constructor(private readonly machine: Machine) {
    this.watcherName = `watcher:telemetry:${machine.machineId}`;
    this.watcherLabel = `Telemetry (${machineLabel(machine)})`;
    registerWatcher(this.watcherName, this.watcherLabel);
  }

  start() {
    this.connect();
  }

  stop() {
    this.stopped = true;
    this.clearReconnect();
    if (this.socket) {
      this.socket.removeAllListeners();
      this.socket.destroy();
      this.socket = null;
    }
  }

  private clearReconnect() {
    if (this.reconnectTimer) {
      clearTimeout(this.reconnectTimer);
      this.reconnectTimer = null;
    }
  }

  private scheduleReconnect(reason: string) {
    if (this.stopped) return;
    this.clearReconnect();
    const delay = Math.min(30_000, Math.pow(2, Math.min(this.attempt, 5)) * 1000);
    recordWatcherEvent(this.watcherName, {
      label: this.watcherLabel,
      message: `${reason}; retrying in ${Math.round(delay / 1000)}s`,
      context: { machineId: this.machine.machineId }
    });
    this.reconnectTimer = setTimeout(() => this.connect(), delay);
    if (typeof this.reconnectTimer.unref === 'function') {
      this.reconnectTimer.unref();
    }
  }

  private connect() {
    if (this.stopped) return;
    const host = this.machine.pcIp?.trim();
    const port = this.machine.pcPort ?? 0;
    if (!host || !port) {
      recordWatcherEvent(this.watcherName, {
        label: this.watcherLabel,
        message: 'Telemetry disabled (missing PC IP/port)',
        context: { machineId: this.machine.machineId }
      });
      return;
    }

    this.attempt += 1;
    this.clearReconnect();

    this.socket = net.createConnection({ host, port }, () => {
      this.attempt = 0;
      this.buffer = '';
      this.lastSignature = null;
      watcherReady(this.watcherName, this.watcherLabel);
      recordWatcherEvent(this.watcherName, {
        label: this.watcherLabel,
        message: 'Connected to telemetry stream',
        context: { host, port, machineId: this.machine.machineId }
      });
    });

    this.socket.setEncoding('utf8');
    this.socket.on('data', (chunk) => this.handleData(chunk));
    this.socket.on('error', (err) => {
      recordWatcherError(this.watcherName, err, {
        host,
        port,
        machineId: this.machine.machineId,
        label: this.watcherLabel
      });
    });
    this.socket.on('close', () => {
      if (this.stopped) return;
      this.socket?.removeAllListeners();
      this.socket = null;
      this.scheduleReconnect('Telemetry connection closed');
    });
  }

  private handleData(chunk: string | Buffer) {
    if (this.stopped) return;
    this.buffer += typeof chunk === 'string' ? chunk : chunk.toString('utf8');
    let index = this.buffer.indexOf('\n');
    while (index !== -1) {
      const raw = this.buffer.slice(0, index).trim();
      this.buffer = this.buffer.slice(index + 1);
      if (raw.length > 0) {
        void this.processLine(raw);
      }
      index = this.buffer.indexOf('\n');
    }
    if (this.buffer.length > 64_000) {
      this.buffer = '';
    }
  }

  private async processLine(line: string) {
    try {
      const payload = JSON.parse(line);
      const normalized = normalizeTelemetryPayload(this.machine, payload);
      const signature = JSON.stringify(normalized);
      if (signature === this.lastSignature) {
        return;
      }
      this.lastSignature = signature;
      await upsertCncStats(normalized);
      const statusSummary = normalized.status ? `status=${normalized.status}` : 'status updated';
      recordWatcherEvent(this.watcherName, {
        label: this.watcherLabel,
        message: `Telemetry update (${statusSummary})`,
        context: { machineId: this.machine.machineId }
      });
    } catch (err) {
      recordWatcherError(this.watcherName, err, {
        machineId: this.machine.machineId,
        label: this.watcherLabel,
        sample: line.slice(0, 500)
      });
    }
  }
}

const telemetryClients: TelemetryClient[] = [];

async function startTelemetryClients() {
  try {
    const machines = await listMachines();
    for (const machine of machines) {
      const host = machine.pcIp?.trim();
      const port = machine.pcPort ?? 0;
      if (!host || !port) continue;
      const client = new TelemetryClient(machine);
      telemetryClients.push(client);
      client.start();
    }
    if (telemetryClients.length === 0) {
      logger.debug('watchersWorker: no telemetry endpoints configured');
    }
  } catch (err) {
    recordWorkerError('telemetry:init', err);
    logger.error({ err }, 'watchersWorker: failed to initialize telemetry clients');
  }
}

async function shutdown(reason?: string) {
  if (shuttingDown) return;
  shuttingDown = true;
  logger.info({ reason }, 'watchersWorker: shutting down background services');
  if (jobsIngestInterval) {
    clearInterval(jobsIngestInterval);
    jobsIngestInterval = null;
  }
  if (grundnerTimer) {
    clearInterval(grundnerTimer);
    grundnerTimer = null;
  }
  const watchers = Array.from(fsWatchers);
  for (const watcher of watchers) {
    try {
      await watcher.close();
    } catch (err) {
      logger.warn({ err }, 'watchersWorker: failed to close file watcher');
    } finally {
      fsWatchers.delete(watcher);
    }
  }
  for (const client of telemetryClients) {
    try {
      client.stop();
    } catch (err) {
      logger.warn({ err }, 'watchersWorker: failed to stop telemetry client');
    }
  }
  telemetryClients.length = 0;
}

let testDataProcessedCount = 0;

async function handleTestDataFile(path: string, client?: PoolClient, options?: { skipDelete?: boolean }): Promise<boolean> {
  const baseName = basename(path);
  try {
    // Rely on chokidar awaitWriteFinish for stability; do not add extra waits here
    const raw = await readFile(path, 'utf8');
    const payloads = parseTestDataPayloads(raw, baseName);
    if (!payloads.length) {
      logger.warn({ file: path }, 'test-data: file contained no payloads');
      return false;
    }

    let processed = 0;
    for (let index = 0; index < payloads.length; index++) {
      const upsert = buildTestDataUpsert(payloads[index], baseName);
      if (!upsert) continue;
      try {
        logger.debug({ file: path, index, key: upsert.key }, 'test-data: upserting telemetry row');
        await upsertCncStats(upsert, client);
        processed += 1;
        logger.debug({ file: path, index, key: upsert.key }, 'test-data: upsert succeeded');
      } catch (err) {
        recordWorkerError(TESTDATA_WATCHER_NAME, err, {
          path,
          key: upsert.key,
          label: TESTDATA_WATCHER_LABEL,
          index
        });
        logger.error({ err, file: path, key: upsert.key }, 'test-data: failed to upsert telemetry entry');
      }
    }

    if (processed > 0) {
      if (!options?.skipDelete) {
        try {
          await unlinkWithRetry(path);
        } catch (e) {
          logger.warn({ err: e, file: path }, 'test-data: failed to delete source file after success');
        }
        testDataProcessedCount += processed;
        if (testDataProcessedCount % 100 === 0) {
          const message = `Processed ${testDataProcessedCount} test-data files`;
          logger.info({ total: testDataProcessedCount }, 'test-data: processed files milestone');
          recordWatcherEvent(TESTDATA_WATCHER_NAME, { label: TESTDATA_WATCHER_LABEL, message });
        }
      }
      if (options?.skipDelete) {
        // When deferring deletion, defer milestone counting as well (outer loop will handle)
      }
      if (testDataProcessedCount % 100 === 0 && !options?.skipDelete) {
        const message = `Processed ${testDataProcessedCount} test-data files`;
        // already emitted above
      }
      return true;
    } else {
      const err = new Error('No valid telemetry rows found');
      recordWatcherError(TESTDATA_WATCHER_NAME, err, { path, label: TESTDATA_WATCHER_LABEL });
      logger.warn({ file: path }, 'test-data: skipping file because no valid rows were ingested');
      return false;
    }
  } catch (err) {
    recordWatcherError(TESTDATA_WATCHER_NAME, err, { path, label: TESTDATA_WATCHER_LABEL });
    logger.error({ err, file: path }, 'test-data: failed to ingest file');
    return false;
  }
}

function enqueueTestDataFile(file: string, reason: string) {
  const normalized = normalize(file);
  if (testDataQueued.has(normalized)) {
    logger.debug({ file: normalized, reason }, 'test-data: already queued');
    return;
  }
  testDataQueued.add(normalized);
  testDataQueue.push(normalized);
  logger.info({ file: normalized, reason, queueSize: testDataQueue.length }, 'test-data: queued file');
  void processNextTestData();
}

const TESTDATA_BATCH_SIZE = 100;

async function processNextTestData() {
  if (testDataProcessing) return;
  testDataProcessing = true;
  try {
    await withClient(async (client) => {
      // Batch files per transaction for fewer commits
      outer: while (true) {
        const toDelete: string[] = [];
        let processedInBatch = 0;
        await client.query('BEGIN');
        try {
          while (processedInBatch < TESTDATA_BATCH_SIZE) {
            let next = testDataQueue.shift() ?? null;
            if (!next && testDataIndexBuilt) {
              while (testDataIndexPos < testDataIndex.length && !next) {
                const candidate = testDataIndex[testDataIndexPos++];
                if (!candidate) continue;
                if (testDataQueued.has(normalize(candidate))) continue;
                if (isTestDataInternalPath(candidate)) continue;
                if (!isTestDataFileName(candidate)) continue;
                next = candidate;
              }
            }
            if (!next) break; // End of batch and possibly all work
            try {
              const ok = await handleTestDataFile(next, client, { skipDelete: true });
              if (ok) toDelete.push(next);
            } finally {
              testDataQueued.delete(next!);
            }
            processedInBatch += 1;
          }
          await client.query('COMMIT');
        } catch (err) {
          await client.query('ROLLBACK');
          logger.warn({ err }, 'test-data: batch failed and was rolled back');
        }

        // Delete files after commit to ensure at-least-once semantics
        if (toDelete.length > 0) {
          for (const file of toDelete) {
            try {
              await unlinkWithRetry(file);
            } catch (e) {
              logger.warn({ err: e, file }, 'test-data: failed to delete file after commit');
            }
            testDataProcessedCount += 1;
            if (testDataProcessedCount % 100 === 0) {
              const message = `Processed ${testDataProcessedCount} test-data files`;
              logger.info({ total: testDataProcessedCount }, 'test-data: processed files milestone');
              recordWatcherEvent(TESTDATA_WATCHER_NAME, { label: TESTDATA_WATCHER_LABEL, message });
            }
          }
        }

        // If batch was empty (no next file), exit
        if (processedInBatch === 0) break outer;
      }
    });
  } finally {
    testDataProcessing = false;
  }
}

async function collectTestDataFilesNoLog(root: string, depth = 0, maxDepth = 4): Promise<string[]> {
  let entries: Dirent[];
  try {
    entries = await readdir(root, { withFileTypes: true });
  } catch {
    return [];
  }
  const results: string[] = [];
  const subdirs: string[] = [];
  for (const entry of entries) {
    const p = join(root, entry.name);
    if (entry.isDirectory()) {
      const lower = entry.name.toLowerCase();
      if (TESTDATA_SKIP_DIRS.has(lower)) continue;
      if (depth < maxDepth) subdirs.push(p);
      continue;
    }
    if (!entry.isFile()) continue;
    if (!isTestDataFileName(p)) continue;
    if (isTestDataInternalPath(p)) continue;
    results.push(p);
  }
  for (const d of subdirs.sort()) {
    const nested = await collectTestDataFilesNoLog(d, depth + 1, maxDepth);
    if (nested.length) results.push(...nested);
  }
  return results;
}

async function buildInitialTestDataIndex(root: string) {
  testDataIndexBuilt = false;
  testDataIndex = await collectTestDataFilesNoLog(root);
  testDataIndexPos = 0;
  testDataIndexBuilt = true;
  logger.info({ folder: root, files: testDataIndex.length }, 'test-data: initial index built');
}

async function collectTestDataFiles(root: string, depth = 0, maxDepth = 3): Promise<string[]> {
  let entries: Dirent[];
  try {
    entries = await readdir(root, { withFileTypes: true });
  } catch (err) {
    logger.warn({ err, dir: root }, 'test-data: failed to read directory during startup scan');
    return [];
  }
  const results: string[] = [];
  for (const entry of entries) {
    const entryPath = join(root, entry.name);
    const lowerName = entry.name.toLowerCase();
    if (entry.isDirectory()) {
      if (TESTDATA_SKIP_DIRS.has(lowerName)) {
        logger.info({ dir: entryPath }, 'test-data: skipping internal directory');
        continue;
      }
      if (depth < maxDepth) {
        const nested = await collectTestDataFiles(entryPath, depth + 1, maxDepth);
        if (nested.length) results.push(...nested);
      }
      continue;
    }
    if (entry.isFile()) {
      const matches = isTestDataFileName(entryPath);
      const internal = isTestDataInternalPath(entryPath);
      if (matches && !internal) {
        // Do not log each file at info level during startup scan to avoid log spam with large folders
        results.push(entryPath);
      }
    }
  }
  return results;
}

function setupTestDataWatcher(root: string) {
  registerWatcher(TESTDATA_WATCHER_NAME, TESTDATA_WATCHER_LABEL);
  const trimmed = root?.trim?.() ?? '';
  if (!trimmed) {
    const err = new Error('Test data folder path is empty');
    recordWatcherError(TESTDATA_WATCHER_NAME, err, { folder: trimmed, label: TESTDATA_WATCHER_LABEL });
    logger.warn('test-data: useTestDataMode enabled but folder path is empty');
    return;
  }
  const normalizedRoot = normalize(trimmed);
  if (!existsSync(normalizedRoot)) {
    const err = new Error('Test data folder does not exist');
    recordWatcherError(TESTDATA_WATCHER_NAME, err, { folder: normalizedRoot, label: TESTDATA_WATCHER_LABEL });
    logger.warn({ folder: normalizedRoot }, 'test-data: folder does not exist');
    return;
  }

  testDataRoot = normalizedRoot;
  const processIfMatches = (file: string, event: 'add' | 'change') => {
    const matches = isTestDataFileName(file);
    const internal = isTestDataInternalPath(file);
    if (!matches) {
      return;
    }
    if (internal) {
      return;
    }
    if (event === 'add') enqueueTestDataFile(file, 'watcher:add');
  };

  const watcher = chokidar.watch(normalizedRoot, {
    ignoreInitial: true,
    depth: 4
  });
  trackWatcher(watcher);
  watcher.on('add', (file) => processIfMatches(file, 'add'));
  watcher.on('error', (err) => {
    recordWatcherError(TESTDATA_WATCHER_NAME, err, { folder: normalizedRoot, label: TESTDATA_WATCHER_LABEL });
    logger.error({ err, folder: normalizedRoot }, 'test-data: watcher error');
  });
  watcher.on('ready', () => {
    watcherReady(TESTDATA_WATCHER_NAME, TESTDATA_WATCHER_LABEL);
    void (async () => {
      await buildInitialTestDataIndex(normalizedRoot);
      await processNextTestData();
    })();
  });
  logger.info({ folder: normalizedRoot }, 'Test data watcher started');
}

async function collectAutoPacCsvs(root: string, depth = 0, maxDepth = 3): Promise<string[]> {
  let entries: Dirent[];
  try {
    entries = await readdir(root, { withFileTypes: true });
  } catch (err) {
    logger.warn({ err, dir: root }, 'AutoPAC watcher: failed to read directory during startup scan');
    return [];
  }
  const results: string[] = [];
  for (const entry of entries) {
    const entryPath = join(root, entry.name);
    if (entry.isDirectory()) {
      if (depth < maxDepth) {
        const nested = await collectAutoPacCsvs(entryPath, depth + 1, maxDepth);
        if (nested.length) results.push(...nested);
      }
      continue;
    }
    if (!entry.isFile()) continue;
    if (!isAutoPacCsvFileName(entry.name)) continue;
    results.push(entryPath);
  }
  return results;
}

function setupAutoPacWatcher(dir: string) {
  registerWatcher(AUTOPAC_WATCHER_NAME, AUTOPAC_WATCHER_LABEL);
  const onAdd = stableProcess(handleAutoPacCsv, 250, {
    watcherName: AUTOPAC_WATCHER_NAME,
    watcherLabel: AUTOPAC_WATCHER_LABEL
  });
  const watcher = chokidar.watch(dir, {
    ignoreInitial: true,
    depth: 3,
    awaitWriteFinish: { stabilityThreshold: 500, pollInterval: 100 }
  });
  trackWatcher(watcher);
  watcher.on('add', onAdd);
  watcher.on('change', onAdd);
  watcher.on('error', (err) => {
    const code = (err as NodeJS.ErrnoException)?.code;
    setMachineHealthIssue({
      machineId: null,
      code: HEALTH_CODES.copyFailure,
      message: `AutoPAC watcher error${code ? ` (${code})` : ''}`,
      severity: 'critical',
      context: { dir, code }
    });
    recordWatcherError(AUTOPAC_WATCHER_NAME, err, { dir, label: AUTOPAC_WATCHER_LABEL });
    logger.error({ err, dir }, 'watcher: AutoPAC error');
  });
  watcher.on('ready', () => {
    watcherReady(AUTOPAC_WATCHER_NAME, AUTOPAC_WATCHER_LABEL);
    clearMachineHealthIssue(null, HEALTH_CODES.copyFailure);
    void (async () => {
      const existing = await collectAutoPacCsvs(dir);
      if (!existing.length) return;
      logger.info({ dir, count: existing.length }, 'AutoPAC watcher: processing existing CSV files on startup');
      for (const file of existing) {
        onAdd(file);
      }
    })();
  });
  logger.info({ dir }, 'AutoPAC watcher started');
}

async function setupNestpickWatchers() {
  try {
    const machines = await listMachines();
    for (const machine of machines) {
      if (!machine.nestpickEnabled || !machine.nestpickFolder) continue;
      const folder = machine.nestpickFolder;
      const processedDir = join(folder, 'processed');
      const processedWatcherName = nestpickProcessedWatcherName(machine);
      const processedWatcherLabel = nestpickProcessedWatcherLabel(machine);
      registerWatcher(processedWatcherName, processedWatcherLabel);
      const processedWatcher = chokidar.watch(processedDir, {
        ignoreInitial: true,
        depth: 1,
        awaitWriteFinish: { stabilityThreshold: 1500, pollInterval: 250 }
      });
      trackWatcher(processedWatcher);
      const handleProcessed = stableProcess(
        (path) => handleNestpickProcessed(machine, path),
        500,
        { watcherName: processedWatcherName, watcherLabel: processedWatcherLabel }
      );
      processedWatcher.on('add', handleProcessed);
      processedWatcher.on('error', (err) => {
        const code = (err as NodeJS.ErrnoException)?.code;
        setMachineHealthIssue({
          machineId: machine.machineId ?? null,
          code: HEALTH_CODES.nestpickShare,
          message: `Processed folder unavailable${code ? ` (${code})` : ''}`,
          severity: 'critical',
          context: { folder: processedDir, machineId: machine.machineId, code }
        });
        recordWatcherError(processedWatcherName, err, {
          folder: processedDir,
          machineId: machine.machineId,
          label: processedWatcherLabel
        });
        logger.error({ err, folder: processedDir }, 'watcher: nestpick processed error');
      });
      processedWatcher.on('ready', () => {
        watcherReady(processedWatcherName, processedWatcherLabel);
        clearMachineHealthIssue(machine.machineId ?? null, HEALTH_CODES.nestpickShare);
      });

      const reportPath = join(folder, NESTPICK_UNSTACK_FILENAME);
      const unstackWatcherName = nestpickUnstackWatcherName(machine);
      const unstackWatcherLabel = nestpickUnstackWatcherLabel(machine);
      registerWatcher(unstackWatcherName, unstackWatcherLabel);
      const reportWatcher = chokidar.watch(reportPath, {
        ignoreInitial: true,
        depth: 0,
        awaitWriteFinish: { stabilityThreshold: 1500, pollInterval: 250 }
      });
      trackWatcher(reportWatcher);
      const handleReport = stableProcess(
        (path) => handleNestpickUnstack(machine, path),
        500,
        { watcherName: unstackWatcherName, watcherLabel: unstackWatcherLabel }
      );
      reportWatcher.on('add', handleReport);
      reportWatcher.on('change', handleReport);
      reportWatcher.on('error', (err) => {
        const code = (err as NodeJS.ErrnoException)?.code;
        setMachineHealthIssue({
          machineId: machine.machineId ?? null,
          code: HEALTH_CODES.nestpickShare,
          message: `Nestpick unstack share unreachable${code ? ` (${code})` : ''}`,
          severity: 'critical',
          context: { file: reportPath, machineId: machine.machineId, code }
        });
        recordWatcherError(unstackWatcherName, err, {
          folder: reportPath,
          machineId: machine.machineId,
          label: unstackWatcherLabel
        });
        logger.error({ err, folder: reportPath }, 'watcher: nestpick unstack error');
      });
      reportWatcher.on('ready', () => {
        watcherReady(unstackWatcherName, unstackWatcherLabel);
        clearMachineHealthIssue(machine.machineId ?? null, HEALTH_CODES.nestpickShare);
      });

      logger.info({ folder }, 'Nestpick watcher started');
    }
  } catch (err) {
    logger.error({ err }, 'watcher: failed to initialize nestpick watchers');
  }
}

function normalizeNumber(value: string | undefined): number | null {
  if (value == null) return null;
  const t = value.trim();
  if (!t) return null;
  const n = Number(t);
  return Number.isFinite(n) ? Math.trunc(n) : null;
}

function indexOfHeader(header: string[], candidates: string[]): number {
  const lower = header.map((h) => stripCsvCell(h).toLowerCase());
  for (const cand of candidates) {
    const i = lower.findIndex((h) => h === cand.toLowerCase());
    if (i !== -1) return i;
  }
  return -1;
}

function parseGrundnerCsv(raw: string): GrundnerCsvRow[] {
  const rows = parseCsvContent(raw);
  if (!rows.length) return [];
  const header = rows[0];
  const hasHeader = header.some((c) => /[A-Za-z]/.test(c));
  const body = hasHeader ? rows.slice(1) : rows;

  let idxType = -1,
    idxCust = -1,
    idxLen = -1,
    idxWid = -1,
    idxThk = -1,
    idxStock = -1,
    idxAvail = -1;
  if (hasHeader) {
    idxType = indexOfHeader(header, ['type_data', 'type']);
    idxCust = indexOfHeader(header, ['customer_id', 'customer']);
    idxLen = indexOfHeader(header, ['length_mm', 'length']);
    idxWid = indexOfHeader(header, ['width_mm', 'width']);
    idxThk = indexOfHeader(header, ['thickness_mm', 'thickness']);
    idxStock = indexOfHeader(header, ['stock']);
    idxAvail = indexOfHeader(header, ['stock_available', 'available']);
  } else {
    // Fallback positions if no header present
    idxType = 0;
    idxCust = 1;
    idxLen = 3;
    idxWid = 4;
    idxThk = 5;
    idxStock = 7;
    idxAvail = 8;
  }

  const out: GrundnerCsvRow[] = [];
  for (const row of body) {
    const typeData = normalizeNumber(row[idxType]);
    const customerIdRaw = idxCust >= 0 ? stripCsvCell(row[idxCust]) : '';
    const customerId = customerIdRaw ? customerIdRaw : null;
    const lengthMm = normalizeNumber(row[idxLen]);
    const widthMm = normalizeNumber(row[idxWid]);
    const thicknessMm = normalizeNumber(row[idxThk]);
    const stock = normalizeNumber(row[idxStock]);
    const stockAvailable = normalizeNumber(row[idxAvail]);
    if (typeData == null) continue;
    out.push({ typeData, customerId, lengthMm, widthMm, thicknessMm, stock, stockAvailable });
  }
  return out;
}

async function grundnerPollOnce(folder: string) {
  try {
    const reqPath = join(folder, 'stock_request.csv');
    const stockPath = join(folder, 'stock.csv');

    // If a pending request exists, do nothing and wait for next interval
    if (await fileExists(reqPath)) {
      recordWatcherEvent(GRUNDNER_WATCHER_NAME, { label: GRUNDNER_WATCHER_LABEL, message: 'Request in flight; skipping' });
      return;
    }

    // 1) Drop request CSV (matching documented example content)
    const tmp = `${reqPath}.tmp-${Date.now()}`;
    await fsp.writeFile(tmp, '0\r\n!E', 'utf8');
    await rename(tmp, reqPath).catch(async () => {
      await fsp.writeFile(reqPath, '0\r\n!E', 'utf8');
    });
    recordWatcherEvent(GRUNDNER_WATCHER_NAME, { label: GRUNDNER_WATCHER_LABEL, message: 'Request dropped' });

    // 2) Wait 3 seconds and check for reply
    await delay(3000);
    if (!(await fileExists(stockPath))) return;
    await waitForStableFile(stockPath);
    const raw = await readFile(stockPath, 'utf8');
    const hash = createHash('sha1').update(raw).digest('hex');
    if (grundnerLastHash === hash) return;
    grundnerLastHash = hash;
    const items = parseGrundnerCsv(raw);
    if (!items.length) return;
    const { inserted, updated } = await upsertGrundnerInventory(items);
    recordWatcherEvent(GRUNDNER_WATCHER_NAME, {
      label: GRUNDNER_WATCHER_LABEL,
      message: `Synced Grundner stock (inserted ${inserted}, updated ${updated})`
    });
  } catch (err) {
    recordWatcherError(GRUNDNER_WATCHER_NAME, err, { label: GRUNDNER_WATCHER_LABEL });
  }
}

function startGrundnerPoller(folder: string) {
  registerWatcher(GRUNDNER_WATCHER_NAME, GRUNDNER_WATCHER_LABEL);
  const trimmed = folder?.trim?.() ?? '';
  if (!trimmed) {
    recordWatcherEvent(GRUNDNER_WATCHER_NAME, { label: GRUNDNER_WATCHER_LABEL, message: 'Disabled (folder not configured)' });
    return;
  }
  const normalizedRoot = normalize(trimmed);
  if (!existsSync(normalizedRoot)) {
    const err = new Error('Grundner folder does not exist');
    recordWatcherError(GRUNDNER_WATCHER_NAME, err, { folder: normalizedRoot, label: GRUNDNER_WATCHER_LABEL });
    return;
  }

  const run = () => {
    if (shuttingDown) return;
    void grundnerPollOnce(normalizedRoot);
  };
  // immediate + interval
  void run();
  grundnerTimer = setInterval(run, 10_000);
  if (typeof grundnerTimer.unref === 'function') grundnerTimer.unref();
  watcherReady(GRUNDNER_WATCHER_NAME, GRUNDNER_WATCHER_LABEL);
}

function startJobsIngestPolling() {
  const INGEST_INTERVAL_MS = 5000; // 5 seconds

  async function runIngest() {
    if (shuttingDown) return;
    try {
      await ingestProcessedJobsRoot();
    } catch (err) {
      logger.error({ err }, 'Jobs ingest poll failed');
    }
  }

  // Run immediately on startup
  void runIngest();

  // Then poll every 5 seconds
  jobsIngestInterval = setInterval(() => {
    void runIngest();
  }, INGEST_INTERVAL_MS);

  if (typeof jobsIngestInterval.unref === 'function') {
    jobsIngestInterval.unref();
  }

  logger.info({ intervalMs: INGEST_INTERVAL_MS }, 'Jobs ingest polling started');
}

async function initWatchers() {
  logger.info('watchers: waiting for database readiness before starting');
  await waitForDbReady();
  const cfg = loadConfig();
  if (cfg.paths.autoPacCsvDir) {
    setupAutoPacWatcher(cfg.paths.autoPacCsvDir);
  }
  if (cfg.paths.grundnerFolderPath) {
    startGrundnerPoller(cfg.paths.grundnerFolderPath);
  }
  if (cfg.test.useTestDataMode) {
    setupTestDataWatcher(cfg.test.testDataFolderPath);
  }
  void setupNestpickWatchers();
  if (cfg.test.useTestDataMode) {
    logger.info('Telemetry disabled: running in test data mode');
  } else {
    void startTelemetryClients();
  }
  startJobsIngestPolling();
}

void initWatchers().catch((err) => {
  recordWorkerError('watchers:init', err);
  logger.error({ err }, 'watchersWorker: failed to initialize watchers');
});

if (channel) {
  channel.on('message', (message: MainToWatcherMessage) => {
    if (!message || typeof message !== 'object') return;
    if (message.type === 'shutdown') {
      void shutdown(message.reason).finally(() => process.exit(0));
    }
  });
}

process.on('SIGINT', () => {
  void shutdown('SIGINT').finally(() => process.exit(0));
});

process.on('SIGTERM', () => {
  void shutdown('SIGTERM').finally(() => process.exit(0));
});

process.on('uncaughtException', (err) => {
  recordWorkerError('watchers-worker', err);
  logger.error({ err }, 'watchersWorker: uncaught exception');
});

process.on('unhandledRejection', (reason) => {
  recordWorkerError('watchers-worker', reason);
  logger.error({ reason }, 'watchersWorker: unhandled rejection');
});

================
File: packages/main/tsconfig.json
================
{
  "extends": "../../tsconfig.base.json",
  "compilerOptions": {
    "outDir": "dist",
    "module": "CommonJS",
    "moduleResolution": "Node",
    "lib": ["ES2020"],
    "types": ["node"],
    "typeRoots": ["./node_modules/@types", "../node_modules/@types", "../../node_modules/@types"],
    "noEmit": false,
    "ignoreDeprecations": "5.0"
  },
  "include": ["src/**/*.ts"]
}

================
File: packages/preload/package.json
================
{
  "name": "@app/preload",
  "version": "0.1.0",
  "private": true,
  "main": "dist/index.js",
  "type": "commonjs",
  "scripts": {
    "build": "tsc -p tsconfig.json",
    "typecheck": "tsc -p tsconfig.json --noEmit"
  },
  "devDependencies": {
    "@types/node": "^20.12.12",
    "electron": "^31.0.0",
    "typescript": "^5.4.5"
  },
  "dependencies": {
    "neverthrow": "^7.1.0",
    "zod": "^3.23.8"
  }
}

================
File: packages/preload/src/index.ts
================
import { contextBridge, ipcRenderer } from 'electron';
import type {
  CopyDiagnosticsResult,
  DbSettings,
  DbStatus,
  DiagnosticsSnapshot,
  DiagnosticsLogsRes,
  DiagnosticsLogTailReq,
  DiagnosticsLogTailRes,
  LogWriteReq,
  ThemePreferenceReq,
  ThemePreferenceRes,
  GrundnerListReq,
  GrundnerListRes,
  GrundnerResyncReq,
  GrundnerUpdateReq,
  HistoryListReq,
  HistoryListRes,
  JobEventsReq,
  JobEventsRes,
  JobTimelineRes,
  JobsFiltersRes,
  JobsListReq,
  JobsListRes,
  LifecycleReq,
  LifecycleRes,
  MachinesListRes,
  Machine,
  PathValidationReq,
  PathValidationRes,
  ReadyListRes,
  ReadyImportReq,
  ReadyImportRes,
  ReadyDeleteReq,
  ReadyDeleteRes,
  RouterListReq,
  RouterListRes,
  SaveMachineReq,
  Settings,
  WorklistAddResult,
  TelemetrySummaryReq,
  TelemetrySummaryRes,
  AlarmsHistoryReq
} from '../../shared/src';
import { type ResultEnvelope } from '../../shared/src/result';

// Normalize all IPC calls to return a simple { ok, value | error } envelope
const invokeResult = <T>(channel: string, ...args: unknown[]): Promise<ResultEnvelope<T>> =>
  ipcRenderer.invoke(channel, ...args) as Promise<ResultEnvelope<T>>;

const api = {
  settings: {
    get: () => invokeResult<Settings>('settings:get'),
    getPath: () => invokeResult<string>('settings:path'),
    save: (next: Settings) => invokeResult<Settings>('settings:save', next),
    validatePath: (input: PathValidationReq) => invokeResult<PathValidationRes>('settings:validatePath', input)
  },
  db: {
    testConnection: (db: DbSettings) => invokeResult<{ ok: true } | { ok: false; error: string }>('db:test', db),
    ping: () => invokeResult<null>('db:ping'),
    getStatus: () => invokeResult<DbStatus>('db:status:get'),
    subscribeStatus: (listener: (status: DbStatus) => void) => {
      const channel = 'db:status:update';
      const handler = (_event: Electron.IpcRendererEvent, status: DbStatus) => listener(status);
      ipcRenderer.on(channel, handler);
      invokeResult<DbStatus>('db:status:subscribe').catch(() => {});
      return () => {
        ipcRenderer.removeListener(channel, handler);
        invokeResult<null>('db:status:unsubscribe').catch(() => {});
      };
    }
  },
  lifecycle: {
    update: (key: string, to: LifecycleReq['to']) => invokeResult<LifecycleRes>('jobs:lifecycle', { key, to })
  },
  jobs: {
    list: (req: JobsListReq) => invokeResult<JobsListRes>('jobs:list', req),
    filters: () => invokeResult<JobsFiltersRes>('jobs:filters'),
    events: (req: JobEventsReq) => invokeResult<JobEventsRes>('jobs:events', req),
    reserve: (key: string) => invokeResult<null>('jobs:reserve', { key }),
    unreserve: (key: string) => invokeResult<null>('jobs:unreserve', { key }),
    addToWorklist: (key: string, machineId: number) => invokeResult<WorklistAddResult>('jobs:addToWorklist', { key, machineId }),
    resync: () => invokeResult<{ inserted: number; updated: number }>('jobs:resync')
  },
  machines: {
    list: () => invokeResult<MachinesListRes>('machines:list'),
    save: (machine: SaveMachineReq) => invokeResult<Machine>('machines:save', machine),
    delete: (machineId: number) => invokeResult<null>('machines:delete', machineId)
  },
  dialog: {
    pickFolder: () => invokeResult<string | null>('dialog:pickFolder')
  },
  files: {
    listReady: (machineId: number) => invokeResult<ReadyListRes>('files:listReady', machineId),
    importReady: (input: ReadyImportReq) => invokeResult<ReadyImportRes>('files:importReady', input),
    deleteReadyAssets: (input: ReadyDeleteReq) => invokeResult<ReadyDeleteRes>('files:ready:delete', input),
    subscribeReady: (machineId: number, listener: (payload: ReadyListRes) => void) => {
      const channel = 'files:ready:update';
      const handler = (_e: Electron.IpcRendererEvent, payload: ReadyListRes) => listener(payload);
      ipcRenderer.on(channel, handler);
      invokeResult<null>('files:ready:subscribe', machineId).catch(() => {});
      return () => {
        ipcRenderer.removeListener(channel, handler);
        invokeResult<null>('files:ready:unsubscribe').catch(() => {});
      };
    }
  },
  router: {
    list: (req?: RouterListReq) => invokeResult<RouterListRes>('router:list', req ?? {})
  },
  grundner: {
    list: (req?: GrundnerListReq) => invokeResult<GrundnerListRes>('grundner:list', req ?? {}),
    update: (input: GrundnerUpdateReq) => invokeResult<{ ok: boolean; updated: number }>('grundner:update', input),
    resync: (input?: GrundnerResyncReq) => invokeResult<{ updated: number }>('grundner:resync', input ?? {})
  },
  hypernest: {
    open: () => invokeResult<null>('hypernest:open')
  },
  alarms: {
    list: () => invokeResult('alarms:list'),
    history: (req: AlarmsHistoryReq) => invokeResult('alarms:history', req),
    subscribe: (listener: (alarms: unknown[]) => void) => {
      const channel = 'alarms:update';
      const handler = (_event: Electron.IpcRendererEvent, alarms: unknown[]) => listener(alarms);
      ipcRenderer.on(channel, handler);
      invokeResult<null>('alarms:subscribe').catch(() => {});
      return () => {
        ipcRenderer.removeListener(channel, handler);
        invokeResult<null>('alarms:unsubscribe').catch(() => {});
      };
    }
  },
  telemetry: {
    summary: (req: TelemetrySummaryReq) => invokeResult<TelemetrySummaryRes>('telemetry:summary', req),
    subscribe: (req: TelemetrySummaryReq, listener: (payload: TelemetrySummaryRes) => void) => {
      const channel = 'telemetry:update';
      const handler = (_e: Electron.IpcRendererEvent, payload: TelemetrySummaryRes) => listener(payload);
      ipcRenderer.on(channel, handler);
      invokeResult<null>('telemetry:subscribe', req).catch(() => {});
      return () => {
        ipcRenderer.removeListener(channel, handler);
        invokeResult<null>('telemetry:unsubscribe').catch(() => {});
      };
    }
  },
  diagnostics: {
    get: () => invokeResult<DiagnosticsSnapshot>('diagnostics:get'),
    copy: () => invokeResult<CopyDiagnosticsResult>('diagnostics:copy'),
    listLogs: () => invokeResult<DiagnosticsLogsRes>('diagnostics:logs:list'),
    logTail: (req: DiagnosticsLogTailReq) =>
      invokeResult<DiagnosticsLogTailRes>('diagnostics:logs:tail', req),
    subscribe: (listener: (snapshot: DiagnosticsSnapshot) => void) => {
      const channel = 'diagnostics:update';
      const handler = (_event: Electron.IpcRendererEvent, snapshot: DiagnosticsSnapshot) => listener(snapshot);
      ipcRenderer.on(channel, handler);
      invokeResult<null>('diagnostics:subscribe').catch(() => {});
      return () => {
        ipcRenderer.removeListener(channel, handler);
        invokeResult<null>('diagnostics:unsubscribe').catch(() => {});
      };
    },
    subscribeLog: (file: string, listener: (payload: { file: string; lines: string[] }) => void) => {
      const channel = 'diagnostics:log:update';
      const handler = (_event: Electron.IpcRendererEvent, payload: { file: string; lines: string[] }) => {
        if (payload?.file === file) listener(payload);
      };
      ipcRenderer.on(channel, handler);
      invokeResult<null>('diagnostics:log:subscribe', { file }).catch(() => {});
      return () => {
        ipcRenderer.removeListener(channel, handler);
        invokeResult<null>('diagnostics:log:unsubscribe').catch(() => {});
      };
    }
  },
  ui: {
    theme: {
      get: () => invokeResult<ThemePreferenceRes>('ui:theme:get'),
      set: (req: ThemePreferenceReq) => invokeResult<ThemePreferenceRes>('ui:theme:set', req)
    }
  },

  history: {
    list: (req?: HistoryListReq) => invokeResult<HistoryListRes>('history:list', req ?? {}),
    timeline: (key: string) => invokeResult<JobTimelineRes | null>('history:timeline', key)
  }
  ,
  log: {
    write: (req: LogWriteReq) => invokeResult<null>('log:write', req),
    trace: (msg: string, context?: Record<string, unknown>) => invokeResult<null>('log:write', { level: 'trace', msg, context }),
    debug: (msg: string, context?: Record<string, unknown>) => invokeResult<null>('log:write', { level: 'debug', msg, context }),
    info: (msg: string, context?: Record<string, unknown>) => invokeResult<null>('log:write', { level: 'info', msg, context }),
    warn: (msg: string, context?: Record<string, unknown>) => invokeResult<null>('log:write', { level: 'warn', msg, context }),
    error: (msg: string, context?: Record<string, unknown>) => invokeResult<null>('log:write', { level: 'error', msg, context }),
    fatal: (msg: string, context?: Record<string, unknown>) => invokeResult<null>('log:write', { level: 'fatal', msg, context })
  }
} as const;

contextBridge.exposeInMainWorld('api', api);

export type Api = typeof api;

================
File: packages/preload/tsconfig.json
================
{
  "extends": "../../tsconfig.base.json",
  "compilerOptions": {
    "outDir": "dist",
    "module": "CommonJS",
    "lib": ["ES2020", "DOM"],
    "types": ["node", "electron"],
    "noEmit": false
  },
  "include": ["src/**/*.ts"]
}

================
File: packages/renderer/components.json
================
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "default",
  "rsc": false,
  "tsx": true,
  "tailwind": {
    "config": "tailwind.config.ts",
    "css": "src/index.css",
    "baseColor": "slate",
    "cssVariables": true
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils"
  }
}

================
File: packages/renderer/index.html
================
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Woodtron</title>
    <!-- Using system-installed 'HarmonyOS Sans' with sans-serif fallbacks; no webfont loaded -->
  </head>
  <body>
    <div id="root"></div>
    <script>
      (function () {
        try {
          var stored = localStorage.getItem('ui:theme') || 'system';
          var prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
          var root = document.documentElement;
          var isDark = stored === 'dark' || (stored === 'system' && prefersDark);
          if (isDark) {
            root.classList.add('dark');
          } else {
            root.classList.remove('dark');
          }
        } catch (error) {
          console.warn('Failed to apply stored theme preference', error);
        }
      })();
    </script>
    <script type="module" src="/src/main.tsx"></script>
  </body>
  </html>

================
File: packages/renderer/package.json
================
{
  "name": "@app/renderer",
  "version": "0.1.0",
  "private": true,
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview",
    "preview:hosted": "vite preview --host 127.0.0.1 --port 5180",
    "typecheck": "tsc -p tsconfig.json --noEmit"
  },
  "dependencies": {
    "@hookform/resolvers": "^3.3.4",
    "@tanstack/react-table": "^8.15.0",
    "@tanstack/react-virtual": "^3.0.0",
    "class-variance-authority": "^0.7.0",
    "clsx": "^2.1.1",
    "lucide-react": "^0.462.0",
    "motion": "^12.23.22",
    "neverthrow": "^7.1.0",
    "react": "^18.3.1",
    "react-dom": "^18.3.1",
    "react-hook-form": "^7.53.0",
    "react-router-dom": "^6.26.1",
    "recharts": "^2.15.4",
    "tailwind-merge": "^2.3.0",
    "zod": "^3.23.8"
  },
  "devDependencies": {
    "@radix-ui/react-dialog": "^1.1.15",
    "@radix-ui/react-label": "^2.1.7",
    "@radix-ui/react-separator": "^1.1.7",
    "@radix-ui/react-slot": "^1.2.3",
    "@radix-ui/react-tooltip": "^1.2.8",
    "@tailwindcss/postcss": "^4.1.13",
    "@types/react": "^18.2.74",
    "@types/react-dom": "^18.2.24",
    "@vitejs/plugin-react": "^4.3.1",
    "autoprefixer": "^10.4.18",
    "postcss": "^8.4.38",
    "tailwindcss": "^4.1.13",
    "typescript": "^5.4.5",
    "vite": "^5.2.10"
  }
}

================
File: packages/renderer/postcss.config.cjs
================
module.exports = {
  plugins: {
    '@tailwindcss/postcss': {},
    autoprefixer: {},
  },
};

================
File: packages/renderer/src/components/AppSidebar.tsx
================
import { NavLink } from 'react-router-dom';
import { LayoutDashboard, Briefcase, Router, History, Settings, PieChart, AlarmClock } from 'lucide-react';
import {
  Sidebar,
  SidebarContent,
  SidebarFooter,
  SidebarHeader,
  SidebarMenu,
  SidebarMenuItem,
} from '@/components/ui/sidebar';
import { cn } from '@/utils/cn';

const nav = [
  { to: '/dashboard', label: 'Dashboard', icon: LayoutDashboard },
  { to: '/jobs', label: 'Jobs', icon: Briefcase },
  { to: '/router', label: 'Router', icon: Router },
  { to: '/history', label: 'History', icon: History },
  { to: '/grundner', label: 'Grundner', icon: PieChart },
  { to: '/telemetry', label: 'Telemetry', icon: PieChart },
  { to: '/cnc-alarms', label: 'CNC Alarms', icon: AlarmClock },
  { to: '/settings', label: 'Settings', icon: Settings },
];

export function AppSidebar() {
  return (
    <Sidebar>
      <SidebarHeader>
        <div className="px-3 font-semibold text-xl">Woodtron</div>
      </SidebarHeader>
      <SidebarContent>
        <SidebarMenu>
          {nav.map((item) => {
            const Icon = item.icon;
            return (
              <SidebarMenuItem key={item.to}>
                <NavLink
                  to={item.to}
                  className={({ isActive }) => cn(
                    'flex h-10 w-full items-center gap-3 overflow-hidden rounded-md pl-4 pr-3 text-left text-base font-medium transition hover:bg-sidebar-accent hover:text-sidebar-accent-foreground [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0',
                    isActive && 'bg-sidebar-accent text-sidebar-accent-foreground font-medium'
                  )}
                >
                  <Icon />
                  <span className="ml-2 text-base font-medium">{item.label}</span>
                </NavLink>
              </SidebarMenuItem>
            );
          })}
        </SidebarMenu>
      </SidebarContent>
      <SidebarFooter>
        <SidebarMenu>
          <SidebarMenuItem>
            <button
              className="flex h-10 w-full ml-2 gap-2 overflow-hidden rounded-md pl-5 pr-3 text-left text-base font-medium transition hover:bg-sidebar-accent hover:text-sidebar-accent-foreground"
              onClick={async () => {
                const res = await window.api.hypernest.open();
                if (!res.ok) alert(`Failed to open Hypernest: ${res.error.message}`);
              }}
              title="Open Hypernest in a separate window"
            >
              Hypernest
            </button>
          </SidebarMenuItem>
        </SidebarMenu>
      </SidebarFooter>
    </Sidebar>
  );
}

================
File: packages/renderer/src/components/table/GlobalTable.tsx
================
import { useMemo } from 'react';
import type { MouseEvent } from 'react';
import { flexRender } from '@tanstack/react-table';
import type { Row, RowData, Table as TableInstance } from '@tanstack/react-table';
import { cn } from '@/utils/cn';

const DEFAULT_ROW_HEIGHT = 50;
const DEFAULT_HEADER_HEIGHT = 40;
const DEFAULT_VIEWPORT_PADDING = 30;

type GlobalTableProps<TData extends RowData> = {
  table: TableInstance<TData>;
  className?: string;
  tableClassName?: string;
  maxHeight?: string;
  stickyHeader?: boolean;
  fillEmptyRows?: boolean;
  minVisibleRows?: number;
  rowHeight?: number;
  headerHeight?: number;
  viewportPadding?: number;
  interactiveRows?: boolean;
  toggleRowSelectionOnClick?: boolean;
  preventContextMenuDefault?: boolean;
  density?: 'normal' | 'compact';
  headerHoverAlways?: boolean;
  onRowClick?: (row: Row<TData>, event: MouseEvent<HTMLTableRowElement>) => void;
  onRowContextMenu?: (row: Row<TData>, event: MouseEvent<HTMLTableRowElement>) => void;
  getRowClassName?: (row: Row<TData>) => string | undefined;
};

export function GlobalTable<TData extends RowData>({
  table,
  className,
  tableClassName,
  maxHeight = 'calc(100vh - 200px)',
  stickyHeader = true,
  fillEmptyRows = true,
  minVisibleRows,
  rowHeight = DEFAULT_ROW_HEIGHT,
  headerHeight = DEFAULT_HEADER_HEIGHT,
  viewportPadding = DEFAULT_VIEWPORT_PADDING,
  interactiveRows = true,
  toggleRowSelectionOnClick = true,
  preventContextMenuDefault = true,
  density = 'normal',
  headerHoverAlways = false,
  onRowClick,
  onRowContextMenu,
  getRowClassName
}: GlobalTableProps<TData>) {
  const rows = table.getRowModel().rows;

  const effectiveMinVisibleRows = useMemo(() => {
    if (!fillEmptyRows) return 0;
    if (typeof minVisibleRows === 'number') {
      return Math.max(0, Math.floor(minVisibleRows));
    }
    if (typeof window === 'undefined') return 0;
    const availableHeight = window.innerHeight - viewportPadding;
    if (availableHeight <= 0) return 0;
    const visible = Math.floor((availableHeight - headerHeight) / rowHeight);
    return visible > 0 ? visible : 0;
  }, [fillEmptyRows, minVisibleRows, rowHeight, headerHeight, viewportPadding]);

  const emptyRowCount = fillEmptyRows ? Math.max(0, effectiveMinVisibleRows - rows.length) : 0;

  const totalWidth = table.getCenterTotalSize();
  const tableStyle = {
    width: Number.isFinite(totalWidth) && totalWidth > 0 ? totalWidth : undefined,
    minWidth: '100%',
    tableLayout: 'fixed' as const
  };

  return (
    <div
      className={cn(
        'overflow-auto bg-table text-[var(--table-text)] border border-[var(--table-border)] rounded-lg',
        className
      )}
      style={{ maxHeight }}
    >
      <table className={cn('text-sm table-text', tableClassName)} style={tableStyle}>
        <thead
          className={cn(
            'text-[var(--table-text)] group',
            stickyHeader && 'sticky top-0 z-10'
          )}
          style={{ background: 'var(--table-header-bg)' }}
        >
          {table.getHeaderGroups().map((headerGroup) => (
            <tr key={headerGroup.id} className="border-b-0 transition-colors group-hover:bg-[var(--table-hover-bg)]">
              {headerGroup.headers.map((header) => {
                const dir = header.column.getIsSorted();
                const canSort = header.column.getCanSort();
                return (
                  <th
                    key={header.id}
                    className={cn(
                      'relative text-left align-middle font-medium whitespace-nowrap text-[var(--table-text)] overflow-hidden',
                      density === 'compact' ? 'h-9 px-2 py-1' : 'h-10 px-4 py-2',
                      (headerHoverAlways || canSort) && 'cursor-pointer select-none'
                    )}
                    style={{ width: header.getSize() }}
                    onClick={canSort ? header.column.getToggleSortingHandler() : undefined}
                  >
                    <div className="flex items-center gap-2 min-w-0">
                      <span className="truncate font-medium">
                        {header.isPlaceholder ? null : flexRender(header.column.columnDef.header, header.getContext())}
                      </span>
                      {dir === 'asc' && <span className="text-xs text-primary">{'▲'}</span>}
                      {dir === 'desc' && <span className="text-xs text-primary">{'▼'}</span>}
                    </div>
                    {header.column.getCanResize() && (
                      <div
                        onMouseDown={header.getResizeHandler()}
                        onTouchStart={header.getResizeHandler()}
                        className={cn(
                          'absolute right-0 top-0 h-full w-1 cursor-col-resize select-none hover:bg-[var(--primary-a20)] transition-colors',
                          header.column.getIsResizing() && 'bg-primary'
                        )}
                      />
                    )}
                  </th>
                );
              })}
            </tr>
          ))}
        </thead>
        <tbody>
          {rows.map((row) => (
            <tr
              key={row.id}
              className={cn(
                'border-b border-[var(--table-row-border)] hover:bg-[var(--table-hover-bg)] transition-colors',
                interactiveRows && 'cursor-pointer',
                row.getIsSelected() && 'bg-[var(--table-selected-bg)] data-[state=selected]:bg-[var(--table-selected-bg)]',
                getRowClassName?.(row)
              )}
              onClick={(event) => {
                if (toggleRowSelectionOnClick) {
                  row.toggleSelected();
                }
                onRowClick?.(row, event);
              }}
              onContextMenu={(event) => {
                if (preventContextMenuDefault) {
                  event.preventDefault();
                }
                onRowContextMenu?.(row, event);
              }}
            >
              {row.getVisibleCells().map((cell) => (
                <td
                  key={cell.id}
                  className={cn(
                    'align-middle whitespace-nowrap font-medium overflow-hidden',
                    density === 'compact' ? 'px-2 py-1' : 'px-4 py-2'
                  )}
                  style={{ width: cell.column.getSize(), maxWidth: cell.column.getSize() }}
                >
                  <div className="min-w-0 truncate overflow-hidden text-ellipsis">
                    {flexRender(cell.column.columnDef.cell, cell.getContext())}
                  </div>
                </td>
              ))}
            </tr>
          ))}
          {Array.from({ length: emptyRowCount }).map((_, index) => (
            <tr key={`empty-${index}`} className="border-b border-[var(--table-row-border)]">
              {table.getVisibleFlatColumns().map((column) => (
                <td
                  key={column.id}
                  className="px-4 py-3 align-middle whitespace-nowrap overflow-hidden"
                  style={{ width: column.getSize(), maxWidth: column.getSize() }}
                >
                  &nbsp;
                </td>
              ))}
            </tr>
          ))}
        </tbody>
      </table>
    </div>
  );
}

================
File: packages/renderer/src/components/ui/badge.tsx
================
import * as React from "react"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const badgeVariants = cva(
  "inline-flex items-center rounded-md border px-2 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring/50",
  {
    variants: {
      variant: {
        default:
          "border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80",
        secondary:
          "border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80",
        destructive:
          "border-transparent bg-destructive text-destructive-foreground shadow hover:bg-destructive/80",
        outline: "text-foreground",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
)

function Badge({ className, variant, ...props }: React.HTMLAttributes<HTMLDivElement> & VariantProps<typeof badgeVariants>) {
  return (
    <div data-slot="badge" className={cn(badgeVariants({ variant }), className)} {...props} />
  )
}

export { Badge, badgeVariants }

================
File: packages/renderer/src/components/ui/button.tsx
================
import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const buttonVariants = cva(
  "inline-flex items-center justify-center gap-3 whitespace-nowrap rounded-lg text-sm font-medium transition-all duration-200 disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive relative overflow-hidden",
  {
    variants: {
      variant: {
        default: "bg-primary text-primary-foreground hover:bg-primary/90 hover:shadow-lg hover:-translate-y-0.5 active:translate-y-0 shadow-md",
        destructive:
          "bg-destructive text-white hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60 hover:shadow-lg hover:-translate-y-0.5 active:translate-y-0 shadow-md",
        outline:
          "border bg-background shadow-sm hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50 hover:border-primary hover:text-primary hover:shadow-md hover:-translate-y-0.5 active:translate-y-0",
        secondary:
          "bg-secondary text-secondary-foreground hover:bg-secondary/80 hover:shadow-md hover:-translate-y-0.5 active:translate-y-0 shadow-sm",
        ghost:
          "hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 hover:shadow-sm hover:-translate-y-0.5 active:translate-y-0",
        link: "text-primary underline-offset-4 hover:underline hover:text-primary/80",
      },
      size: {
        default: "h-10 px-6 py-3 has-[>svg]:px-5",
        sm: "h-9 rounded-lg gap-2 px-4 py-2 has-[>svg]:px-3",
        lg: "h-12 rounded-lg px-8 py-4 has-[>svg]:px-6",
        icon: "size-10 rounded-lg",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  }
)

function Button({
  className,
  variant,
  size,
  asChild = false,
  ...props
}: React.ComponentProps<"button"> &
  VariantProps<typeof buttonVariants> & {
    asChild?: boolean
  }) {
  const Comp = asChild ? Slot : "button"

  return (
    <Comp
      data-slot="button"
      className={cn(buttonVariants({ variant, size, className }))}
      {...props}
    />
  )
}

export { Button, buttonVariants }

================
File: packages/renderer/src/components/ui/card.tsx
================
import * as React from "react"

import { cn } from "@/lib/utils"
import { GlowingEffect } from "@/components/ui/glowing-effect"

function Card({ className, children, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card"
      className={cn(
        "relative bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-[var(--shadow-soft)] hover:shadow-[var(--shadow-medium)] transition-shadow",
        className
      )}
      {...props}
    >
      <GlowingEffect
        // Neon deep purple configuration
        variant="purple"
        blur={12}
        inactiveZone={0.7}
        proximity={96}
        spread={32}
        movementDuration={1.2}
        borderWidth={2}
        disabled={false}
        glow={false}
      />
      {children}
    </div>
  )
}

function CardHeader({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-header"
      className={cn(
        "@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-1.5 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6",
        className
      )}
      {...props}
    />
  )
}

function CardTitle({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-title"
      className={cn("leading-none font-semibold", className)}
      {...props}
    />
  )
}

function CardDescription({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-description"
      className={cn("text-muted-foreground text-sm", className)}
      {...props}
    />
  )
}

function CardAction({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-action"
      className={cn(
        "col-start-2 row-span-2 row-start-1 self-start justify-self-end",
        className
      )}
      {...props}
    />
  )
}

function CardContent({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-content"
      className={cn("px-6", className)}
      {...props}
    />
  )
}

function CardFooter({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-footer"
      className={cn("flex items-center px-6 [.border-t]:pt-6", className)}
      {...props}
    />
  )
}

export {
  Card,
  CardHeader,
  CardFooter,
  CardTitle,
  CardAction,
  CardDescription,
  CardContent,
}

================
File: packages/renderer/src/components/ui/glowing-effect.tsx
================
"use client";

import { memo, useCallback, useEffect, useRef } from "react";
import { cn } from "@/lib/utils";
import { animate } from "motion/react";

interface GlowingEffectProps {
  blur?: number;
  inactiveZone?: number;
  proximity?: number;
  spread?: number;
  variant?: "default" | "white" | "purple";
  glow?: boolean;
  className?: string;
  disabled?: boolean;
  movementDuration?: number;
  borderWidth?: number;
}
const GlowingEffect = memo(
  ({
    blur = 0,
    inactiveZone = 0.7,
    proximity = 0,
    spread = 20,
    variant = "default",
    glow = false,
    className,
    movementDuration = 2,
    borderWidth = 1,
    disabled = true,
  }: GlowingEffectProps) => {
    const containerRef = useRef<HTMLDivElement>(null);
    const lastPosition = useRef({ x: 0, y: 0 });
    const animationFrameRef = useRef<number>(0);

    const handleMove = useCallback(
      (e?: MouseEvent | { x: number; y: number }) => {
        if (!containerRef.current) return;

        if (animationFrameRef.current) {
          cancelAnimationFrame(animationFrameRef.current);
        }

        animationFrameRef.current = requestAnimationFrame(() => {
          const element = containerRef.current;
          if (!element) return;

          const { left, top, width, height } = element.getBoundingClientRect();
          const mouseX = e?.x ?? lastPosition.current.x;
          const mouseY = e?.y ?? lastPosition.current.y;

          if (e) {
            lastPosition.current = { x: mouseX, y: mouseY };
          }

          const center = [left + width * 0.5, top + height * 0.5];
          const distanceFromCenter = Math.hypot(
            mouseX - center[0],
            mouseY - center[1]
          );
          const inactiveRadius = 0.5 * Math.min(width, height) * inactiveZone;

          if (distanceFromCenter < inactiveRadius) {
            element.style.setProperty("--active", "0");
            return;
          }

          const isActive =
            mouseX > left - proximity &&
            mouseX < left + width + proximity &&
            mouseY > top - proximity &&
            mouseY < top + height + proximity;

          element.style.setProperty("--active", isActive ? "1" : "0");

          if (!isActive) return;

          const currentAngle =
            parseFloat(element.style.getPropertyValue("--start")) || 0;
          const targetAngle =
            (180 * Math.atan2(mouseY - center[1], mouseX - center[0])) /
              Math.PI +
            90;

          const angleDiff = ((targetAngle - currentAngle + 180) % 360) - 180;
          const newAngle = currentAngle + angleDiff;

          animate(currentAngle, newAngle, {
            duration: movementDuration,
            ease: [0.16, 1, 0.3, 1],
            onUpdate: (value) => {
              element.style.setProperty("--start", String(value));
            },
          });
        });
      },
      [inactiveZone, proximity, movementDuration]
    );

    useEffect(() => {
      if (disabled) return;

      const handleScroll = () => handleMove();
      const handlePointerMove = (e: PointerEvent) => handleMove(e);

      window.addEventListener("scroll", handleScroll, { passive: true });
      document.body.addEventListener("pointermove", handlePointerMove, {
        passive: true,
      });

      return () => {
        if (animationFrameRef.current) {
          cancelAnimationFrame(animationFrameRef.current);
        }
        window.removeEventListener("scroll", handleScroll);
        document.body.removeEventListener("pointermove", handlePointerMove);
      };
    }, [handleMove, disabled]);

    return (
      <>
        <div
          className={cn(
            "pointer-events-none absolute -inset-px hidden rounded-[inherit] border opacity-0 transition-opacity",
            glow && "opacity-100",
            variant === "white" && "border-white",
            disabled && "!block"
          )}
        />
        <div
          ref={containerRef}
          style={
            {
              "--blur": `${blur}px`,
              "--spread": spread,
              "--start": "0",
              "--active": "0",
              "--glowingeffect-border-width": `${borderWidth}px`,
              "--repeating-conic-gradient-times": "5",
              "--gradient":
                variant === "white"
                  ? `repeating-conic-gradient(
                      from 236.84deg at 50% 50%,
                      var(--black),
                      var(--black) calc(25% / var(--repeating-conic-gradient-times))
                    )`
                  : variant === "purple"
                  ? `radial-gradient(circle at 20% 25%, rgba(124, 58, 237, 0.85) 0%, rgba(124,58,237,0) 25%),
                      radial-gradient(circle at 80% 25%, rgba(168, 85, 247, 0.8) 0%, rgba(168,85,247,0) 28%),
                      radial-gradient(circle at 25% 80%, rgba(147, 51, 234, 0.85) 0%, rgba(147,51,234,0) 24%),
                      radial-gradient(circle at 70% 75%, rgba(109, 40, 217, 0.85) 0%, rgba(109,40,217,0) 26%),
                      repeating-conic-gradient(
                        from 236.84deg at 50% 50%,
                        #7C3AED 0%,
                        #A855F7 calc(25% / var(--repeating-conic-gradient-times)),
                        #9333EA calc(50% / var(--repeating-conic-gradient-times)),
                        #6D28D9 calc(75% / var(--repeating-conic-gradient-times)),
                        #7C3AED calc(100% / var(--repeating-conic-gradient-times))
                      )`
                  : `radial-gradient(circle, #dd7bbb 10%, #dd7bbb00 20%),
                      radial-gradient(circle at 40% 40%, #d79f1e 5%, #d79f1e00 15%),
                      radial-gradient(circle at 60% 60%, #5a922c 10%, #5a922c00 20%), 
                      radial-gradient(circle at 40% 60%, #4c7894 10%, #4c789400 20%),
                      repeating-conic-gradient(
                        from 236.84deg at 50% 50%,
                        #dd7bbb 0%,
                        #d79f1e calc(25% / var(--repeating-conic-gradient-times)),
                        #5a922c calc(50% / var(--repeating-conic-gradient-times)), 
                        #4c7894 calc(75% / var(--repeating-conic-gradient-times)),
                        #dd7bbb calc(100% / var(--repeating-conic-gradient-times))
                      )`,
            } as React.CSSProperties
          }
          className={cn(
            "pointer-events-none absolute inset-0 rounded-[inherit] opacity-100 transition-opacity",
            glow && "opacity-100",
            blur > 0 && "blur-[var(--blur)] ",
            className,
            disabled && "!hidden"
          )}
        >
          <div
            className={cn(
              "glow",
              "rounded-[inherit]",
              'after:content-[""] after:rounded-[inherit] after:absolute after:inset-[calc(-1*var(--glowingeffect-border-width))]',
              "after:[border:var(--glowingeffect-border-width)_solid_transparent]",
              "after:[background:var(--gradient)] after:[background-attachment:fixed]",
              "after:opacity-[var(--active)] after:transition-opacity after:duration-300",
              "after:[mask-clip:padding-box,border-box]",
              "after:[mask-composite:intersect]",
              "after:[mask-image:linear-gradient(#0000,#0000),conic-gradient(from_calc((var(--start)-var(--spread))*1deg),#00000000_0deg,#fff,#00000000_calc(var(--spread)*2deg))]"
            )}
          />
        </div>
      </>
    );
  }
);

GlowingEffect.displayName = "GlowingEffect";

export { GlowingEffect };

================
File: packages/renderer/src/components/ui/separator.tsx
================
import * as React from "react"
import * as SeparatorPrimitive from "@radix-ui/react-separator"

import { cn } from "@/lib/utils"

function Separator({ className, orientation = "horizontal", decorative = true, ...props }: React.ComponentProps<typeof SeparatorPrimitive.Root>) {
  return (
    <SeparatorPrimitive.Root
      data-slot="separator"
      decorative={decorative}
      orientation={orientation}
      className={cn(
        "bg-border shrink-0",
        orientation === "horizontal" ? "h-[1px] w-full" : "h-full w-[1px]",
        className
      )}
      {...props}
    />
  )}

export { Separator }

================
File: packages/renderer/src/components/ui/sheet.tsx
================
"use client"

import * as React from "react"
import * as DialogPrimitive from "@radix-ui/react-dialog"

import { cn } from "@/lib/utils"

const Sheet = DialogPrimitive.Root
const SheetTrigger = DialogPrimitive.Trigger
const SheetClose = DialogPrimitive.Close

const SheetPortal = DialogPrimitive.Portal
const SheetOverlay = React.forwardRef<
  React.ElementRef<typeof DialogPrimitive.Overlay>,
  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Overlay>
>(({ className, ...props }, ref) => (
  <DialogPrimitive.Overlay
    ref={ref}
    className={cn("bg-black/80 fixed inset-0 z-50", className)}
    {...props}
  />
))
SheetOverlay.displayName = DialogPrimitive.Overlay.displayName

const SheetContent = React.forwardRef<
  React.ElementRef<typeof DialogPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Content> & {
    side?: "left" | "right" | "top" | "bottom"
  }
>(({ side = "right", className, children, ...props }, ref) => (
  <SheetPortal>
    <SheetOverlay />
    <DialogPrimitive.Content
      ref={ref}
      className={cn(
        "fixed z-50 gap-4 bg-background p-6 shadow-lg transition ease-in-out data-[state=open]:animate-in data-[state=closed]:animate-out",
        side === "right" && "inset-y-0 right-0 h-full w-80 border-l",
        side === "left" && "inset-y-0 left-0 h-full w-80 border-r",
        side === "top" && "inset-x-0 top-0 w-full border-b",
        side === "bottom" && "inset-x-0 bottom-0 w-full border-t",
        className
      )}
      {...props}
    >
      {children}
    </DialogPrimitive.Content>
  </SheetPortal>
))
SheetContent.displayName = DialogPrimitive.Content.displayName

const SheetHeader = ({ className, ...props }: React.HTMLAttributes<HTMLDivElement>) => (
  <div className={cn("flex flex-col space-y-2 text-center sm:text-left", className)} {...props} />
)

const SheetFooter = ({ className, ...props }: React.HTMLAttributes<HTMLDivElement>) => (
  <div className={cn("flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2", className)} {...props} />
)

const SheetTitle = React.forwardRef<
  React.ElementRef<typeof DialogPrimitive.Title>,
  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Title>
>(({ className, ...props }, ref) => (
  <DialogPrimitive.Title
    ref={ref}
    className={cn("text-lg font-semibold text-foreground", className)}
    {...props}
  />
))
SheetTitle.displayName = DialogPrimitive.Title.displayName

const SheetDescription = React.forwardRef<
  React.ElementRef<typeof DialogPrimitive.Description>,
  React.ComponentPropsWithoutRef<typeof DialogPrimitive.Description>
>(({ className, ...props }, ref) => (
  <DialogPrimitive.Description
    ref={ref}
    className={cn("text-sm text-muted-foreground", className)}
    {...props}
  />
))
SheetDescription.displayName = DialogPrimitive.Description.displayName

export {
  Sheet,
  SheetPortal,
  SheetOverlay,
  SheetTrigger,
  SheetClose,
  SheetContent,
  SheetHeader,
  SheetFooter,
  SheetTitle,
  SheetDescription,
}

================
File: packages/renderer/src/components/ui/sidebar.tsx
================
"use client"

import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"
import { PanelLeftIcon } from "lucide-react"

import { useIsMobile } from "@/hooks/use-mobile"
import { cn } from "@/lib/utils"
import { Button } from "@/components/ui/button"
import { Sheet, SheetContent, SheetDescription, SheetHeader, SheetTitle } from "@/components/ui/sheet"

const SIDEBAR_WIDTH = "12rem"
const SIDEBAR_WIDTH_ICON = "3rem"

type SidebarContextProps = {
  open: boolean
  setOpen: (open: boolean) => void
  openMobile: boolean
  setOpenMobile: (open: boolean) => void
  isMobile: boolean
  toggleSidebar: () => void
}

const SidebarContext = React.createContext<SidebarContextProps | null>(null)

function useSidebar() {
  const context = React.useContext(SidebarContext)
  if (!context) throw new Error("useSidebar must be used within a SidebarProvider.")
  return context
}

function SidebarProvider({ className, style, children, ...props }: React.ComponentProps<"div">) {
  const isMobile = useIsMobile()
  const [open, setOpen] = React.useState(true)
  const [openMobile, setOpenMobile] = React.useState(false)
  const toggleSidebar = React.useCallback(() => {
    if (isMobile) setOpenMobile((v) => !v)
    else setOpen((v) => !v)
  }, [isMobile])

  const sidebarVars: Record<string, string> = {
    "--sidebar-width": SIDEBAR_WIDTH,
    "--sidebar-width-icon": SIDEBAR_WIDTH_ICON,
  }

  return (
    <SidebarContext.Provider value={{ open, setOpen, openMobile, setOpenMobile, isMobile, toggleSidebar }}>
      <div
        data-collapsible={open ? "full" : "icon"}
        className={cn("group/sidebar-wrapper flex min-h-svh w-full max-w-full overflow-x-hidden", className)}
        style={{
          ...(style as React.CSSProperties),
          ...sidebarVars,
        }}
        {...props}
      >
        {children}
      </div>
    </SidebarContext.Provider>
  )
}

function Sidebar({ className, children, ...props }: React.ComponentProps<"div">) {
  const { isMobile, openMobile, setOpenMobile } = useSidebar()
  if (isMobile) {
    return (
      <Sheet open={openMobile} onOpenChange={setOpenMobile}>
        <SheetContent side="left" className="bg-sidebar text-sidebar-foreground w-(--sidebar-width) p-0 [&>button]:hidden">
          <SheetHeader className="sr-only">
            <SheetTitle>Sidebar</SheetTitle>
            <SheetDescription>Displays the mobile sidebar.</SheetDescription>
          </SheetHeader>
          <div className="bg-sidebar flex h-full w-full flex-col">
            {children}
          </div>
        </SheetContent>
      </Sheet>
    )
  }
  return (
    <aside
      data-slot="sidebar"
      className={cn(
        "text-sidebar-foreground w-(--sidebar-width) border-r bg-sidebar",
        className
      )}
      {...props}
    >
      {children}
    </aside>
  )
}

function SidebarTrigger({ className, ...props }: React.ComponentProps<typeof Button>) {
  const { toggleSidebar } = useSidebar()
  return (
    <Button variant="outline" size="icon" className={cn("shrink-0", className)} onClick={toggleSidebar} {...props}>
      <PanelLeftIcon className="size-5" />
      <span className="sr-only">Toggle Sidebar</span>
    </Button>
  )
}

function SidebarInset({ className, ...props }: React.ComponentProps<"main">) {
  return <main data-slot="sidebar-inset" className={cn("flex min-h-svh flex-1 flex-col min-w-0 overflow-x-hidden", className)} {...props} />
}

function SidebarHeader({ className, ...props }: React.ComponentProps<"div">) {
  return <div data-slot="sidebar-header" className={cn("flex items-center h-12 px-3", className)} {...props} />
}

function SidebarContent({ className, ...props }: React.ComponentProps<"div">) {
  return <div data-slot="sidebar-content" className={cn("flex-1 p-2", className)} {...props} />
}

function SidebarFooter({ className, ...props }: React.ComponentProps<"div">) {
  return <div data-slot="sidebar-footer" className={cn("p-2", className)} {...props} />
}

function SidebarMenu({ className, ...props }: React.ComponentProps<"ul">) {
  return <ul data-slot="sidebar-menu" className={cn("flex flex-col gap-1", className)} {...props} />
}

function SidebarMenuItem({ className, ...props }: React.ComponentProps<"li">) {
  return <li data-slot="sidebar-menu-item" className={cn("", className)} {...props} />
}

const sidebarMenuButtonVariants = cva(
  "peer/menu-button flex w-full items-center gap-2 overflow-hidden rounded-md pl-6 pr-2 text-left text-base font-medium outline-hidden ring-sidebar-ring transition hover:bg-sidebar-accent hover:text-sidebar-accent-foreground [&>span:last-child]:truncate [&>span:last-child]:pl-3 [&>svg]:size-4 [&>svg]:shrink-0",
  {
    variants: {
      size: { default: "h-9", sm: "h-8", lg: "h-10" },
      variant: { default: "", outline: "bg-background shadow-[0_0_0_1px_var(--sidebar-border)]" },
    },
    defaultVariants: { size: "default", variant: "default" },
  }
)

function SidebarMenuButton({ className, size, variant, asChild = false, ...props }: React.ComponentProps<"button"> & VariantProps<typeof sidebarMenuButtonVariants> & { asChild?: boolean }) {
  const Comp = asChild ? Slot : "button"
  return <Comp data-slot="sidebar-menu-button" className={cn(sidebarMenuButtonVariants({ size, variant }), className)} {...props} />
}

export {
  useSidebar,
  SidebarProvider,
  Sidebar,
  SidebarTrigger,
  SidebarInset,
  SidebarHeader,
  SidebarFooter,
  SidebarContent,
  SidebarMenu,
  SidebarMenuItem,
  SidebarMenuButton,
}

================
File: packages/renderer/src/components/ui/skeleton.tsx
================
import * as React from "react"
import { cn } from "@/lib/utils"

function Skeleton({ className, ...props }: React.HTMLAttributes<HTMLDivElement>) {
  return (
    <div
      className={cn("animate-pulse rounded-md bg-muted", className)}
      {...props}
    />
  )
}

export { Skeleton }

================
File: packages/renderer/src/components/ui/table.tsx
================
"use client"

import * as React from "react"

import { cn } from "@/lib/utils"

function Table({ className, ...props }: React.ComponentProps<"table">) {
  return (
    <div
      data-slot="table-container"
      className="relative w-full overflow-x-auto border border-[var(--table-border)] rounded-lg"
    >
      <table
        data-slot="table"
        className={cn("w-full caption-bottom text-sm", className)}
        {...props}
      />
    </div>
  )
}

function TableHeader({ className, ...props }: React.ComponentProps<"thead">) {
  return (
    <thead
      data-slot="table-header"
      className={cn(
        "[&_tr]:border-b [&_tr]:border-[var(--table-row-border)] text-xs uppercase tracking-wide text-[var(--table-text)]",
        className
      )}
      style={{ background: 'var(--table-header-bg)' }}
      {...props}
    />
  )
}

function TableBody({ className, ...props }: React.ComponentProps<"tbody">) {
  return (
    <tbody
      data-slot="table-body"
      className={cn("[&_tr:last-child]:border-0", className)}
      {...props}
    />
  )
}

function TableFooter({ className, ...props }: React.ComponentProps<"tfoot">) {
  return (
    <tfoot
      data-slot="table-footer"
      className={cn(
        "bg-[var(--muted-a50)] border-t border-[var(--table-row-border)] font-medium [&>tr]:last:border-b-0",
        className
      )}
      {...props}
    />
  )
}

function TableRow({ className, ...props }: React.ComponentProps<"tr">) {
  return (
    <tr
      data-slot="table-row"
      className={cn(
        "hover:bg-[var(--muted-a50)] data-[state=selected]:bg-[var(--muted)] border-b border-[var(--table-row-border)] transition-colors",
        className
      )}
      {...props}
    />
  )
}

function TableHead({ className, ...props }: React.ComponentProps<"th">) {
  return (
    <th
      data-slot="table-head"
      className={cn(
        "h-10 px-4 py-2 text-left align-middle font-medium whitespace-nowrap text-[var(--table-text)] overflow-hidden [&:has([role=checkbox])]:pr-0 [&>[role=checkbox]]:translate-y-[2px]",
        className
      )}
      {...props}
    />
  )
}

function TableCell({ className, ...props }: React.ComponentProps<"td">) {
  return (
    <td
      data-slot="table-cell"
      className={cn(
        "px-4 py-3 align-middle whitespace-nowrap font-medium overflow-hidden [&:has([role=checkbox])]:pr-0 [&>[role=checkbox]]:translate-y-[2px]",
        className
      )}
      {...props}
    />
  )
}

function TableCaption({
  className,
  ...props
}: React.ComponentProps<"caption">) {
  return (
    <caption
      data-slot="table-caption"
      className={cn("text-muted-foreground mt-4 text-sm", className)}
      {...props}
    />
  )
}

export {
  Table,
  TableHeader,
  TableBody,
  TableFooter,
  TableHead,
  TableRow,
  TableCell,
  TableCaption,
}

================
File: packages/renderer/src/components/ui/tooltip.tsx
================
"use client"

import * as React from "react"
import * as TooltipPrimitive from "@radix-ui/react-tooltip"

import { cn } from "@/lib/utils"

const TooltipProvider = TooltipPrimitive.Provider

const Tooltip = TooltipPrimitive.Root

const TooltipTrigger = TooltipPrimitive.Trigger

const TooltipContent = React.forwardRef<
  React.ElementRef<typeof TooltipPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof TooltipPrimitive.Content>
>(({ className, sideOffset = 4, ...props }, ref) => (
  <TooltipPrimitive.Content
    ref={ref}
    sideOffset={sideOffset}
    className={cn(
      "bg-popover text-popover-foreground z-50 overflow-hidden rounded-md border px-3 py-1.5 text-xs shadow-md",
      className
    )}
    {...props}
  />
))
TooltipContent.displayName = TooltipPrimitive.Content.displayName

export { Tooltip, TooltipTrigger, TooltipContent, TooltipProvider }

================
File: packages/renderer/src/hooks/use-mobile.ts
================
import * as React from "react"

const MOBILE_BREAKPOINT = 768

export function useIsMobile() {
  const [isMobile, setIsMobile] = React.useState<boolean | undefined>(undefined)

  React.useEffect(() => {
    const mql = window.matchMedia(`(max-width: ${MOBILE_BREAKPOINT - 1}px)`)
    const onChange = () => {
      setIsMobile(window.innerWidth < MOBILE_BREAKPOINT)
    }
    mql.addEventListener("change", onChange)
    setIsMobile(window.innerWidth < MOBILE_BREAKPOINT)
    return () => mql.removeEventListener("change", onChange)
  }, [])

  return !!isMobile
}

================
File: packages/renderer/src/index.css
================
/* Modern Design System for Woodtron App */

/* Import the clean theme system */
@import './styles/theme.css';

/* Import Tailwind CSS */
@import 'tailwindcss';

/* Tailwind base layer integration */
@layer base {
  * { border-color: var(--border); }
  html, body, #root {
    width: 100%;
    height: 100%;
    overflow-x: hidden;
    margin: 0;
    padding: 0;
  }
  body {
    background: var(--background-body);
    box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.05);
    color: var(--foreground);
  }
}

/* Application specific component styles */
@layer components {
  /* Simple table container */
  .table-container {
    border: 1px solid var(--border);
    border-radius: var(--radius);
    overflow: hidden;
    box-shadow: 0 1px 3px var(--border-a10);
  }
  
  /* Sidebar component - now uses simple bg-sidebar class */
  .sidebar {
    border-right: 1px solid var(--sidebar-border);
  }
  
  /* General card component */
  .card {
    background-color: var(--card);
    color: var(--card-foreground);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    box-shadow: 0 1px 3px var(--border-a10), 0 1px 2px var(--border-a06);
    transition: all var(--transition-normal);
  }
  
  .card:hover {
    box-shadow: 0 4px 6px var(--border-a10), 0 2px 4px var(--border-a06);
    transform: translateY(-1px);
    border-color: var(--primary-a20);
  }

  /* Dashboard cards */
  .dashboard-card {
    background-color: var(--card);
    color: var(--card-foreground);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    box-shadow: 0 1px 3px var(--border-a10), 0 1px 2px var(--border-a06);
    transition: all var(--transition-normal);
  }
  
  .dashboard-card:hover {
    box-shadow: 0 4px 6px var(--border-a10), 0 2px 4px var(--border-a06);
    transform: translateY(-2px);
    border-color: var(--primary-a30);
  }
  
  /* Table styles */
  .data-table {
    background-color: var(--card);
    color: var(--card-foreground);
    font-size: 0.875rem;
    box-shadow: var(--shadow-sm);
    border-radius: var(--radius);
  }

  .data-table th {
    background-color: var(--muted-a50);
    color: var(--muted-foreground);
    border-bottom: 1px solid var(--border);
  }

  .data-table td {
    border-bottom: 1px solid var(--border);
  }

  .data-table tbody tr:hover {
    background-color: var(--muted-a50);
  }
  
  /* Form sections */
  .form-section {
    background-color: var(--card);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    box-shadow: var(--shadow-sm);
  }

  /* Status indicators */
  .status-indicator.success {
    background-color: var(--status-success-bg);
    color: var(--status-success-text);
  }

  .status-indicator.warning {
    background-color: var(--status-warning-bg);
    color: var(--status-warning-text);
  }

  .status-indicator.error {
    background-color: var(--status-error-bg);
    color: var(--status-error-text);
  }
  
  /* Loading spinner */
  .loading-spinner {
    border-color: var(--muted);
    border-top-color: var(--primary);
  }
  
  /* Page layout */
  .page-title {
    color: var(--foreground);
  }

  .page-description { 
    color: var(--muted-foreground); 
  }
  
  /* Settings components */
  .settings-sidebar,
  .settings-content {
    background-color: var(--card);
    color: var(--card-foreground);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    box-shadow: var(--shadow-sm);
  }
}

/* Modern theme specific enhancements */
@layer components {
  .modern .sidebar {
    border-right: 2px solid var(--primary-a20);
    box-shadow: 2px 0 8px var(--border-a10);
  }
  
  .modern header {
    background: var(--background);
    backdrop-filter: blur(16px);
    -webkit-backdrop-filter: blur(16px);
    border-bottom: 2px solid var(--primary-a20);
    box-shadow: 0 6px 14px rgba(0, 0, 0, 0.25);
  }
  
  .modern header button {
    position: relative;
    overflow: hidden;
    transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
  }
  
  .modern header button::before {
    content: '';
    position: absolute;
    top: 0;
    left: -100%;
    width: 100%;
    height: 100%;
    background: linear-gradient(90deg, transparent, var(--primary-a20), transparent);
    transition: left 0.6s ease;
  }
  
  .modern header button:hover {
    transform: translateY(-2px) scale(1.05);
    box-shadow: 0 4px 12px var(--primary-a30);
    border-color: var(--primary);
  }
  
  .modern header button:hover::before {
    left: 100%;
  }
  
  .modern header select {
    transition: all 0.3s ease;
    border: 2px solid var(--border);
  }
  
  .modern header select:hover {
    border-color: var(--primary);
    box-shadow: 0 2px 8px var(--primary-a20);
    transform: translateY(-1px);
  }
  
  .modern .dashboard-card {
    border: 1px solid var(--border-a10);
    box-shadow: 0 4px 6px var(--border-a08), 0 2px 4px var(--border-a06);
    transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
    position: relative;
    overflow: hidden;
  }
  
  .modern .dashboard-card::before {
    content: '';
    position: absolute;
    top: 0;
    left: -100%;
    width: 100%;
    height: 100%;
    background: linear-gradient(90deg, transparent, var(--primary-a10), transparent);
    transition: left 0.8s ease;
  }
  
  .modern .dashboard-card:hover {
    box-shadow: 0 12px 24px var(--primary-a15), 0 6px 12px var(--border-a08);
    transform: translateY(-4px) scale(1.02);
    border-color: var(--primary-a30);
  }
  
  .modern .dashboard-card:hover::before {
    left: 100%;
  }
  
  .modern .dashboard-card:hover::after {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 4px;
    background: linear-gradient(90deg, var(--primary), var(--accent), var(--primary));
    animation: shimmer 2s ease-in-out infinite;
  }
  
  @keyframes shimmer {
    0%, 100% { opacity: 0.6; }
    50% { opacity: 1; }
  }
  
  .modern .table-container {
    border-color: var(--primary-a20);
    box-shadow: 0 4px 12px var(--primary-a15);
  }
  
  .modern .card {
    border-color: var(--primary-a20);
    box-shadow: 0 2px 8px var(--primary-a10);
  }
  
  .modern .card:hover {
    border-color: var(--primary-a30);
    box-shadow: 0 6px 16px var(--primary-a15);
    transform: translateY(-2px);
  }
}

================
File: packages/renderer/src/lib/utils.ts
================
export { cn } from '@/utils/cn';

================
File: packages/renderer/src/main.tsx
================
import React from 'react';
import ReactDOM from 'react-dom/client';
import { createBrowserRouter, RouterProvider } from 'react-router-dom';
import './index.css';
import { installRendererConsoleForwarding } from './setupLogger';
import { AppLayout } from './shell/AppLayout';
import { DashboardPage } from './pages/DashboardPage';
import { JobsPage } from './pages/JobsPage';
import { RouterPage } from './pages/RouterPage';
import { HistoryPage } from './pages/HistoryPage';
import { SettingsPage } from './pages/SettingsPage';
import { MachinesPage } from './pages/MachinesPage';
import ThemeShowcase from './pages/ThemeShowcase';
import TelemetryPage from './pages/TelemetryPage';
import CncAlarmsPage from './pages/CncAlarmsPage';
import { GrundnerPage } from './pages/GrundnerPage';

const router = createBrowserRouter([
  {
    path: '/',
    element: <AppLayout />,
    children: [
      { path: '/dashboard', element: <DashboardPage /> },
      { path: '/jobs', element: <JobsPage /> },
      { path: '/router', element: <RouterPage /> },
      { path: '/history', element: <HistoryPage /> },
      { path: '/telemetry', element: <TelemetryPage /> },
      { path: '/cnc-alarms', element: <CncAlarmsPage /> },
      { path: '/grundner', element: <GrundnerPage /> },
      { path: '/settings', element: <SettingsPage /> },
      { path: '/settings/machines', element: <MachinesPage /> },
      { path: '/theme', element: <ThemeShowcase /> },
      { index: true, element: <DashboardPage /> }
    ]
  }
]);

// Forward console.* and uncaught errors to main logger
installRendererConsoleForwarding();

ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
    <RouterProvider router={router} />
  </React.StrictMode>
);

================
File: packages/renderer/src/pages/CncAlarmsPage.tsx
================
import { useEffect, useMemo, useState } from 'react';
import type { AlarmsHistoryRes, Machine } from '../../../shared/src';
import { createColumnHelper, getCoreRowModel, useReactTable } from '@tanstack/react-table';
import { GlobalTable } from '@/components/table/GlobalTable';

type Filters = {
  from: string;
  to: string;
  machineIds: number[] | 'all';
};

function toIsoDateTimeBoundary(dateStr: string, endOfDay: boolean): string | undefined {
  if (!dateStr) return undefined;
  return endOfDay ? `${dateStr}T23:59:59.999Z` : `${dateStr}T00:00:00.000Z`;
}

function formatTime(iso: string): string {
  const d = new Date(iso);
  const hh = String(d.getHours()).padStart(2, '0');
  const mm = String(d.getMinutes()).padStart(2, '0');
  const ss = String(d.getSeconds()).padStart(2, '0');
  const DD = String(d.getDate()).padStart(2, '0');
  const MM = String(d.getMonth() + 1).padStart(2, '0');
  const YYYY = d.getFullYear();
  return `${hh}:${mm}:${ss} ${DD}:${MM}:${YYYY}`;
}

function defaultDateRange(): { from: string; to: string } {
  const to = new Date();
  const from = new Date(to);
  from.setMonth(from.getMonth() - 1);
  const toStr = `${to.getFullYear()}-${String(to.getMonth() + 1).padStart(2, '0')}-${String(to.getDate()).padStart(2, '0')}`;
  const fromStr = `${from.getFullYear()}-${String(from.getMonth() + 1).padStart(2, '0')}-${String(from.getDate()).padStart(2, '0')}`;
  return { from: fromStr, to: toStr };
}

export function CncAlarmsPage() {
  const [machines, setMachines] = useState<Machine[]>([]);
  const [filters, setFilters] = useState<Filters>({ ...defaultDateRange(), machineIds: 'all' });
  const [data, setData] = useState<AlarmsHistoryRes | null>(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const { from: filterFrom, to: filterTo, machineIds } = filters;

  useEffect(() => {
    (async () => {
      const res = await window.api.machines.list();
      if (res.ok) setMachines(res.value.items);
    })();
  }, []);

  useEffect(() => {
    (async () => {
      setLoading(true);
      setError(null);
      try {
        const req: { from?: string; to?: string; machineIds?: number[] } = {};
        if (filterFrom) req.from = toIsoDateTimeBoundary(filterFrom, false);
        if (filterTo) req.to = toIsoDateTimeBoundary(filterTo, true);
        if (machineIds !== 'all') req.machineIds = machineIds;
        const res = await window.api.alarms.history(req);
        if (!res.ok) {
          setError(res.error.message);
          setData(null);
        } else {
          setData(res.value);
        }
      } catch (e) {
        setError((e as Error).message);
        setData(null);
      } finally {
        setLoading(false);
      }
    })();
  }, [filterFrom, filterTo, machineIds]);

  const columnHelper = createColumnHelper<AlarmsHistoryRes['items'][number]>();
  const columns = useMemo(() => [
    columnHelper.accessor('startAt', {
      header: 'DateTime',
      cell: (ctx) => formatTime(ctx.getValue())
    }),
    columnHelper.accessor('alarmId', { header: 'Alarm ID', cell: (ctx) => ctx.getValue() ?? '' }),
    columnHelper.accessor('description', { header: 'Description' }),
    columnHelper.accessor('machineName', {
      header: 'Machine',
      cell: (ctx) => ctx.getValue() ?? (ctx.row.original.machineId != null ? `Machine ${ctx.row.original.machineId}` : 'Unknown')
    }),
    columnHelper.accessor('durationMinutes', { header: 'Duration (min)', cell: (ctx) => ctx.getValue() })
  ], [columnHelper]);

  const table = useReactTable({
    data: data?.items ?? [],
    columns,
    getCoreRowModel: getCoreRowModel()
  });

  return (
    <div className="p-4 space-y-3">
      <h1 className="text-xl font-semibold">CNC Alarms</h1>

      <div className="grid grid-cols-1 md:grid-cols-4 gap-3">
        <label className="text-sm flex flex-col gap-1">
          <span>From</span>
          <input
            type="date"
            className="border rounded px-2 py-1"
            value={filters.from}
            onChange={(e) => setFilters((prev) => ({ ...prev, from: e.target.value }))}
          />
        </label>
        <label className="text-sm flex flex-col gap-1">
          <span>To</span>
          <input
            type="date"
            className="border rounded px-2 py-1"
            value={filters.to}
            onChange={(e) => setFilters((prev) => ({ ...prev, to: e.target.value }))}
          />
        </label>
        <div className="md:col-span-2">
          <div className="text-sm">Machines</div>
          <div className="flex flex-wrap gap-3 mt-1">
            <label className="inline-flex items-center gap-1 text-sm">
              <input
                type="checkbox"
                checked={machineIds === 'all'}
                onChange={(e) => setFilters((prev) => ({ ...prev, machineIds: e.target.checked ? 'all' : [] }))}
              />
              All
            </label>
            {machines.map((m) => {
              const isAll = machineIds === 'all';
              const checked = isAll ? true : machineIds.includes(m.machineId);
              return (
                <label key={m.machineId} className="inline-flex items-center gap-1 text-sm">
                  <input
                    type="checkbox"
                    checked={checked}
                    onChange={(e) =>
                      setFilters((prev) => {
                        if (prev.machineIds === 'all') return { ...prev, machineIds: [m.machineId] };
                        const ids = new Set(prev.machineIds as number[]);
                        if (e.target.checked) ids.add(m.machineId);
                        else ids.delete(m.machineId);
                        return { ...prev, machineIds: Array.from(ids) };
                      })
                    }
                  />
                  {m.name}
                </label>
              );
            })}
          </div>
        </div>
      </div>

      {error && <div className="border border-red-300 bg-red-50 text-red-700 text-sm px-3 py-2 rounded">{error}</div>}
      {loading && <div className="text-sm text-muted-foreground">Loading...</div>}

      <GlobalTable table={table} />
    </div>
  );
}

export default CncAlarmsPage;

================
File: packages/renderer/src/pages/DashboardPage.tsx
================
import { useEffect, useMemo, useState } from 'react';
import type {
  DiagnosticsSnapshot,
  JobRow,
  JobsListReq,
  Machine,
  MachineHealthEntry,
  MachineHealthCode
} from '../../../shared/src';
import { cn } from '../utils/cn';
import { Card, CardContent } from '@/components/ui/card';
import { Table, TableBody, TableCell, TableHead, TableHeader, TableRow } from '@/components/ui/table';

const ACTIVE_STATUSES: NonNullable<JobsListReq['filter']['statusIn']> = [
  'STAGED',
  'LOAD_FINISH',
  'LABEL_FINISH',
  'CNC_FINISH',
  'FORWARDED_TO_NESTPICK'
];

export function DashboardPage() {
  const [jobs, setJobs] = useState<JobRow[]>([]);
  const [error, setError] = useState<string | null>(null);
  const [loading, setLoading] = useState<boolean>(true);
  const [machines, setMachines] = useState<Machine[]>([]);
  const [diagnostics, setDiagnostics] = useState<DiagnosticsSnapshot | null>(null);

  useEffect(() => {
    let cancelled = false;
    (async () => {
      setError(null);
      setLoading(true);
      const res = await window.api.jobs.list({
        sortBy: 'dateadded',
        sortDir: 'desc',
        limit: 100,
        filter: { statusIn: ACTIVE_STATUSES }
      });
      if (cancelled) return;
      if (!res.ok) {
        setError(res.error.message);
        setLoading(false);
        return;
      }
      setJobs(res.value.items);
      setLoading(false);
    })();
    return () => {
      cancelled = true;
    };
  }, []);

  useEffect(() => {
    let cancelled = false;
    (async () => {
      const res = await window.api.machines.list();
      if (cancelled) return;
      if (res.ok) setMachines(res.value.items);
    })();
    return () => { cancelled = true; };
  }, []);

  useEffect(() => {
    let cancelled = false;
    window.api.diagnostics
      .get()
      .then((res) => {
        if (cancelled) return;
        if (res.ok) setDiagnostics(res.value);
      })
      .catch(() => {});
    const unsubscribe = window.api.diagnostics.subscribe((snapshot) => {
      if (!cancelled) setDiagnostics(snapshot);
    });
    return () => {
      cancelled = true;
      unsubscribe?.();
    };
  }, []);

  const machineNameById = useMemo(() => {
    const map = new Map<number, string>();
    for (const m of machines) map.set(m.machineId, m.name);
    return map;
  }, [machines]);

  const machineIssuesById = useMemo(() => {
    const entries: MachineHealthEntry[] = diagnostics?.machineHealth ?? [];
    const byId = new Map<number | 'global', MachineHealthEntry[]>();
    for (const issue of entries) {
      const key = issue.machineId ?? 'global';
      const list = byId.get(key) ?? [];
      list.push(issue);
      byId.set(key, list);
    }
    return byId;
  }, [diagnostics]);

  function healthLabel(code: MachineHealthCode): string {
    switch (code) {
      case 'NO_PARTS_CSV':
        return 'Parts CSV missing';
      case 'NESTPICK_SHARE_UNREACHABLE':
        return 'Nestpick share unreachable';
      case 'COPY_FAILURE':
        return 'Copy failures';
    }
    return (code as string).replace(/_/g, ' ');
  }

  function severityDotClass(severity: MachineHealthEntry['severity']): string {
    switch (severity) {
      case 'critical':
        return 'bg-red-500';
      case 'warning':
        return 'bg-amber-500';
      default:
        return 'bg-slate-400';
    }
  }

  return (
    <div className="space-y-4 w-full">
      <h1 className="text-xl font-semibold">Dashboard</h1>
      <div className="grid grid-cols-1 md:grid-cols-3 gap-3">
        <div className="border rounded p-4 flex flex-col">
          <div className="font-medium mb-2">Jobs Pending</div>
          {loading ? (
            <div className="text-sm text-muted-foreground flex items-center gap-2">
              <div className="animate-spin rounded-full h-4 w-4 border-b-2 border-current"></div>
              Loading...
            </div>
          ) : error ? (
            <div className="text-sm text-destructive">Failed to load jobs: {error}</div>
          ) : jobs.length === 0 ? (
            <div className="text-sm text-muted-foreground">No active jobs found.</div>
          ) : (
            <Card className="overflow-hidden">
              <CardContent className="px-6 py-2">
                <Table aria-label="Active jobs pending processing">
                  <caption className="sr-only">Table showing active jobs with their key, machine, material, and status</caption>
                  <TableHeader>
                    <TableRow>
                      <TableHead scope="col">Key</TableHead>
                      <TableHead scope="col">Machine</TableHead>
                      <TableHead scope="col">Material</TableHead>
                      <TableHead scope="col">Status</TableHead>
                    </TableRow>
                  </TableHeader>
                  <TableBody>
                    {jobs.map((job) => (
                      <TableRow key={job.key}>
                        <TableCell className="py-1 pr-2">{job.key}</TableCell>
                        <TableCell className="py-1 pr-2">
                        {job.machineId != null ? (
                          (() => {
                            const id = job.machineId!;
                            const name = machineNameById.get(id) ?? id;
                            const issues: MachineHealthEntry[] = [
                              ...(machineIssuesById.get(id) ?? []),
                              ...(machineIssuesById.get('global') ?? [])
                            ]
                              .slice()
                              .sort((a, b) => {
                                const sev = (s: MachineHealthEntry['severity']) => (s === 'critical' ? 2 : s === 'warning' ? 1 : 0);
                                const d = sev(b.severity) - sev(a.severity);
                                if (d) return d;
                                return b.lastUpdatedAt.localeCompare(a.lastUpdatedAt);
                              });
                            return (
                              <div className="flex items-center gap-2">
                                <span>{String(name)}</span>
                                {issues.length > 0 && (
                                  <div className="flex flex-wrap items-center gap-1">
                                    {issues.slice(0, 2).map((issue) => (
                                      <span
                                        key={issue.id}
                                        className={cn(
                                          'inline-flex items-center gap-1 rounded px-1.5 py-0.5 text-[10px] font-medium text-white',
                                          issue.severity === 'critical'
                                            ? 'bg-red-600'
                                            : issue.severity === 'warning'
                                            ? 'bg-amber-600'
                                            : 'bg-slate-500'
                                        )}
                                        title={`${healthLabel(issue.code)} GÇö ${issue.message}`}
                                      >
                                        <span className={cn('h-1.5 w-1.5 rounded-full', severityDotClass(issue.severity))} />
                                        <span>{healthLabel(issue.code)}</span>
                                      </span>
                                    ))}
                                    {issues.length > 2 && (
                                      <span className="text-[10px] text-muted-foreground">+{issues.length - 2} more</span>
                                    )}
                                  </div>
                                )}
                              </div>
                            );
                          })()
                        ) : (
                          '-'
                        )}
                        </TableCell>
                        <TableCell className="py-1 pr-2">{job.material ?? '-'}</TableCell>
                        <TableCell className="py-1">{job.status}</TableCell>
                      </TableRow>
                    ))}
                  </TableBody>
                </Table>
              </CardContent>
            </Card>
          )}
        </div>
        <div className="border rounded p-4">Jobs In Progress</div>
        <div className="border rounded p-4">Completed Today</div>
      </div>
    </div>
  );
}

================
File: packages/renderer/src/pages/GrundnerPage.tsx
================
import { useCallback, useEffect, useMemo, useState } from 'react';
import {
  getCoreRowModel,
  getSortedRowModel,
  useReactTable
} from '@tanstack/react-table';
import type { ColumnDef, SortingState } from '@tanstack/react-table';
import { GlobalTable } from '@/components/table/GlobalTable';
import type { GrundnerListReq, GrundnerRow } from '../../../shared/src';

type Filters = {
  search: string;
  onlyAvailable: boolean;
  onlyReserved: boolean;
};

type EditState = {
  stockAvailable?: string;
  reservedStock?: string;
};

export function GrundnerPage() {
  const [rows, setRows] = useState<GrundnerRow[]>([]);
  const [filters, setFilters] = useState<Filters>({ search: '', onlyAvailable: false, onlyReserved: false });
  const [limit, setLimit] = useState(200);
  const [editing, setEditing] = useState<Record<number, EditState>>({});
  const [loading, setLoading] = useState(false);
  const [sorting, setSorting] = useState<SortingState>([{ id: 'typeData', desc: false }]);

  const totalStock = useMemo(() => rows.reduce((sum, row) => sum + (row.stock ?? 0), 0), [rows]);
  const totalAvailable = useMemo(() => rows.reduce((sum, row) => sum + (row.stockAvailable ?? 0), 0), [rows]);
  const totalReserved = useMemo(() => rows.reduce((sum, row) => sum + (row.reservedStock ?? 0), 0), [rows]);

  const load = useCallback(async () => {
    setLoading(true);
    const req: GrundnerListReq = {
      limit,
      filter: {
        search: filters.search || undefined,
        onlyAvailable: filters.onlyAvailable || undefined,
        onlyReserved: filters.onlyReserved || undefined
      }
    };
    const res = await window.api.grundner.list(req);
    if (!res.ok) {
      alert(`Failed to load Grundner inventory: ${res.error.message}`);
      setRows([]);
      setLoading(false);
      return;
    }
    setRows(res.value.items);
    setLoading(false);
  }, [filters, limit]);

  useEffect(() => { load(); }, [load]);

  const parseField = (value: string | undefined) => {
    if (!value || value.trim() === '') return null;
    const numeric = Number(value);
    if (Number.isNaN(numeric)) throw new Error('Please enter a valid number');
    return numeric;
  };

  const updateRow = async (row: GrundnerRow) => {
    const edit = editing[row.id] ?? {};
    const payload: { stockAvailable?: number | null; reservedStock?: number | null } = {};
    let dirty = false;

    if (Object.prototype.hasOwnProperty.call(edit, 'stockAvailable')) {
      payload.stockAvailable = parseField(edit.stockAvailable);
      dirty = true;
    }
    if (Object.prototype.hasOwnProperty.call(edit, 'reservedStock')) {
      payload.reservedStock = parseField(edit.reservedStock);
      dirty = true;
    }

    if (!dirty) {
      alert('No changes to apply.');
      return;
    }

    const res = await window.api.grundner.update({ id: row.id, ...payload });
    if (!res.ok) {
      alert(`Failed to update row: ${res.error.message}`);
      return;
    }
    if (!res.value.ok) {
      alert('Failed to update row.');
      return;
    }
    setEditing((prev) => {
      const next = { ...prev };
      delete next[row.id];
      return next;
    });
    await load();
  };

  const resyncReserved = async (id?: number) => {
    const res = await window.api.grundner.resync(id ? { id } : undefined);
    if (!res.ok) {
      alert(`Resync failed: ${res.error.message}`);
      return;
    }
    await load();
  };
  const columns = useMemo<ColumnDef<GrundnerRow>[]>(() => [
    {
      id: 'typeData',
      accessorKey: 'typeData',
      header: 'Type',
      cell: (ctx) => <span className="font-mono text-xs">{ctx.getValue<number | null>() ?? ''}</span>,
      size: 120
    },
    {
      id: 'customerId',
      accessorKey: 'customerId',
      header: 'Customer',
      cell: (ctx) => ctx.getValue<string | null>() ?? '',
      size: 200
    },
    {
      id: 'thicknessMm',
      accessorKey: 'thicknessMm',
      header: 'Thickness',
      cell: (ctx) => ctx.getValue<number | null>() ?? '',
      size: 110
    },
    {
      id: 'stock',
      accessorKey: 'stock',
      header: 'Stock',
      cell: (ctx) => ctx.getValue<number | null>() ?? '',
      size: 90
    },
    {
      id: 'stockAvailable',
      accessorKey: 'stockAvailable',
      header: 'Available',
      size: 120,
      cell: (ctx) => ctx.getValue<number | null>() ?? ''
    },
    {
      id: 'reservedStock',
      accessorKey: 'reservedStock',
      header: 'Reserved',
      size: 120,
      cell: (ctx) => {
        const row = ctx.row.original;
        const edit = editing[row.id] ?? {};
        const val = edit.reservedStock ?? (row.reservedStock != null ? String(row.reservedStock) : '');
        return (
          <input
            className="border rounded px-1 py-0.5 w-16 text-right text-xs h-7"
            type="number"
            value={val}
            onChange={(e) => setEditing((prev) => ({ ...prev, [row.id]: { ...prev[row.id], reservedStock: e.target.value } }))}
          />
        );
      }
    },
    {
      id: 'lastUpdated',
      accessorKey: 'lastUpdated',
      header: 'Last Updated',
      cell: (ctx) => <span className="text-xs text-muted-foreground">{ctx.getValue<string | null>() ?? ''}</span>,
      size: 180
    },
    {
      id: 'actions',
      header: 'Actions',
      size: 200,
      cell: (ctx) => {
        const row = ctx.row.original;
        return (
          <div className="flex gap-2">
            <button className="border rounded px-2 py-1 text-sm" onClick={() => { /* TODO: implement Reserve */ }}>
              Reserve
            </button>
            <button className="border rounded px-2 py-1 text-sm" onClick={() => { /* TODO: implement Lock */ }}>
              Lock
            </button>
          </div>
        );
      }
    }
  ], [editing]);

  const table = useReactTable({
    data: rows,
    columns,
    state: { sorting },
    onSortingChange: setSorting,
    getCoreRowModel: getCoreRowModel(),
    getSortedRowModel: getSortedRowModel(),
    defaultColumn: { size: 120 }
  });

  return (
    <div className="space-y-4 w-full">
      <div className="flex items-center justify-between">
        <div>
          <h1 className="text-xl font-semibold">Grundner Inventory</h1>
          <p className="text-sm text-muted-foreground">stock {totalStock}</p>
        </div>
        <div className="flex gap-2">
          <button className="border rounded px-3 py-1" onClick={() => resyncReserved()}>Resync All</button>
          <button className="border rounded px-3 py-1" onClick={load} disabled={loading}>{loading ? 'Loading…' : 'Refresh'}</button>
        </div>
      </div>

      <div className="flex flex-wrap gap-3 items-end">
        <label className="flex flex-col gap-1 text-sm">
          <span>Search</span>
          <input className="border rounded px-2 py-1" value={filters.search} onChange={(e) => setFilters((prev) => ({ ...prev, search: e.target.value }))} placeholder="Type data or customer" />
        </label>
        <label className="flex items-center gap-2 text-sm">
          <input type="checkbox" checked={filters.onlyAvailable} onChange={(e) => setFilters((prev) => ({ ...prev, onlyAvailable: e.target.checked }))} />
          Only available
        </label>
        <label className="flex items-center gap-2 text-sm">
          <input type="checkbox" checked={filters.onlyReserved} onChange={(e) => setFilters((prev) => ({ ...prev, onlyReserved: e.target.checked }))} />
          Only reserved
        </label>
        <label className="flex flex-col gap-1 text-sm">
          <span>Limit</span>
          <select className="border rounded px-2 py-1" value={limit} onChange={(e) => setLimit(Number(e.target.value))}>
            {[100, 200, 300, 500].map((value) => (
              <option key={value} value={value}>{value}</option>
            ))}
          </select>
        </label>
      </div>

      <GlobalTable table={table} stickyHeader fillEmptyRows />
    </div>
  );
}

================
File: packages/renderer/src/pages/HistoryPage.tsx
================
import { useCallback, useEffect, useMemo, useState } from "react";
import { Table, TableBody, TableCell, TableHead, TableHeader, TableRow } from '@/components/ui/table';
import type { HistoryListReq, HistoryRow, JobTimelineRes, Machine } from "../../../shared/src";

function formatDate(value: string | null | undefined) {
  if (!value) return "";
  const d = new Date(value);
  if (Number.isNaN(d.getTime())) return "";
  const months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'];
  const day = d.getDate();
  const mon = months[d.getMonth()];
  const year = d.getFullYear();
  let h = d.getHours();
  const m = String(d.getMinutes()).padStart(2, '0');
  const ampm = h >= 12 ? 'pm' : 'am';
  h = h % 12; if (h === 0) h = 12;
  return `${day} ${mon} ${year} ${h}:${m}${ampm}`;
}

function humanize(value: string) {
  return value
    .split(/[_\s]+/)
    .filter(Boolean)
    .map((part) => part.charAt(0).toUpperCase() + part.slice(1).toLowerCase())
    .join(" ");
}

type TimelineItem = {
  id: string;
  at: string | null;
  label: string;
  description?: string;
};

type HistoryFilters = {
  machine: "all" | number;
  search: string;
  from: string;
  to: string;
  limit: number;
};

function buildTimeline(data: JobTimelineRes): TimelineItem[] {
  const items: TimelineItem[] = [];
  const { job, events } = data;

  const addItem = (idSuffix: string, at: string | null, label: string, description?: string) => {
    items.push({
      id: `${job.key}:${idSuffix}`,
      at,
      label,
      description: description && description.trim().length ? description : undefined
    });
  };

  if (job.dateadded) addItem("imported", job.dateadded, "Imported", "Job detected in database");
  if (job.stagedAt) addItem("staged", job.stagedAt, "Staged", "Staged timestamp recorded");
  if (job.cutAt) addItem("cut", job.cutAt, "CNC Finish", "Cut completion timestamp recorded");
  if (job.nestpickCompletedAt) addItem("nestpick", job.nestpickCompletedAt, "Nestpick Complete", "Nestpick reported completion");
  if (job.finishAt) {
    const finishLabel = job.finishSource === "nestpick" ? "Finished (Nestpick)" : job.finishSource === "cut" ? "Finished (Cut)" : "Finished";
    const finishDesc = job.finishSource === "nestpick" ? "Finish derived from nestpick completion" : job.finishSource === "cut" ? "Finish derived from CNC completion" : undefined;
    addItem("finished", job.finishAt, finishLabel, finishDesc);
  }

  let lastMachineId: number | null | undefined = job.machineId ?? null;

  events.forEach((event, index) => {
    const [category, actionRaw] = event.eventType.split(":", 2);
    const action = actionRaw ?? "";
    const descriptionParts: string[] = [];
    const payload = event.payload as Record<string, unknown> | null | undefined;

    if (payload && typeof payload === "object") {
      if (typeof payload.source === "string") descriptionParts.push(`Source: ${payload.source}`);
      if (typeof payload.file === "string") descriptionParts.push(`File: ${payload.file}`);
      if (typeof payload.pallet === "string" && payload.pallet) descriptionParts.push(`Pallet: ${payload.pallet}`);
      if (typeof payload.from === "string" && typeof payload.to === "string") {
        descriptionParts.push(`Status ${payload.from} -> ${payload.to}`);
      }
      const machineCandidate = payload.machineId as unknown;
      const payloadMachine =
        typeof machineCandidate === "number"
          ? machineCandidate
          : typeof machineCandidate === "string"
            ? Number(machineCandidate)
            : undefined;
      if (payloadMachine != null && !Number.isNaN(payloadMachine) && payloadMachine !== lastMachineId) {
        const machineLabel = event.machineName ? `${event.machineName} (#${payloadMachine})` : `Machine #${payloadMachine}`;
        descriptionParts.push(`Machine -> ${machineLabel}`);
        lastMachineId = payloadMachine;
      }
    }

    if (event.machineId != null && event.machineId !== lastMachineId) {
      const machineLabel = event.machineName ? `${event.machineName} (#${event.machineId})` : `Machine #${event.machineId}`;
      descriptionParts.push(`Machine -> ${machineLabel}`);
      lastMachineId = event.machineId;
    }

    let label: string;
    switch (category) {
      case "status":
        label = `Status -> ${action}`;
        break;
      case "autopac":
        label = `AutoPAC ${humanize(action)}`;
        break;
      case "nestpick":
        label = `Nestpick ${humanize(action)}`;
        break;
      default:
        label = humanize(event.eventType);
        break;
    }

    addItem(`event-${index}`, event.createdAt ?? null, label, descriptionParts.join(" | "));
  });

  return items
    .sort((a, b) => {
      const aTime = a.at ? new Date(a.at).getTime() : Number.POSITIVE_INFINITY;
      const bTime = b.at ? new Date(b.at).getTime() : Number.POSITIVE_INFINITY;
      if (aTime === bTime) return a.id.localeCompare(b.id);
      return aTime - bTime;
    });
}

export function HistoryPage() {
  const [rows, setRows] = useState<HistoryRow[]>([]);
  const [machines, setMachines] = useState<Machine[]>([]);
  const [filters, setFilters] = useState<HistoryFilters>({ machine: "all", search: "", from: "", to: "", limit: 100 });
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [selectedKey, setSelectedKey] = useState<string | null>(null);
  const [timeline, setTimeline] = useState<JobTimelineRes | null>(null);
  const [timelineLoading, setTimelineLoading] = useState(false);

  const selectedRow = useMemo(() => rows.find((row) => row.key === selectedKey) ?? null, [rows, selectedKey]);

  const fetchHistory = useCallback(async () => {
    setLoading(true);
    setError(null);
    const req: HistoryListReq = {
      limit: filters.limit,
      ...(filters.machine !== "all" ? { machineId: filters.machine } : {}),
      ...(filters.search.trim() ? { search: filters.search.trim() } : {})
    };
    if (filters.from) req.from = new Date(`${filters.from}T00:00:00`).toISOString();
    if (filters.to) req.to = new Date(`${filters.to}T23:59:59.999`).toISOString();
    const res = await window.api.history.list(req);
    if (!res.ok) {
      setError(res.error.message);
      setRows([]);
      setLoading(false);
      return;
    }
    setRows(res.value.items);
    if (res.value.items.length && (!selectedKey || !res.value.items.some((item: HistoryRow) => item.key === selectedKey))) {
      setSelectedKey(res.value.items[0].key);
    }
    setLoading(false);
  }, [filters, selectedKey]);

  const fetchTimeline = useCallback(async (key: string) => {
    setTimelineLoading(true);
    const res = await window.api.history.timeline(key);
    if (!res.ok) {
      const message = res.error.message;
      setError((prev) => (prev ? `${prev}; Timeline: ${message}` : `Timeline: ${message}`));
      setTimeline(null);
      setTimelineLoading(false);
      return;
    }
    setTimeline(res.value ?? null);
    setTimelineLoading(false);
  }, []);

  useEffect(() => {
    (async () => {
      const res = await window.api.machines.list();
      if (!res.ok) {
        console.error('Failed to load machines', res.error);
        return;
      }
      setMachines(res.value.items);
    })();
  }, []);

  useEffect(() => {
    fetchHistory();
  }, [fetchHistory]);

  useEffect(() => {
    if (selectedKey) {
      fetchTimeline(selectedKey);
    } else {
      setTimeline(null);
    }
  }, [selectedKey, fetchTimeline]);

  const timelineItems = useMemo(() => (timeline ? buildTimeline(timeline) : []), [timeline]);

  return (
    <div className="space-y-4 w-full">
      <div className="flex items-center justify-between">
        <div>
          <h1 className="text-xl font-semibold">History</h1>
          <p className="text-sm text-muted-foreground">{loading ? "Loading..." : `${rows.length} completed jobs`}</p>
        </div>
        <button className="border rounded px-3 py-1 text-sm" onClick={fetchHistory} disabled={loading}>
          Refresh
        </button>
      </div>

      <div className="flex flex-wrap gap-3 items-end border rounded p-3">
        <label className="text-sm flex flex-col gap-1">
          <span>Search</span>
          <input
            className="border rounded px-2 py-1"
            placeholder="Key or material"
            value={filters.search}
            onChange={(e) => setFilters((prev) => ({ ...prev, search: e.target.value }))}
          />
        </label>
        <label className="text-sm flex flex-col gap-1">
          <span>Machine</span>
          <select
            className="border rounded px-2 py-1"
            value={filters.machine === "all" ? "" : String(filters.machine)}
            onChange={(e) => setFilters((prev) => ({ ...prev, machine: e.target.value ? Number(e.target.value) : "all" }))}
          >
            <option value="">All Machines</option>
            {machines.map((machine) => (
              <option key={machine.machineId} value={machine.machineId}>{machine.name}</option>
            ))}
          </select>
        </label>
        <label className="text-sm flex flex-col gap-1">
          <span>From</span>
          <input
            type="date"
            className="border rounded px-2 py-1"
            value={filters.from}
            onChange={(e) => setFilters((prev) => ({ ...prev, from: e.target.value }))}
          />
        </label>
        <label className="text-sm flex flex-col gap-1">
          <span>To</span>
          <input
            type="date"
            className="border rounded px-2 py-1"
            value={filters.to}
            onChange={(e) => setFilters((prev) => ({ ...prev, to: e.target.value }))}
          />
        </label>
        <label className="text-sm flex flex-col gap-1">
          <span>Limit</span>
          <select
            className="border rounded px-2 py-1"
            value={filters.limit}
            onChange={(e) => setFilters((prev) => ({ ...prev, limit: Number(e.target.value) }))}
          >
            {[50, 100, 150, 200].map((value) => (
              <option key={value} value={value}>{value}</option>
            ))}
          </select>
        </label>
      </div>

      {error && (
        <div className="border border-red-300 bg-red-50 text-red-700 text-sm px-3 py-2 rounded">{error}</div>
      )}

      <div className="grid gap-4 lg:grid-cols-[2fr_3fr]">
        <div className="border rounded bg-table text-[var(--table-text)] overflow-hidden">
          <Table>
            <TableHeader>
              <TableRow>
                <TableHead className="px-2 py-2">NC File</TableHead>
                <TableHead className="px-2 py-2">Machine</TableHead>
                <TableHead className="px-2 py-2">Finish</TableHead>
              </TableRow>
            </TableHeader>
            <TableBody>
              {rows.map((row) => {
                const isActive = row.key === selectedKey;
                const machineLabel = row.machineName ?? (row.machineId != null ? `Machine #${row.machineId}` : "Unassigned");
                return (
                  <TableRow
                    key={row.key}
                    className={isActive ? 'data-[state=selected]:bg-[var(--muted)]' : ''}
                    onClick={() => setSelectedKey(row.key)}
                  >
                    <TableCell className="px-2 py-2">{row.ncfile ?? ""}</TableCell>
                    <TableCell className="px-2 py-2">{machineLabel}</TableCell>
                    <TableCell className="px-2 py-2 text-xs">{formatDate(row.finishAt)}</TableCell>
                  </TableRow>
                );
              })}
              {!rows.length && !loading && (
                <TableRow>
                  <TableCell colSpan={3} className="px-2 py-6 text-center text-sm text-muted-foreground">No completed jobs found.</TableCell>
                </TableRow>
              )}
            </TableBody>
          </Table>
        </div>

        <div className="border rounded p-4 space-y-3 min-h-[320px]">
          {!selectedRow && <div className="text-sm text-muted-foreground">Select a job to view its timeline.</div>}
          {selectedRow && (
            <>
              <div>
                <h2 className="text-lg font-semibold">{selectedRow.key}</h2>
                <div className="text-xs text-muted-foreground space-y-1">
                  <p>NC File: {selectedRow.ncfile ?? "-"}</p>
                  <p>Machine: {selectedRow.machineName ?? (selectedRow.machineId != null ? `Machine #${selectedRow.machineId}` : "Unassigned")}</p>
                  <p>Finished: {formatDate(selectedRow.finishAt)} ({selectedRow.finishSource === "nestpick" ? "Nestpick completion" : "Cut completion"})</p>
                </div>
              </div>
              <div className="pt-2 border-t">
                {timelineLoading && <div className="text-sm text-muted-foreground">Loading timeline...</div>}
                {!timelineLoading && timelineItems.length === 0 && (
                  <div className="text-sm text-muted-foreground">No timeline events recorded.</div>
                )}
                {!timelineLoading && timelineItems.length > 0 && (
                  <ul className="space-y-3">
                    {timelineItems.map((item) => (
                      <li key={item.id} className="relative pl-5">
                        <span className="absolute left-0 top-2 h-2 w-2 rounded-full bg-primary" />
                        <div className="text-xs text-muted-foreground">{item.at ? formatDate(item.at) : "No timestamp"}</div>
                        <div className="text-sm font-medium">{item.label}</div>
                        {item.description && <div className="text-xs text-muted-foreground">{item.description}</div>}
                      </li>
                    ))}
                  </ul>
                )}
              </div>
            </>
          )}
        </div>
      </div>
    </div>
  );
}

================
File: packages/renderer/src/pages/JobsPage.tsx
================
import { useCallback, useEffect, useMemo, useState } from 'react';
import type { MouseEvent } from 'react';
import {
  getCoreRowModel,
  getSortedRowModel,
  useReactTable,
} from '@tanstack/react-table';
import type { ColumnDef, ColumnSizingState, RowSelectionState, SortingState } from '@tanstack/react-table';
import type {
  DiagnosticsSnapshot,
  JobEvent,
  JobRow,
  JobsFiltersRes,
  JobsListReq,
  JobStatus,
  Machine,
  MachineHealthEntry,
  MachineHealthCode
} from '../../../shared/src';
import { JOB_STATUS_VALUES } from '../../../shared/src';
import { cn } from '../utils/cn';
import { GlobalTable } from '@/components/table/GlobalTable';
import { Button } from '@/components/ui/button';
import {
  Filter,
  FilterX,
  Lock,
  Unlock,
  Plus,
  Eye,
  EyeOff,
  RefreshCw,
  PlayCircle
} from 'lucide-react';

const COLUMN_SIZING_KEY = 'jobs:columnSizing';
const AUTO_REFRESH_ENABLED_KEY = 'jobs:autoRefresh';
const AUTO_REFRESH_INTERVAL_KEY = 'jobs:autoRefreshInterval';
const DEFAULT_LIMIT = 200;
const HISTORY_LIMIT = 200;

type FiltersState = {
  statusQuick: NonNullable<JobsListReq['filter']['status']>;
  statuses: JobStatus[];
  materials: string[];
  machineId?: number;
};

type ContextMenuState = {
  position: { x: number; y: number };
  keys: string[];
};

const defaultFilters: FiltersState = {
  statusQuick: 'all',
  statuses: [],
  materials: [],
  machineId: undefined
};

function formatTimestamp(value: string) {
  const d = new Date(value);
  if (Number.isNaN(d.getTime())) return value;
  const months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'];
  const day = d.getDate();
  const mon = months[d.getMonth()];
  const year = d.getFullYear();
  let h = d.getHours();
  const m = String(d.getMinutes()).padStart(2, '0');
  const ampm = h >= 12 ? 'pm' : 'am';
  h = h % 12; if (h === 0) h = 12;
  return `${day} ${mon} ${year} ${h}:${m}${ampm}`;
}

function formatStatusLabel(value: string) {
  const upper = value.toUpperCase();
  if (upper === 'FORWARDED_TO_NESTPICK') return 'Nestpick Processing';
  const parts = value.split(/[_\s]+/).filter(Boolean).map((p) => p.toLowerCase());
  return parts.map((p) => p.charAt(0).toUpperCase() + p.slice(1)).join(' ');
}

function statusBadgeClass(status: JobStatus) {
  switch (status) {
    case 'CNC_FINISH':
    case 'FORWARDED_TO_NESTPICK':
    case 'NESTPICK_COMPLETE':
      return 'bg-green-100 text-green-800';
    case 'LABEL_FINISH':
    case 'LOAD_FINISH':
      return 'bg-amber-100 text-amber-800';
    case 'STAGED':
      return 'bg-blue-100 text-blue-800';
    case 'PENDING':
    default:
      return 'bg-accent text-accent-foreground';
  }
}

function loadColumnSizing(): ColumnSizingState {
  if (typeof window === 'undefined') return {};
  try {
    const raw = window.localStorage.getItem(COLUMN_SIZING_KEY);
    return raw ? (JSON.parse(raw) as ColumnSizingState) : {};
  } catch (err) {
    console.warn('Failed to load jobs column sizing', err);
    return {};
  }
}


export function JobsPage() {
  const [data, setData] = useState<JobRow[]>([]);
  const [machines, setMachines] = useState<Machine[]>([]);
  const [diagnostics, setDiagnostics] = useState<DiagnosticsSnapshot | null>(null);
  const [search, setSearch] = useState('');
  const [sorting, setSorting] = useState<SortingState>([{ id: 'dateadded', desc: true }]);
  const [filters, setFilters] = useState<FiltersState>({ ...defaultFilters });
  const [filterOptions, setFilterOptions] = useState<JobsFiltersRes['options']>({ materials: [], statuses: JOB_STATUS_VALUES });
  const [rowSelection, setRowSelection] = useState<RowSelectionState>({});
  const [columnSizing, setColumnSizing] = useState<ColumnSizingState>(loadColumnSizing);
  const [contextMenu, setContextMenu] = useState<ContextMenuState | null>(null);
  
  const [bulkMachine, setBulkMachine] = useState<number | ''>('');
  const [actionBusy, setActionBusy] = useState(false);
  const [loading, setLoading] = useState(false);
  const [autoRefreshEnabled, _setAutoRefreshEnabled] = useState(() => {
    if (typeof window === 'undefined') return false;
    return window.localStorage.getItem(AUTO_REFRESH_ENABLED_KEY) === 'true';
  });
  const [autoRefreshInterval, _setAutoRefreshInterval] = useState(() => {
    if (typeof window === 'undefined') return 30;
    const stored = Number(window.localStorage.getItem(AUTO_REFRESH_INTERVAL_KEY)) || 0;
    return stored >= 5 ? stored : 30;
  });
  const [listError, setListError] = useState<string | null>(null);
  const [historyEvents, setHistoryEvents] = useState<JobEvent[]>([]);
  const [historyLoading, setHistoryLoading] = useState(false);
  const [historyError, setHistoryError] = useState<string | null>(null);
  const [historyOpen, setHistoryOpen] = useState(true);

  useEffect(() => {
    if (typeof window === 'undefined') return;
    try {
      window.localStorage.setItem(COLUMN_SIZING_KEY, JSON.stringify(columnSizing));
    } catch (err) {
      console.warn('Failed to persist jobs column sizing', err);
    }
  }, [columnSizing]);

  useEffect(() => {
    if (typeof window === 'undefined') return;
    window.localStorage.setItem(AUTO_REFRESH_ENABLED_KEY, autoRefreshEnabled ? 'true' : 'false');
  }, [autoRefreshEnabled]);

  useEffect(() => {
    if (typeof window === 'undefined') return;
    window.localStorage.setItem(AUTO_REFRESH_INTERVAL_KEY, String(autoRefreshInterval));
  }, [autoRefreshInterval]);

  useEffect(() => {
    (async () => {
      try {
        const res = await window.api.machines.list();
        if (!res.ok) {
          console.error('Failed to load machines', res.error);
        } else {
          setMachines(res.value.items);
        }
      } catch (err) {
        console.error('Failed to load machines', err);
      }
    })();
  }, []);

  useEffect(() => {
    let cancelled = false;
    window.api.diagnostics
      .get()
      .then((res) => {
        if (cancelled) return;
        if (res.ok) setDiagnostics(res.value);
      })
      .catch(() => {});
    const unsubscribe = window.api.diagnostics.subscribe((snapshot) => {
      if (!cancelled) setDiagnostics(snapshot);
    });
    return () => {
      cancelled = true;
      unsubscribe?.();
    };
  }, []);

  useEffect(() => {
    (async () => {
      try {
        const res = await window.api.jobs.filters();
        if (!res.ok) {
          console.error('Failed to load job filter options', res.error);
        } else {
          setFilterOptions(res.value.options);
        }
      } catch (err) {
        console.error('Failed to load job filter options', err);
      }
    })();
  }, []);

  const refresh = useCallback(async (override?: { filters?: FiltersState; search?: string; sorting?: SortingState }) => {
    setLoading(true);
    try {
      const sortingState = override?.sorting ?? sorting;
      const primarySort = sortingState[0] ?? { id: 'dateadded', desc: true };
      const filterState = override?.filters ?? filters;
      const searchValue = override?.search ?? search;
      const filter: JobsListReq['filter'] = {
        status: filterState.statusQuick,
        machineId: filterState.machineId
      };
      if (filterState.statuses.length) {
        filter.statusIn = filterState.statuses as JobsListReq['filter']['statusIn'];
      }
      if (filterState.materials.length) {
        filter.materialIn = [...filterState.materials];
      }
      const res = await window.api.jobs.list({
        search: searchValue || undefined,
        sortBy: primarySort.id as JobsListReq['sortBy'],
        sortDir: (primarySort.desc ? 'desc' : 'asc') as JobsListReq['sortDir'],
        limit: DEFAULT_LIMIT,
        filter
      });
      if (!res.ok) {
        console.error('Failed to load jobs', res.error);
        setListError(res.error.message);
        setData([]);
      } else {
        setListError(null);
        setData(res.value.items);
      }
    } catch (err) {
      console.error('Failed to load jobs', err);
    } finally {
      setLoading(false);
    }
  }, [filters, search, sorting]);

  useEffect(() => { refresh(); }, [refresh]);

  useEffect(() => {
    if (!autoRefreshEnabled) return;
    const id = window.setInterval(() => {
      if (!loading) {
        refresh();
      }
    }, autoRefreshInterval * 1000);
    return () => window.clearInterval(id);
  }, [autoRefreshEnabled, autoRefreshInterval, loading, refresh]);

  useEffect(() => {
    setRowSelection((prev) => {
      if (!Object.keys(prev).length) return prev;
      const available = new Set(data.map((row) => row.key));
      const next: RowSelectionState = {};
      for (const key of Object.keys(prev)) {
        if (available.has(key)) next[key] = true;
      }
      return next;
    });
  }, [data]);

  useEffect(() => {
    if (!contextMenu) return;
    if (!contextMenu.keys?.some((key) => rowSelection[key])) {
      setContextMenu(null);
    }
  }, [contextMenu, rowSelection]);

  const machineNameById = useMemo(() => {
    const map = new Map<number, string>();
    for (const machine of machines) {
      map.set(machine.machineId, machine.name);
    }
    return map;
  }, [machines]);

  const machineIssuesById = useMemo(() => {
    const entries: MachineHealthEntry[] = diagnostics?.machineHealth ?? [];
    const byId = new Map<number | 'global', MachineHealthEntry[]>();
    for (const issue of entries) {
      const key = issue.machineId ?? 'global';
      const list = byId.get(key) ?? [];
      list.push(issue);
      byId.set(key, list);
    }
    return byId;
  }, [diagnostics]);

  function healthLabel(code: MachineHealthCode): string {
    switch (code) {
      case 'NO_PARTS_CSV':
        return 'Parts CSV missing';
      case 'NESTPICK_SHARE_UNREACHABLE':
        return 'Nestpick share unreachable';
      case 'COPY_FAILURE':
        return 'Copy failures';
    }
    return (code as string).replace(/_/g, ' ');
  }

  function severityDotClass(severity: MachineHealthEntry['severity']): string {
    switch (severity) {
      case 'critical':
        return 'bg-red-500';
      case 'warning':
        return 'bg-amber-500';
      default:
        return 'bg-muted-foreground';
    }
  }

  const jobByKey = useMemo(() => {
    const map = new Map<string, JobRow>();
    for (const job of data) {
      map.set(job.key, job);
    }
    return map;
  }, [data]);

  const formatFolderLabel = useCallback((value: string | null) => {
    if (!value) return '';
    const parts = value.split(/[\\/]/).filter(Boolean);
    return parts.length ? parts[parts.length - 1] : value;
  }, []);

  const columns = useMemo<ColumnDef<JobRow>[]>(() => [
    {
      accessorKey: 'folder',
      header: 'Folder',
      size: 220,
      minSize: 160,
      maxSize: 300,
      cell: ({ getValue }) => {
        const value = getValue<string | null>();
        return formatFolderLabel(value);
      }
    },
    {
      accessorKey: 'ncfile',
      header: 'NC File',
      size: 240,
      minSize: 180,
      maxSize: 350
    },
    {
      accessorKey: 'material',
      header: 'Material',
      size: 120,
      minSize: 100,
      maxSize: 180
    },
    {
      accessorKey: 'parts',
      header: 'Parts',
      size: 40,
      minSize: 40,
      maxSize: 100
    },
    {
      accessorKey: 'size',
      header: 'Size',
      size: 120,
      minSize: 100,
      maxSize: 160
    },
    {
      accessorKey: 'thickness',
      header: 'Thickness',
      size: 90,
      minSize: 80,
      maxSize: 120
    },
    {
      accessorKey: 'processingSeconds',
      header: 'Processing Time',
      size: 130,
      minSize: 110,
      maxSize: 160,
      enableSorting: false,
      cell: ({ getValue }) => {
        const seconds = getValue<number | null | undefined>();
        if (seconds == null || !Number.isFinite(seconds)) return '';
        const total = Math.max(0, Math.floor(seconds));
        const dd = Math.floor(total / 86400);
        const hh = Math.floor((total % 86400) / 3600);
        const mm = Math.floor((total % 3600) / 60);
        const ss = total % 60;
        if (dd > 0) return `${dd}d ${String(hh).padStart(2,'0')}:${String(mm).padStart(2,'0')}:${String(ss).padStart(2,'0')}`;
        if (hh > 0) return `${hh}:${String(mm).padStart(2,'0')}:${String(ss).padStart(2,'0')}`;
        return `${mm}:${String(ss).padStart(2,'0')}`;
      }
    },
    {
      accessorKey: 'dateadded',
      header: 'Date Added',
      size: 160,
      minSize: 140,
      maxSize: 200,
      cell: ({ getValue }) => {
        const value = getValue<string | null>();
        if (!value) return '';
        return formatTimestamp(value);
      }
    },
    {
      accessorKey: 'reserved',
      header: 'Reserved',
      size: 80,
      minSize: 70,
      maxSize: 100,
      cell: ({ getValue }) => (getValue<boolean>() ? 'Yes' : 'No')
    },
    {
      accessorKey: 'status',
      header: 'Status',
      size: 120,
      minSize: 100,
      maxSize: 180,
      cell: ({ getValue }) => {
        const raw = getValue<JobStatus | null>();
        if (!raw) return <span className="text-muted-foreground">-</span>;
        return (
          <span className={cn('inline-flex items-center rounded px-2 py-0.5 text-sm font-medium', statusBadgeClass(raw))}>
            {formatStatusLabel(raw)}
          </span>
        );
      }
    },
    {
      accessorKey: 'machineId',
      header: 'Machine',
      size: 150,
      minSize: 120,
      maxSize: 220,
      enableSorting: false,
      cell: ({ getValue }) => {
        const id = getValue<number | null>();
        if (id == null) return '';
        const name = machineNameById.get(id) ?? String(id);
        const issues: MachineHealthEntry[] = [
          ...(machineIssuesById.get(id) ?? []),
          ...(machineIssuesById.get('global') ?? [])
        ]
          .slice()
          .sort((a, b) => {
            const sev = (s: MachineHealthEntry['severity']) => (s === 'critical' ? 2 : s === 'warning' ? 1 : 0);
            const d = sev(b.severity) - sev(a.severity);
            if (d) return d;
            return b.lastUpdatedAt.localeCompare(a.lastUpdatedAt);
          });
        return (
          <div className="flex items-center gap-2">
            <span>{name}</span>
            {issues.length > 0 && (
              <div className="flex flex-wrap items-center gap-1">
                {issues.slice(0, 2).map((issue) => (
                  <span
                    key={issue.id}
                    className={cn(
                      'inline-flex items-center gap-1 rounded px-1.5 py-0.5 text-[10px] font-medium text-white',
                      issue.severity === 'critical'
                        ? 'bg-red-600'
                        : issue.severity === 'warning'
                        ? 'bg-amber-600'
                        : 'bg-muted-foreground'
                    )}
                    title={`${healthLabel(issue.code)} ? ${issue.message}`}
                  >
                    <span className={cn('h-1.5 w-1.5 rounded-full', severityDotClass(issue.severity))} />
                    <span>{healthLabel(issue.code)}</span>
                  </span>
                ))}
                {issues.length > 2 && (
                  <span className="text-[10px] text-muted-foreground">+{issues.length - 2} more</span>
                )}
              </div>
            )}
          </div>
        );
      }
    }
  ], [formatFolderLabel, machineNameById, machineIssuesById]);

  const table = useReactTable({
    data,
    columns,
    state: {
      sorting,
      rowSelection,
      columnSizing
    },
    getRowId: (row) => row.key,
    onSortingChange: setSorting,
    onRowSelectionChange: setRowSelection,
    onColumnSizingChange: setColumnSizing,
    columnResizeMode: 'onChange',
    enableRowSelection: true,
    enableColumnResizing: true,
    enableMultiSort: false,
    getCoreRowModel: getCoreRowModel(),
    getSortedRowModel: getSortedRowModel()
  });

  const selectedRows = table.getSelectedRowModel().rows;
  const selectedKeys = selectedRows.map((row) => row.original.key);
  const selectedCount = selectedKeys.length;
  const anyReserved = selectedRows.some((row) => row.original.reserved);
  const anyUnreserved = selectedRows.some((row) => !row.original.reserved);
  const allPendingForSelection =
    selectedRows.length > 0 && selectedRows.every((row) => row.original.status === 'PENDING');
  const historyKey = selectedKeys[0] ?? null;
  const canBulkReserve = anyUnreserved && allPendingForSelection;


  const performReserve = useCallback(
    async (targetKeys: string[], mode: 'reserve' | 'unreserve') => {
      if (!targetKeys.length) return;
      if (mode === 'reserve') {
        const blocked = targetKeys.filter((key) => {
          const job = jobByKey.get(key);
          if (!job) return true;
          return job.status !== 'PENDING';
        });
        if (blocked.length) {
          alert(
            'Only jobs in PENDING status can be reserved. Please deselect jobs that are not pending before reserving.'
          );
          setContextMenu(null);
          return;
        }
      }
      setActionBusy(true);
      try {
        const failures: string[] = [];
        for (const key of targetKeys) {
          const res = mode === 'reserve' ? await window.api.jobs.reserve(key) : await window.api.jobs.unreserve(key);
          if (!res.ok) {
            console.error(`Failed to ${mode} job`, key, res.error);
            failures.push(`${key}: ${res.error.message}`);
          }
        }
        if (failures.length) {
          alert(`Failed to ${mode} ${failures.length} job(s): ${failures.join(', ')}`);
        }
        await refresh();
        setRowSelection({});
      } finally {
        setActionBusy(false);
        setContextMenu(null);
      }
    },
    [jobByKey, refresh]
  );

  const performWorklist = useCallback(async (targetKeys: string[], machineId: number) => {
    if (!targetKeys.length) return;
    setActionBusy(true);
    try {
      const failures: string[] = [];
      let successCount = 0;
      for (const key of targetKeys) {
        const res = await window.api.jobs.addToWorklist(key, machineId);
        if (!res.ok) {
          console.error('Failed to add job to worklist', key, res.error);
          failures.push(`${key}: ${res.error.message}`);
        } else if (res.value.ok) {
          successCount += 1;
        } else {
          failures.push(`${key}: ${res.value.error}`);
        }
      }
      if (successCount) {
        alert(`Added ${successCount} job(s) to worklist.`);
      }
      if (failures.length) {
        alert(`Failed to add ${failures.length} job(s): ${failures.join(', ')}`);
      }
      await refresh();
      setRowSelection({});
      setBulkMachine('');
    } finally {
      setActionBusy(false);
      setContextMenu(null);
    }
  }, [refresh]);

  const loadHistory = useCallback(async (key: string) => {
    setHistoryLoading(true);
    setHistoryError(null);
    const res = await window.api.jobs.events({ key, limit: HISTORY_LIMIT });
    if (!res.ok) {
      console.error('Failed to load job events', res.error);
      setHistoryEvents([]);
      setHistoryError(res.error.message);
    } else {
      const events = Array.isArray(res.value.events) ? res.value.events : [];
      if (!Array.isArray(res.value.events)) {
        console.warn('jobs.events returned unexpected payload, defaulting to empty list', res.value);
      }
      setHistoryEvents(events);
    }
    setHistoryLoading(false);
  }, []);

  useEffect(() => {
    if (!historyKey) {
      setHistoryEvents([]);
      setHistoryError(null);
      return;
    }
    if (!historyOpen) return;
    loadHistory(historyKey);
  }, [historyKey, historyOpen, loadHistory]);

  useEffect(() => {
    if (historyKey) setHistoryOpen(true);
  }, [historyKey]);

  const refreshHistory = useCallback(() => {
    if (historyKey) loadHistory(historyKey);
  }, [historyKey, loadHistory]);

  const handleRowContextMenu = useCallback((event: MouseEvent<HTMLTableRowElement>, rowKey: string) => {
    event.preventDefault();
    const keys = Object.keys(rowSelection).length ? Object.keys(rowSelection) : [rowKey];
    setContextMenu({ position: { x: event.clientX, y: event.clientY }, keys });
  }, [rowSelection]);

  useEffect(() => {
    if (!contextMenu) return;
    const handleMouse = (event: globalThis.MouseEvent) => {
      if ((event.target as HTMLElement).closest('[data-context-menu]')) return;
      setContextMenu(null);
    };
    const handleKey = (event: KeyboardEvent) => {
      if (event.key === 'Escape') setContextMenu(null);
    };
    window.addEventListener('mousedown', handleMouse);
    window.addEventListener('contextmenu', handleMouse);
    window.addEventListener('keydown', handleKey);
    return () => {
      window.removeEventListener('mousedown', handleMouse);
      window.removeEventListener('contextmenu', handleMouse);
      window.removeEventListener('keydown', handleKey);
    };
  }, [contextMenu]);

  const statusOptions = filterOptions?.statuses?.length ? filterOptions.statuses : JOB_STATUS_VALUES;
  const materialOptions = filterOptions?.materials || [];

  return (
    <div className="space-y-4 w-full">
      <div className="flex items-center justify-between">
        <div>
          <p className="text-sm text-muted-foreground">{loading ? 'Refreshing?' : `${data.length} rows`}</p>
        </div>
        {listError && (
          <div className="border border-red-300 bg-red-50 text-red-700 text-sm px-3 py-2 rounded">{listError}</div>
        )}
      </div>

      <div className="flex flex-wrap gap-3 items-end">
        <label className="flex flex-col gap-1 text-sm">
          <span className="text-xs font-medium">Search</span>
          <input
            type="search"
            value={search}
            onChange={(e) => setSearch(e.target.value)}
            placeholder="Search all fields"
          />
        </label>
        <label className="flex flex-col gap-1 text-sm">
          <span className="text-xs font-medium">Quick Status</span>
          <select
            value={filters.statusQuick}
            onChange={(e) => setFilters((prev) => ({ ...prev, statusQuick: e.target.value as FiltersState['statusQuick'] }))}
            className="border rounded px-2 py-1"
          >
            <option value="all">All</option>
            <option value="cut">Cut</option>
            <option value="uncut">Uncut</option>
          </select>
        </label>
        <label className="flex flex-col gap-1 text-sm">
          <span className="text-xs font-medium">Status</span>
          <select
            value={filters.statuses[0] ?? ''}
            onChange={(e) => {
              const v = e.target.value as '' | JobStatus;
              setFilters((prev) => ({ ...prev, statuses: v ? [v] : [] }));
            }}
            className="border rounded px-2 py-1"
          >
            <option value="">Any</option>
            {statusOptions.map((status) => (
              <option key={status} value={status}>{formatStatusLabel(status)}</option>
            ))}
          </select>
        </label>
        <label className="flex flex-col gap-1 text-sm">
          <span className="text-xs font-medium">Material</span>
          <select
            value={filters.materials[0] ?? ''}
            onChange={(e) => {
              const v = e.target.value;
              setFilters((prev) => ({ ...prev, materials: v ? [v] : [] }));
            }}
            className="border rounded px-2 py-1"
          >
            <option value="">Any</option>
            {materialOptions.map((material) => (
              <option key={material} value={material}>{material}</option>
            ))}
          </select>
        </label>
        <label className="flex flex-col gap-1 text-sm">
          <span className="text-xs font-medium">Machine</span>
          <select
            value={filters.machineId != null ? String(filters.machineId) : ''}
            onChange={(e) => setFilters((prev) => ({ ...prev, machineId: e.target.value ? Number(e.target.value) : undefined }))}
            className="border rounded px-2 py-1"
          >
            <option value="">Any</option>
            {machines.map((machine) => (
              <option key={machine.machineId} value={machine.machineId}>{machine.name}</option>
            ))}
          </select>
        </label>
        <div className="flex gap-2">
          <Button
            variant="default"
            size="sm"
            onClick={() => refresh()}
            disabled={loading}
          >
            <Filter />
            Apply
          </Button>
          <Button
            variant="outline"
            size="sm"
            onClick={() => {
              const reset = { ...defaultFilters };
              setSearch('');
              setFilters(reset);
              setRowSelection({});
              setContextMenu(null);
              setBulkMachine('');
              refresh({ filters: reset, search: '' });
            }}
            disabled={loading}
          >
            <FilterX />
            Reset
          </Button>
        </div>
      </div>

      {selectedCount > 0 && (
        <div className="flex flex-wrap items-center gap-3 border rounded px-3 py-2 bg-muted/40">
          <span className="text-sm font-medium">{selectedCount} selected</span>
          <Button
            variant="outline"
            size="sm"
            onClick={() => performReserve(selectedKeys, 'reserve')}
            disabled={actionBusy || !canBulkReserve}
          >
            <Lock />
            Reserve
          </Button>
          <Button
            variant="outline"
            size="sm"
            onClick={() => performReserve(selectedKeys, 'unreserve')}
            disabled={actionBusy || !anyReserved}
          >
            <Unlock />
            Unreserve
          </Button>
          <div className="flex items-center gap-2">
            <select
              value={bulkMachine === '' ? '' : String(bulkMachine)}
              onChange={(e) => setBulkMachine(e.target.value ? Number(e.target.value) : '')}
              className="border rounded px-2 py-1 text-sm"
            >
              <option value="">Select machine</option>
              {machines.map((machine) => (
                <option key={machine.machineId} value={machine.machineId}>{machine.name}</option>
              ))}
            </select>
            <Button
              variant="default"
              size="sm"
              onClick={() => {
                if (typeof bulkMachine === 'number') {
                  performWorklist(selectedKeys, bulkMachine);
                }
              }}
              disabled={actionBusy || typeof bulkMachine !== 'number'}
            >
              <Plus />
              Add to Worklist
            </Button>
          </div>
        </div>
      )}

      <GlobalTable
        table={table}
        onRowContextMenu={(row, event) => handleRowContextMenu(event, row.original.key)}
      />

      {historyKey && historyOpen && (
        <div className="border rounded bg-card text-card-foreground p-3 space-y-2">
          <div className="flex items-center justify-between">
            <div>
              <h2 className="text-sm font-semibold">History ? {historyKey}</h2>
              <p className="text-xs text-muted-foreground">
                {historyLoading ? 'Loading?' : historyError ? historyError : `${historyEvents?.length || 0} event(s)`}
              </p>
            </div>
            <div className="flex gap-2">
              <Button variant="outline" size="sm" onClick={refreshHistory} disabled={historyLoading}>
                <RefreshCw />
                Refresh
              </Button>
              <Button variant="outline" size="sm" onClick={() => setHistoryOpen(false)}>
                <EyeOff />
                Hide
              </Button>
            </div>
          </div>
          <div className="max-h-60 overflow-auto border border-[var(--table-border)] rounded bg-table">
            <table className="w-full text-xs text-[var(--table-text)] table-text">
              <thead className="bg-[var(--table-header-bg)] text-[var(--table-text)] sticky top-0 z-10">
                <tr className="border-b-0">
                  <th className="text-left px-2 py-1 font-medium">Time</th>
                  <th className="text-left px-2 py-1 font-medium">Event</th>
                  <th className="text-left px-2 py-1 font-medium">Machine</th>
                  <th className="text-left px-2 py-1 font-medium">Details</th>
                </tr>
              </thead>
              <tbody>
                {historyEvents.map((event) => (
                  <tr key={event.id} className="border-b border-[var(--table-row-border)]">
                    <td className="px-2 py-1 whitespace-nowrap">{formatTimestamp(event.createdAt)}</td>
                    <td className="px-2 py-1 font-mono text-[11px]">{event.eventType}</td>
                    <td className="px-2 py-1">{event.machineId != null ? machineNameById.get(event.machineId) ?? event.machineId : ''}</td>
                    <td className="px-2 py-1">
                      <pre className="whitespace-pre-wrap text-[11px]">{event.payload != null ? JSON.stringify(event.payload, null, 2) : ''}</pre>
                    </td>
                  </tr>
                ))}
                {!(historyEvents?.length) && !historyLoading && !historyError && (
                  <tr>
                    <td colSpan={4} className="px-2 py-3 text-center text-muted-foreground">No history events.</td>
                  </tr>
                )}
              </tbody>
            </table>
          </div>
        </div>
      )}

      {historyKey && !historyOpen && (
        <div className="text-xs text-muted-foreground">
          History hidden ? <Button variant="link" size="sm" onClick={() => setHistoryOpen(true)}>
            <Eye />
            show for {historyKey}
          </Button>
        </div>
      )}

      {contextMenu && (
        <div className="fixed inset-0 z-30" onClick={() => setContextMenu(null)}>
          <div
            data-context-menu
            className="absolute min-w-[220px] rounded border bg-background shadow-lg p-2 space-y-2"
            style={{
              top: Math.min(contextMenu.position.y, window.innerHeight - 220),
              left: Math.min(contextMenu.position.x, window.innerWidth - 240)
            }}
            onClick={(event) => event.stopPropagation()}
          >
            <div className="text-xs text-muted-foreground">{contextMenu.keys?.length || 0} job(s) selected</div>
            <div className="border-t pt-2">
              <div className="text-xs uppercase text-muted-foreground mb-1">Add to Worklist</div>
              <div className="max-h-64 overflow-auto">
                {machines.map((machine) => (
                  <Button
                    key={machine.machineId}
                    variant="ghost"
                    size="sm"
                    className="w-full justify-start"
                    disabled={actionBusy}
                    onClick={() => performWorklist(contextMenu.keys || [], machine.machineId)}
                  >
                    <PlayCircle />
                    {machine.name}
                  </Button>
                ))}
              </div>
            </div>
          </div>
        </div>
      )}
    </div>
  );
}

================
File: packages/renderer/src/pages/MachinesPage.tsx
================
import { useEffect, useMemo, useState } from 'react';
import type {
  DiagnosticsSnapshot,
  Machine,
  MachineHealthEntry,
  MachineHealthCode,
  SaveMachineReq
} from '../../../shared/src';
import { cn } from '../utils/cn';
import { Table, TableBody, TableCell, TableHead, TableHeader, TableRow } from '@/components/ui/table';

export function MachinesPage() {
  const [items, setItems] = useState<Machine[]>([]);
  const [editing, setEditing] = useState<Machine | null>(null);
  const [diagnostics, setDiagnostics] = useState<DiagnosticsSnapshot | null>(null);

  async function load() {
    const res = await window.api.machines.list();
    if (!res.ok) {
      alert(`Failed to load machines: ${res.error.message}`);
      setItems([]);
      return;
    }
    setItems(res.value.items);
  }
  useEffect(() => { load(); }, []);

  useEffect(() => {
    let cancelled = false;
    window.api.diagnostics
      .get()
      .then((res) => {
        if (cancelled) return;
        if (res.ok) setDiagnostics(res.value);
      })
      .catch(() => {});
    const unsubscribe = window.api.diagnostics.subscribe((snapshot) => {
      if (!cancelled) setDiagnostics(snapshot);
    });
    return () => {
      cancelled = true;
      unsubscribe?.();
    };
  }, []);

  const machineIssuesById = useMemo(() => {
    const entries: MachineHealthEntry[] = diagnostics?.machineHealth ?? [];
    const byId = new Map<number | 'global', MachineHealthEntry[]>();
    for (const issue of entries) {
      const key = issue.machineId ?? 'global';
      const list = byId.get(key) ?? [];
      list.push(issue);
      byId.set(key, list);
    }
    return byId;
  }, [diagnostics]);

  function healthLabel(code: MachineHealthCode): string {
    switch (code) {
      case 'NO_PARTS_CSV':
        return 'Parts CSV missing';
      case 'NESTPICK_SHARE_UNREACHABLE':
        return 'Nestpick share unreachable';
      case 'COPY_FAILURE':
        return 'Copy failures';
    }
    return (code as string).replace(/_/g, ' ');
  }

  function severityDotClass(severity: MachineHealthEntry['severity']): string {
    switch (severity) {
      case 'critical':
        return 'bg-red-500';
      case 'warning':
        return 'bg-amber-500';
      default:
        return 'bg-muted-foreground';
    }
  }

  const onSave = async () => {
    if (!editing) return;
    const req: SaveMachineReq = {
      machineId: editing.machineId,
      name: editing.name,
      pcIp: editing.pcIp ?? undefined,
      cncIp: editing.cncIp ?? undefined,
      cncPort: editing.cncPort ?? undefined,
      apJobfolder: editing.apJobfolder,
      nestpickFolder: editing.nestpickFolder,
      nestpickEnabled: editing.nestpickEnabled,
      pcPort: editing.pcPort
    };
    const res = await window.api.machines.save(req);
    if (!res.ok) {
      alert(`Failed to save machine: ${res.error.message}`);
      return;
    }
    setEditing(null);
    await load();
  };

  return (
    <div className="space-y-4 w-full">
      <h1 className="text-xl font-semibold">Machines</h1>
      <div className="border rounded bg-table text-[var(--table-text)]">
        <Table>
          <TableHeader>
            <TableRow>
              <TableHead className="px-2 py-2">ID</TableHead>
              <TableHead className="px-2 py-2">Name</TableHead>
              <TableHead className="px-2 py-2">Health</TableHead>
              <TableHead className="px-2 py-2">PC IP</TableHead>
              <TableHead className="px-2 py-2">CNC IP</TableHead>
              <TableHead className="px-2 py-2">AP Job Folder</TableHead>
              <TableHead className="px-2 py-2">Nestpick Folder</TableHead>
              <TableHead className="px-2 py-2">Enabled</TableHead>
              <TableHead className="px-2 py-2"></TableHead>
            </TableRow>
          </TableHeader>
          <TableBody>
            {items.map(m => {
              const issues: MachineHealthEntry[] = [
                ...(machineIssuesById.get(m.machineId) ?? []),
                ...(machineIssuesById.get('global') ?? [])
              ]
                .slice()
                .sort((a, b) => {
                  const sev = (s: MachineHealthEntry['severity']) => (s === 'critical' ? 2 : s === 'warning' ? 1 : 0);
                  const d = sev(b.severity) - sev(a.severity);
                  if (d) return d;
                  return b.lastUpdatedAt.localeCompare(a.lastUpdatedAt);
                });
              return (
                <TableRow key={m.machineId}>
                  <TableCell className="px-2 py-1">{m.machineId}</TableCell>
                  <TableCell className="px-2 py-1">{m.name}</TableCell>
                  <TableCell className="px-2 py-1">
                    {issues.length === 0 ? (
                      <span className="text-xs text-muted-foreground">—</span>
                    ) : (
                      <div className="flex flex-wrap items-center gap-1">
                        {issues.slice(0, 3).map((issue) => (
                          <span
                            key={issue.id}
                            className={cn(
                              'inline-flex items-center gap-1 rounded px-1.5 py-0.5 text-[10px] font-medium text-white',
                              issue.severity === 'critical'
                                ? 'bg-red-600'
                                : issue.severity === 'warning'
                                ? 'bg-amber-600'
                                : 'bg-muted-foreground'
                            )}
                            title={`${healthLabel(issue.code)} — ${issue.message}`}
                          >
                            <span className={cn('h-1.5 w-1.5 rounded-full', severityDotClass(issue.severity))} />
                            <span>{healthLabel(issue.code)}</span>
                          </span>
                        ))}
                        {issues.length > 3 && (
                          <span className="text-[10px] text-muted-foreground">+{issues.length - 3} more</span>
                        )}
                      </div>
                    )}
                  </TableCell>
                  <TableCell className="px-2 py-1">{m.pcIp ?? '—'}</TableCell>
                  <TableCell className="px-2 py-1">{m.cncIp ?? '—'}</TableCell>
                  <TableCell className="px-2 py-1">{m.apJobfolder}</TableCell>
                  <TableCell className="px-2 py-1">{m.nestpickFolder}</TableCell>
                  <TableCell className="px-2 py-1">{m.nestpickEnabled ? 'Yes' : 'No'}</TableCell>
                  <TableCell className="px-2 py-1"><button className="border rounded px-2 py-0.5" onClick={()=>setEditing(m)}>Edit</button></TableCell>
                </TableRow>
              );
            })}
          </TableBody>
        </Table>
      </div>

      {editing && (
        <div className="border rounded bg-card text-card-foreground p-3 space-y-2">
          <div className="font-medium">Edit Machine {editing.machineId}</div>
          <div className="grid grid-cols-2 gap-2">
            <label className="text-sm">Name<input className="border rounded w-full px-2 py-1" value={editing.name} onChange={e=>setEditing({...editing, name: e.target.value})} /></label>
            <label className="text-sm">PC IP<input className="border rounded w-full px-2 py-1" value={editing.pcIp ?? ''} onChange={e=>setEditing({...editing, pcIp: e.target.value})} /></label>
            <label className="text-sm">CNC IP<input className="border rounded w-full px-2 py-1" value={editing.cncIp ?? ''} onChange={e=>setEditing({...editing, cncIp: e.target.value})} /></label>
            <label className="text-sm">CNC Port<input className="border rounded w-full px-2 py-1" type="number" value={editing.cncPort ?? 0} onChange={e=>setEditing({...editing, cncPort: Number(e.target.value)})} /></label>
            <label className="text-sm">AP Job Folder<div className="flex gap-2"><input className="border rounded w-full px-2 py-1" value={editing.apJobfolder} onChange={e=>setEditing({...editing, apJobfolder: e.target.value})} /><button className="border rounded px-2" onClick={async()=>{ const picked = await window.api.dialog.pickFolder(); if (picked.ok && picked.value) setEditing({...editing, apJobfolder: picked.value}); }}>Browse</button></div></label>
            <label className="text-sm">Nestpick Folder<div className="flex gap-2"><input className="border rounded w-full px-2 py-1" value={editing.nestpickFolder} onChange={e=>setEditing({...editing, nestpickFolder: e.target.value})} /><button className="border rounded px-2" onClick={async()=>{ const picked = await window.api.dialog.pickFolder(); if (picked.ok && picked.value) setEditing({...editing, nestpickFolder: picked.value}); }}>Browse</button></div></label>
            <label className="text-sm">Enabled<select className="border rounded w-full px-2 py-1" value={editing.nestpickEnabled ? 'true':'false'} onChange={e=>setEditing({...editing, nestpickEnabled: e.target.value==='true'})}><option value="true">Yes</option><option value="false">No</option></select></label>
            <label className="text-sm">PC Port<input className="border rounded w-full px-2 py-1" type="number" value={editing.pcPort} onChange={e=>setEditing({...editing, pcPort: Number(e.target.value)})} /></label>
          </div>
          <div className="flex gap-2">
            <button className="border rounded px-3 py-1" onClick={onSave}>Save</button>
            <button className="border rounded px-3 py-1" onClick={()=>setEditing(null)}>Cancel</button>
          </div>
        </div>
      )}
    </div>
  );
}

================
File: packages/renderer/src/pages/ReadyPage.tsx
================
import { useCallback, useEffect, useMemo, useState } from 'react';
import type {
  DiagnosticsSnapshot,
  JobStatus,
  Machine,
  MachineHealthEntry,
  MachineHealthCode,
  ReadyFile
} from '../../../shared/src';
import { cn } from '../utils/cn';
import { Table, TableBody, TableCell, TableHead, TableHeader, TableRow } from '@/components/ui/table';

function formatDateTime(value: string | number | null | undefined) {
  if (value == null) return '-';
  const d = typeof value === 'number' ? new Date(value) : new Date(value);
  if (Number.isNaN(d.getTime())) return '-';
  const months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'];
  const day = d.getDate();
  const mon = months[d.getMonth()];
  const year = d.getFullYear();
  let h = d.getHours();
  const m = String(d.getMinutes()).padStart(2, '0');
  const ampm = h >= 12 ? 'pm' : 'am';
  h = h % 12; if (h === 0) h = 12;
  return `${day} ${mon} ${year} ${h}:${m}${ampm}`;
}

function statusLabel(status: JobStatus | null) {
  if (!status) return 'Not in DB';
  const upper = status.toUpperCase();
  if (upper === 'FORWARDED_TO_NESTPICK') return 'Nestpick Processing';
  const parts = status.split(/[_\s]+/).filter(Boolean).map((p) => p.toLowerCase());
  return parts.map((p) => p.charAt(0).toUpperCase() + p.slice(1)).join(' ');
}

export function ReadyPage() {
  const [machines, setMachines] = useState<Machine[]>([]);
  const [selected, setSelected] = useState<number | null>(null);
  const [files, setFiles] = useState<ReadyFile[]>([]);
  const [importing, setImporting] = useState<string | null>(null);
  const [feedback, setFeedback] = useState<{ type: 'success' | 'error'; message: string } | null>(null);
  const [diagnostics, setDiagnostics] = useState<DiagnosticsSnapshot | null>(null);

  const missingCount = useMemo(() => files.filter((file) => !file.inDatabase).length, [files]);

  const loadMachines = useCallback(async () => {
    const res = await window.api.machines.list();
    if (!res.ok) {
      alert('Failed to load machines: ' + res.error.message);
      setMachines([]);
      return;
    }
    const items = res.value.items;
    setMachines(items);
    if (items.length && selected == null) {
      setSelected(items[0].machineId);
    }
  }, [selected]);

  useEffect(() => {
    void loadMachines();
  }, [loadMachines]);

  const loadFiles = useCallback(async () => {
    if (selected == null) return;
    const res = await window.api.files.listReady(selected);
    if (!res.ok) {
      alert('Failed to load files: ' + res.error.message);
      setFiles([]);
      return;
    }
    setFiles(res.value.files);
  }, [selected]);

  useEffect(() => {
    void loadFiles();
  }, [loadFiles]);

  useEffect(() => {
    let cancelled = false;
    window.api.diagnostics
      .get()
      .then((res) => {
        if (cancelled) return;
        if (res.ok) setDiagnostics(res.value);
      })
      .catch(() => {});
    const unsubscribe = window.api.diagnostics.subscribe((snapshot) => {
      if (!cancelled) setDiagnostics(snapshot);
    });
    return () => {
      cancelled = true;
      unsubscribe?.();
    };
  }, []);

  const machineIssuesById = useMemo(() => {
    const entries: MachineHealthEntry[] = diagnostics?.machineHealth ?? [];
    const byId = new Map<number | 'global', MachineHealthEntry[]>();
    for (const issue of entries) {
      const key = issue.machineId ?? 'global';
      const list = byId.get(key) ?? [];
      list.push(issue);
      byId.set(key, list);
    }
    return byId;
  }, [diagnostics]);

  function healthLabel(code: MachineHealthCode): string {
    switch (code) {
      case 'NO_PARTS_CSV':
        return 'Parts CSV missing';
      case 'NESTPICK_SHARE_UNREACHABLE':
        return 'Nestpick share unreachable';
      case 'COPY_FAILURE':
        return 'Copy failures';
    }
    return (code as string).replace(/_/g, ' ');
  }

  function severityDotClass(severity: MachineHealthEntry['severity']): string {
    switch (severity) {
      case 'critical':
        return 'bg-red-500';
      case 'warning':
        return 'bg-amber-500';
      default:
        return 'bg-muted-foreground';
    }
  }

  const handleImport = useCallback(
    async (file: ReadyFile) => {
      if (selected == null) return;
      setFeedback(null);
      setImporting(file.relativePath);
      try {
        const res = await window.api.files.importReady({ machineId: selected, relativePath: file.relativePath });
        if (!res.ok) {
          setFeedback({ type: 'error', message: 'Import failed: ' + res.error.message });
          return;
        }
        const { jobKey, created } = res.value;
        setFeedback({
          type: 'success',
          message: (created ? 'Created job ' : 'Updated job ') + jobKey
        });
        await loadFiles();
      } catch (error) {
        const message = error instanceof Error ? error.message : String(error);
        setFeedback({ type: 'error', message: 'Import failed: ' + message });
      } finally {
        setImporting(null);
      }
    },
    [selected, loadFiles]
  );

  return (
    <div className="grid h-full grid-cols-[280px_1fr] gap-4 w-full">
      <div className="overflow-auto rounded border bg-table text-[var(--table-text)] p-2">
        <div className="mb-2 font-medium">Machines</div>
        <ul className="space-y-1">
          {machines.map((machine) => {
            const issues: MachineHealthEntry[] = [
              ...(machineIssuesById.get(machine.machineId) ?? []),
              ...(machineIssuesById.get('global') ?? [])
            ];
            // Sort by severity (critical -> warning -> info) then recent first
            issues.sort((a, b) => {
              const sev = (s: MachineHealthEntry['severity']) => (s === 'critical' ? 2 : s === 'warning' ? 1 : 0);
              const d = sev(b.severity) - sev(a.severity);
              if (d) return d;
              return b.lastUpdatedAt.localeCompare(a.lastUpdatedAt);
            });
            return (
              <li key={machine.machineId}>
                <button
                  className={cn(
                    'w-full rounded px-2 py-1 text-left',
                    selected === machine.machineId && 'bg-accent'
                  )}
                  onClick={() => setSelected(machine.machineId)}
                >
                  <div className="flex items-center justify-between gap-2">
                    <span>{machine.name}</span>
                    {issues.length > 0 && (
                      <div className="flex flex-wrap items-center gap-1">
                        {issues.slice(0, 3).map((issue) => (
                          <span
                            key={issue.id}
                            className={cn(
                              'inline-flex items-center gap-1 rounded px-1.5 py-0.5 text-[10px] font-medium text-white',
                              issue.severity === 'critical'
                                ? 'bg-red-600'
                                : issue.severity === 'warning'
                                ? 'bg-amber-600'
                                : 'bg-muted-foreground'
                            )}
                            title={`${healthLabel(issue.code)} — ${issue.message}`}
                          >
                            <span className={cn('h-1.5 w-1.5 rounded-full', severityDotClass(issue.severity))} />
                            <span>{healthLabel(issue.code)}</span>
                          </span>
                        ))}
                        {issues.length > 3 && (
                          <span className="text-[10px] text-muted-foreground">+{issues.length - 3} more</span>
                        )}
                      </div>
                    )}
                  </div>
                </button>
              </li>
            );
          })}
        </ul>
      </div>
      <div className="overflow-auto rounded border bg-table text-[var(--table-text)] p-2">
        <div className="mb-3 flex items-center justify-between">
          <div>
            <div className="font-medium">Ready-To-Run Files (.nc)</div>
            <div className="text-xs text-muted-foreground">
              {files.length} item{files.length === 1 ? '' : 's'} - {missingCount} not in database
            </div>
            {feedback && (
              <div
                className={cn(
                  'mt-1 text-xs',
                  feedback.type === 'success' ? 'text-emerald-600' : 'text-red-600'
                )}
              >
                {feedback.message}
              </div>
            )}
          </div>
          <div className="flex gap-2">
            <button className="rounded border px-2 py-1" onClick={() => void loadFiles()}>
              Refresh
            </button>
            <a className="rounded border px-2 py-1" href="#/settings/machines">
              Edit Folders
            </a>
          </div>
        </div>
        <div className="overflow-auto">
          <Table>
            <TableHeader>
              <TableRow>
                <TableHead className="px-2 py-1">Relative Path</TableHead>
                <TableHead className="px-2 py-1">Material</TableHead>
                <TableHead className="px-2 py-1">Size</TableHead>
                <TableHead className="px-2 py-1">Parts</TableHead>
                <TableHead className="px-2 py-1">Thickness</TableHead>
                <TableHead className="px-2 py-1">Date Added (R2R)</TableHead>
                <TableHead className="px-2 py-1">Status</TableHead>
                <TableHead className="px-2 py-1">Actions</TableHead>
              </TableRow>
            </TableHeader>
            <TableBody>
              {files.map((file) => (
                <TableRow
                  key={file.relativePath}
                  className={cn('border-t', !file.inDatabase && 'bg-red-50 text-red-700')}
                >
                  <TableCell className="px-2 py-1 font-mono text-xs">{file.relativePath}</TableCell>
                  <TableCell className="px-2 py-1">{file.jobMaterial ?? '-'}</TableCell>
                  <TableCell className="px-2 py-1">{file.jobSize ?? '-'}</TableCell>
                  <TableCell className="px-2 py-1">{file.jobParts ?? '-'}</TableCell>
                  <TableCell className="px-2 py-1">{file.jobThickness ?? '-'}</TableCell>
                  <TableCell className="px-2 py-1">{formatDateTime(file.addedAtR2R ?? file.mtimeMs)}</TableCell>
                  <TableCell className="px-2 py-1">
                    <span
                      className={cn(
                        'inline-flex items-center rounded px-2 py-0.5 text-xs font-medium',
                        !file.inDatabase ? 'bg-red-100 text-red-800' : 'bg-accent text-accent-foreground'
                      )}
                    >
                      {statusLabel(file.status)}
                    </span>
                  </TableCell>
                  <TableCell className="px-2 py-1">
                    {file.inDatabase ? (
                      <span className="text-xs text-muted-foreground">In database</span>
                    ) : (
                      <button
                        className="rounded border px-2 py-1 text-xs"
                        onClick={() => handleImport(file)}
                        disabled={importing === file.relativePath || selected == null}
                      >
                        {importing === file.relativePath ? 'Importing...' : 'Import'}
                      </button>
                    )}
                  </TableCell>
                </TableRow>
              ))}
              {!files.length && (
                <TableRow>
                  <TableCell className="px-2 py-4 text-center text-sm text-muted-foreground" colSpan={7}>
                    No files found.
                  </TableCell>
                </TableRow>
              )}
            </TableBody>
          </Table>
        </div>
      </div>
    </div>
  );
}

================
File: packages/renderer/src/pages/RouterPage.tsx
================
import { useCallback, useEffect, useMemo, useState } from 'react';
import type {
  DiagnosticsSnapshot,
  Machine,
  JobStatus,
  ReadyFile,
  ReadyListRes
} from '../../../shared/src';
import { JOB_STATUS_VALUES } from '../../../shared/src';
import { cn } from '../utils/cn';
import { GlobalTable } from '@/components/table/GlobalTable';
import type { ColumnDef, RowSelectionState } from '@tanstack/react-table';
import { getCoreRowModel, useReactTable } from '@tanstack/react-table';

const AUTO_REFRESH_ENABLED_KEY = 'router:autoRefresh';
const AUTO_REFRESH_INTERVAL_KEY = 'router:autoRefreshInterval';
const DEFAULT_AUTO_REFRESH_SECONDS = 30;

type RouterReadyFile = ReadyFile & { machineId: number };

function formatIso(value: string | null) {
  if (!value) return '';
  const d = new Date(value);
  if (Number.isNaN(d.getTime())) return '';
  const months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'];
  const day = d.getDate();
  const mon = months[d.getMonth()];
  const year = d.getFullYear();
  let h = d.getHours();
  const m = String(d.getMinutes()).padStart(2, '0');
  const ampm = h >= 12 ? 'pm' : 'am';
  h = h % 12;
  if (h === 0) h = 12;
  return `${day} ${mon} ${year} ${h}:${m}${ampm}`;
}

function formatStatusLabel(value: string) {
  const upper = value.toUpperCase();
  if (upper === 'FORWARDED_TO_NESTPICK') return 'Nestpick Processing';
  const parts = value.split(/[_\s]+/).filter(Boolean).map((p) => p.toLowerCase());
  return parts.map((p) => p.charAt(0).toUpperCase() + p.slice(1)).join(' ');
}

  function statusClass(status: JobStatus) {
    switch (status) {
      case 'CNC_FINISH':
      case 'FORWARDED_TO_NESTPICK':
      case 'NESTPICK_COMPLETE':
        return 'bg-green-100 text-green-800';
      case 'LABEL_FINISH':
      case 'LOAD_FINISH':
        return 'bg-amber-100 text-amber-800';
      case 'STAGED':
        return 'bg-blue-100 text-blue-800';
      default:
        return 'bg-accent text-accent-foreground';
    }
  }

export function RouterPage() {
  const [files, setFiles] = useState<RouterReadyFile[]>([]);
  const [machines, setMachines] = useState<Machine[]>([]);
  const [_diagnostics, setDiagnostics] = useState<DiagnosticsSnapshot | null>(null);
  const [machineFilter, setMachineFilter] = useState<'all' | number>('all');
  const [statusFilter, setStatusFilter] = useState<'all' | JobStatus>('all');
  const [loading, setLoading] = useState(false);
  const [banner, setBanner] = useState<{ type: 'success' | 'error'; message: string } | null>(null);
  const [autoRefreshEnabled, setAutoRefreshEnabled] = useState(() => {
    if (typeof window === 'undefined') return false;
    return window.localStorage.getItem(AUTO_REFRESH_ENABLED_KEY) === 'true';
  });
  const [autoRefreshInterval, setAutoRefreshInterval] = useState(() => {
    if (typeof window === 'undefined') return DEFAULT_AUTO_REFRESH_SECONDS;
    const stored = Number(window.localStorage.getItem(AUTO_REFRESH_INTERVAL_KEY)) || 0;
    return stored >= 5 ? stored : DEFAULT_AUTO_REFRESH_SECONDS;
  });
  const [rowSelection, setRowSelection] = useState<RowSelectionState>({});
  const [deleting, setDeleting] = useState(false);
  const [clearedByMachine, setClearedByMachine] = useState<Map<number, Map<string, number>>>(() => new Map());

  const applyClearedFilter = useCallback(
    (items: ReadyFile[], machineId: number): ReadyFile[] => {
      const cleared = clearedByMachine.get(machineId);
      if (!cleared?.size) return items;
      return items.filter((item) => {
        if (item.status !== 'NESTPICK_COMPLETE') return true;
        const clearedMtime = cleared.get(item.relativePath);
        return clearedMtime === undefined || clearedMtime !== item.mtimeMs;
      });
    },
    [clearedByMachine]
  );

  const hasClearable = useMemo(() => {
    if (!files.length) return false;
    if (machineFilter === 'all') {
      return files.some((file) => file.status === 'NESTPICK_COMPLETE');
    }
    return files.some((file) => file.status === 'NESTPICK_COMPLETE' && file.machineId === machineFilter);
  }, [files, machineFilter]);

  useEffect(() => {
    if (typeof window === 'undefined') return;
    try {
      window.localStorage.setItem(AUTO_REFRESH_ENABLED_KEY, autoRefreshEnabled ? 'true' : 'false');
    } catch (err) {
      console.warn('Failed to persist router auto refresh toggle', err);
    }
  }, [autoRefreshEnabled]);

  useEffect(() => {
    if (typeof window === 'undefined') return;
    try {
      window.localStorage.setItem(AUTO_REFRESH_INTERVAL_KEY, String(autoRefreshInterval));
    } catch (err) {
      console.warn('Failed to persist router auto refresh interval', err);
    }
  }, [autoRefreshInterval]);

  // Removed unused helpers (machine map / issues, health labeling)

  const loadMachines = useCallback(async () => {
    const res = await window.api.machines.list();
    if (!res.ok) {
      alert(`Failed to load machines: ${res.error.message}`);
      setMachines([]);
      return;
    }
    setMachines(res.value.items);
  }, []);
  useEffect(() => { loadMachines(); }, [loadMachines]);

  useEffect(() => {
    let cancelled = false;
    window.api.diagnostics
      .get()
      .then((res) => {
        if (cancelled) return;
        if (res.ok) setDiagnostics(res.value);
      })
      .catch(() => {});
    const unsubscribe = window.api.diagnostics.subscribe((snapshot) => {
      if (!cancelled) setDiagnostics(snapshot);
    });
    return () => {
      cancelled = true;
      unsubscribe?.();
    };
  }, []);

  // Watch Ready-To-Run folder(s) and update file list
  // Removed unused startSubscription helper

  useEffect(() => {
    const unsubs: Array<() => void> = [];
    const byMachine = new Map<number, RouterReadyFile[]>();

    const emit = () => {
      const merged: RouterReadyFile[] = [];
      for (const list of byMachine.values()) merged.push(...list);
      setFiles(merged);
    };

    const subOne = (mid: number) => {
      const unsub = window.api.files.subscribeReady(mid, (payload: ReadyListRes) => {
        if (payload.machineId !== mid) return;
        let items = payload.files as ReadyFile[];
        if (statusFilter !== 'all') {
          items = items.filter((f) => f.status === statusFilter);
        }
        items = applyClearedFilter(items, mid);
        const enriched = items.map((item) => ({ ...item, machineId: mid }));
        byMachine.set(mid, enriched);
        emit();
      });
      unsubs.push(unsub);
    };

    if (machineFilter === 'all') {
      if (machines.length === 0) {
        setFiles([]);
      } else {
        machines.forEach((m) => subOne(m.machineId));
      }
    } else {
      subOne(machineFilter);
    }

    return () => {
      for (const u of unsubs) {
        try {
          u();
        } catch (error) {
          console.warn('Failed to unsubscribe:', error);
        }
      }
    };
  }, [machineFilter, machines, statusFilter, applyClearedFilter]);

  // Optional periodic refresh as a safety net
  useEffect(() => {
    if (!autoRefreshEnabled) return;
    const id = window.setInterval(async () => {
      if (loading) return;
      if (machineFilter === 'all') {
        const all: RouterReadyFile[] = [];
        for (const m of machines) {
          const res = await window.api.files.listReady(m.machineId);
          if (!res.ok) continue;
          let items = res.value.files as ReadyFile[];
          if (statusFilter !== 'all') {
            items = items.filter((f) => f.status === statusFilter);
          }
          items = applyClearedFilter(items, m.machineId);
          all.push(...items.map((item) => ({ ...item, machineId: m.machineId })));
        }
        setFiles(all);
      } else {
        const res = await window.api.files.listReady(machineFilter);
        if (!res.ok) return;
        let items = res.value.files as ReadyFile[];
        if (statusFilter !== 'all') {
          items = items.filter((f) => f.status === statusFilter);
        }
        items = applyClearedFilter(items, machineFilter);
        setFiles(items.map((item) => ({ ...item, machineId: machineFilter })));
      }
    }, autoRefreshInterval * 1000);
    return () => window.clearInterval(id);
  }, [autoRefreshEnabled, autoRefreshInterval, loading, machineFilter, statusFilter, machines, applyClearedFilter]);

  const extractLeafFolder = useCallback((relativePath: string) => {
    const parts = relativePath.split(/[\\/]/).filter(Boolean);
    return parts.length > 1 ? parts[parts.length - 2] : '';
  }, []);

  const columns = useMemo<ColumnDef<RouterReadyFile>[]>(() => [
    {
      accessorKey: 'relativePath',
      header: 'Folder',
      size: 220,
      minSize: 180,
      maxSize: 300,
      enableSorting: false,
      cell: ({ row }) => (
        <div className="truncate">{extractLeafFolder(row.original.relativePath)}</div>
      )
    },
    {
      accessorKey: 'name',
      header: 'NC File',
      size: 240,
      minSize: 200,
      maxSize: 360,
      enableSorting: false,
      cell: ({ row }) => <div className="truncate">{row.original.name}</div>
    },
    {
      accessorKey: 'jobMaterial',
      header: 'Material',
      size: 140,
      minSize: 120,
      maxSize: 200,
      enableSorting: false,
      cell: ({ row }) => <div className="truncate">{row.original.jobMaterial ?? '-'}</div>
    },
    {
      accessorKey: 'jobSize',
      header: 'Size',
      size: 140,
      minSize: 120,
      maxSize: 200,
      enableSorting: false,
      cell: ({ row }) => <div className="truncate">{row.original.jobSize ?? '-'}</div>
    },
    {
      accessorKey: 'jobParts',
      header: 'Parts',
      size: 80,
      minSize: 60,
      maxSize: 120,
      enableSorting: false,
      cell: ({ row }) => <div className="truncate">{row.original.jobParts ?? '-'}</div>
    },
    {
      accessorKey: 'status',
      header: 'Status',
      size: 180,
      minSize: 160,
      maxSize: 260,
      enableSorting: false,
      cell: ({ row }) => {
        const status = row.original.status;
        if (!status) return <span className="text-muted-foreground">-</span>;
        return (
          <span className={cn('inline-flex items-center rounded px-2 py-0.5 text-sm font-medium', statusClass(status))}>
            {formatStatusLabel(status)}
          </span>
        );
      }
    },
    {
      accessorKey: 'addedAtR2R',
      header: 'Staged',
      size: 200,
      minSize: 160,
      maxSize: 260,
      enableSorting: false,
      cell: ({ row }) => {
        const raw =
          row.original.addedAtR2R ??
          row.original.jobDateadded ??
          (row.original.mtimeMs != null ? new Date(row.original.mtimeMs).toISOString() : null);
        return <div className="truncate">{formatIso(raw)}</div>;
      }
    },
    {
      accessorKey: 'inDatabase',
      header: 'In Database',
      size: 140,
      minSize: 120,
      maxSize: 200,
      enableSorting: false,
      cell: ({ row }) => <div className="truncate">{row.original.inDatabase ? 'Yes' : 'No'}</div>
    }
  ], [extractLeafFolder]);

  const table = useReactTable({
    data: files,
    columns,
    state: { rowSelection },
    onRowSelectionChange: setRowSelection,
    getRowId: (row) => row.relativePath,
    getCoreRowModel: getCoreRowModel(),
    columnResizeMode: 'onChange',
    enableColumnResizing: true,
    enableRowSelection: true,
    enableSorting: false
  });

  const selectedRows = table.getSelectedRowModel().rows;
  const selectedCount = selectedRows.length;

  const handleClearProcessed = () => {
    const targets = files.filter((file) => {
      if (file.status !== 'NESTPICK_COMPLETE') return false;
      if (machineFilter === 'all') return typeof file.machineId === 'number';
      return file.machineId === machineFilter;
    });
    if (!targets.length) return;

    const entriesByMachine = new Map<number, Array<{ path: string; mtime: number }>>();
    for (const file of targets) {
      const mid = file.machineId;
      if (typeof mid !== 'number') continue;
      const list = entriesByMachine.get(mid) ?? [];
      list.push({ path: file.relativePath, mtime: file.mtimeMs });
      entriesByMachine.set(mid, list);
    }
    if (!entriesByMachine.size) return;

    setClearedByMachine((prev) => {
      const next = new Map(prev);
      for (const [mid, entries] of entriesByMachine.entries()) {
        const existing = new Map(next.get(mid) ?? new Map<string, number>());
        for (const entry of entries) {
          existing.set(entry.path, entry.mtime);
        }
        next.set(mid, existing);
      }
      return next;
    });

    setFiles((prev) =>
      prev.filter((file) => {
        if (file.status !== 'NESTPICK_COMPLETE') return true;
        const mid = file.machineId;
        if (typeof mid !== 'number') return true;
        return !entriesByMachine.has(mid);
      })
    );
    setRowSelection({});

    const clearedCount = targets.length;
    const message =
      machineFilter === 'all'
        ? `Cleared ${clearedCount} processed job${clearedCount === 1 ? '' : 's'} from view`
        : `Cleared ${clearedCount} processed job${clearedCount === 1 ? '' : 's'} for ${
            machines.find((m) => m.machineId === machineFilter)?.name ?? `Machine ${machineFilter}`
          }`;
    setBanner({ type: 'success', message });
  };

  const handleDeleteSelected = async () => {
    if (!selectedCount || deleting) return;
    const confirmed = window.confirm(
      'Delete associated NC, CSV, image, and part files (nc/csv/bmp/jpg/png/pts/lpt) for the selected jobs?'
    );
    if (!confirmed) return;

    setDeleting(true);
    setBanner(null);

    const grouped = new Map<number, Set<string>>();
    for (const row of selectedRows) {
      const rels = grouped.get(row.original.machineId) ?? new Set<string>();
      rels.add(row.original.relativePath);
      grouped.set(row.original.machineId, rels);
    }

    let deletedTotal = 0;
    const errorMessages: string[] = [];

    for (const [machineId, relSet] of grouped) {
      if (relSet.size === 0) continue;
      try {
        const res = await window.api.files.deleteReadyAssets({
          machineId,
          relativePaths: Array.from(relSet)
        });
        if (!res.ok) {
          errorMessages.push(`Machine ${machineId}: ${res.error.message ?? 'Failed to delete files'}`);
          continue;
        }
        deletedTotal += res.value.deleted;
        if (res.value.errors.length) {
          for (const failure of res.value.errors) {
            errorMessages.push(`${failure.file}: ${failure.message}`);
          }
        }
      } catch (err) {
        errorMessages.push(`Machine ${machineId}: ${err instanceof Error ? err.message : String(err)}`);
      }
    }

    if (errorMessages.length) {
      setBanner({ type: 'error', message: errorMessages.join('; ') });
    } else {
      setBanner({
        type: 'success',
        message:
          deletedTotal > 0
            ? `Deleted ${deletedTotal} file${deletedTotal === 1 ? '' : 's'} associated with the selected jobs.`
            : 'No matching asset files were found for the selected jobs.'
      });
    }

    setRowSelection({});
    setDeleting(false);
  };

  const exportCsv = () => {
    const header = 'Folder,NC File,Material,Size,Parts,Status,Date Added,In Database';
    const lines = files.map(f => [
      extractLeafFolder(f.relativePath),
      f.name,
      f.jobMaterial ?? '',
      f.jobSize ?? '',
      f.jobParts ?? '',
      f.status ?? '',
      formatIso(
        f.addedAtR2R ??
          f.jobDateadded ??
          (f.mtimeMs != null ? new Date(f.mtimeMs).toISOString() : null)
      ),
      f.inDatabase ? 'Yes' : 'No'
    ].map(field => `"${String(field ?? '').replace(/"/g, '""')}"`).join(','));
    const csv = [header, ...lines].join('\n');
    const blob = new Blob([csv], { type: 'text/csv' });
    const url = URL.createObjectURL(blob);
    const link = document.createElement('a');
    link.href = url;
    link.download = 'router-files.csv';
    link.click();
    URL.revokeObjectURL(url);
  };

  return (
    <div className="space-y-4 w-full">
      <div className="flex items-center justify-between">
        <div>
          <p className="text-sm text-muted-foreground">{loading ? 'Refreshing...' : `${files.length} files`}</p>
        </div>
        <div className="flex flex-col items-end gap-2">
          {banner && (
            <div
              className={cn(
                'text-sm px-3 py-2 rounded border',
                banner.type === 'error'
                  ? 'border-red-300 bg-red-50 text-red-700'
                  : 'border-emerald-300 bg-emerald-50 text-emerald-700'
              )}
            >
              {banner.message}
            </div>
          )}
          <div className="flex items-center gap-3">
            <div className="flex items-center gap-2 border rounded px-2 py-1 text-xs">
              <label className="flex items-center gap-1">
                <input
                  type="checkbox"
                  checked={autoRefreshEnabled}
                  onChange={(e) => setAutoRefreshEnabled(e.target.checked)}
                />
                Auto
              </label>
              <select
                className="border rounded px-1 py-0.5"
                value={autoRefreshInterval}
                onChange={(e) => setAutoRefreshInterval(Number(e.target.value))}
                disabled={!autoRefreshEnabled}
              >
                {[15, 30, 60, 120].map((seconds) => (
                  <option key={seconds} value={seconds}>{seconds}s</option>
                ))}
              </select>
            </div>
            <div className="flex gap-2">
              {machineFilter !== 'all' && (
                <button
                  className="border rounded px-3 py-1"
                  onClick={async () => {
                    setLoading(true);
                    const res = await window.api.files.listReady(machineFilter as number);
                    if (res.ok) {
                      let items = res.value.files as ReadyFile[];
                      if (statusFilter !== 'all') {
                        items = items.filter((f) => f.status === statusFilter);
                      }
                      items = applyClearedFilter(items, machineFilter as number);
                      setFiles(items.map((item) => ({ ...item, machineId: machineFilter as number })));
                    }
                    setLoading(false);
                  }}
                  disabled={loading}
                >
                  Refresh
                </button>
              )}
              <button
                className="border rounded px-3 py-1"
                onClick={handleClearProcessed}
                disabled={!hasClearable || deleting}
              >
                Clear Processed
              </button>
              <button
                className="border rounded px-3 py-1"
                onClick={handleDeleteSelected}
                disabled={deleting || selectedCount === 0}
              >
                {deleting ? 'Deleting...' : selectedCount > 1 ? `Delete Selected (${selectedCount})` : 'Delete Selected'}
              </button>
              <button className="border rounded px-3 py-1" onClick={exportCsv}>
                Export CSV
              </button>
            </div>
          </div>
        </div>
      </div>

      <div className="flex items-center gap-3">
        <label className="text-sm flex items-center gap-2">
          <span>Machine</span>
          <select className="border rounded px-2 py-1" value={machineFilter === 'all' ? '' : machineFilter}
            onChange={(e) => setMachineFilter(e.target.value ? Number(e.target.value) : 'all')}>
            <option value="">All</option>
            {machines.map(m => (
              <option key={m.machineId} value={m.machineId}>{m.name}</option>
            ))}
          </select>
        </label>
        <label className="text-sm flex items-center gap-2">
          <span>Status</span>
          <select className="border rounded px-2 py-1" value={statusFilter === 'all' ? '' : statusFilter}
            onChange={(e) => setStatusFilter(e.target.value ? (e.target.value as JobStatus) : 'all')}>
            <option value="">All</option>
            {JOB_STATUS_VALUES.map(status => (
              <option key={status} value={status}>{status}</option>
            ))}
          </select>
        </label>
      </div>

      <div className="flex justify-between items-center px-1">
        <div className="text-sm text-muted-foreground">Ready-To-Run folder view</div>
      </div>
      <GlobalTable
        table={table}
        maxHeight="calc(100vh - 200px)"
        rowHeight={41}
        headerHeight={40}
        viewportPadding={200}
        density="normal"
        headerHoverAlways
      />
    </div>
  );
}

================
File: packages/renderer/src/pages/SettingsPage.tsx
================
import { useCallback, useEffect, useMemo, useState } from 'react';
import { Trash2 } from 'lucide-react';
import { useForm } from 'react-hook-form';
import { zodResolver } from '@hookform/resolvers/zod';
import { z } from 'zod';
import type { DbSettings, Settings, Machine, SaveMachineReq, DbStatus } from '../../../shared/src';
import { CURRENT_SETTINGS_VERSION } from '../../../shared/src';

const schema = z.object({
  host: z.string().default(''),
  port: z.coerce.number().int().min(1).max(65535).default(5432),
  database: z.string().default(''),
  user: z.string().default(''),
  password: z.string().default(''),
  sslMode: z.enum(['disable', 'require', 'verify-ca', 'verify-full']).default('disable'),
  statementTimeoutMs: z.coerce.number().int().min(0).max(600000).default(30000)
});

const DEFAULT_FORM_VALUES: DbSettings = {
  host: '',
  port: 5432,
  database: '',
  user: '',
  password: '', // Will be validated as required by schema
  sslMode: 'disable',
  statementTimeoutMs: 30000
};

type FormValues = z.infer<typeof schema>;
type PathsState = Settings['paths'];
type TestState = Settings['test'];
type GrundnerState = Settings['grundner'];

const DEFAULT_PATHS: PathsState = { processedJobsRoot: '', autoPacCsvDir: '', grundnerFolderPath: '' };
const DEFAULT_TEST: TestState = { testDataFolderPath: '', useTestDataMode: false, sheetIdMode: 'type_data' };
const DEFAULT_GRUNDNER: GrundnerState = { reservedAdjustmentMode: 'delta' };

type PathFieldKey = 'processedJobsRoot' | 'autoPacCsvDir' | 'grundnerFolderPath' | 'testDataFolderPath';
type PathValidationState = { status: 'empty' | 'checking' | 'valid' | 'invalid'; message: string };
type MachinePathKey = 'machineApJobfolder' | 'machineNestpickFolder';

const PATH_STATUS_COLORS: Record<PathValidationState['status'], string> = {
  valid: 'text-success',
  invalid: 'text-destructive',
  checking: 'text-warning',
  empty: 'text-muted-foreground'
};

function createInitialPathStatus(): Record<PathFieldKey, PathValidationState> {
  return {
    processedJobsRoot: { status: 'empty', message: 'Not set' },
    autoPacCsvDir: { status: 'empty', message: 'Not set' },
    grundnerFolderPath: { status: 'empty', message: 'Not set' },
    testDataFolderPath: { status: 'empty', message: 'Not set' }
  };
}

function createInitialMachinePathStatus(): Record<MachinePathKey, PathValidationState> {
  return {
    machineApJobfolder: { status: 'empty', message: 'Select a machine to edit' },
    machineNestpickFolder: { status: 'empty', message: 'Select a machine to edit' }
  };
}

function statusBorderClass(status: PathValidationState) {
  switch (status.status) {
    case 'valid':
      return 'border-success focus:ring-success/40';
    case 'invalid':
      return 'border-destructive focus:ring-destructive/40';
    case 'checking':
      return 'border-warning focus:ring-warning/40';
    default:
      return 'border-border';
  }
}

function withDefaults<T extends object>(defaults: T, value?: Partial<T> | null): T {
  return { ...defaults, ...(value ?? {}) };
}

type ResultEnvelope<T> = { ok: true; value: T } | { ok: false; error: { message: string } };

function extractResult<T>(raw: unknown): ResultEnvelope<T> {
  // Direct value fallback (older stubs or IPC shims)
  if (typeof raw === 'string' || raw === null) {
    return { ok: true, value: raw as unknown as T };
  }

  if (raw && typeof raw === 'object') {
    const obj = raw as Record<string, unknown>;

    // neverthrow-like Result<T,E>
    const hasNtOk = Object.prototype.hasOwnProperty.call(obj, 'isOk');
    const hasNtErr = Object.prototype.hasOwnProperty.call(obj, 'isErr');
    const isNtOkFn = hasNtOk && typeof (obj as { isOk?: unknown }).isOk === 'function';
    const isNtErrFn = hasNtErr && typeof (obj as { isErr?: unknown }).isErr === 'function';
    if (isNtOkFn && isNtErrFn) {
      try {
        const isErr = ((obj as { isErr: () => boolean }).isErr)();
        if (isErr) {
          const errValue = obj.error as { message?: string } | string | undefined;
          const message = typeof errValue === 'string' ? errValue : errValue?.message ?? 'Unknown error';
          return { ok: false, error: { message } };
        }
        const value = (obj as { value?: T }).value as T;
        return { ok: true, value };
      } catch (err) {
        const message = err instanceof Error ? err.message : String(err);
        return { ok: false, error: { message } };
      }
    }

    // Envelope { ok, value | error }
    if (Object.prototype.hasOwnProperty.call(obj, 'ok')) {
      const okFlag = Boolean((obj as { ok?: unknown }).ok as boolean);
      if (okFlag) {
        return { ok: true, value: (obj as { value?: T }).value as T };
      }
      const errValue = (obj as { error?: unknown }).error as { message?: string } | string | undefined;
      const message = typeof errValue === 'string' ? errValue : errValue?.message ?? 'Unknown error';
      return { ok: false, error: { message } };
    }

    // Tolerate boolean-style flags (defensive)
    const maybeIsOk = (obj as { isOk?: unknown }).isOk;
    if (typeof maybeIsOk === 'boolean') {
      const okFlag = Boolean(maybeIsOk);
      if (okFlag) return { ok: true, value: (obj as { value?: T }).value as T };
      const errValue = (obj as { error?: unknown }).error as { message?: string } | string | undefined;
      const message = typeof errValue === 'string' ? errValue : errValue?.message ?? 'Unknown error';
      return { ok: false, error: { message } };
    }
  }

  return { ok: false, error: { message: 'Unexpected response from API' } };
}

export function SettingsPage() {
  const { register, handleSubmit, reset, formState: { isSubmitting } } = useForm<FormValues>({
    resolver: zodResolver(schema),
    defaultValues: DEFAULT_FORM_VALUES
  });

  const [configVersion, setConfigVersion] = useState<number>(CURRENT_SETTINGS_VERSION);
  const [configPath, setConfigPath] = useState<string | null>(null);
  const [machines, setMachines] = useState<Machine[]>([]);
  const [selectedMachineId, setSelectedMachineId] = useState<number | null>(null);
  const [editingMachine, setEditingMachine] = useState<Machine | null>(null);
  const [paths, setPaths] = useState<PathsState>(DEFAULT_PATHS);
  const [testState, setTestState] = useState<TestState>(DEFAULT_TEST);
  const [grundnerState, setGrundnerState] = useState<GrundnerState>(DEFAULT_GRUNDNER);
  const [dbStatus, setDbStatus] = useState<DbStatus | null>(null);
  const [pathStatus, setPathStatus] = useState<Record<PathFieldKey, PathValidationState>>(() => createInitialPathStatus());
  const [machinePathStatus, setMachinePathStatus] = useState<Record<MachinePathKey, PathValidationState>>(() => createInitialMachinePathStatus());
  const [dbTestResult, setDbTestResult] = useState<{ status: 'idle' | 'testing' | 'ok' | 'error'; message: string }>({ status: 'idle', message: '' });

  const lastCheckedLabel = useMemo(() => {
    if (!dbStatus) return null;
    const date = new Date(dbStatus.checkedAt);
    if (Number.isNaN(date.getTime()) || date.getTime() === 0) return null;
    return date.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit', second: '2-digit' });
  }, [dbStatus]);

  const latencyLabel = useMemo(() => {
    return dbStatus?.online && typeof dbStatus.latencyMs === 'number' ? `${dbStatus.latencyMs} ms` : null;
  }, [dbStatus]);

  const statusLabel = useMemo(() => {
    if (!dbStatus) return 'Checking...';
    return dbStatus.online
      ? 'Online'
      : dbStatus.error ? 'Offline' : 'Checking...';
  }, [dbStatus]);

  const hasPathErrors = useMemo(() => Object.values(pathStatus).some((entry) => entry.status === 'invalid'), [pathStatus]);
  const isPathValidationPending = useMemo(() => Object.values(pathStatus).some((entry) => entry.status === 'checking'), [pathStatus]);

  const machineHasErrors = useMemo(() => {
    if (!editingMachine) return false;
    return Object.entries(machinePathStatus).some(([key, state]) => {
      if (key === 'machineNestpickFolder' && !editingMachine.nestpickEnabled) return false;
      return state.status === 'invalid';
    });
  }, [editingMachine, machinePathStatus]);

  const machineValidationPending = useMemo(() => {
    if (!editingMachine) return false;
    return Object.entries(machinePathStatus).some(([key, state]) => {
      if (key === 'machineNestpickFolder' && !editingMachine.nestpickEnabled) return false;
      return state.status === 'checking';
    });
  }, [editingMachine, machinePathStatus]);

  const machineHasBlockingIssues = machineHasErrors || machineValidationPending;

  const statusToneClass = useMemo(() => {
    if (dbStatus?.online) return 'text-success';
    if (dbStatus?.error) return 'text-destructive';
    return 'text-warning';
  }, [dbStatus]);

  const indicatorToneClass = useMemo(() => {
    if (dbStatus?.online) return 'bg-success';
    if (dbStatus?.error) return 'bg-destructive';
    return 'bg-warning';
  }, [dbStatus]);

  const applyMachines = useCallback((items: Machine[], preferredId?: number | null) => {
    setMachines(items);
    if (!items.length) {
      setSelectedMachineId(null);
      setEditingMachine(null);
      return;
    }

    const targetId = preferredId ?? selectedMachineId ?? items[0].machineId;
    const match = items.find((m) => m.machineId === targetId) ?? items[0];
    setSelectedMachineId(match.machineId);
    setEditingMachine({ ...match });
  }, [selectedMachineId]);

  const loadMachines = useCallback(async (preferredId?: number | null) => {
    const raw = await window.api.machines.list();
    const result = extractResult<{ items: Machine[] }>(raw as unknown);
    if (!result.ok) {
      alert(`Failed to load machines: ${result.error.message}`);
      applyMachines([], preferredId);
      return;
    }
    applyMachines(result.value.items, preferredId);
  }, [applyMachines]);

  const loadSettings = useCallback(async () => {
    const settingsRaw = await window.api.settings.get();
    const settingsRes = extractResult<Settings>(settingsRaw as unknown);
    if (!settingsRes.ok) {
      alert(`Failed to load settings: ${settingsRes.error.message}`);
      return;
    }
    const settings = settingsRes.value;
    const pathRaw = await window.api.settings.getPath();
    const pathRes = extractResult<string>(pathRaw as unknown);
    if (pathRes.ok) {
      setConfigPath(pathRes.value);
    }
    setConfigVersion(settings.version ?? CURRENT_SETTINGS_VERSION);
    
    // Merge settings and show password as-is per product decision
    const dbSettings = withDefaults(DEFAULT_FORM_VALUES, settings.db);
    reset(dbSettings);
    setPaths(withDefaults(DEFAULT_PATHS, settings.paths));
    setTestState(withDefaults(DEFAULT_TEST, settings.test));
    setGrundnerState(withDefaults(DEFAULT_GRUNDNER, settings.grundner));
    await loadMachines();
  }, [loadMachines, reset]);

  useEffect(() => {
    void loadSettings();
  }, [loadSettings]);

  useEffect(() => {
    let cancelled = false;
    window.api.db.getStatus()
      .then((raw) => {
        if (cancelled) return;
        const res = extractResult<DbStatus>(raw as unknown);
        if (res.ok) setDbStatus(res.value);
      })
      .catch(() => {});
    const unsubscribe = window.api.db.subscribeStatus((status) => setDbStatus(status));
    return () => {
      cancelled = true;
      unsubscribe?.();
    };
  }, []);

  useEffect(() => {
    const descriptors: Array<{ key: PathFieldKey; value: string; required: boolean }> = [
      { key: 'processedJobsRoot', value: paths.processedJobsRoot ?? '', required: true },
      { key: 'autoPacCsvDir', value: paths.autoPacCsvDir ?? '', required: false },
      { key: 'grundnerFolderPath', value: paths.grundnerFolderPath ?? '', required: false },
      { key: 'testDataFolderPath', value: testState.testDataFolderPath ?? '', required: false }
    ];
    setPathStatus((prev) => {
      const next = { ...prev };
      descriptors.forEach((descriptor) => {
        const trimmed = descriptor.value.trim();
        if (!trimmed) {
          next[descriptor.key] = {
            status: descriptor.required ? 'invalid' : 'empty',
            message: descriptor.required ? 'Required' : 'Not set'
          };
        } else {
          next[descriptor.key] = { status: 'checking', message: 'Checking...' };
        }
      });
      return next;
    });

    let cancelled = false;

    (async () => {
      for (const descriptor of descriptors) {
        const trimmed = descriptor.value.trim();
        if (!trimmed) continue;
        const raw = await window.api.settings.validatePath({ path: trimmed, kind: 'directory' });
        const res = extractResult<{ path: string; exists: boolean; isDirectory: boolean; isFile: boolean; error: string | null }>(raw as unknown);
        if (cancelled) return;
        if (!res.ok) {
          setPathStatus((prev) => ({
            ...prev,
            [descriptor.key]: { status: 'invalid', message: res.error.message }
          }));
          continue;
        }
        const data = res.value;
        const ok = data.exists && data.isDirectory;
        setPathStatus((prev) => ({
          ...prev,
          [descriptor.key]: {
            status: ok ? 'valid' : 'invalid',
            message: ok ? 'Directory found' : data.exists ? 'Not a directory' : 'Directory not found'
          }
        }));
      }
    })();

    return () => {
      cancelled = true;
    };
  }, [paths.processedJobsRoot, paths.autoPacCsvDir, paths.grundnerFolderPath, testState.testDataFolderPath]);

  useEffect(() => {
    if (!editingMachine) {
      setMachinePathStatus(createInitialMachinePathStatus());
      return;
    }

    const descriptors: Array<{ key: MachinePathKey; value: string; required: boolean; disabledMessage?: string }> = [
      { key: 'machineApJobfolder', value: editingMachine.apJobfolder ?? '', required: true },
      { key: 'machineNestpickFolder', value: editingMachine.nestpickFolder ?? '', required: !!editingMachine.nestpickEnabled, disabledMessage: editingMachine.nestpickEnabled ? undefined : 'Nestpick disabled' }
    ];

    setMachinePathStatus((prev) => {
      const next = { ...prev };
      descriptors.forEach((descriptor) => {
        const trimmed = descriptor.value.trim();
        if (!trimmed) {
          const message = descriptor.required
            ? 'Required'
            : descriptor.disabledMessage ?? 'Not set';
          next[descriptor.key] = {
            status: descriptor.required ? 'invalid' : 'empty',
            message
          };
        } else if (descriptor.disabledMessage && !descriptor.required) {
          next[descriptor.key] = { status: 'empty', message: descriptor.disabledMessage };
        } else {
          next[descriptor.key] = { status: 'checking', message: 'Checking...' };
        }
      });
      return next;
    });

    let cancelled = false;

    (async () => {
      for (const descriptor of descriptors) {
        const trimmed = descriptor.value.trim();
        if (!trimmed) continue;
        if (descriptor.disabledMessage && !descriptor.required && !editingMachine.nestpickEnabled) continue;
        const raw = await window.api.settings.validatePath({ path: trimmed, kind: 'directory' });
        const res = extractResult<{ path: string; exists: boolean; isDirectory: boolean; isFile: boolean; error: string | null }>(raw as unknown);
        if (cancelled) return;
        if (!res.ok) {
          setMachinePathStatus((prev) => ({
            ...prev,
            [descriptor.key]: { status: 'invalid', message: res.error.message }
          }));
          continue;
        }
        const data = res.value;
        const ok = data.exists && data.isDirectory;
        setMachinePathStatus((prev) => ({
          ...prev,
          [descriptor.key]: {
            status: ok ? 'valid' : 'invalid',
            message: ok ? 'Directory found' : data.exists ? 'Not a directory' : 'Directory not found'
          }
        }));
      }
    })();

    return () => {
      cancelled = true;
    };
  }, [editingMachine]);

  const onTest = async (values: FormValues) => {
    setDbTestResult({ status: 'testing', message: 'Testing connection...' });
    const res = extractResult<{ ok: true } | { ok: false; error: string }>(
      await window.api.db.testConnection(values as DbSettings)
    );
    if (!res.ok) {
      setDbTestResult({ status: 'error', message: res.error.message });
      return;
    }
    if (res.value.ok) {
      setDbTestResult({ status: 'ok', message: 'Connection OK' });
    } else {
      setDbTestResult({ status: 'error', message: res.value.error ?? 'Unknown error' });
    }
  };

  const onSave = async (values: FormValues) => {
    const next: Settings = {
      version: configVersion,
      db: values as DbSettings,
      paths,
      test: testState,
      grundner: grundnerState
    };
    const saved = extractResult<Settings>(await window.api.settings.save(next));
    if (!saved.ok) {
      alert(`Failed to save settings: ${saved.error.message}`);
      return;
    }
    setConfigVersion(saved.value.version ?? CURRENT_SETTINGS_VERSION);
    await loadSettings();
    setDbTestResult({ status: 'idle', message: '' });
    alert('Settings saved');
  };

  const addMachine = async () => {
    const createdRaw = await window.api.machines.save({
      name: 'New Machine',
      apJobfolder: '',
      nestpickFolder: '',
      nestpickEnabled: true,
      pcPort: 5000
    });
    const created = extractResult<Machine>(createdRaw as unknown);
    if (!created.ok) {
      alert(`Failed to create machine: ${created.error.message}`);
      return;
    }
    await loadMachines(created.value.machineId ?? undefined);
  };

  const saveMachine = async () => {
    if (!editingMachine) return;
    if (machineHasBlockingIssues) {
      alert('Machine folder validation is pending or has errors.');
      return;
    }

    const payload: SaveMachineReq = {
      machineId: editingMachine.machineId,
      name: editingMachine.name,
      pcIp: editingMachine.pcIp ?? null,
      cncIp: editingMachine.cncIp ?? null,
      cncPort: editingMachine.cncPort ?? null,
      apJobfolder: editingMachine.apJobfolder,
      nestpickFolder: editingMachine.nestpickFolder,
      nestpickEnabled: editingMachine.nestpickEnabled,
      pcPort: editingMachine.pcPort
    };

    const raw = await window.api.machines.save(payload);
    const res = extractResult<Machine>(raw as unknown);
    if (!res.ok) {
      alert(`Failed to save machine: ${res.error.message}`);
      return;
    }
    await loadMachines(editingMachine.machineId);
  };

  const deleteMachine = async () => {
    if (selectedMachineId == null) return;
    if (!confirm('Delete this machine?')) return;
    const raw = await window.api.machines.delete(selectedMachineId);
    const res = extractResult<null>(raw as unknown);
    if (!res.ok) {
      alert(`Failed to delete machine: ${res.error.message}`);
      return;
    }
    await loadMachines();
  };

  const deleteMachineById = async (id: number, name?: string | null) => {
    if (!confirm(`Delete machine "${name ?? id}"?`)) return;
    const raw = await window.api.machines.delete(id);
    const res = extractResult<null>(raw as unknown);
    if (!res.ok) {
      alert(`Failed to delete machine: ${res.error.message}`);
      return;
    }
    await loadMachines();
  };

  const handleSelectMachine = (machineId: number) => {
    const machine = machines.find((m) => m.machineId === machineId);
    if (!machine) return;
    setSelectedMachineId(machine.machineId);
    setEditingMachine({ ...machine });
  };

  const browseFolder = async (setter: (value: string) => void, initial?: string) => {
    try {
      const raw = await window.api.dialog.pickFolder();
      const res = extractResult<string | null>(raw as unknown);
      if (!res.ok) {
        alert(`Failed to open folder picker: ${res.error.message}`);
        console.error('Folder picker error', res.error.message);
        return;
      }
      const value = res.value;
      if (value) {
        console.debug('Picked folder:', value);
        setter(value);
      } else if (initial !== undefined) {
        console.debug('Picker cancelled, keeping initial:', initial);
        setter(initial);
      }
    } catch (err) {
      const msg = err instanceof Error ? err.message : String(err);
      alert(`Failed to open folder picker: ${msg}`);
      console.error('Folder picker error', msg);
    }
  };

  return (
    <div className="space-section max-w-6xl">
      <div className="mb-6">
        <h1 className="text-3xl font-bold text-foreground">Settings</h1>
        {configPath && (
          <div className="text-sm text-muted-foreground mt-2 break-all">Config file: {configPath}</div>
        )}
      </div>

      <div className="grid grid-cols-[320px_1fr] gap-8">
        <div className="card p-6 h-[320px]">
          <div className="flex justify-between items-center mb-4">
            <h3 className="font-semibold text-foreground">Machines</h3>
            <button type="button" className="btn-secondary text-sm" onClick={addMachine}>Add</button>
          </div>
          <div className="h-[calc(100%-2.5rem)] overflow-auto">
            <ul className="space-y-1">
              {machines.map((machine) => (
                <li key={machine.machineId} className="relative group">
                  <button
                    type="button"
                    className={`w-full text-left pr-10 pl-3 py-2 rounded-lg text-sm transition-colors ${
                      machine.machineId === selectedMachineId
                        ? 'bg-primary text-primary-foreground'
                        : 'hover:bg-muted text-foreground'
                    }`}
                    onClick={() => handleSelectMachine(machine.machineId)}
                    title={machine.name}
                  >
                    {machine.name}
                  </button>
                  <button
                    type="button"
                    aria-label="Delete machine"
                    title="Delete machine"
                    className={`absolute right-2 top-1/2 -translate-y-1/2 p-1 rounded transition-colors ${
                      machine.machineId === selectedMachineId
                        ? 'text-primary-foreground/90 hover:text-destructive hover:bg-destructive/10'
                        : 'text-muted-foreground hover:text-destructive hover:bg-destructive/10'
                    }`}
                    onClick={(e) => { e.stopPropagation(); void deleteMachineById(machine.machineId, machine.name); }}
                  >
                    <Trash2 className="w-4 h-4" />
                  </button>
                </li>
              ))}
              {!machines.length && <li className="text-sm text-muted-foreground p-2">No machines configured yet.</li>}
            </ul>
          </div>
        </div>

        <div className="card p-6 space-y-4">
          <h3 className="font-semibold text-foreground">Machine Details</h3>
          {machineHasErrors ? (
            <div className="text-sm text-destructive">Fix required machine folders before saving.</div>
          ) : machineValidationPending ? (
            <div className="text-sm text-warning">Validating machine folders...</div>
          ) : null}
          {editingMachine ? (
            <div className="grid grid-cols-2 gap-3">
              <label className="form-label">
                <span>Name</span>
                <input
                  className="form-input"
                  value={editingMachine.name}
                  onChange={(e) => setEditingMachine((prev) => prev ? { ...prev, name: e.target.value } : prev)}
                />
              </label>
              <label className="form-label">
                <span>PC IP</span>
                <input
                  className="form-input"
                  value={editingMachine.pcIp ?? ''}
                  onChange={(e) => setEditingMachine((prev) => prev ? { ...prev, pcIp: e.target.value || null } : prev)}
                />
              </label>
              <label className="form-label">
                <span>CNC IP</span>
                <input
                  className="form-input"
                  value={editingMachine.cncIp ?? ''}
                  onChange={(e) => setEditingMachine((prev) => prev ? { ...prev, cncIp: e.target.value || null } : prev)}
                />
              </label>
              <label className="form-label">
                <span>CNC Port</span>
                <input
                  className="form-input"
                  type="number"
                  value={editingMachine.cncPort ?? ''}
                  onChange={(e) => setEditingMachine((prev) => prev ? {
                    ...prev,
                    cncPort: e.target.value === '' ? null : Number(e.target.value)
                  } : prev)}
                />
              </label>
              <div className="col-span-2">
                <label className="form-label">
                  <span>Ready-To-Run Folder</span>
                  <div className="flex gap-2 items-start">
                    <input
                      className={`form-input flex-1 border-2 border-gray-700 ${statusBorderClass(machinePathStatus.machineApJobfolder)}`}
                      value={editingMachine.apJobfolder}
                      onChange={(e) => setEditingMachine((prev) => prev ? { ...prev, apJobfolder: e.target.value } : prev)}
                    />
                    <button
                      type="button"
                      className="btn-secondary whitespace-nowrap"
                      onClick={() => browseFolder((value) => setEditingMachine((prev) => prev ? { ...prev, apJobfolder: value } : prev), editingMachine.apJobfolder)}
                    >
                      Browse
                    </button>
                  </div>
                  <span className={`text-xs ${PATH_STATUS_COLORS[machinePathStatus.machineApJobfolder.status]}`}>
                    {machinePathStatus.machineApJobfolder.message}
                  </span>
                </label>
              </div>
              <div className="col-span-2">
                <label className="form-label">
                  <span>Nestpick Folder</span>
                  <div className="flex gap-2 items-start">
                    <input
                      className={`form-input flex-1 border-2 border-gray-700 ${statusBorderClass(machinePathStatus.machineNestpickFolder)}`}
                      value={editingMachine.nestpickFolder}
                      onChange={(e) => setEditingMachine((prev) => prev ? { ...prev, nestpickFolder: e.target.value } : prev)}
                    />
                    <button
                      type="button"
                      className="btn-secondary whitespace-nowrap"
                      onClick={() => browseFolder((value) => setEditingMachine((prev) => prev ? { ...prev, nestpickFolder: value } : prev), editingMachine.nestpickFolder)}
                    >
                      Browse
                    </button>
                  </div>
                  <span className={`text-xs ${PATH_STATUS_COLORS[machinePathStatus.machineNestpickFolder.status]}`}>
                    {machinePathStatus.machineNestpickFolder.message}
                  </span>
                </label>
              </div>
              <label className="form-label">
                <span>Nestpick Enabled</span>
                <select
                  className="form-input"
                  value={editingMachine.nestpickEnabled ? 'true' : 'false'}
                  onChange={(e) => setEditingMachine((prev) => prev ? { ...prev, nestpickEnabled: e.target.value === 'true' } : prev)}
                >
                  <option value="true">Yes</option>
                  <option value="false">No</option>
                </select>
              </label>
              <label className="form-label">
                <span>PC Port</span>
                <input
                  className="form-input"
                  type="number"
                  value={editingMachine.pcPort}
                  onChange={(e) => {
                    const val = e.target.value;
                    if (val === '') {
                      setEditingMachine((prev) => prev ? { ...prev, pcPort: prev.pcPort } : prev);
                    } else {
                      const numVal = Number(val);
                      setEditingMachine((prev) => prev ? { ...prev, pcPort: isNaN(numVal) ? prev.pcPort : numVal } : prev);
                    }
                  }}
                />
              </label>
            </div>
          ) : (
            <div className="text-sm text-muted-foreground p-4 text-center">Select a machine to edit</div>
          )}
          <div className="flex gap-3 pt-2">
            <button type="button" className="btn-primary" onClick={saveMachine} disabled={!editingMachine || machineHasBlockingIssues}>Save Machine</button>
            <button type="button" className="btn-secondary" onClick={deleteMachine} disabled={selectedMachineId == null}>Delete</button>
          </div>
        </div>
      </div>

      <div className="grid grid-cols-1 md:grid-cols-2 gap-8 mt-12">
        <div className="card p-6 space-y-4">
          <h3 className="font-semibold text-foreground">Paths</h3>
          {hasPathErrors ? (
            <div className="text-sm text-destructive">Some paths are missing; update as needed.</div>
          ) : isPathValidationPending ? (
            <div className="text-sm text-warning">Validating paths...</div>
          ) : null}
          <label className="flex flex-col gap-1 text-sm">
            <span>Processed Jobs Root</span>
            <div className="flex gap-2 items-start">
              <input
                className={`border-2 border-gray-700 rounded px-2 py-1 w-full ${statusBorderClass(pathStatus.processedJobsRoot)}`}
                value={paths.processedJobsRoot}
                onChange={(e) => setPaths({ ...paths, processedJobsRoot: e.target.value })}
              />
              <button
                type="button"
                className="border rounded px-2"
                onClick={() => browseFolder((value) => setPaths((prev) => ({ ...prev, processedJobsRoot: value })), paths.processedJobsRoot)}
              >
                Browse
              </button>
            </div>
            <span className={`text-xs ${PATH_STATUS_COLORS[pathStatus.processedJobsRoot.status]}`}>
              {pathStatus.processedJobsRoot.message}
            </span>
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>AutoPAC CSV Directory</span>
            <div className="flex gap-2 items-start">
              <input
                className={`border-2 border-gray-700 rounded px-2 py-1 w-full ${statusBorderClass(pathStatus.autoPacCsvDir)}`}
                value={paths.autoPacCsvDir}
                onChange={(e) => setPaths({ ...paths, autoPacCsvDir: e.target.value })}
              />
              <button
                type="button"
                className="border rounded px-2"
                onClick={() => browseFolder((value) => setPaths((prev) => ({ ...prev, autoPacCsvDir: value })), paths.autoPacCsvDir)}
              >
                Browse
              </button>
            </div>
            <span className={`text-xs ${PATH_STATUS_COLORS[pathStatus.autoPacCsvDir.status]}`}>
              {pathStatus.autoPacCsvDir.message}
            </span>
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Grundner Folder</span>
            <div className="flex gap-2 items-start">
              <input
                className={`border-2 border-gray-700 rounded px-2 py-1 w-full ${statusBorderClass(pathStatus.grundnerFolderPath)}`}
                value={paths.grundnerFolderPath}
                onChange={(e) => setPaths({ ...paths, grundnerFolderPath: e.target.value })}
              />
              <button
                type="button"
                className="border rounded px-2"
                onClick={() => browseFolder((value) => setPaths((prev) => ({ ...prev, grundnerFolderPath: value })), paths.grundnerFolderPath)}
              >
                Browse
              </button>
            </div>
            <span className={`text-xs ${PATH_STATUS_COLORS[pathStatus.grundnerFolderPath.status]}`}>
              {pathStatus.grundnerFolderPath.message}
            </span>
          </label>
        </div>

        <div className="card p-6 space-y-4">
          <h3 className="font-semibold text-foreground">Test / Grundner</h3>
          <label className="flex flex-col gap-1 text-sm">
            <span>Test Data Folder</span>
            <div className="flex gap-2 items-start">
              <input
                className={`border-2 border-gray-700 rounded px-2 py-1 w-full ${statusBorderClass(pathStatus.testDataFolderPath)}`}
                value={testState.testDataFolderPath}
                onChange={(e) => setTestState({ ...testState, testDataFolderPath: e.target.value })}
              />
              <button
                type="button"
                className="border rounded px-2"
                onClick={() => browseFolder((value) => setTestState((prev) => ({ ...prev, testDataFolderPath: value })), testState.testDataFolderPath)}
              >
                Browse
              </button>
            </div>
            <span className={`text-xs ${PATH_STATUS_COLORS[pathStatus.testDataFolderPath.status]}`}>
              {pathStatus.testDataFolderPath.message}
            </span>
          </label>
          <label className="flex items-center gap-2 text-sm">
            <input
              type="checkbox"
              checked={testState.useTestDataMode}
              onChange={(e) => setTestState({ ...testState, useTestDataMode: e.target.checked })}
            />
            Use test data mode
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Sheet ID Mode</span>
            <select
              className="border-2 border-gray-700 rounded px-2 py-1"
              value={testState.sheetIdMode}
              onChange={(e) => setTestState({ ...testState, sheetIdMode: e.target.value as TestState['sheetIdMode'] })}
            >
              <option value="type_data">type_data</option>
              <option value="customer_id">customer_id</option>
            </select>
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Grundner Reserved Mode</span>
            <select
              className="border-2 border-gray-700 rounded px-2 py-1"
              value={grundnerState.reservedAdjustmentMode}
              onChange={(e) => setGrundnerState({ reservedAdjustmentMode: e.target.value as GrundnerState['reservedAdjustmentMode'] })}
            >
              <option value="delta">delta</option>
              <option value="absolute">absolute</option>
            </select>
          </label>
        </div>
      </div>

      <form className="card p-6 space-y-4 mt-12" onSubmit={handleSubmit(onSave)}>
        <div className="flex items-center justify-between">
          <h2 className="font-medium text-lg" id="db-settings-heading">Database</h2>
          {dbStatus && (
            <div
              className="flex items-center gap-2 text-sm"
              title={!dbStatus.online && dbStatus.error ? dbStatus.error : undefined}
            >
              <span
                className={`h-2.5 w-2.5 rounded-full ${indicatorToneClass}`}
                aria-hidden
              />
              <span className={statusToneClass}>
                {statusLabel}
              </span>
              {lastCheckedLabel && (
                <span className="text-muted-foreground">{lastCheckedLabel}</span>
              )}
              {latencyLabel && (
                <span className="text-muted-foreground">{latencyLabel}</span>
              )}
              {!dbStatus.online && dbStatus.error && (
                <span className="text-xs text-muted-foreground max-w-[220px] truncate">
                  {dbStatus.error}
                </span>
              )}
            </div>
          )}
        </div>
        <div className="grid grid-cols-2 gap-3">
          <label className="flex flex-col gap-1 text-sm">
            <span>Host</span>
            <input className="border-2 border-gray-700 rounded px-2 py-1" {...register('host')} />
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Port</span>
            <input className="border-2 border-gray-700 rounded px-2 py-1" type="number" {...register('port', { valueAsNumber: true })} />
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Database</span>
            <input className="border-2 border-gray-700 rounded px-2 py-1" {...register('database')} />
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>User</span>
            <input className="border-2 border-gray-700 rounded px-2 py-1" {...register('user')} />
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Password</span>
            <input className="border-2 border-gray-700 rounded px-2 py-1" type="password" autoComplete="off" {...register('password')} />
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>SSL Mode</span>
            <select className="border-2 border-gray-700 rounded px-2 py-1" {...register('sslMode')}>
              <option value="disable">disable</option>
              <option value="require">require</option>
              <option value="verify-ca">verify-ca</option>
              <option value="verify-full">verify-full</option>
            </select>
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Statement Timeout (ms)</span>
            <input className="border-2 border-gray-700 rounded px-2 py-1" type="number" {...register('statementTimeoutMs', { valueAsNumber: true })} />
          </label>
        </div>
        <div className="flex gap-2">
          <button type="button" className="border rounded px-3 py-1" disabled={isSubmitting || dbTestResult.status === 'testing'} onClick={handleSubmit(onTest)}>Test</button>
          <button type="submit" className="border rounded px-3 py-1" disabled={isSubmitting}>Save</button>
        </div>
        {dbTestResult.status !== 'idle' && (
          <div className={`text-xs ${dbTestResult.status === 'ok' ? 'text-success' : dbTestResult.status === 'error' ? 'text-destructive' : 'text-warning'}`}>
            {dbTestResult.message}
          </div>
        )}
      </form>
    </div>
  );
}

================
File: packages/renderer/src/pages/SettingsPage.tsx.tmp
================
import { useCallback, useEffect, useMemo, useState } from 'react';
import { useForm } from 'react-hook-form';
import { zodResolver } from '@hookform/resolvers/zod';
import { z } from 'zod';
import type { DbSettings, Settings, Machine, SaveMachineReq, DbStatus } from '../../../shared/src';
import { CURRENT_SETTINGS_VERSION } from '../../../shared/src';

const schema = z.object({
  host: z.string().default(''),
  port: z.coerce.number().int().min(1).max(65535).default(5432),
  database: z.string().default(''),
  user: z.string().default(''),
  password: z.string().default(''),
  sslMode: z.enum(['disable', 'require', 'verify-ca', 'verify-full']).default('disable'),
  statementTimeoutMs: z.coerce.number().int().min(0).max(600000).default(30000)
});

const DEFAULT_FORM_VALUES: DbSettings = {
  host: '',
  port: 5432,
  database: '',
  user: '',
  password: '', // Will be validated as required by schema
  sslMode: 'disable',
  statementTimeoutMs: 30000
};

type FormValues = z.infer<typeof schema>;
type PathsState = Settings['paths'];
type TestState = Settings['test'];
type GrundnerState = Settings['grundner'];

const DEFAULT_PATHS: PathsState = { processedJobsRoot: '', autoPacCsvDir: '', grundnerFolderPath: '' };
const DEFAULT_TEST: TestState = { testDataFolderPath: '', useTestDataMode: false, sheetIdMode: 'type_data' };
const DEFAULT_GRUNDNER: GrundnerState = { reservedAdjustmentMode: 'delta' };

type PathFieldKey = 'processedJobsRoot' | 'autoPacCsvDir' | 'grundnerFolderPath' | 'testDataFolderPath';
type PathValidationState = { status: 'empty' | 'checking' | 'valid' | 'invalid'; message: string };
type MachinePathKey = 'machineApJobfolder' | 'machineNestpickFolder';

const PATH_STATUS_COLORS: Record<PathValidationState['status'], string> = {
  valid: 'text-success',
  invalid: 'text-destructive',
  checking: 'text-warning',
  empty: 'text-muted-foreground'
};

function createInitialPathStatus(): Record<PathFieldKey, PathValidationState> {
  return {
    processedJobsRoot: { status: 'empty', message: 'Not set' },
    autoPacCsvDir: { status: 'empty', message: 'Not set' },
    grundnerFolderPath: { status: 'empty', message: 'Not set' },
    testDataFolderPath: { status: 'empty', message: 'Not set' }
  };
}

function createInitialMachinePathStatus(): Record<MachinePathKey, PathValidationState> {
  return {
    machineApJobfolder: { status: 'empty', message: 'Select a machine to edit' },
    machineNestpickFolder: { status: 'empty', message: 'Select a machine to edit' }
  };
}

function statusBorderClass(status: PathValidationState) {
  switch (status.status) {
    case 'valid':
      return 'border-success focus:ring-success/40';
    case 'invalid':
      return 'border-destructive focus:ring-destructive/40';
    case 'checking':
      return 'border-warning focus:ring-warning/40';
    default:
      return 'border-border';
  }
}

function withDefaults<T extends object>(defaults: T, value?: Partial<T> | null): T {
  return { ...defaults, ...(value ?? {}) };
}

type ResultEnvelope<T> = { ok: true; value: T } | { ok: false; error: { message: string } };

function extractResult<T>(raw: unknown): ResultEnvelope<T> {
  // Direct value fallback (older stubs or IPC shims)
  if (typeof raw === 'string' || raw === null) {
    return { ok: true, value: raw as unknown as T };
  }

  if (raw && typeof raw === 'object') {
    const obj = raw as Record<string, unknown>;

    // neverthrow-like Result<T,E>
    const hasNtOk = Object.prototype.hasOwnProperty.call(obj, 'isOk');
    const hasNtErr = Object.prototype.hasOwnProperty.call(obj, 'isErr');
    const isNtOkFn = hasNtOk && typeof (obj as { isOk?: unknown }).isOk === 'function';
    const isNtErrFn = hasNtErr && typeof (obj as { isErr?: unknown }).isErr === 'function';
    if (isNtOkFn && isNtErrFn) {
      try {
        const isErr = ((obj as { isErr: () => boolean }).isErr)();
        if (isErr) {
          const errValue = obj.error as { message?: string } | string | undefined;
          const message = typeof errValue === 'string' ? errValue : errValue?.message ?? 'Unknown error';
          return { ok: false, error: { message } };
        }
        const value = (obj as { value?: T }).value as T;
        return { ok: true, value };
      } catch (err) {
        const message = err instanceof Error ? err.message : String(err);
        return { ok: false, error: { message } };
      }
    }

    // Envelope { ok, value | error }
    if (Object.prototype.hasOwnProperty.call(obj, 'ok')) {
      const okFlag = Boolean((obj as { ok?: unknown }).ok as boolean);
      if (okFlag) {
        return { ok: true, value: (obj as { value?: T }).value as T };
      }
      const errValue = (obj as { error?: unknown }).error as { message?: string } | string | undefined;
      const message = typeof errValue === 'string' ? errValue : errValue?.message ?? 'Unknown error';
      return { ok: false, error: { message } };
    }

    // Tolerate boolean-style flags (defensive)
    const maybeIsOk = (obj as { isOk?: unknown }).isOk;
    if (typeof maybeIsOk === 'boolean') {
      const okFlag = Boolean(maybeIsOk);
      if (okFlag) return { ok: true, value: (obj as { value?: T }).value as T };
      const errValue = (obj as { error?: unknown }).error as { message?: string } | string | undefined;
      const message = typeof errValue === 'string' ? errValue : errValue?.message ?? 'Unknown error';
      return { ok: false, error: { message } };
    }
  }

  return { ok: false, error: { message: 'Unexpected response from API' } };
}

export function SettingsPage() {
  const { register, handleSubmit, reset, formState: { isSubmitting } } = useForm<FormValues>({
    resolver: zodResolver(schema),
    defaultValues: DEFAULT_FORM_VALUES
  });

  const [configVersion, setConfigVersion] = useState<number>(CURRENT_SETTINGS_VERSION);
  const [configPath, setConfigPath] = useState<string | null>(null);
  const [machines, setMachines] = useState<Machine[]>([]);
  const [selectedMachineId, setSelectedMachineId] = useState<number | null>(null);
  const [editingMachine, setEditingMachine] = useState<Machine | null>(null);
  const [paths, setPaths] = useState<PathsState>(DEFAULT_PATHS);
  const [testState, setTestState] = useState<TestState>(DEFAULT_TEST);
  const [grundnerState, setGrundnerState] = useState<GrundnerState>(DEFAULT_GRUNDNER);
  const [dbStatus, setDbStatus] = useState<DbStatus | null>(null);
  const [pathStatus, setPathStatus] = useState<Record<PathFieldKey, PathValidationState>>(() => createInitialPathStatus());
  const [machinePathStatus, setMachinePathStatus] = useState<Record<MachinePathKey, PathValidationState>>(() => createInitialMachinePathStatus());
  const [dbTestResult, setDbTestResult] = useState<{ status: 'idle' | 'testing' | 'ok' | 'error'; message: string }>({ status: 'idle', message: '' });

  const lastCheckedLabel = useMemo(() => {
    if (!dbStatus) return null;
    const date = new Date(dbStatus.checkedAt);
    if (Number.isNaN(date.getTime()) || date.getTime() === 0) return null;
    return date.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit', second: '2-digit' });
  }, [dbStatus]);

  const latencyLabel = useMemo(() => {
    return dbStatus?.online && typeof dbStatus.latencyMs === 'number' ? `${dbStatus.latencyMs} ms` : null;
  }, [dbStatus]);

  const statusLabel = useMemo(() => {
    if (!dbStatus) return 'Checking...';
    return dbStatus.online
      ? 'Online'
      : dbStatus.error ? 'Offline' : 'Checking...';
  }, [dbStatus]);

  const hasPathErrors = useMemo(() => Object.values(pathStatus).some((entry) => entry.status === 'invalid'), [pathStatus]);
  const isPathValidationPending = useMemo(() => Object.values(pathStatus).some((entry) => entry.status === 'checking'), [pathStatus]);

  const machineHasErrors = useMemo(() => {
    if (!editingMachine) return false;
    return Object.entries(machinePathStatus).some(([key, state]) => {
      if (key === 'machineNestpickFolder' && !editingMachine.nestpickEnabled) return false;
      return state.status === 'invalid';
    });
  }, [editingMachine, machinePathStatus]);

  const machineValidationPending = useMemo(() => {
    if (!editingMachine) return false;
    return Object.entries(machinePathStatus).some(([key, state]) => {
      if (key === 'machineNestpickFolder' && !editingMachine.nestpickEnabled) return false;
      return state.status === 'checking';
    });
  }, [editingMachine, machinePathStatus]);

  const machineHasBlockingIssues = machineHasErrors || machineValidationPending;

  const statusToneClass = useMemo(() => {
    if (dbStatus?.online) return 'text-success';
    if (dbStatus?.error) return 'text-destructive';
    return 'text-warning';
  }, [dbStatus]);

  const indicatorToneClass = useMemo(() => {
    if (dbStatus?.online) return 'bg-success';
    if (dbStatus?.error) return 'bg-destructive';
    return 'bg-warning';
  }, [dbStatus]);

  const applyMachines = useCallback((items: Machine[], preferredId?: number | null) => {
    setMachines(items);
    if (!items.length) {
      setSelectedMachineId(null);
      setEditingMachine(null);
      return;
    }

    const targetId = preferredId ?? selectedMachineId ?? items[0].machineId;
    const match = items.find((m) => m.machineId === targetId) ?? items[0];
    setSelectedMachineId(match.machineId);
    setEditingMachine({ ...match });
  }, [selectedMachineId]);

  const loadMachines = useCallback(async (preferredId?: number | null) => {
    const raw = await window.api.machines.list();
    const result = extractResult<{ items: Machine[] }>(raw as unknown);
    if (!result.ok) {
      alert(`Failed to load machines: ${result.error.message}`);
      applyMachines([], preferredId);
      return;
    }
    applyMachines(result.value.items, preferredId);
  }, [applyMachines]);

  const loadSettings = useCallback(async () => {
    const settingsRaw = await window.api.settings.get();
    const settingsRes = extractResult<Settings>(settingsRaw as unknown);
    if (!settingsRes.ok) {
      alert(`Failed to load settings: ${settingsRes.error.message}`);
      return;
    }
    const settings = settingsRes.value;
    const pathRaw = await window.api.settings.getPath();
    const pathRes = extractResult<string>(pathRaw as unknown);
    if (pathRes.ok) {
      setConfigPath(pathRes.value);
    }
    setConfigVersion(settings.version ?? CURRENT_SETTINGS_VERSION);
    
    // Merge settings and show password as-is per product decision
    const dbSettings = withDefaults(DEFAULT_FORM_VALUES, settings.db);
    reset(dbSettings);
    setPaths(withDefaults(DEFAULT_PATHS, settings.paths));
    setTestState(withDefaults(DEFAULT_TEST, settings.test));
    setGrundnerState(withDefaults(DEFAULT_GRUNDNER, settings.grundner));
    await loadMachines();
  }, [loadMachines, reset]);

  useEffect(() => {
    void loadSettings();
  }, [loadSettings]);

  useEffect(() => {
    let cancelled = false;
    window.api.db.getStatus()
      .then((raw) => {
        if (cancelled) return;
        const res = extractResult<DbStatus>(raw as unknown);
        if (res.ok) setDbStatus(res.value);
      })
      .catch(() => {});
    const unsubscribe = window.api.db.subscribeStatus((status) => setDbStatus(status));
    return () => {
      cancelled = true;
      unsubscribe?.();
    };
  }, []);

  useEffect(() => {
    const descriptors: Array<{ key: PathFieldKey; value: string; required: boolean }> = [
      { key: 'processedJobsRoot', value: paths.processedJobsRoot ?? '', required: true },
      { key: 'autoPacCsvDir', value: paths.autoPacCsvDir ?? '', required: false },
      { key: 'grundnerFolderPath', value: paths.grundnerFolderPath ?? '', required: false },
      { key: 'testDataFolderPath', value: testState.testDataFolderPath ?? '', required: false }
    ];
    setPathStatus((prev) => {
      const next = { ...prev };
      descriptors.forEach((descriptor) => {
        const trimmed = descriptor.value.trim();
        if (!trimmed) {
          next[descriptor.key] = {
            status: descriptor.required ? 'invalid' : 'empty',
            message: descriptor.required ? 'Required' : 'Not set'
          };
        } else {
          next[descriptor.key] = { status: 'checking', message: 'Checking...' };
        }
      });
      return next;
    });

    let cancelled = false;

    (async () => {
      for (const descriptor of descriptors) {
        const trimmed = descriptor.value.trim();
        if (!trimmed) continue;
        const raw = await window.api.settings.validatePath({ path: trimmed, kind: 'directory' });
        const res = extractResult<{ path: string; exists: boolean; isDirectory: boolean; isFile: boolean; error: string | null }>(raw as unknown);
        if (cancelled) return;
        if (!res.ok) {
          setPathStatus((prev) => ({
            ...prev,
            [descriptor.key]: { status: 'invalid', message: res.error.message }
          }));
          continue;
        }
        const data = res.value;
        const ok = data.exists && data.isDirectory;
        setPathStatus((prev) => ({
          ...prev,
          [descriptor.key]: {
            status: ok ? 'valid' : 'invalid',
            message: ok ? 'Directory found' : data.exists ? 'Not a directory' : 'Directory not found'
          }
        }));
      }
    })();

    return () => {
      cancelled = true;
    };
  }, [paths.processedJobsRoot, paths.autoPacCsvDir, paths.grundnerFolderPath, testState.testDataFolderPath]);

  useEffect(() => {
    if (!editingMachine) {
      setMachinePathStatus(createInitialMachinePathStatus());
      return;
    }

    const descriptors: Array<{ key: MachinePathKey; value: string; required: boolean; disabledMessage?: string }> = [
      { key: 'machineApJobfolder', value: editingMachine.apJobfolder ?? '', required: true },
      { key: 'machineNestpickFolder', value: editingMachine.nestpickFolder ?? '', required: !!editingMachine.nestpickEnabled, disabledMessage: editingMachine.nestpickEnabled ? undefined : 'Nestpick disabled' }
    ];

    setMachinePathStatus((prev) => {
      const next = { ...prev };
      descriptors.forEach((descriptor) => {
        const trimmed = descriptor.value.trim();
        if (!trimmed) {
          const message = descriptor.required
            ? 'Required'
            : descriptor.disabledMessage ?? 'Not set';
          next[descriptor.key] = {
            status: descriptor.required ? 'invalid' : 'empty',
            message
          };
        } else if (descriptor.disabledMessage && !descriptor.required) {
          next[descriptor.key] = { status: 'empty', message: descriptor.disabledMessage };
        } else {
          next[descriptor.key] = { status: 'checking', message: 'Checking...' };
        }
      });
      return next;
    });

    let cancelled = false;

    (async () => {
      for (const descriptor of descriptors) {
        const trimmed = descriptor.value.trim();
        if (!trimmed) continue;
        if (descriptor.disabledMessage && !descriptor.required && !editingMachine.nestpickEnabled) continue;
        const raw = await window.api.settings.validatePath({ path: trimmed, kind: 'directory' });
        const res = extractResult<{ path: string; exists: boolean; isDirectory: boolean; isFile: boolean; error: string | null }>(raw as unknown);
        if (cancelled) return;
        if (!res.ok) {
          setMachinePathStatus((prev) => ({
            ...prev,
            [descriptor.key]: { status: 'invalid', message: res.error.message }
          }));
          continue;
        }
        const data = res.value;
        const ok = data.exists && data.isDirectory;
        setMachinePathStatus((prev) => ({
          ...prev,
          [descriptor.key]: {
            status: ok ? 'valid' : 'invalid',
            message: ok ? 'Directory found' : data.exists ? 'Not a directory' : 'Directory not found'
          }
        }));
      }
    })();

    return () => {
      cancelled = true;
    };
  }, [editingMachine]);

  const onTest = async (values: FormValues) => {
    setDbTestResult({ status: 'testing', message: 'Testing connection...' });
    const res = extractResult<{ ok: true } | { ok: false; error: string }>(
      await window.api.db.testConnection(values as DbSettings)
    );
    if (!res.ok) {
      setDbTestResult({ status: 'error', message: res.error.message });
      return;
    }
    if (res.value.ok) {
      setDbTestResult({ status: 'ok', message: 'Connection OK' });
    } else {
      setDbTestResult({ status: 'error', message: res.value.error ?? 'Unknown error' });
    }
  };

  const onSave = async (values: FormValues) => {
    const next: Settings = {
      version: configVersion,
      db: values as DbSettings,
      paths,
      test: testState,
      grundner: grundnerState
    };
    const saved = extractResult<Settings>(await window.api.settings.save(next));
    if (!saved.ok) {
      alert(`Failed to save settings: ${saved.error.message}`);
      return;
    }
    setConfigVersion(saved.value.version ?? CURRENT_SETTINGS_VERSION);
    await loadSettings();
    setDbTestResult({ status: 'idle', message: '' });
    alert('Settings saved');
  };

  const addMachine = async () => {
    const createdRaw = await window.api.machines.save({
      name: 'New Machine',
      apJobfolder: '',
      nestpickFolder: '',
      nestpickEnabled: true,
      pcPort: 5000
    });
    const created = extractResult<Machine>(createdRaw as unknown);
    if (!created.ok) {
      alert(`Failed to create machine: ${created.error.message}`);
      return;
    }
    await loadMachines(created.value.machineId ?? undefined);
  };

  const saveMachine = async () => {
    if (!editingMachine) return;
    if (machineHasBlockingIssues) {
      alert('Machine folder validation is pending or has errors.');
      return;
    }

    const payload: SaveMachineReq = {
      machineId: editingMachine.machineId,
      name: editingMachine.name,
      pcIp: editingMachine.pcIp ?? null,
      cncIp: editingMachine.cncIp ?? null,
      cncPort: editingMachine.cncPort ?? null,
      apJobfolder: editingMachine.apJobfolder,
      nestpickFolder: editingMachine.nestpickFolder,
      nestpickEnabled: editingMachine.nestpickEnabled,
      pcPort: editingMachine.pcPort
    };

    const raw = await window.api.machines.save(payload);
    const res = extractResult<Machine>(raw as unknown);
    if (!res.ok) {
      alert(`Failed to save machine: ${res.error.message}`);
      return;
    }
    await loadMachines(editingMachine.machineId);
  };

  const deleteMachine = async () => {
    if (selectedMachineId == null) return;
    if (!confirm('Delete this machine?')) return;
    const raw = await window.api.machines.delete(selectedMachineId);
    const res = extractResult<null>(raw as unknown);
    if (!res.ok) {
      alert(`Failed to delete machine: ${res.error.message}`);
      return;
    }
    await loadMachines();
  };

  const handleSelectMachine = (machineId: number) => {
    const machine = machines.find((m) => m.machineId === machineId);
    if (!machine) return;
    setSelectedMachineId(machine.machineId);
    setEditingMachine({ ...machine });
  };

  const browseFolder = async (setter: (value: string) => void, initial?: string) => {
    try {
      const raw = await window.api.dialog.pickFolder();
      const res = extractResult<string | null>(raw as unknown);
      if (!res.ok) {
        alert(`Failed to open folder picker: ${res.error.message}`);
        console.error('Folder picker error', res.error.message);
        return;
      }
      const value = res.value;
      if (value) {
        console.debug('Picked folder:', value);
        setter(value);
      } else if (initial !== undefined) {
        console.debug('Picker cancelled, keeping initial:', initial);
        setter(initial);
      }
    } catch (err) {
      const msg = err instanceof Error ? err.message : String(err);
      alert(`Failed to open folder picker: ${msg}`);
      console.error('Folder picker error', msg);
    }
  };

  return (
    <div className="space-section max-w-6xl">
      <div className="mb-6">
        <h1 className="text-3xl font-bold text-foreground">Settings</h1>
        {configPath && (
          <div className="text-sm text-muted-foreground mt-2 break-all">Config file: {configPath}</div>
        )}
      </div>

      <div className="grid grid-cols-[320px_1fr] gap-6">
        <div className="card p-4 h-[320px]">
          <div className="flex justify-between items-center mb-4">
            <h3 className="font-semibold text-foreground">Machines</h3>
            <button type="button" className="btn-secondary text-sm" onClick={addMachine}>Add</button>
          </div>
          <div className="h-[calc(100%-2.5rem)] overflow-auto">
            <ul className="space-y-1">
              {machines.map((machine) => (
                <li key={machine.machineId}>
                  <button
                    type="button"
                    className={`w-full text-left px-3 py-2 rounded-lg text-sm transition-colors ${
                      machine.machineId === selectedMachineId
                        ? 'bg-primary text-primary-foreground'
                        : 'hover:bg-muted text-foreground'
                    }`}
                    onClick={() => handleSelectMachine(machine.machineId)}
                  >
                    {machine.name}
                  </button>
                </li>
              ))}
              {!machines.length && <li className="text-sm text-muted-foreground p-2">No machines configured yet.</li>}
            </ul>
          </div>
        </div>

        <div className="card p-6 space-y-4">
          <h3 className="font-semibold text-foreground">Machine Details</h3>
          {machineHasErrors ? (
            <div className="text-sm text-destructive">Fix required machine folders before saving.</div>
          ) : machineValidationPending ? (
            <div className="text-sm text-warning">Validating machine folders...</div>
          ) : null}
          {editingMachine ? (
            <div className="grid grid-cols-2 gap-3">
              <label className="form-label">
                <span>Name</span>
                <input
                  className="form-input"
                  value={editingMachine.name}
                  onChange={(e) => setEditingMachine((prev) => prev ? { ...prev, name: e.target.value } : prev)}
                />
              </label>
              <label className="form-label">
                <span>PC IP</span>
                <input
                  className="form-input"
                  value={editingMachine.pcIp ?? ''}
                  onChange={(e) => setEditingMachine((prev) => prev ? { ...prev, pcIp: e.target.value || null } : prev)}
                />
              </label>
              <label className="form-label">
                <span>CNC IP</span>
                <input
                  className="form-input"
                  value={editingMachine.cncIp ?? ''}
                  onChange={(e) => setEditingMachine((prev) => prev ? { ...prev, cncIp: e.target.value || null } : prev)}
                />
              </label>
              <label className="form-label">
                <span>CNC Port</span>
                <input
                  className="form-input"
                  type="number"
                  value={editingMachine.cncPort ?? ''}
                  onChange={(e) => setEditingMachine((prev) => prev ? {
                    ...prev,
                    cncPort: e.target.value === '' ? null : Number(e.target.value)
                  } : prev)}
                />
              </label>
              <div className="col-span-2">
                <label className="form-label">
                  <span>Ready-To-Run Folder</span>
                  <div className="flex gap-2 items-start">
                    <input
                      className={`form-input flex-1 ${statusBorderClass(machinePathStatus.machineApJobfolder)}`}
                      value={editingMachine.apJobfolder}
                      onChange={(e) => setEditingMachine((prev) => prev ? { ...prev, apJobfolder: e.target.value } : prev)}
                    />
                    <button
                      type="button"
                      className="btn-secondary whitespace-nowrap"
                      onClick={() => browseFolder((value) => setEditingMachine((prev) => prev ? { ...prev, apJobfolder: value } : prev), editingMachine.apJobfolder)}
                    >
                      Browse
                    </button>
                  </div>
                  <span className={`text-xs ${PATH_STATUS_COLORS[machinePathStatus.machineApJobfolder.status]}`}>
                    {machinePathStatus.machineApJobfolder.message}
                  </span>
                </label>
              </div>
              <div className="col-span-2">
                <label className="form-label">
                  <span>Nestpick Folder</span>
                  <div className="flex gap-2 items-start">
                    <input
                      className={`form-input flex-1 ${statusBorderClass(machinePathStatus.machineNestpickFolder)}`}
                      value={editingMachine.nestpickFolder}
                      onChange={(e) => setEditingMachine((prev) => prev ? { ...prev, nestpickFolder: e.target.value } : prev)}
                    />
                    <button
                      type="button"
                      className="btn-secondary whitespace-nowrap"
                      onClick={() => browseFolder((value) => setEditingMachine((prev) => prev ? { ...prev, nestpickFolder: value } : prev), editingMachine.nestpickFolder)}
                    >
                      Browse
                    </button>
                  </div>
                  <span className={`text-xs ${PATH_STATUS_COLORS[machinePathStatus.machineNestpickFolder.status]}`}>
                    {machinePathStatus.machineNestpickFolder.message}
                  </span>
                </label>
              </div>
              <label className="form-label">
                <span>Nestpick Enabled</span>
                <select
                  className="form-input"
                  value={editingMachine.nestpickEnabled ? 'true' : 'false'}
                  onChange={(e) => setEditingMachine((prev) => prev ? { ...prev, nestpickEnabled: e.target.value === 'true' } : prev)}
                >
                  <option value="true">Yes</option>
                  <option value="false">No</option>
                </select>
              </label>
              <label className="form-label">
                <span>PC Port</span>
                <input
                  className="form-input"
                  type="number"
                  value={editingMachine.pcPort}
                  onChange={(e) => {
                    const val = e.target.value;
                    if (val === '') {
                      setEditingMachine((prev) => prev ? { ...prev, pcPort: prev.pcPort } : prev);
                    } else {
                      const numVal = Number(val);
                      setEditingMachine((prev) => prev ? { ...prev, pcPort: isNaN(numVal) ? prev.pcPort : numVal } : prev);
                    }
                  }}
                />
              </label>
            </div>
          ) : (
            <div className="text-sm text-muted-foreground p-4 text-center">Select a machine to edit</div>
          )}
          <div className="flex gap-3 pt-2">
            <button type="button" className="btn-primary" onClick={saveMachine} disabled={!editingMachine || machineHasBlockingIssues}>Save Machine</button>
            <button type="button" className="btn-secondary" onClick={deleteMachine} disabled={selectedMachineId == null}>Delete</button>
          </div>
        </div>
      </div>

      <div className="grid grid-cols-[320px_1fr] gap-6">
        <div className="card p-6 space-y-4">
          <h3 className="font-semibold text-foreground">Paths</h3>
          {hasPathErrors ? (
            <div className="text-sm text-destructive">Some paths are missing; update as needed.</div>
          ) : isPathValidationPending ? (
            <div className="text-sm text-warning">Validating paths...</div>
          ) : null}
          <label className="flex flex-col gap-1 text-sm">
            <span>Processed Jobs Root</span>
            <div className="flex gap-2 items-start">
              <input
                className={`border rounded px-2 py-1 w-full ${statusBorderClass(pathStatus.processedJobsRoot)}`}
                value={paths.processedJobsRoot}
                onChange={(e) => setPaths({ ...paths, processedJobsRoot: e.target.value })}
              />
              <button
                type="button"
                className="border rounded px-2"
                onClick={() => browseFolder((value) => setPaths((prev) => ({ ...prev, processedJobsRoot: value })), paths.processedJobsRoot)}
              >
                Browse
              </button>
            </div>
            <span className={`text-xs ${PATH_STATUS_COLORS[pathStatus.processedJobsRoot.status]}`}>
              {pathStatus.processedJobsRoot.message}
            </span>
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>AutoPAC CSV Directory</span>
            <div className="flex gap-2 items-start">
              <input
                className={`border rounded px-2 py-1 w-full ${statusBorderClass(pathStatus.autoPacCsvDir)}`}
                value={paths.autoPacCsvDir}
                onChange={(e) => setPaths({ ...paths, autoPacCsvDir: e.target.value })}
              />
              <button
                type="button"
                className="border rounded px-2"
                onClick={() => browseFolder((value) => setPaths((prev) => ({ ...prev, autoPacCsvDir: value })), paths.autoPacCsvDir)}
              >
                Browse
              </button>
            </div>
            <span className={`text-xs ${PATH_STATUS_COLORS[pathStatus.autoPacCsvDir.status]}`}>
              {pathStatus.autoPacCsvDir.message}
            </span>
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Grundner Folder</span>
            <div className="flex gap-2 items-start">
              <input
                className={`border rounded px-2 py-1 w-full ${statusBorderClass(pathStatus.grundnerFolderPath)}`}
                value={paths.grundnerFolderPath}
                onChange={(e) => setPaths({ ...paths, grundnerFolderPath: e.target.value })}
              />
              <button
                type="button"
                className="border rounded px-2"
                onClick={() => browseFolder((value) => setPaths((prev) => ({ ...prev, grundnerFolderPath: value })), paths.grundnerFolderPath)}
              >
                Browse
              </button>
            </div>
            <span className={`text-xs ${PATH_STATUS_COLORS[pathStatus.grundnerFolderPath.status]}`}>
              {pathStatus.grundnerFolderPath.message}
            </span>
          </label>
        </div>

        <div className="card p-6 space-y-4">
          <h3 className="font-semibold text-foreground">Test / Grundner</h3>
          <label className="flex flex-col gap-1 text-sm">
            <span>Test Data Folder</span>
            <div className="flex gap-2 items-start">
              <input
                className={`border rounded px-2 py-1 w-full ${statusBorderClass(pathStatus.testDataFolderPath)}`}
                value={testState.testDataFolderPath}
                onChange={(e) => setTestState({ ...testState, testDataFolderPath: e.target.value })}
              />
              <button
                type="button"
                className="border rounded px-2"
                onClick={() => browseFolder((value) => setTestState((prev) => ({ ...prev, testDataFolderPath: value })), testState.testDataFolderPath)}
              >
                Browse
              </button>
            </div>
            <span className={`text-xs ${PATH_STATUS_COLORS[pathStatus.testDataFolderPath.status]}`}>
              {pathStatus.testDataFolderPath.message}
            </span>
          </label>
          <label className="flex items-center gap-2 text-sm">
            <input
              type="checkbox"
              checked={testState.useTestDataMode}
              onChange={(e) => setTestState({ ...testState, useTestDataMode: e.target.checked })}
            />
            Use test data mode
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Sheet ID Mode</span>
            <select
              className="border rounded px-2 py-1"
              value={testState.sheetIdMode}
              onChange={(e) => setTestState({ ...testState, sheetIdMode: e.target.value as TestState['sheetIdMode'] })}
            >
              <option value="type_data">type_data</option>
              <option value="customer_id">customer_id</option>
            </select>
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Grundner Reserved Mode</span>
            <select
              className="border rounded px-2 py-1"
              value={grundnerState.reservedAdjustmentMode}
              onChange={(e) => setGrundnerState({ reservedAdjustmentMode: e.target.value as GrundnerState['reservedAdjustmentMode'] })}
            >
              <option value="delta">delta</option>
              <option value="absolute">absolute</option>
            </select>
          </label>
        </div>
      </div>

      <form className="space-y-3 border rounded p-3" onSubmit={handleSubmit(onSave)}>
        <div className="flex items-center justify-between">
          <h2 className="font-medium text-lg" id="db-settings-heading">Database</h2>
          {dbStatus && (
            <div
              className="flex items-center gap-2 text-sm"
              title={!dbStatus.online && dbStatus.error ? dbStatus.error : undefined}
            >
              <span
                className={`h-2.5 w-2.5 rounded-full ${indicatorToneClass}`}
                aria-hidden
              />
              <span className={statusToneClass}>
                {statusLabel}
              </span>
              {lastCheckedLabel && (
                <span className="text-muted-foreground">{lastCheckedLabel}</span>
              )}
              {latencyLabel && (
                <span className="text-muted-foreground">{latencyLabel}</span>
              )}
              {!dbStatus.online && dbStatus.error && (
                <span className="text-xs text-muted-foreground max-w-[220px] truncate">
                  {dbStatus.error}
                </span>
              )}
            </div>
          )}
        </div>
        <div className="grid grid-cols-2 gap-3">
          <label className="flex flex-col gap-1 text-sm">
            <span>Host</span>
            <input className="border rounded px-2 py-1" {...register('host')} />
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Port</span>
            <input className="border rounded px-2 py-1" type="number" {...register('port', { valueAsNumber: true })} />
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Database</span>
            <input className="border rounded px-2 py-1" {...register('database')} />
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>User</span>
            <input className="border rounded px-2 py-1" {...register('user')} />
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Password</span>
            <input className="border rounded px-2 py-1" type="password" autoComplete="off" {...register('password')} />
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>SSL Mode</span>
            <select className="border rounded px-2 py-1" {...register('sslMode')}>
              <option value="disable">disable</option>
              <option value="require">require</option>
              <option value="verify-ca">verify-ca</option>
              <option value="verify-full">verify-full</option>
            </select>
          </label>
          <label className="flex flex-col gap-1 text-sm">
            <span>Statement Timeout (ms)</span>
            <input className="border rounded px-2 py-1" type="number" {...register('statementTimeoutMs', { valueAsNumber: true })} />
          </label>
        </div>
        <div className="flex gap-2">
          <button type="button" className="border rounded px-3 py-1" disabled={isSubmitting || dbTestResult.status === 'testing'} onClick={handleSubmit(onTest)}>Test</button>
          <button type="submit" className="border rounded px-3 py-1" disabled={isSubmitting}>Save</button>
        </div>
        {dbTestResult.status !== 'idle' && (
          <div className={`text-xs ${dbTestResult.status === 'ok' ? 'text-success' : dbTestResult.status === 'error' ? 'text-destructive' : 'text-warning'}`}>
            {dbTestResult.message}
          </div>
        )}
      </form>
    </div>
  );
}

================
File: packages/renderer/src/pages/TelemetryPage.tsx
================
import { useEffect, useMemo, useState } from 'react';
import type { Machine, TelemetrySummaryRes } from '../../../shared/src';
import { PieChart, Pie, Cell, Tooltip, Legend, ResponsiveContainer } from 'recharts';
import type { LegendProps } from 'recharts';

type Filters = {
  from: string;
  to: string;
  machineIds: number[] | 'all';
};

const COLORS = {
  BUSY: '#22c55e', // green
  READY: '#3b82f6', // blue
  'B-STOP': '#f97316', // orange
  ALARM_EMG: '#ef4444', // red
  OTHER: '#6b7280' // gray
};

function toIsoDateTimeBoundary(dateStr: string, endOfDay: boolean): string | undefined {
  if (!dateStr) return undefined;
  return endOfDay ? `${dateStr}T23:59:59.999Z` : `${dateStr}T00:00:00.000Z`;
}

function sumSeconds(item: TelemetrySummaryRes['items'][number]) {
  const s = item.seconds;
  return s.READY + s['B-STOP'] + s.BUSY + s.ALARM + s.EMG + s.OTHER;
}

function defaultDateRange(): { from: string; to: string } {
  const to = new Date();
  const from = new Date(to);
  from.setMonth(from.getMonth() - 1);
  const toStr = `${to.getFullYear()}-${String(to.getMonth() + 1).padStart(2, '0')}-${String(to.getDate()).padStart(2, '0')}`;
  const fromStr = `${from.getFullYear()}-${String(from.getMonth() + 1).padStart(2, '0')}-${String(from.getDate()).padStart(2, '0')}`;
  return { from: fromStr, to: toStr };
}

export function TelemetryPage() {
  const [machines, setMachines] = useState<Machine[]>([]);
  const [filters, setFilters] = useState<Filters>({ ...defaultDateRange(), machineIds: 'all' });
  const [data, setData] = useState<TelemetrySummaryRes | null>(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const { from: filterFrom, to: filterTo, machineIds } = filters;

  useEffect(() => {
    (async () => {
      const res = await window.api.machines.list();
      if (res.ok) setMachines(res.value.items);
    })();
  }, []);

  useEffect(() => {
    setLoading(true);
    setError(null);
    const req: { from?: string; to?: string; machineIds?: number[] } = {};
    if (filterFrom) req.from = toIsoDateTimeBoundary(filterFrom, false);
    if (filterTo) req.to = toIsoDateTimeBoundary(filterTo, true);
    if (machineIds !== 'all') req.machineIds = machineIds;
    // eslint-disable-next-line no-console
    console.log('telemetry: subscribe', req);
    const unsubscribe = window.api.telemetry.subscribe(req, (payload) => {
      try {
        // Dev console visibility
        // eslint-disable-next-line no-console
        console.log('telemetry:update', payload);
      } catch { /* noop */ void 0; }
      setData(payload);
      setLoading(false);
    });
    return () => unsubscribe();
  }, [filterFrom, filterTo, machineIds]);

  const selectedMachineIds = useMemo(() => {
    if (machineIds === 'all') return new Set(machines.map((m) => m.machineId));
    return new Set(machineIds);
  }, [machineIds, machines]);

  const visibleItems = useMemo(() => {
    const items = data?.items ?? [];
    return items.filter((i) => i.machineId != null && selectedMachineIds.has(i.machineId));
  }, [data, selectedMachineIds]);

  const aggregate = useMemo(() => {
    const agg = { READY: 0, 'B-STOP': 0, BUSY: 0, ALARM: 0, EMG: 0, OTHER: 0 };
    for (const it of visibleItems) {
      const s = it.seconds;
      agg.READY += s.READY;
      agg['B-STOP'] += s['B-STOP'];
      agg.BUSY += s.BUSY;
      agg.ALARM += s.ALARM;
      agg.EMG += s.EMG;
      agg.OTHER += s.OTHER;
    }
    return agg;
  }, [visibleItems]);

  const onlyOne = visibleItems.length === 1;

  function buildChartData(seconds: { READY: number; 'B-STOP': number; BUSY: number; ALARM: number; EMG: number; OTHER: number }) {
    const red = seconds.ALARM + seconds.EMG;
    const items = [
      { name: 'Busy', key: 'BUSY', value: seconds.BUSY, color: COLORS.BUSY },
      { name: 'Ready', key: 'READY', value: seconds.READY, color: COLORS.READY },
      { name: 'B-Stop', key: 'B-STOP', value: seconds['B-STOP'], color: COLORS['B-STOP'] },
      { name: 'Alarm/EMG', key: 'ALARM_EMG', value: red, color: COLORS.ALARM_EMG },
      { name: 'Other', key: 'OTHER', value: seconds.OTHER, color: COLORS.OTHER }
    ];
    return items.filter((d) => d.value > 0);
  }

  function formatPct(value: number, total: number) {
    if (total <= 0) return '0%';
    return `${Math.round((value / total) * 100)}%`;
  }

  function MachinePie({ name, seconds }: { name: string; seconds: { READY: number; 'B-STOP': number; BUSY: number; ALARM: number; EMG: number; OTHER: number } }) {
    const dataset = buildChartData(seconds);
    const total = dataset.reduce((acc, d) => acc + d.value, 0);
    return (
      <div className="border rounded p-3">
        <div className="text-sm font-medium mb-2">{name}</div>
        <div className="w-full h-72">
          <ResponsiveContainer>
            <PieChart>
              <Pie dataKey="value" data={dataset} outerRadius={160}>
                {dataset.map((entry, index) => (
                  <Cell key={`cell-${index}`} fill={entry.color} />
                ))}
              </Pie>
              <Tooltip formatter={(v: unknown) => `${String(v)} sec`} />
              <Legend
                formatter={((value, entry) => {
                  const payloadKey = typeof entry === 'object' && entry && 'payload' in entry
                    ? (entry as { payload?: { key?: string } }).payload?.key
                    : undefined;
                  const item = dataset.find((d) => d.key === payloadKey);
                  return `${String(value)} ${item ? formatPct(item.value, total) : ''}`;
                }) as LegendProps['formatter']}
              />
            </PieChart>
          </ResponsiveContainer>
        </div>
      </div>
    );
  }

  return (
    <div className="p-4 space-y-3">
      <h1 className="text-xl font-semibold">CNC Telemetry</h1>

      <div className="grid grid-cols-1 md:grid-cols-4 gap-3">
        <label className="text-sm flex flex-col gap-1">
          <span>From</span>
          <input
            type="date"
            className="border rounded px-2 py-1"
            value={filters.from}
            onChange={(e) => setFilters((prev) => ({ ...prev, from: e.target.value }))}
          />
        </label>
        <label className="text-sm flex flex-col gap-1">
          <span>To</span>
          <input
            type="date"
            className="border rounded px-2 py-1"
            value={filters.to}
            onChange={(e) => setFilters((prev) => ({ ...prev, to: e.target.value }))}
          />
        </label>
        <div className="md:col-span-2">
          <div className="text-sm">Machines</div>
          <div className="flex flex-wrap gap-3 mt-1">
            <label className="inline-flex items-center gap-1 text-sm">
              <input
                type="checkbox"
                checked={machineIds === 'all'}
                onChange={(e) => setFilters((prev) => ({ ...prev, machineIds: e.target.checked ? 'all' : [] }))}
              />
              All
            </label>
            {machines.map((m) => {
              const isAll = machineIds === 'all';
              const checked = isAll ? true : machineIds.includes(m.machineId);
              return (
                <label key={m.machineId} className="inline-flex items-center gap-1 text-sm">
                  <input
                    type="checkbox"
                    checked={checked}
                    onChange={(e) =>
                      setFilters((prev) => {
                        if (prev.machineIds === 'all') return { ...prev, machineIds: [m.machineId] };
                        const ids = new Set(prev.machineIds as number[]);
                        if (e.target.checked) ids.add(m.machineId);
                        else ids.delete(m.machineId);
                        return { ...prev, machineIds: Array.from(ids) };
                      })
                    }
                  />
                  {m.name}
                </label>
              );
            })}
          </div>
        </div>
      </div>

      {error && <div className="border border-red-300 bg-red-50 text-red-700 text-sm px-3 py-2 rounded">{error}</div>}
      {loading && <div className="text-sm text-muted-foreground">Loading...</div>}
      {!loading && data && data.items.length > 0 && visibleItems.length === 0 && (
        <div className="border border-amber-300 bg-amber-50 text-amber-700 text-sm px-3 py-2 rounded">
          No machine mapping found for the selected filters. Ensure machine PC IP matches cncstats API IP.
        </div>
      )}

      {!onlyOne && (
        <div className="border rounded p-4">
          <div className="text-sm font-medium mb-2">Aggregated</div>
          <div className="w-full h-96">
            <ResponsiveContainer>
              <PieChart>
                <Pie dataKey="value" data={buildChartData(aggregate)} outerRadius={220}>
                  {buildChartData(aggregate).map((entry, index) => (
                    <Cell key={`agg-${index}`} fill={entry.color} />
                  ))}
                </Pie>
                <Tooltip formatter={(v: unknown) => `${String(v)} sec`} />
                <Legend />
              </PieChart>
            </ResponsiveContainer>
          </div>
        </div>
      )}

      <div className="grid md:grid-cols-1 lg:grid-cols-2 gap-3">
        {visibleItems
          .sort((a, b) => sumSeconds(b) - sumSeconds(a))
          .map((it) => (
            <MachinePie key={it.machineId ?? -1} name={it.machineName ?? `Machine ${it.machineId}`} seconds={it.seconds} />
          ))}
      </div>
    </div>
  );
}

export default TelemetryPage;

================
File: packages/renderer/src/pages/Theme.tsx
================
import React from 'react';
import { Table, TableBody, TableCell, TableHead, TableHeader, TableRow } from '@/components/ui/table';

export default function Theme() {
  return (
    <div className="space-y-4">
      <h1 className="text-xl font-semibold">Theme</h1>
      <div className="grid gap-3 md:grid-cols-3">
        <div className="rounded border bg-card text-card-foreground p-4 space-y-2">
          <div className="font-medium">Buttons</div>
          <div className="space-x-2">
            <button className="rounded border border-border bg-primary px-3 py-1 text-primary-foreground">Primary</button>
            <button className="rounded border border-border bg-secondary px-3 py-1 text-secondary-foreground">Secondary</button>
            <button className="rounded border border-border bg-destructive px-3 py-1 text-destructive-foreground">Destructive</button>
            <button className="rounded border border-border px-3 py-1">Outline</button>
          </div>
        </div>
        <div className="rounded border bg-card text-card-foreground p-4 space-y-2">
          <div className="font-medium">Forms</div>
          <input className="w-full rounded border border-input bg-background px-3 py-1 text-sm placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring" placeholder="Placeholder text" />
          <div className="text-sm text-muted-foreground">Muted foreground sample</div>
        </div>
        <div className="rounded border bg-card text-card-foreground p-4 space-y-2">
          <div className="font-medium">Surfaces</div>
          <div className="rounded border bg-accent p-2">bg-accent</div>
          <div className="rounded border bg-muted p-2">bg-muted</div>
          <div className="rounded border p-2">bg-card (this block)</div>
        </div>
      </div>
      <div className="rounded border p-4 bg-table text-[var(--table-text)]">
        <Table>
          <TableHeader>
            <TableRow>
              <TableHead className="px-2 py-1">Role</TableHead>
              <TableHead className="px-2 py-1">Class</TableHead>
            </TableRow>
          </TableHeader>
          <TableBody>
            {[
              ['Background', 'bg-background'],
              ['Foreground', 'text-foreground'],
              ['Border', 'border-border'],
              ['Muted', 'bg-muted / text-muted-foreground'],
              ['Primary', 'bg-primary / text-primary-foreground'],
              ['Secondary', 'bg-secondary / text-secondary-foreground'],
              ['Destructive', 'text-destructive / bg-destructive'],
              ['Ring', 'focus-visible:ring-ring']
            ].map(([label, cls]) => (
              <TableRow key={label}>
                <TableCell className="px-2 py-1">{label}</TableCell>
                <TableCell className="px-2 py-1 font-mono text-xs">{cls}</TableCell>
              </TableRow>
            ))}
          </TableBody>
        </Table>
      </div>
    </div>
  );
}

================
File: packages/renderer/src/pages/ThemeShowcase.tsx
================
import React from 'react';
import { Button } from '@/components/ui/button';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';
import { Separator } from '@/components/ui/separator';
import { Table, TableBody, TableCell, TableHead, TableHeader, TableRow } from '@/components/ui/table';

export default function ThemeShowcase() {
  return (
    <div className="min-h-screen bg-background p-8">
      <div className="max-w-6xl mx-auto space-y-8">
        {/* Header */}
        <div className="text-center space-y-4">
          <h1 className="text-4xl font-bold text-foreground">Modern Theme Showcase</h1>
          <p className="text-lg text-muted-foreground">
            Experience the new modern design system with enhanced colors and interactions
          </p>
        </div>

        {/* Color Palette */}
        <Card>
          <CardHeader>
            <CardTitle>Color Palette</CardTitle>
          </CardHeader>
          <CardContent className="space-y-6">
            {/* Primary Colors */}
            <div>
              <h3 className="text-lg font-semibold mb-3">Primary (Indigo)</h3>
              <div className="flex flex-wrap gap-2">
                <Badge className="bg-primary-50 text-primary-900 border-primary-200">50</Badge>
                <Badge className="bg-primary-100 text-primary-900 border-primary-300">100</Badge>
                <Badge className="bg-primary-200 text-primary-900 border-primary-400">200</Badge>
                <Badge className="bg-primary-300 text-primary-900 border-primary-500">300</Badge>
                <Badge className="bg-primary-400 text-white border-primary-600">400</Badge>
                <Badge className="bg-primary-500 text-white border-primary-700">500</Badge>
                <Badge className="bg-primary-600 text-white border-primary-800">600</Badge>
                <Badge className="bg-primary-700 text-white border-primary-900">700</Badge>
                <Badge className="bg-primary-800 text-white border-primary-950">800</Badge>
                <Badge className="bg-primary-900 text-white border-primary-950">900</Badge>
              </div>
            </div>

            {/* Secondary Colors */}
            <div>
              <h3 className="text-lg font-semibold mb-3">Secondary (Emerald)</h3>
              <div className="flex flex-wrap gap-2">
                <Badge className="bg-secondary-50 text-secondary-900 border-secondary-200">50</Badge>
                <Badge className="bg-secondary-100 text-secondary-900 border-secondary-300">100</Badge>
                <Badge className="bg-secondary-200 text-secondary-900 border-secondary-400">200</Badge>
                <Badge className="bg-secondary-300 text-secondary-900 border-secondary-500">300</Badge>
                <Badge className="bg-secondary-400 text-white border-secondary-600">400</Badge>
                <Badge className="bg-secondary-500 text-white border-secondary-700">500</Badge>
                <Badge className="bg-secondary-600 text-white border-secondary-800">600</Badge>
                <Badge className="bg-secondary-700 text-white border-secondary-900">700</Badge>
                <Badge className="bg-secondary-800 text-white border-secondary-900">800</Badge>
                <Badge className="bg-secondary-900 text-white border-secondary-900">900</Badge>
              </div>
            </div>

            {/* Neutral Colors */}
            <div>
              <h3 className="text-lg font-semibold mb-3">Neutral (Slate)</h3>
              <div className="flex flex-wrap gap-2">
                <Badge className="bg-neutral-50 text-neutral-900 border-neutral-200">50</Badge>
                <Badge className="bg-neutral-100 text-neutral-900 border-neutral-300">100</Badge>
                <Badge className="bg-neutral-200 text-neutral-900 border-neutral-400">200</Badge>
                <Badge className="bg-neutral-300 text-neutral-900 border-neutral-500">300</Badge>
                <Badge className="bg-neutral-400 text-white border-neutral-600">400</Badge>
                <Badge className="bg-neutral-500 text-white border-neutral-700">500</Badge>
                <Badge className="bg-neutral-600 text-white border-neutral-800">600</Badge>
                <Badge className="bg-neutral-700 text-white border-neutral-900">700</Badge>
                <Badge className="bg-neutral-800 text-white border-neutral-900">800</Badge>
                <Badge className="bg-neutral-900 text-white border-neutral-950">900</Badge>
              </div>
            </div>
          </CardContent>
        </Card>

        {/* Buttons */}
        <Card>
          <CardHeader>
            <CardTitle>Interactive Elements</CardTitle>
          </CardHeader>
          <CardContent className="space-y-6">
            <div>
              <h3 className="text-lg font-semibold mb-3">Buttons with Modern Hover Effects</h3>
              <div className="flex flex-wrap gap-3">
                <Button variant="default">Primary Button</Button>
                <Button variant="secondary">Secondary Button</Button>
                <Button variant="outline">Outline Button</Button>
                <Button variant="ghost">Ghost Button</Button>
                <Button variant="destructive">Destructive Button</Button>
                <Button variant="link">Link Button</Button>
              </div>
            </div>

            <Separator />

            <div>
              <h3 className="text-lg font-semibold mb-3">Button Sizes</h3>
              <div className="flex flex-wrap items-center gap-3">
                <Button size="sm">Small</Button>
                <Button size="default">Default</Button>
                <Button size="lg">Large</Button>
                <Button size="icon">⚙️</Button>
              </div>
            </div>
          </CardContent>
        </Card>

        {/* Cards */}
        <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
          <Card className="dashboard-card">
            <CardHeader>
              <CardTitle>Dashboard Card</CardTitle>
            </CardHeader>
            <CardContent>
              <p className="text-muted-foreground">
                This card has enhanced hover effects with a gradient top border and smooth transitions.
              </p>
            </CardContent>
          </Card>

          <Card className="glass-card">
            <CardHeader>
              <CardTitle>Glass Card</CardTitle>
            </CardHeader>
            <CardContent>
              <p className="text-muted-foreground">
                This card features a modern glass morphism effect with backdrop blur.
              </p>
            </CardContent>
          </Card>

          <Card>
            <CardHeader>
              <CardTitle>Standard Card</CardTitle>
            </CardHeader>
            <CardContent>
              <p className="text-muted-foreground">
                A standard card with subtle shadows and hover effects.
              </p>
            </CardContent>
          </Card>
        </div>

        {/* Form Elements */}
        <Card>
          <CardHeader>
            <CardTitle>Form Elements</CardTitle>
          </CardHeader>
          <CardContent className="space-y-4">
            <div className="form-label">
              <label htmlFor="sample-input">Sample Input</label>
              <input
                id="sample-input"
                type="text"
                className="form-input"
                placeholder="Type something here..."
              />
            </div>
            <div className="form-label">
              <label htmlFor="sample-textarea">Sample Textarea</label>
              <textarea
                id="sample-textarea"
                className="form-input"
                rows={3}
                placeholder="Enter your message..."
              />
            </div>
          </CardContent>
        </Card>

        {/* Status Indicators */}
        <Card>
          <CardHeader>
            <CardTitle>Status Indicators</CardTitle>
          </CardHeader>
          <CardContent>
            <div className="flex flex-wrap gap-4">
              <div className="status-indicator success">
                <div className="w-2 h-2 rounded-full bg-current"></div>
                Success Status
              </div>
              <div className="status-indicator warning">
                <div className="w-2 h-2 rounded-full bg-current"></div>
                Warning Status
              </div>
              <div className="status-indicator error">
                <div className="w-2 h-2 rounded-full bg-current"></div>
                Error Status
        </div>
      </div>
          </CardContent>
        </Card>

        {/* Table Example */}
        <Card>
          <CardHeader>
            <CardTitle>Modern Table</CardTitle>
          </CardHeader>
          <CardContent>
            <div className="overflow-hidden rounded-lg border bg-table text-[var(--table-text)]">
              <Table>
                <TableHeader>
                  <TableRow>
                    <TableHead>Name</TableHead>
                    <TableHead>Status</TableHead>
                    <TableHead>Date</TableHead>
                    <TableHead>Actions</TableHead>
                  </TableRow>
                </TableHeader>
                <TableBody>
                  <TableRow>
                    <TableCell>John Doe</TableCell>
                    <TableCell><Badge className="bg-success-100 text-success-700">Active</Badge></TableCell>
                    <TableCell>2024-01-15</TableCell>
                    <TableCell><Button size="sm" variant="outline">Edit</Button></TableCell>
                  </TableRow>
                  <TableRow>
                    <TableCell>Jane Smith</TableCell>
                    <TableCell><Badge className="bg-warning-100 text-warning-700">Pending</Badge></TableCell>
                    <TableCell>2024-01-14</TableCell>
                    <TableCell><Button size="sm" variant="outline">Edit</Button></TableCell>
                  </TableRow>
                  <TableRow>
                    <TableCell>Bob Johnson</TableCell>
                    <TableCell><Badge className="bg-error-100 text-error-700">Inactive</Badge></TableCell>
                    <TableCell>2024-01-13</TableCell>
                    <TableCell><Button size="sm" variant="outline">Edit</Button></TableCell>
                  </TableRow>
                </TableBody>
              </Table>
            </div>
          </CardContent>
        </Card>

        {/* Typography */}
        <Card>
          <CardHeader>
            <CardTitle>Typography</CardTitle>
          </CardHeader>
          <CardContent className="space-y-4">
            <div>
              <h1 className="text-4xl font-bold">Heading 1</h1>
              <h2 className="text-3xl font-bold">Heading 2</h2>
              <h3 className="text-2xl font-semibold">Heading 3</h3>
              <h4 className="text-xl font-semibold">Heading 4</h4>
              <h5 className="text-lg font-medium">Heading 5</h5>
              <h6 className="text-base font-medium">Heading 6</h6>
            </div>
            <Separator />
            <div className="space-y-2">
              <p className="text-base">This is a regular paragraph with <strong>bold text</strong> and <em>italic text</em>.</p>
              <p className="text-sm text-muted-foreground">This is small muted text for secondary information.</p>
              <p className="text-xs text-muted-foreground">This is extra small text for fine print.</p>
            </div>
          </CardContent>
        </Card>
      </div>
    </div>
  );
}

================
File: packages/renderer/src/setupLogger.ts
================
function serializeArg(arg: unknown): string {
  if (typeof arg === 'string') return arg;
  if (arg instanceof Error) return `${arg.name}: ${arg.message}`;
  try {
    return JSON.stringify(arg);
  } catch {
    try { return String(arg); } catch { return '[unserializable]'; }
  }
}

function formatMessage(args: unknown[]): string {
  return args.map(serializeArg).join(' ');
}

export function installRendererConsoleForwarding() {
  type ApiLog = { [k: string]: (msg: string, ctx?: Record<string, unknown>) => Promise<unknown> };
  const apiWrapper = (window as unknown as { api?: { log?: ApiLog } }).api;
  if (!apiWrapper || !apiWrapper.log) return;
  const apiLog: ApiLog = apiWrapper.log;

  const orig = { ...console };
  console.log = (...args: unknown[]) => {
    orig.log(...args);
    void apiLog.info?.(formatMessage(args));
  };
  console.info = (...args: unknown[]) => {
    orig.info(...args);
    void apiLog.info?.(formatMessage(args));
  };
  console.debug = (...args: unknown[]) => {
    orig.debug?.(...args);
    void apiLog.debug?.(formatMessage(args));
  };
  console.warn = (...args: unknown[]) => {
    orig.warn(...args);
    void apiLog.warn?.(formatMessage(args));
  };
  console.error = (...args: unknown[]) => {
    orig.error(...args);
    const msg = formatMessage(args);
    void apiLog.error?.(msg);
  };

  // Capture unhandled errors and rejections
  window.addEventListener('error', (ev) => {
    const message = ev?.error instanceof Error ? `${ev.error.name}: ${ev.error.message}` : String(ev.message ?? 'Unhandled error');
    void apiLog.error?.(message);
  });
  window.addEventListener('unhandledrejection', (ev) => {
    const reason = (ev as PromiseRejectionEvent)?.reason;
    const message = reason instanceof Error ? `${reason.name}: ${reason.message}` : serializeArg(reason);
    void apiLog.error?.(`Unhandled rejection: ${message}`);
  });
}

================
File: packages/renderer/src/shell/alarmUtils.ts
================
import type { AlarmEntry } from '../../../shared/src';

export function selectCurrentAlarms(entries: AlarmEntry[]): AlarmEntry[] {
  if (!entries.length) return [];
  const seen = new Set<string>();
  const result: AlarmEntry[] = [];
  for (const entry of entries) {
    if (!entry) continue;
    if (seen.has(entry.key)) continue;
    seen.add(entry.key);
    result.push(entry);
  }
  return result;
}

================
File: packages/renderer/src/shell/AppLayout.tsx
================
import { useCallback, useEffect, useMemo, useRef, useState } from 'react';
import { Outlet, useLocation } from 'react-router-dom';
import { SidebarProvider, SidebarInset } from '@/components/ui/sidebar';
import { AppSidebar } from '@/components/AppSidebar';
import type { AlarmEntry, DiagnosticsLogSummary, DiagnosticsLogTailRes, DiagnosticsSnapshot, MachineHealthEntry, ThemePreference } from '../../../shared/src';
import { cn } from '../utils/cn';
import { selectCurrentAlarms } from './alarmUtils';

// Nav is defined in AppSidebar; no local nav here.
const PAGE_TITLES: Record<string, string> = {
  '/dashboard': 'Dashboard',
  '/jobs': 'Jobs',
  '/history': 'History',
  '/machines': 'Machines',
  '/settings': 'Settings',
  '/grundner': 'Grundner',
  '/router': 'Router',
  '/theme': 'Theme',
  '/telemetry': 'Telemetry',
  '/cnc-alarms': 'CNC Alarms'
};

export function AppLayout() {
  const { pathname } = useLocation();
  const pageTitle = PAGE_TITLES[pathname] || pathname;

  const [alarms, setAlarms] = useState<AlarmEntry[]>([]);
  const [dismissedAlarmIds, setDismissedAlarmIds] = useState<Set<string>>(new Set());
  const alarmTimers = useRef<Map<string, ReturnType<typeof setTimeout>>>(new Map());
  const [showAlarmPanel, setShowAlarmPanel] = useState(false);

  const [diagnostics, setDiagnostics] = useState<DiagnosticsSnapshot | null>(null);
  const [showDiagnostics, setShowDiagnostics] = useState(false);
  const [copyingDiagnostics, setCopyingDiagnostics] = useState(false);
  const [copyFeedback, setCopyFeedback] = useState<{ type: 'success' | 'error'; message: string } | null>(null);
  const [logList, setLogList] = useState<DiagnosticsLogSummary[]>([]);
  const [logListLoading, setLogListLoading] = useState(false);
  const [logSelectedFile, setLogSelectedFile] = useState<string | null>(null);
  const [logLimit, setLogLimit] = useState(200);
  const [logTail, setLogTail] = useState<DiagnosticsLogTailRes | null>(null);
  const logTailRef = useRef<DiagnosticsLogTailRes | null>(null);
  const [logLinesLive, setLogLinesLive] = useState<string[] | null>(null);
  const [logLoading, setLogLoading] = useState(false);
  const [logError, setLogError] = useState<string | null>(null);
  const [themePreference, setThemePreference] = useState<ThemePreference>('system');

  const applyThemePreference = useCallback((preference: ThemePreference) => {
    const root = document.documentElement;
    const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
    
    // Remove all theme classes
    root.classList.remove('dark', 'modern');
    
    // Apply the appropriate theme class
    if (preference === "dark") {
      root.classList.add('dark');
    } else if (preference === "modern") {
      root.classList.add('modern');
    } else if (preference === "system") {
      if (prefersDark) {
        root.classList.add('dark');
      }
      // For light system preference, no class needed (default light theme)
    }
  }, []);

  const dismissAlarm = useCallback((id: string) => {
    const t = alarmTimers.current.get(id);
    if (t) {
      clearTimeout(t);
      alarmTimers.current.delete(id);
    }
    setDismissedAlarmIds((prev) => {
      const next = new Set(prev);
      next.add(id);
      return next;
    });
    setAlarms((prev) => prev.filter((a) => a.id !== id));
  }, []);

  const clearAllToasts = useCallback(() => {
    for (const a of alarms) {
      dismissAlarm(a.id);
    }
  }, [alarms, dismissAlarm]);

  const applyAlarms = useCallback((entries: AlarmEntry[]) => {
    const current = selectCurrentAlarms(entries);
    const visible = current.filter((a) => !dismissedAlarmIds.has(a.id));

    // Schedule auto-hide for new visible alarms
    for (const a of visible) {
      if (!alarmTimers.current.has(a.id)) {
        const ms = a.severity === 'critical' ? 30000 : 10000; // critical: 30s, others: 10s
        const t = setTimeout(() => {
          dismissAlarm(a.id);
          alarmTimers.current.delete(a.id);
        }, ms);
        alarmTimers.current.set(a.id, t);
      }
    }

    // Clear timers for alarms no longer visible
    for (const [id, t] of Array.from(alarmTimers.current.entries())) {
      if (!visible.some((a) => a.id === id)) {
        clearTimeout(t);
        alarmTimers.current.delete(id);
      }
    }

    setAlarms(visible);
  }, [dismissedAlarmIds, dismissAlarm]);

  const fetchLogList = useCallback(async () => {
    setLogListLoading(true);
    setLogError(null);
    try {
      const res = await window.api.diagnostics.listLogs();
      if (!res.ok) {
        setLogError(res.error.message);
        setLogList([]);
        setLogSelectedFile(null);
        setLogTail(null);
        return;
      }
      const items: DiagnosticsLogSummary[] = res.value.items;
      setLogList(items);
      if (!items.length) {
        setLogSelectedFile(null);
        setLogTail(null);
        return;
      }
      setLogSelectedFile((prev) => {
        if (prev && items.some((item: DiagnosticsLogSummary) => item.file === prev)) return prev;
        return items[0].file;
      });
    } catch (err) {
      setLogError(err instanceof Error ? err.message : String(err));
    } finally {
      setLogListLoading(false);
    }
  }, []);

  const fetchLogTail = useCallback(async (file: string, limit: number) => {
    setLogLoading(true);
    setLogError(null);
    try {
      const res = await window.api.diagnostics.logTail({ file, limit });
      if (!res.ok) {
        setLogTail(null);
        setLogError(res.error.message);
        return;
      }
      const data = res.value;
      // Avoid unnecessary rerenders to reduce flicker
      const prev = logTailRef.current;
      const unchanged =
        prev != null &&
        prev.file === data.file &&
        prev.limit === data.limit &&
        prev.available === data.available &&
        prev.size === data.size &&
        prev.updatedAt === data.updatedAt &&
        prev.lines.length === data.lines.length &&
        prev.lines[prev.lines.length - 1] === data.lines[data.lines.length - 1];
      if (!unchanged) {
        setLogTail(data);
      }
      if (data.limit !== logLimit) setLogLimit(data.limit);
      setLogList((items: DiagnosticsLogSummary[]) =>
        items.map((item) => (item.file === data.file ? { ...item, size: data.size, updatedAt: data.updatedAt } : item))
      );
    } catch (err) {
      setLogTail(null);
      setLogError(err instanceof Error ? err.message : String(err));
    } finally {
      setLogLoading(false);
    }
  }, [logLimit]);

  const refreshLogTail = useCallback(() => {
    if (logSelectedFile) {
      fetchLogTail(logSelectedFile, logLimit);
    }
  }, [fetchLogTail, logLimit, logSelectedFile]);

  const handleThemeChange = useCallback(async (next: ThemePreference) => {
    setThemePreference(next);
    applyThemePreference(next);
    try {
      const res = await window.api.ui.theme.set({ preference: next });
      if (!res.ok) {
        console.error('Failed to persist theme preference', res.error);
      }
    } catch (err) {
      console.error('Failed to persist theme preference', err);
    }
  }, [applyThemePreference]);

  useEffect(() => {
    let cancelled = false;
    window.api.alarms
      .list()
      .then((res) => {
        if (cancelled) return;
        if (res.ok) applyAlarms(res.value);
      })
      .catch((err) => console.error('Failed to load alarms', err));
    const unsubscribe = window.api.alarms.subscribe((next) => {
      if (!cancelled) applyAlarms(next);
    });
    return () => {
      cancelled = true;
      unsubscribe?.();
    };
  }, [applyAlarms]);

  useEffect(() => {
    let cancelled = false;
    window.api.diagnostics
      .get()
      .then((res) => {
        if (cancelled) return;
        if (!res.ok) {
          console.error('Failed to load diagnostics snapshot', res.error);
          return;
        }
        setDiagnostics(res.value);
      })
      .catch((err) => console.error('Failed to load diagnostics snapshot', err));
    const unsubscribe = window.api.diagnostics.subscribe((snapshot) => {
      if (!cancelled) setDiagnostics(snapshot);
    });
    return () => {
      cancelled = true;
      unsubscribe?.();
    };
  }, []);

  useEffect(() => {
    let cancelled = false;
    window.api.ui.theme
      .get()
      .then((res) => {
        if (cancelled) return;
        if (!res.ok) {
          console.error('Failed to load theme preference', res.error);
          return;
        }
        setThemePreference(res.value.preference);
      })
      .catch((err) => console.error('Failed to load theme preference', err));
    return () => {
      cancelled = true;
    };
  }, []);

  useEffect(() => {
    applyThemePreference(themePreference);
    try {
      window.localStorage.setItem('ui:theme', themePreference);
    } catch (error) {
      console.warn('Failed to persist theme preference locally', error);
    }
  }, [applyThemePreference, themePreference]);

  useEffect(() => {
    if (themePreference !== 'system') return;
    const query = window.matchMedia('(prefers-color-scheme: dark)');
    const handler = () => applyThemePreference('system');
    query.addEventListener('change', handler);
    return () => query.removeEventListener('change', handler);
  }, [applyThemePreference, themePreference]);

  useEffect(() => {
    if (!copyFeedback) return;
    const timer = setTimeout(() => setCopyFeedback(null), 5000);
    return () => clearTimeout(timer);
  }, [copyFeedback]);

  useEffect(() => {
    if (!showDiagnostics) return;
    fetchLogList();
  }, [fetchLogList, showDiagnostics]);

  useEffect(() => {
    if (!showDiagnostics) return;
    if (!logSelectedFile) return;
    // Initial fetch
    fetchLogTail(logSelectedFile, logLimit);
    // Subscribe stream if available; otherwise fallback to light polling
    type DiagApi = { subscribeLog?: (file: string, listener: (payload: { file: string; lines: string[] }) => void) => () => void };
    const diagApi = (window as unknown as { api?: { diagnostics?: DiagApi } }).api?.diagnostics;
    const maybeSub = diagApi?.subscribeLog;
    if (typeof maybeSub === 'function') {
      const unsubscribe = maybeSub(logSelectedFile, ({ lines }: { file: string; lines: string[] }) => {
        if (!Array.isArray(lines) || lines.length === 0) return;
        setLogLinesLive((prev) => {
          const next = prev ? [...lines].reverse().concat(prev) : [...lines].reverse();
          return next.slice(0, Math.max(2000, logLimit));
        });
      });
      return () => {
        unsubscribe?.();
      };
    } else {
      const id = setInterval(() => {
        fetchLogTail(logSelectedFile, logLimit);
      }, 1000);
      return () => clearInterval(id);
    }
  }, [fetchLogTail, logLimit, logSelectedFile, showDiagnostics]);

  const activeAlarmCount = alarms.length;
  const hasActiveAlarms = activeAlarmCount > 0;
  const diagnosticsWatchers = diagnostics?.watchers ?? [];
  const diagnosticsErrors = diagnostics?.recentErrors ?? [];
  const machineHealthEntries: MachineHealthEntry[] = diagnostics?.machineHealth ?? [];
  const machineHealthAlerts = machineHealthEntries.filter((issue) => issue.severity !== 'info');
  const watcherAlerts = diagnosticsWatchers.filter((watcher) => watcher.status === 'error');
  const recentErrorIsFresh = diagnosticsErrors.some((entry) => {
    const parsed = Date.parse(entry.timestamp);
    return !Number.isNaN(parsed) && Date.now() - parsed < 15 * 60 * 1000;
  });
  const diagnosticsAlertCount =
    machineHealthAlerts.length + watcherAlerts.length + (recentErrorIsFresh ? 1 : 0);
  const hasDiagnosticsAlert = diagnosticsAlertCount > 0;
  const selectedLogSummary = useMemo(
    () => logList.find((item) => item.file === logSelectedFile) ?? null,
    [logList, logSelectedFile]
  );
  const logLines = useMemo(() => (logLinesLive ?? (logTail?.lines ? [...logTail.lines].reverse() : [])), [logLinesLive, logTail]);
  const logAvailable = logTail?.available ?? null;

  // Keep a ref of the latest tail for equality checks
  useEffect(() => {
    logTailRef.current = logTail;
  }, [logTail]);

  const toggleAlarmPanel = () => {
    setShowAlarmPanel((prev) => {
      const next = !prev;
      if (next) setShowDiagnostics(false);
      return next;
    });
  };

  const toggleDiagnosticsPanel = () => {
    setShowDiagnostics((prev) => {
      const next = !prev;
      if (next) setShowAlarmPanel(false);
      return next;
    });
  };

  const handleCopyDiagnostics = async () => {
    setCopyingDiagnostics(true);
    setCopyFeedback(null);
    const res = await window.api.diagnostics.copy();
    if (!res.ok) {
      setCopyFeedback({ type: 'error', message: `Copy failed: ${res.error.message}` });
      setCopyingDiagnostics(false);
      return;
    }
    const { logCount } = res.value;
    setCopyFeedback({
      type: 'success',
      message: `Copied diagnostics snapshot (${logCount} log${logCount === 1 ? '' : 's'}) to clipboard.`
    });
    setCopyingDiagnostics(false);
  };

  const alarmBadgeClass = cn(
    'inline-flex min-w-[1.5rem] items-center justify-center rounded-full px-1.5 text-xs font-medium',
    hasActiveAlarms ? 'bg-red-500 text-white' : 'bg-slate-200 text-slate-700 dark:bg-slate-700 dark:text-slate-100'
  );

  const diagnosticsButtonClass = cn(
    'flex items-center gap-1 rounded border px-2 py-1 text-sm',
    hasDiagnosticsAlert && 'border-amber-500 text-amber-600'
  );
  const diagnosticsBadgeClass = cn(
    'inline-flex min-w-[1.5rem] items-center justify-center rounded-full px-1.5 text-xs font-medium',
    diagnosticsAlertCount > 0
      ? 'bg-amber-500 text-white'
      : 'bg-slate-200 text-slate-700 dark:bg-slate-700 dark:text-slate-100'
  );

  return (
    <SidebarProvider style={{ '--sidebar-width': '12rem', '--header-height': '3rem' } as React.CSSProperties}>
  <AppSidebar />
  <SidebarInset>
    <header className="flex h-12 items-center justify-between gap-2 border-b px-3 bg-card/95 shadow-sm backdrop-blur supports-[backdrop-filter]:bg-card/80">
      <div className="flex items-center gap-2">
        <div className="page-title-gradient">{pageTitle}</div>
      </div>
      <div className="flex items-center gap-2">
        <button
          className={cn('flex items-center gap-1 rounded border px-2 py-1 text-sm', hasActiveAlarms && 'border-red-500 text-red-600')}
          onClick={toggleAlarmPanel}
        >
          Alarms
          <span className={alarmBadgeClass}>{activeAlarmCount}</span>
        </button>
        <button className={diagnosticsButtonClass} onClick={toggleDiagnosticsPanel}>
          Diagnostics
          {diagnosticsAlertCount > 0 && <span className={diagnosticsBadgeClass}>{diagnosticsAlertCount}</span>}
        </button>
        <div className="flex items-center gap-2">
          <label className="text-xs text-muted-foreground">Theme</label>
          <select
            className="rounded border px-2 py-1 text-sm"
            value={themePreference}
            onChange={(e) => handleThemeChange(e.target.value as ThemePreference)}
          >
            <option value="system">System</option>
            <option value="light">Light</option>
            <option value="dark">Dark</option>
          </select>
        </div>
      </div>
    </header>
    <main className="overflow-auto p-4 min-w-0">
      <Outlet />
    </main>{alarms.length > 0 && (
        <div className="fixed right-8 top-16 z-50 space-y-2">
          <div className="flex justify-end">
            <button className="rounded border border-slate-800 bg-red-400 px-3 py-1.5 text-xs text-slate-900 hover:bg-red-300 hover:text-slate-900 dark:border-slate-600 dark:bg-slate-800 dark:text-slate-100 dark:hover:bg-blue-500" title="Clear all toasts" onClick={clearAllToasts}>
              Clear All
            </button>
          </div>
          {alarms.map((alarm) => (
            <div
              key={alarm.id}
              className="relative w-72 rounded border border-red-200 bg-red-100 p-3 shadow-lg dark:border-red-700 dark:bg-red-950/70"
            >
              <button
                className="absolute right-1 top-1 rounded px-1 text-xs text-red-700 hover:bg-red-100 dark:text-red-300 dark:hover:bg-red-900/40"
                title="Dismiss"
                onClick={() => dismissAlarm(alarm.id)}
              >
                X
              </button>
              <div className="space-y-1">
                <div className="text-sm font-semibold text-red-700 dark:text-red-300">{alarm.alarm}</div>
                <div className="text-xs text-muted-foreground">{alarm.key}</div>
                {alarm.status && <div className="text-xs text-muted-foreground">Status: {alarm.status}</div>}
              </div>
            </div>
          ))}
        </div>
      )}

      {showAlarmPanel && (
        <div className="fixed right-4 top-16 z-40 w-80 rounded border bg-background shadow-lg">
          <div className="flex items-center justify-between border-b px-3 py-2">
            <div className="text-sm font-semibold">Active Alarms</div>
            <button className="text-xs text-muted-foreground" onClick={() => setShowAlarmPanel(false)}>
              Close
            </button>
          </div>
          <div className="max-h-80 space-y-2 overflow-y-auto p-3 text-sm">
            {alarms.length === 0 ? (
              <div className="text-muted-foreground">No active alarms.</div>
            ) : (
              alarms.map((alarm) => (
                <div key={alarm.id} className="rounded border p-2">
                  <div className="font-medium">{alarm.key}</div>
                  <div className="text-sm">{alarm.alarm}</div>
                  {alarm.mode && <div className="text-xs text-muted-foreground">Mode: {alarm.mode}</div>}
                  {alarm.status && <div className="text-xs text-muted-foreground">Status: {alarm.status}</div>}
                  {alarm.lastSeenAt && (
                    <div className="text-xs text-muted-foreground">
                      Last seen {new Date(alarm.lastSeenAt).toLocaleTimeString()}
                    </div>
                  )}
                </div>
              ))
            )}
          </div>
        </div>
      )}
      {showDiagnostics && (
        <div className="fixed right-4 top-16 z-40 w-[800px] rounded border bg-background shadow-lg">
          <div className="flex items-center justify-between border-b px-3 py-2">
            <div className="text-sm font-semibold">Diagnostics</div>
            <div className="flex items-center gap-2">
              <button
                className="text-xs rounded border px-2 py-1"
                onClick={handleCopyDiagnostics}
                disabled={copyingDiagnostics}
              >
                {copyingDiagnostics ? 'Copying...' : 'Copy Diagnostics'}
              </button>
              <button className="text-xs text-muted-foreground" onClick={() => setShowDiagnostics(false)}>
                Close
              </button>
            </div>
          </div>
          <div className="space-y-3 p-3 text-sm">
            {copyFeedback && (
              <div
                className={cn(
                  'rounded border px-2 py-1 text-xs',
                  copyFeedback.type === 'success'
                    ? 'border-emerald-300 bg-emerald-50 text-emerald-700'
                    : 'border-red-300 bg-red-50 text-red-700'
                )}
              >
                {copyFeedback.message}
              </div>
            )}
            <div>
              <div className="text-xs uppercase text-muted-foreground">Database</div>
              <div className="mt-1 flex items-center gap-2">
                <span
                  className={cn(
                    'h-2.5 w-2.5 rounded-full',
                    diagnostics?.dbStatus?.online ? 'bg-emerald-500' : 'bg-red-500'
                  )}
                  aria-hidden
                />
                <span>{diagnostics?.dbStatus?.online ? 'Online' : 'Offline'}</span>
                {typeof diagnostics?.dbStatus?.latencyMs === 'number' && (
                  <span className="text-xs text-muted-foreground">{diagnostics.dbStatus.latencyMs} ms</span>
                )}
              </div>
              {diagnostics?.dbStatus?.error && (
                <div className="text-xs text-red-600">{diagnostics.dbStatus.error}</div>
              )}
            </div>
            <div>
              <div className="text-xs uppercase text-muted-foreground">Machine Health</div>
              <div className="mt-1 space-y-2">
                {machineHealthEntries.length === 0 ? (
                  <></>
                ) : (
                  machineHealthEntries.map((issue) => (
                    <div key={issue.id} className="rounded border p-2">
                      <div className="flex items-center justify-between gap-2">
                        <span className="font-medium">
                          {issue.machineId != null ? `Machine ${issue.machineId}` : 'General'}
                        </span>
                        <span
                          className={cn(
                            'text-xs font-semibold uppercase tracking-wide',
                            issue.severity === 'critical'
                              ? 'text-red-600'
                              : issue.severity === 'warning'
                              ? 'text-amber-600'
                              : 'text-muted-foreground'
                          )}
                        >
                          {issue.code.replace(/_/g, ' ')}
                        </span>
                      </div>
                      <div className="mt-1 text-sm">{issue.message}</div>
                      <div className="text-xs text-muted-foreground">
                        {new Date(issue.lastUpdatedAt).toLocaleTimeString()}
                      </div>
                    </div>
                  ))
                )}
              </div>
            </div>
            <div>
              <div className="text-xs uppercase text-muted-foreground">Watchers</div>
              <div className="mt-1 grid grid-cols-2 gap-2">
                {diagnosticsWatchers.length === 0 ? (
                  <div className="text-xs text-muted-foreground col-span-2">No watcher metrics available.</div>
                ) : (
                  diagnosticsWatchers.map((watcher) => (
                    <div key={watcher.name} className="rounded border p-2">
                      <div className="flex items-center justify-between">
                        <span className="font-medium truncate" title={watcher.label}>{watcher.label}</span>
                        <span
                          className={cn(
                            'text-xs font-semibold uppercase tracking-wide',
                            watcher.status === 'error'
                              ? 'text-red-600'
                              : watcher.status === 'watching'
                              ? 'text-emerald-600'
                              : 'text-muted-foreground'
                          )}
                        >
                          {watcher.status}
                        </span>
                      </div>
                    </div>
                  ))
                )}
              </div>
            </div>
            <div>
              <div className="text-xs uppercase text-muted-foreground">Logs</div>
              <div className="mt-1 space-y-2">
                <div className="flex flex-wrap items-center gap-2">
                  <select
                    className="border rounded px-2 py-1 text-xs"
                    value={logSelectedFile ?? ""}
                    onChange={(e) => setLogSelectedFile(e.target.value ? e.target.value : null)}
                    disabled={logListLoading || logList.length === 0}
                  >
                    {logList.map((item) => (
                      <option key={item.file} value={item.file}>
                        {item.name}
                      </option>
                    ))}
                  </select>
                  <select
                    className="border rounded px-2 py-1 text-xs"
                    value={logLimit}
                    onChange={(e) => setLogLimit(Number(e.target.value))}
                    disabled={logLoading || !logSelectedFile}
                  >
                    {[200, 500, 1000, 2000].map((value) => (
                      <option key={value} value={value}>
                        {value} lines
                      </option>
                    ))}
                  </select>
                  <button
                    className="border rounded px-2 py-1 text-xs"
                    onClick={fetchLogList}
                    disabled={logListLoading}
                  >
                    Refresh List
                  </button>
                  <button
                    className="border rounded px-2 py-1 text-xs"
                    onClick={refreshLogTail}
                    disabled={logLoading || !logSelectedFile}
                  >
                    Reload Log
                  </button>
                </div>
                {logListLoading && logList.length === 0 ? (
                  <div className="text-xs text-muted-foreground">Loading logs...</div>
                ) : logList.length === 0 ? (
                  <div className={cn('text-xs', logError ? 'text-red-600' : 'text-muted-foreground')}>
                    {logError ? `Load failed: ${logError}` : 'No log files available.'}
                  </div>
                ) : (
                  <>
                    {selectedLogSummary && (
                      <div className="flex flex-wrap items-center gap-x-3 gap-y-1 text-xs text-muted-foreground">
                        <span>{selectedLogSummary.name}</span>
                        <span>
                          Updated {selectedLogSummary.updatedAt ? new Date(selectedLogSummary.updatedAt).toLocaleString() : '-'}
                        </span>
                        <span>
                          Size {typeof selectedLogSummary.size === 'number' ? (selectedLogSummary.size < 1024 ? `${selectedLogSummary.size} B` : `${(selectedLogSummary.size / 1024).toFixed(1)} KB`) : '-'}
                        </span>
                      </div>
                    )}
                    {logTail && (
                      <div className="text-xs text-muted-foreground">
                        Showing {logLines.length} {logLines.length === 1 ? "line" : "lines"}
                        {logAvailable != null ? ` of ${logAvailable}` : ""} (limit {logLimit})
                      </div>
                    )}
                    {logError && <div className="text-xs text-red-600">{logError}</div>}
                    <pre key={logSelectedFile ?? 'none'} className="max-h-96 overflow-auto rounded border bg-muted/40 p-2 font-mono text-[11px] leading-snug whitespace-pre-wrap">
                      {logLoading
                        ? 'Loading log...'
                        : logLines.length
                          ? logLines.join('\n')
                          : 'No log lines to display.'}
                    </pre>
                  </>
                )}
              </div>
            </div>
            <div>
              <div className="text-xs uppercase text-muted-foreground">Recent Errors</div>
              <div className="mt-1 max-h-40 space-y-2 overflow-y-auto">
                {diagnosticsErrors.length === 0 ? (
                  <div className="text-xs text-muted-foreground">No errors recorded.</div>
                ) : (
                  diagnosticsErrors.slice(0, 5).map((entry) => (
                    <div key={entry.id} className="rounded border p-2">
                      <div className="text-xs text-muted-foreground">
                        {new Date(entry.timestamp).toLocaleTimeString()}
                      </div>
                      <div className="text-sm font-medium">{entry.source}</div>
                      <div>{entry.message}</div>
                    </div>
                  ))
                )}
              </div>
            </div>
          </div>
        </div>
      )}
      </SidebarInset>
    </SidebarProvider>
  );
}

================
File: packages/renderer/src/styles/theme.css
================
/* Clean, Minimal Theme System - Only What's Actually Used */

@layer base {
  :root {
    /* Core colors - Light theme with gradient effects */
    --background: linear-gradient(135deg, theme('colors.neutral.200') 0%, theme('colors.neutral.100') 50%, theme('colors.neutral.100') 100%);  /* Header/UI elements background gradient */
    --background-body: linear-gradient(to right, theme('colors.neutral.50'), theme('colors.neutral.100'), theme('colors.neutral.50'));  /* Main app body background - red to pink gradient */
    --foreground: theme('colors.zinc.900');         /* Main text color - nearly black */
    --card: linear-gradient(135deg, theme('colors.gray.600') 0%, theme('colors.neutral.700') 50%, theme('colors.neutral.300') 100%);  /* Card background - warm gradient */
    --card-foreground: theme('colors.zinc.900');   /* Card text - dark blue-gray */
    --primary: theme('colors.blue.500');          /* Primary action color - vibrant indigo */
    --destructive: theme('colors.rose.600');        /* Destructive actions - red */
    --muted: theme('colors.slate.100');             /* Muted background elements */
    --muted-foreground: theme('colors.slate.100');  /* Muted text - gray */
    --border: theme('colors.stone.500');            /* Border color - warm gray */

    /* Status indicator colors */
    --status-success-bg: theme('colors.emerald.100');
    --status-success-text: theme('colors.emerald.700');
    --status-warning-bg: theme('colors.amber.100');
    --status-warning-text: theme('colors.amber.700');
    --status-error-bg: theme('colors.rose.100');
    --status-error-text: theme('colors.rose.700');

    /* Table colors */
    --table-bg:  linear-gradient(135deg, theme('colors.gray.50') 0%, theme('colors.gray.100') 50%, theme('colors.gray.300') 100%);  /* Table background gradient */
    --table-header-bg:  linear-gradient(135deg, theme('colors.neutral.50') 0%, theme('colors.slate.300') 70%, theme('colors.slate.100') 100%);   /* Table header background - dark to match table */
    --table-text: theme('colors.gray.800');        /* Table text - light for dark background */
    --table-border: theme('colors.neutral.100');     /* Table outer border */
    --table-row-border: theme('colors.neutral.300'); /* Horizontal lines between rows */
    --table-hover-bg: color-mix(in srgb, theme('colors.cyan.900') 50%, transparent); /* Row hover background */
    --table-selected-bg: color-mix(in srgb, theme('colors.stone.900') 50%, transparent); /* Row selected background */

    /* Sidebar colors - Metallic/Marble effect */
    --sidebar: linear-gradient(135deg, theme('colors.neutral.900') 0%, theme('colors.neutral.700') 50%, theme('colors.neutral.900') 100%);  /* Metallic gradient background */
    --sidebar-foreground: theme('colors.slate.100'); /* Light text on dark metallic bg */
    --sidebar-accent: linear-gradient(135deg, theme('colors.red.700') 0%, theme('colors.red.900') 20%, theme('colors.red.700')100%);  /* Lighter metallic accent for active items */
    --sidebar-border: theme('colors.slate.600');     /* Metallic border */

    /* Input field styling */
    --input-border: theme('colors.gray.700');       /* Input border color */
    --input-border-width: 1.5px;                      /* Input border width */
    --input-bg: theme('colors.gray.200');              /* Input background color */

    /* Page title gradient */
    --page-title-gradient: linear-gradient(135deg, theme('colors.stone.900') 0%, theme('colors.stone.700') 50%, theme('colors.stone.900') 100%);

  /* Design tokens */
    --radius: 0.75rem;
    --shadow-sm: 0 1px 2px 0 rgba(0,0,0,0.05);
    --shadow-base: 0 1px 3px 0 rgba(0,0,0,0.10), 0 1px 2px -1px rgba(0,0,0,0.10);
    --shadow-md: 0 4px 6px -1px rgba(0,0,0,0.10), 0 2px 4px -2px rgba(0,0,0,0.10);
    --shadow-lg: 0 10px 15px -3px rgba(0,0,0,0.10), 0 4px 6px -4px rgba(0,0,0,0.10);
    --shadow-xl: 0 20px 25px -5px rgba(0,0,0,0.10), 0 8px 10px -6px rgba(0,0,0,0.10);
    --transition-fast: 150ms ease;
    --transition-normal: 200ms ease;
    --transition-slow: 300ms ease;

    /* Alpha variants - using Tailwind colors with opacity */
    --muted-a50: color-mix(in srgb, theme('colors.cyan.900') 50%, transparent);  /* Table row hover, table footer bg, inputs */
    --muted-a40: color-mix(in srgb, theme('colors.slate.100') 40%, transparent);  /* [unused] */
    --muted-a30: color-mix(in srgb, theme('colors.slate.100') 30%, transparent);  /* [unused] */
    --muted-a10: color-mix(in srgb, theme('colors.slate.100') 10%, transparent);  /* [unused] */
    --primary-a10: color-mix(in srgb, theme('colors.indigo.500') 10%, transparent);  /* Selected row bg, gradient effects */
    --primary-a15: color-mix(in srgb, theme('colors.indigo.500') 15%, transparent);  /* Box shadows, hover shadows */
    --primary-a20: color-mix(in srgb, theme('colors.indigo.500') 20%, transparent);  /* Borders on focus, selected row borders, resizer hover */
    --primary-a30: color-mix(in srgb, theme('colors.indigo.500') 30%, transparent);  /* Focus states, strong borders, box shadows */
    --border-a05: color-mix(in srgb, theme('colors.slate.200') 5%, transparent);   /* [unused] */
    --border-a06: color-mix(in srgb, theme('colors.slate.200') 6%, transparent);   /* Subtle box shadows */
    --border-a08: color-mix(in srgb, theme('colors.slate.200') 8%, transparent);   /* Box shadows, elevated shadows */
    --border-a10: color-mix(in srgb, theme('colors.slate.200') 10%, transparent);  /* Box shadows, table cell borders */
    --border-a30: color-mix(in srgb, theme('colors.slate.200') 30%, transparent);  /* Table header borders */
    --card-a95: color-mix(in srgb, theme('colors.white') 95%, transparent);        /* [unused] */
    --card-a90: color-mix(in srgb, theme('colors.white') 90%, transparent);        /* [unused] */
  }

  .dark {
    /* Dark theme - using Tailwind slate/gray colors */
    --background: theme('colors.slate.900');        /* Dark background - deep slate */
    --foreground: theme('colors.gray.200');         /* Light text on dark bg */
    --card: theme('colors.gray.800');               /* Card background - dark gray */
    --card-foreground: theme('colors.gray.200');    /* Card text - light gray */
    --muted: theme('colors.slate.700');             /* Muted backgrounds */
    --muted-foreground: theme('colors.slate.400');  /* Muted text */
    --accent: theme('colors.slate.700');            /* Accent elements */
    --border: theme('colors.slate.700');            /* Borders */
    --table-bg: theme('colors.gray.800');           /* Table background */
    --table-header-bg: theme('colors.slate.700');   /* Table header */
    --table-text: theme('colors.gray.200');         /* Table text */
    --table-hover-bg: color-mix(in srgb, theme('colors.slate.200') 10%, transparent); /* Row hover background */
    --table-selected-bg: color-mix(in srgb, theme('colors.indigo.400') 20%, transparent); /* Row selected background */
    --sidebar: theme('colors.slate.900');           /* Sidebar background */
    --sidebar-foreground: theme('colors.gray.200'); /* Sidebar text */
    --sidebar-accent: theme('colors.gray.800');     /* Sidebar active items */
    --sidebar-border: theme('colors.slate.700');    /* Sidebar border */
  }

  .modern {
    /* Modern theme - using Tailwind blue/slate colors */
    --background: theme('colors.blue.50');          /* Light blue background */
    --foreground: theme('colors.slate.900');        /* Dark text */
    --card: theme('colors.white');                  /* Pure white cards */
    --card-foreground: theme('colors.slate.900');   /* Dark text on cards */
    --primary: theme('colors.sky.500');             /* Sky blue primary */
    --accent: theme('colors.blue.400');             /* Blue accent */
    --muted: theme('colors.slate.50');              /* Very light muted bg */
    --muted-foreground: theme('colors.slate.500');  /* Medium gray text */
    --border: theme('colors.blue.200');             /* Light blue border */
    --table-bg: theme('colors.white');              /* White table background */
    --table-header-bg: theme('colors.slate.50');    /* Light table header */
    --table-text: theme('colors.slate.900');        /* Dark table text */
    --table-hover-bg: color-mix(in srgb, theme('colors.slate.900') 6%, transparent); /* Row hover background */
    --table-selected-bg: color-mix(in srgb, theme('colors.sky.500') 12%, transparent); /* Row selected background */
    --sidebar: theme('colors.blue.50');             /* Light blue sidebar */
    --sidebar-foreground: theme('colors.slate.900'); /* Dark sidebar text */
    --sidebar-accent: theme('colors.blue.100');     /* Light blue sidebar accent */
    --sidebar-border: theme('colors.blue.200');     /* Light blue border */
  }
}

@layer utilities {
  /* Only the utility classes that are actually used */
  .bg-background {
    background: var(--background);
    box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.05);
  }
  .bg-card {
    background: var(--card);
    box-shadow: inset 0 1px 2px rgba(255, 255, 255, 0.1), 0 2px 4px rgba(0, 0, 0, 0.1);
  }
  .bg-muted { background-color: var(--muted); }
  .bg-muted\/50 { background-color: var(--muted-a50); }
  .bg-muted\/40 { background-color: var(--muted-a40); }
  .bg-accent { background-color: var(--table-header-bg) !important; }
  .bg-primary { background-color: var(--primary); }
  .bg-destructive { background-color: var(--destructive); }

  .text-background { color: var(--background); }
  .text-foreground { color: var(--foreground); }
  .text-card-foreground { color: var(--card-foreground); }
  .text-muted-foreground { color: var(--table-text) !important; }
  .text-accent-foreground { color: var(--table-text) !important; }
  .text-destructive-foreground { color: #ffffff; }

  .border-border { border-color: var(--border); }
  .border-muted { border-color: var(--muted); }

  /* Sidebar utilities - with metallic/marble gradient */
  .bg-sidebar {
    background: var(--sidebar);
    box-shadow: inset 1px 0 3px rgba(255, 255, 255, 0.1);
  }
  .text-sidebar-foreground { color: var(--sidebar-foreground); }
  .hover\:bg-sidebar-accent:hover {
    background: var(--sidebar-accent);
  }

  /* Main content area gradient */
  .bg-main-gradient {
    background: linear-gradient(135deg, theme('colors.stone.200') 0%, theme('colors.stone.100') 50%, theme('colors.stone.200') 100%);
    box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.05);
  }

  /* Table background utility - uses background instead of background-color for gradients */
  .bg-table {
    background: var(--table-bg);
  }

  /* Table styles - now simple since we removed layered components */
  .table-text {
    color: var(--table-text);
  }

  /* Input field styling */
  input[type="text"],
  input[type="search"],
  input[type="number"],
  input[type="email"],
  input[type="password"],
  select,
  textarea {
    border: var(--input-border-width) solid var(--input-border) !important;
    background-color: var(--input-bg) !important;
    border-radius: 0.375rem;
    padding: 0.5rem;
  }

  /* Page title gradient text */
  .page-title-gradient {
    background: var(--page-title-gradient);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    font-size: 1.5rem;
    font-weight: 600;
    font-family: 'aptos' ,sans-serif;  /* Add this line */
  }
}

================
File: packages/renderer/src/types/global.d.ts
================
import type {
  AppError,
  AlarmEntry,
  CopyDiagnosticsResult,
  DbSettings,
  DbStatus,
  DiagnosticsSnapshot,
  GrundnerListReq,
  GrundnerListRes,
  GrundnerResyncReq,
  GrundnerUpdateReq,
  HistoryListReq,
  HistoryListRes,
  JobEventsReq,
  JobEventsRes,
  JobTimelineRes,
  JobsFiltersRes,
  JobsListReq,
  JobsListRes,
  Machine,
  MachinesListRes,
  PathValidationReq,
  PathValidationRes,
  ReadyListRes,
  ReadyImportReq,
  ReadyImportRes,
  ReadyDeleteReq,
  ReadyDeleteRes,
  RouterListReq,
  RouterListRes,
  SaveMachineReq,
  Settings,
  WorklistAddResult,
  DiagnosticsLogsRes,
  DiagnosticsLogTailReq,
  DiagnosticsLogTailRes,
  ThemePreferenceReq,
  ThemePreferenceRes
} from '../../../shared/src';
import type { TelemetrySummaryReq, TelemetrySummaryRes, AlarmsHistoryReq, AlarmsHistoryRes } from '../../../shared/src';

declare global {
  interface Window {
    api: {
      settings: {
        get: () => Promise<Result<Settings, AppError>>;
        getPath: () => Promise<Result<string, AppError>>;
        save: (s: Settings) => Promise<Result<Settings, AppError>>;
        validatePath: (input: PathValidationReq) => Promise<Result<PathValidationRes, AppError>>;
      };
      db: {
        testConnection: (db: DbSettings) => Promise<Result<{ ok: true } | { ok: false; error: string }, AppError>>;
        getStatus: () => Promise<Result<DbStatus, AppError>>;
        subscribeStatus: (listener: (status: DbStatus) => void) => () => void;
      };
      jobs: {
        list: (req: JobsListReq) => Promise<Result<JobsListRes, AppError>>;
        filters: () => Promise<Result<JobsFiltersRes, AppError>>;
        events: (req: JobEventsReq) => Promise<Result<JobEventsRes, AppError>>;
        reserve: (key: string) => Promise<Result<null, AppError>>;
        unreserve: (key: string) => Promise<Result<null, AppError>>;
        addToWorklist: (key: string, machineId: number) => Promise<Result<WorklistAddResult, AppError>>;
        resync: () => Promise<Result<{ inserted: number; updated: number }, AppError>>;
      };
      machines: {
        list: () => Promise<Result<MachinesListRes, AppError>>;
        save: (m: SaveMachineReq) => Promise<Result<Machine, AppError>>;
        delete: (id: number) => Promise<Result<null, AppError>>;
      };
      dialog: {
        pickFolder: () => Promise<Result<string | null, AppError>>;
      };
      files: {
        listReady: (machineId: number) => Promise<Result<ReadyListRes, AppError>>;
        importReady: (input: ReadyImportReq) => Promise<Result<ReadyImportRes, AppError>>;
        deleteReadyAssets: (input: ReadyDeleteReq) => Promise<Result<ReadyDeleteRes, AppError>>;
        subscribeReady: (
          machineId: number,
          listener: (payload: ReadyListRes) => void
        ) => () => void;
      };
      router: {
        list: (req?: RouterListReq) => Promise<Result<RouterListRes, AppError>>;
      };
      grundner: {
        list: (req?: GrundnerListReq) => Promise<Result<GrundnerListRes, AppError>>;
        update: (input: GrundnerUpdateReq) => Promise<Result<{ ok: boolean; updated: number }, AppError>>;
        resync: (input?: GrundnerResyncReq) => Promise<Result<{ updated: number }, AppError>>;
      };
      hypernest: {
        open: () => Promise<Result<null, AppError>>;
      };
      alarms: {
        list: () => Promise<Result<AlarmEntry[], AppError>>;
        history: (req: AlarmsHistoryReq) => Promise<Result<AlarmsHistoryRes, AppError>>;
        subscribe: (listener: (alarms: AlarmEntry[]) => void) => () => void;
      };
      telemetry: {
        summary: (req: TelemetrySummaryReq) => Promise<Result<TelemetrySummaryRes, AppError>>;
        subscribe: (
          req: TelemetrySummaryReq,
          listener: (payload: TelemetrySummaryRes) => void
        ) => () => void;
      };
      diagnostics: {
        get: () => Promise<Result<DiagnosticsSnapshot, AppError>>;
        copy: () => Promise<Result<CopyDiagnosticsResult, AppError>>;
        listLogs: () => Promise<Result<DiagnosticsLogsRes, AppError>>;
        logTail: (req: DiagnosticsLogTailReq) => Promise<Result<DiagnosticsLogTailRes, AppError>>;
        subscribe: (listener: (snapshot: DiagnosticsSnapshot) => void) => () => void;
      };
      ui: {
        theme: {
          get: () => Promise<Result<ThemePreferenceRes, AppError>>;
          set: (req: ThemePreferenceReq) => Promise<Result<ThemePreferenceRes, AppError>>;
        };
      };
      history: {
        list: (req?: HistoryListReq) => Promise<Result<HistoryListRes, AppError>>;
        timeline: (key: string) => Promise<Result<JobTimelineRes | null, AppError>>;
      };
    };
  }
}

export {};

================
File: packages/renderer/src/utils/cn.ts
================
import { clsx, type ClassValue } from 'clsx';
import { twMerge } from 'tailwind-merge';

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs));
}

================
File: packages/renderer/tailwind.config.ts
================
import type { Config } from 'tailwindcss';

export default {
  darkMode: ['class'],
  content: [
    './index.html',
    './src/**/*.{ts,tsx}',
  ],
  theme: {
    extend: {
      // Modern professional font stack
      fontFamily: {
        sans: ['Inter', '-apple-system', 'BlinkMacSystemFont', 'Segoe UI', 'Roboto', 'sans-serif'],
        mono: ['JetBrains Mono', 'Fira Code', 'Consolas', 'monospace']
      },

      // Design system colors mapped to CSS variables (hex values)
      colors: {
        // Semantic colors
        border: 'var(--border)',
        input: 'var(--input)',
        ring: 'var(--ring)',
        background: 'var(--background)',
        foreground: 'var(--foreground)',
        primary: {
          DEFAULT: 'var(--primary)',
          foreground: 'var(--primary-foreground)',
          50: 'var(--primary-50)',
          100: 'var(--primary-100)',
          200: 'var(--primary-200)',
          300: 'var(--primary-300)',
          400: 'var(--primary-400)',
          500: 'var(--primary-500)',
          600: 'var(--primary-600)',
          700: 'var(--primary-700)',
          800: 'var(--primary-800)',
          900: 'var(--primary-900)',
          950: 'var(--primary-950)'
        },
        secondary: {
          DEFAULT: 'var(--secondary)',
          foreground: 'var(--secondary-foreground)',
          50: 'var(--secondary-50)',
          100: 'var(--secondary-100)',
          200: 'var(--secondary-200)',
          300: 'var(--secondary-300)',
          400: 'var(--secondary-400)',
          500: 'var(--secondary-500)',
          600: 'var(--secondary-600)',
          700: 'var(--secondary-700)',
          800: 'var(--secondary-800)',
          900: 'var(--secondary-900)'
        },
        muted: {
          DEFAULT: 'var(--muted)',
          foreground: 'var(--muted-foreground)'
        },
        accent: {
          DEFAULT: 'var(--accent)',
          foreground: 'var(--accent-foreground)'
        },
        destructive: {
          DEFAULT: 'var(--destructive)',
          foreground: 'var(--destructive-foreground)'
        },
        card: {
          DEFAULT: 'var(--card)',
          foreground: 'var(--card-foreground)'
        },
        popover: {
          DEFAULT: 'var(--popover)',
          foreground: 'var(--popover-foreground)'
        },

        // Status colors
        success: {
          50: 'var(--success-50)',
          100: 'var(--success-100)',
          200: 'var(--success-200)',
          300: 'var(--success-300)',
          400: 'var(--success-400)',
          500: 'var(--success-500)',
          600: 'var(--success-600)',
          700: 'var(--success-700)',
          800: 'var(--success-800)',
          900: 'var(--success-900)'
        },
        warning: {
          50: 'var(--warning-50)',
          100: 'var(--warning-100)',
          200: 'var(--warning-200)',
          300: 'var(--warning-300)',
          400: 'var(--warning-400)',
          500: 'var(--warning-500)',
          600: 'var(--warning-600)',
          700: 'var(--warning-700)',
          800: 'var(--warning-800)',
          900: 'var(--warning-900)'
        },
        error: {
          50: 'var(--error-50)',
          100: 'var(--error-100)',
          200: 'var(--error-200)',
          300: 'var(--error-300)',
          400: 'var(--error-400)',
          500: 'var(--error-500)',
          600: 'var(--error-600)',
          700: 'var(--error-700)',
          800: 'var(--error-800)',
          900: 'var(--error-900)'
        },

        // Neutral scale
        neutral: {
          50: 'var(--neutral-50)',
          100: 'var(--neutral-100)',
          200: 'var(--neutral-200)',
          300: 'var(--neutral-300)',
          400: 'var(--neutral-400)',
          500: 'var(--neutral-500)',
          600: 'var(--neutral-600)',
          700: 'var(--neutral-700)',
          800: 'var(--neutral-800)',
          900: 'var(--neutral-900)',
          950: 'var(--neutral-950)'
        }
      },

      // Border radius using design tokens
      borderRadius: {
        lg: 'var(--radius)',
        md: 'calc(var(--radius) - 2px)',
        sm: 'calc(var(--radius) - 4px)',
      },

      // Shadows using design tokens
      boxShadow: {
        sm: 'var(--shadow-sm)',
        DEFAULT: 'var(--shadow-base)',
        md: 'var(--shadow-md)',
        lg: 'var(--shadow-lg)',
        xl: 'var(--shadow-xl)',
        '2xl': 'var(--shadow-2xl)',
      },

      // Typography scale
      fontSize: {
        xs: ['var(--text-xs)', { lineHeight: 'var(--leading-tight)' }],
        sm: ['var(--text-sm)', { lineHeight: 'var(--leading-normal)' }],
        base: ['var(--text-base)', { lineHeight: 'var(--leading-normal)' }],
        lg: ['var(--text-lg)', { lineHeight: 'var(--leading-normal)' }],
        xl: ['var(--text-xl)', { lineHeight: 'var(--leading-snug)' }],
        '2xl': ['var(--text-2xl)', { lineHeight: 'var(--leading-snug)' }],
        '3xl': ['var(--text-3xl)', { lineHeight: 'var(--leading-tight)' }],
        '4xl': ['var(--text-4xl)', { lineHeight: 'var(--leading-tight)' }],
      },

      // Spacing using design tokens
      spacing: {
        '0': 'var(--spacing-0)',
        '1': 'var(--spacing-1)',
        '2': 'var(--spacing-2)',
        '3': 'var(--spacing-3)',
        '4': 'var(--spacing-4)',
        '5': 'var(--spacing-5)',
        '6': 'var(--spacing-6)',
        '8': 'var(--spacing-8)',
        '10': 'var(--spacing-10)',
        '12': 'var(--spacing-12)',
        '16': 'var(--spacing-16)',
      },

      // Animation and transitions
      transitionDuration: {
        fast: 'var(--transition-fast)',
        normal: 'var(--transition-normal)',
        slow: 'var(--transition-slow)',
      },

      // Z-index scale
      zIndex: {
        dropdown: 'var(--z-dropdown)',
        sticky: 'var(--z-sticky)',
        fixed: 'var(--z-fixed)',
        'modal-backdrop': 'var(--z-modal-backdrop)',
        modal: 'var(--z-modal)',
        popover: 'var(--z-popover)',
        tooltip: 'var(--z-tooltip)',
      },

      animation: {
        pulse: 'pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite',
        spin: 'spin 1s linear infinite',
      },
    }
  },
  plugins: [],
} satisfies Config;

================
File: packages/renderer/tsconfig.json
================
{
  "extends": "../../tsconfig.base.json",
  "compilerOptions": {
    "jsx": "react-jsx",
    "module": "ESNext",
    "moduleResolution": "Bundler",
    "lib": ["ES2020", "DOM"],
    "types": ["vite/client"],
    "noEmit": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["src/*"]
    }
  },
  "include": ["src/**/*", "vite.config.ts"]
}

================
File: packages/renderer/vite.config.ts
================
import { defineConfig } from 'vite';
import path from 'path';
import react from '@vitejs/plugin-react';

export default defineConfig({
  // Use relative paths in production builds so Electron can load
  // assets from file:// URLs without breaking CSS/JS links.
  base: './',
  plugins: [react()],
  resolve: {
    alias: {
      '@': path.resolve(__dirname, './src')
    }
  },
  server: {
    port: 5180,
    strictPort: true
  },
  build: {
    outDir: 'dist',
    emptyOutDir: true
  }
});

================
File: packages/settings.json
================
{
  "version": 1,
  "db": {
    "host": "db.internal",
    "port": 5432,
    "database": "woodtron",
    "user": "woodtron_user",
    "password": "secret",
    "sslMode": "disable",
    "statementTimeoutMs": 30000
  },
  "paths": {
    "processedJobsRoot": "C:/jobs",
    "autoPacCsvDir": "",
    "grundnerFolderPath": ""
  },
  "test": {
    "testDataFolderPath": "",
    "useTestDataMode": false,
    "sheetIdMode": "type_data"
  },
  "grundner": {
    "reservedAdjustmentMode": "delta"
  }
}

================
File: packages/shared/package.json
================
{
  "name": "@app/shared",
  "version": "0.1.0",
  "private": true,
  "type": "commonjs",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "scripts": {
    "build": "tsc -b",
    "clean": "rimraf dist",
    "typecheck": "tsc -p tsconfig.json --noEmit"
  },
  "devDependencies": {
    "typescript": "^5.4.5"
  },
  "dependencies": {
    "zod": "^3.23.8",
    "neverthrow": "^7.1.0"
  }
}

================
File: packages/shared/src/index.ts
================
export * from './ipc';
export * from './result';

================
File: packages/shared/src/ipc.ts
================
import { z } from 'zod';
import type { ResultEnvelope } from './result';

export const SslMode = z.enum(['disable', 'require', 'verify-ca', 'verify-full']);

export const DbSettingsSchema = z.object({
  host: z.string().min(1),
  port: z.number().int().min(1).max(65535).default(5432),
  database: z.string().min(1),
  user: z.string().min(1),
  password: z.string().min(1, 'Password is required'),
  sslMode: SslMode.default('disable'),
  statementTimeoutMs: z.number().int().min(0).max(600000).default(30000)
});
export type DbSettings = z.infer<typeof DbSettingsSchema>;

export const DbStatusSchema = z.object({
  online: z.boolean(),
  checkedAt: z.string(),
  latencyMs: z.number().int().nonnegative().nullable(),
  error: z.string().nullable()
});
export type DbStatus = z.infer<typeof DbStatusSchema>;

export const CURRENT_SETTINGS_VERSION = 1 as const;

export const ThemePreference = z.enum(['system', 'light', 'dark', 'modern']);
export type ThemePreference = z.infer<typeof ThemePreference>;

export const ThemePreferenceReq = z.object({ preference: ThemePreference });
export type ThemePreferenceReq = z.infer<typeof ThemePreferenceReq>;

export const ThemePreferenceRes = z.object({ preference: ThemePreference });
export type ThemePreferenceRes = z.infer<typeof ThemePreferenceRes>;

export const SettingsSchema = z.object({
  version: z.number().int().min(1).default(CURRENT_SETTINGS_VERSION),
  db: DbSettingsSchema,
  paths: z.object({
    processedJobsRoot: z.string().default(''),
    autoPacCsvDir: z.string().default(''),
    grundnerFolderPath: z.string().default(''),
  }).default({ processedJobsRoot: '', autoPacCsvDir: '', grundnerFolderPath: '' }),
  test: z.object({
    testDataFolderPath: z.string().default(''),
    useTestDataMode: z.boolean().default(false),
    sheetIdMode: z.enum(['type_data', 'customer_id']).default('type_data')
  }).default({ testDataFolderPath: '', useTestDataMode: false, sheetIdMode: 'type_data' }),
  grundner: z.object({
    reservedAdjustmentMode: z.enum(['delta', 'absolute']).default('delta')
  }).default({ reservedAdjustmentMode: 'delta' })
});
export type Settings = z.infer<typeof SettingsSchema>;

export const AppErrorSchema = z.object({
  code: z.string(),
  message: z.string(),
  details: z.any().optional()
});
export type AppError = z.infer<typeof AppErrorSchema>;

export const JobStatus = z.enum([
  'PENDING',
  'STAGED',
  'LOAD_FINISH',
  'LABEL_FINISH',
  'CNC_FINISH',
  'FORWARDED_TO_NESTPICK',
  'NESTPICK_COMPLETE'
]);
export const JOB_STATUS_VALUES = JobStatus.options;
export type JobStatus = z.infer<typeof JobStatus>;

export const JobsListFilter = z.object({
  folder: z.string().optional(),
  material: z.string().optional(),
  materialIn: z.array(z.string().min(1)).optional(),
  size: z.string().optional(),
  thickness: z.string().optional(),
  status: z.enum(['all', 'cut', 'uncut']).optional(),
  statusIn: z.array(JobStatus).optional(),
  machineId: z.number().int().optional()
});

export const JobsListReq = z.object({
  search: z.string().optional(),
  sortBy: z.enum(['folder', 'ncfile', 'material', 'parts', 'size', 'thickness', 'dateadded', 'reserved', 'status']).default('dateadded'),
  sortDir: z.enum(['asc', 'desc']).default('desc'),
  cursor: z.string().nullable().optional(),
  limit: z.number().int().min(1).max(200).default(50),
  filter: JobsListFilter.default({})
});
export type JobsListReq = z.infer<typeof JobsListReq>;

export const JobRow = z.object({
  key: z.string(),
  folder: z.string().nullable(),
  ncfile: z.string().nullable(),
  material: z.string().nullable(),
  parts: z.string().nullable(),
  size: z.string().nullable(),
  thickness: z.string().nullable(),
  dateadded: z.string().nullable(),
  reserved: z.boolean(),
  status: JobStatus,
  machineId: z.number().int().nullable(),
  processingSeconds: z.number().int().nullable().optional()
});
export type JobRow = z.infer<typeof JobRow>;

export const JobsListRes = z.object({
  items: z.array(JobRow),
  nextCursor: z.string().nullable()
});
export type JobsListRes = z.infer<typeof JobsListRes>;

export const JobsFilterOptions = z.object({
  materials: z.array(z.string().min(1)),
  statuses: z.array(JobStatus)
});
export type JobsFilterOptions = z.infer<typeof JobsFilterOptions>;

export const JobsFiltersRes = z.object({ options: JobsFilterOptions });
export type JobsFiltersRes = z.infer<typeof JobsFiltersRes>;

export const ReserveReq = z.object({ key: z.string().min(1) });
export type ReserveReq = z.infer<typeof ReserveReq>;

export const UnreserveReq = z.object({ key: z.string().min(1) });
export type UnreserveReq = z.infer<typeof UnreserveReq>;

export const JobEvent = z.object({
  id: z.number().int(),
  key: z.string(),
  eventType: z.string(),
  payload: z.unknown().nullable(),
  machineId: z.number().int().nullable(),
  createdAt: z.string()
});
export type JobEvent = z.infer<typeof JobEvent>;

export const JobEventsReq = z.object({
  key: z.string().min(1),
  limit: z.number().int().min(1).max(200).default(50)
});
export type JobEventsReq = z.infer<typeof JobEventsReq>;

export const JobEventsRes = z.object({ events: z.array(JobEvent) });
export type JobEventsRes = z.infer<typeof JobEventsRes>;

export type Result<T> = ResultEnvelope<T>;

export const Machine = z.object({
  machineId: z.number().int(),
  name: z.string(),
  pcIp: z.string().nullable().optional(),
  cncIp: z.string().nullable().optional(),
  cncPort: z.number().int().nullable().optional(),
  apJobfolder: z.string(),
  nestpickFolder: z.string(),
  nestpickEnabled: z.boolean(),
  pcPort: z.number().int()
});
export type Machine = z.infer<typeof Machine>;

export const SaveMachineReq = Machine.partial({ machineId: true }).extend({ machineId: z.number().int().optional() });
export type SaveMachineReq = z.infer<typeof SaveMachineReq>;

export const MachinesListRes = z.object({ items: z.array(Machine) });
export type MachinesListRes = z.infer<typeof MachinesListRes>;


export const WorklistSkippedFile = z.object({
  relativePath: z.string(),
  reason: z.enum(['skip-pattern', 'exists', 'error']),
  message: z.string().optional()
});
export type WorklistSkippedFile = z.infer<typeof WorklistSkippedFile>;

export const WorklistCollisionInfo = z.object({
  originalPath: z.string(),
  redirectedPath: z.string()
});
export type WorklistCollisionInfo = z.infer<typeof WorklistCollisionInfo>;

export const WorklistAddSuccess = z.object({
  ok: z.literal(true),
  path: z.string(),
  copied: z.number().int(),
  skipped: z.array(WorklistSkippedFile),
  stagedAt: z.string().nullable(),
  alreadyStaged: z.boolean(),
  collision: WorklistCollisionInfo.optional()
});
export type WorklistAddSuccess = z.infer<typeof WorklistAddSuccess>;

export const WorklistAddFailure = z.object({
  ok: z.literal(false),
  error: z.string(),
  skipped: z.array(WorklistSkippedFile).optional()
});
export type WorklistAddFailure = z.infer<typeof WorklistAddFailure>;

export const WorklistAddResult = z.union([WorklistAddSuccess, WorklistAddFailure]);
export type WorklistAddResult = z.infer<typeof WorklistAddResult>;
export const ReadyFile = z.object({
  name: z.string(),
  relativePath: z.string(),
  size: z.number().int(),
  mtimeMs: z.number(),
  inDatabase: z.boolean(),
  jobKey: z.string().nullable(),
  status: JobStatus.nullable(),
  // Enriched job metadata when a matching job row exists
  jobMaterial: z.string().nullable().optional(),
  jobSize: z.string().nullable().optional(),
  jobParts: z.string().nullable().optional(),
  jobThickness: z.string().nullable().optional(),
  jobDateadded: z.string().nullable().optional(),
  // When the file appeared in Ready-To-Run (based on filesystem mtime)
  addedAtR2R: z.string().optional()
});
export type ReadyFile = z.infer<typeof ReadyFile>;
export const ReadyListRes = z.object({ machineId: z.number().int(), files: z.array(ReadyFile) });
export type ReadyListRes = z.infer<typeof ReadyListRes>;

export const ReadyImportReq = z.object({
  machineId: z.number().int(),
  relativePath: z.string().min(1)
});
export type ReadyImportReq = z.infer<typeof ReadyImportReq>;

export const ReadyImportRes = z.object({
  jobKey: z.string(),
  created: z.boolean(),
  status: JobStatus,
  folder: z.string(),
  ncfile: z.string(),
  material: z.string().nullable(),
  size: z.string().nullable(),
  thickness: z.string().nullable(),
  parts: z.string().nullable()
});
export type ReadyImportRes = z.infer<typeof ReadyImportRes>;

export const ReadyDeleteReq = z.object({
  machineId: z.number().int(),
  relativePaths: z.array(z.string().min(1)).min(1)
});
export type ReadyDeleteReq = z.infer<typeof ReadyDeleteReq>;

export const ReadyDeleteError = z.object({
  file: z.string(),
  message: z.string()
});
export type ReadyDeleteError = z.infer<typeof ReadyDeleteError>;

export const ReadyDeleteRes = z.object({
  deleted: z.number().int().nonnegative(),
  files: z.array(z.string()),
  errors: z.array(ReadyDeleteError)
});
export type ReadyDeleteRes = z.infer<typeof ReadyDeleteRes>;

export const RouterListReq = z.object({
  machineId: z.number().int().optional(),
  statusIn: z.array(JobStatus).optional(),
  limit: z.number().int().min(1).max(500).default(200)
});
export type RouterListReq = z.infer<typeof RouterListReq>;

export const RouterRow = z.object({
  key: z.string(),
  folder: z.string().nullable(),
  ncfile: z.string().nullable(),
  material: z.string().nullable(),
  status: JobStatus,
  machineId: z.number().int().nullable(),
  stagedAt: z.string().nullable(),
  cutAt: z.string().nullable(),
  nestpickCompletedAt: z.string().nullable(),
  updatedAt: z.string().nullable(),
  pallet: z.string().nullable(),
  lastError: z.string().nullable()
});
export type RouterRow = z.infer<typeof RouterRow>;

export const RouterListRes = z.object({ items: z.array(RouterRow) });
export type RouterListRes = z.infer<typeof RouterListRes>;

export const LifecycleReq = z.object({
  key: z.string().min(1),
  to: JobStatus,
  machineId: z.number().int().nullable().optional(),
  source: z.string().min(1).optional(),
  payload: z.unknown().optional()
});
export type LifecycleReq = z.infer<typeof LifecycleReq>;

export const LifecycleRes = z.object({
  ok: z.boolean(),
  reason: z.enum(['NOT_FOUND', 'INVALID_TRANSITION', 'NO_CHANGE']).optional(),
  previousStatus: JobStatus.optional(),
  status: JobStatus.optional(),
  machineId: z.number().int().nullable().optional()
});
export type LifecycleRes = z.infer<typeof LifecycleRes>;
export const GrundnerFilter = z.object({
  search: z.string().optional(),
  onlyAvailable: z.boolean().optional(),
  onlyReserved: z.boolean().optional(),
  thicknessMin: z.number().int().optional(),
  thicknessMax: z.number().int().optional()
});

export const GrundnerListReq = z.object({
  limit: z.number().int().min(1).max(500).default(200),
  filter: GrundnerFilter.default({})
});
export type GrundnerListReq = z.infer<typeof GrundnerListReq>;

export const GrundnerRow = z.object({
  id: z.number().int(),
  typeData: z.number().int().nullable(),
  customerId: z.string().nullable(),
  lengthMm: z.number().int().nullable(),
  widthMm: z.number().int().nullable(),
  thicknessMm: z.number().int().nullable(),
  stock: z.number().int().nullable(),
  stockAvailable: z.number().int().nullable(),
  reservedStock: z.number().int().nullable(),
  lastUpdated: z.string().nullable()
});
export type GrundnerRow = z.infer<typeof GrundnerRow>;

export const GrundnerListRes = z.object({ items: z.array(GrundnerRow) });
export type GrundnerListRes = z.infer<typeof GrundnerListRes>;

export const GrundnerUpdateReq = z.object({
  id: z.number().int(),
  stock: z.number().int().nullable().optional(),
  stockAvailable: z.number().int().nullable().optional(),
  reservedStock: z.number().int().nullable().optional()
}).refine((data) =>
  Object.prototype.hasOwnProperty.call(data, 'stock') ||
  Object.prototype.hasOwnProperty.call(data, 'stockAvailable') ||
  Object.prototype.hasOwnProperty.call(data, 'reservedStock'),
  { message: 'At least one field must be provided' }
);
export type GrundnerUpdateReq = z.infer<typeof GrundnerUpdateReq>;

export const GrundnerResyncReq = z.object({ id: z.number().int().optional() });
export type GrundnerResyncReq = z.infer<typeof GrundnerResyncReq>;










export const PathValidationReq = z.object({
  path: z.string().min(1),
  kind: z.enum(['any', 'file', 'directory']).default('directory')
});
export type PathValidationReq = z.infer<typeof PathValidationReq>;

export const PathValidationRes = z.object({
  path: z.string(),
  exists: z.boolean(),
  isDirectory: z.boolean(),
  isFile: z.boolean(),
  error: z.string().nullable()
});
export type PathValidationRes = z.infer<typeof PathValidationRes>;
export const HistoryListReq = z.object({
  limit: z.number().int().min(1).max(200).default(100),
  machineId: z.number().int().optional(),
  search: z.string().optional(),
  from: z.string().optional(),
  to: z.string().optional()
});
export type HistoryListReq = z.infer<typeof HistoryListReq>;

export const HistoryRow = z.object({
  key: z.string(),
  folder: z.string().nullable(),
  ncfile: z.string().nullable(),
  material: z.string().nullable(),
  machineId: z.number().int().nullable(),
  machineName: z.string().nullable(),
  machineNestpickEnabled: z.boolean().nullable(),
  status: JobStatus,
  stagedAt: z.string().nullable(),
  cutAt: z.string().nullable(),
  nestpickCompletedAt: z.string().nullable(),
  finishAt: z.string(),
  finishSource: z.enum(['cut', 'nestpick']),
  pallet: z.string().nullable(),
  updatedAt: z.string().nullable()
});
export type HistoryRow = z.infer<typeof HistoryRow>;

export const HistoryListRes = z.object({ items: z.array(HistoryRow) });
export type HistoryListRes = z.infer<typeof HistoryListRes>;

export const JobTimelineEvent = z.object({
  id: z.string(),
  eventType: z.string(),
  createdAt: z.string().nullable(),
  machineId: z.number().int().nullable(),
  machineName: z.string().nullable(),
  payload: z.unknown().nullable()
});
export type JobTimelineEvent = z.infer<typeof JobTimelineEvent>;

export const JobTimelineRes = z.object({
  job: z.object({
    key: z.string(),
    folder: z.string().nullable(),
    ncfile: z.string().nullable(),
    material: z.string().nullable(),
    machineId: z.number().int().nullable(),
    machineName: z.string().nullable(),
    machineNestpickEnabled: z.boolean().nullable(),
    status: JobStatus,
    dateadded: z.string().nullable(),
    stagedAt: z.string().nullable(),
    cutAt: z.string().nullable(),
    nestpickCompletedAt: z.string().nullable(),
    finishAt: z.string().nullable(),
    finishSource: z.enum(['pending', 'cut', 'nestpick']),
    pallet: z.string().nullable(),
    updatedAt: z.string().nullable()
  }),
  events: z.array(JobTimelineEvent)
});
export type JobTimelineRes = z.infer<typeof JobTimelineRes>;

const ALARM_INACTIVE_VALUES = ['ok', 'ready', '0', 'none', ''] as const;

export const AlarmEntry = z.object({
  id: z.string(),
  key: z.string(),
  alarm: z.string(),
  status: z.string().nullable().optional(),
  mode: z.string().nullable().optional(),
  currentProgram: z.string().nullable().optional(),
  alarmHistory: z.string().nullable().optional(),
  lastSeenAt: z.string(),
  severity: z.enum(['info', 'warning', 'critical']).default('warning')
});
export type AlarmEntry = z.infer<typeof AlarmEntry>;

export const WatcherStatus = z.object({
  name: z.string(),
  label: z.string(),
  status: z.enum(['idle', 'watching', 'error']),
  lastEventAt: z.string().nullable(),
  lastEvent: z.string().nullable(),
  lastErrorAt: z.string().nullable(),
  lastError: z.string().nullable()
});
export type WatcherStatus = z.infer<typeof WatcherStatus>;

export const WorkerErrorEntry = z.object({
  id: z.string(),
  source: z.string(),
  message: z.string(),
  timestamp: z.string(),
  stack: z.string().nullable().optional(),
  context: z.record(z.unknown()).optional()
});
export type WorkerErrorEntry = z.infer<typeof WorkerErrorEntry>;

export const MachineHealthCode = z.enum(['NO_PARTS_CSV', 'NESTPICK_SHARE_UNREACHABLE', 'COPY_FAILURE']);
export type MachineHealthCode = z.infer<typeof MachineHealthCode>;

export const MachineHealthEntry = z.object({
  id: z.string(),
  machineId: z.number().int().nullable(),
  code: MachineHealthCode,
  severity: z.enum(['info', 'warning', 'critical']).default('warning'),
  message: z.string(),
  lastUpdatedAt: z.string(),
  context: z.record(z.unknown()).optional()
});
export type MachineHealthEntry = z.infer<typeof MachineHealthEntry>;

export const DiagnosticsSnapshot = z.object({
  dbStatus: DbStatusSchema.optional(),
  watchers: z.array(WatcherStatus),
  recentErrors: z.array(WorkerErrorEntry),
  machineHealth: z.array(MachineHealthEntry),
  lastUpdatedAt: z.string()
});
export type DiagnosticsSnapshot = z.infer<typeof DiagnosticsSnapshot>;

export const DiagnosticsLogSummary = z.object({
  file: z.string(),
  name: z.string(),
  size: z.number().int().nonnegative().nullable(),
  updatedAt: z.string().nullable()
});
export type DiagnosticsLogSummary = z.infer<typeof DiagnosticsLogSummary>;

export const DiagnosticsLogsRes = z.object({ items: z.array(DiagnosticsLogSummary) });
export type DiagnosticsLogsRes = z.infer<typeof DiagnosticsLogsRes>;

export const DiagnosticsLogTailReq = z.object({
  file: z.string(),
  limit: z.number().int().min(10).max(2000).default(200)
});
export type DiagnosticsLogTailReq = z.infer<typeof DiagnosticsLogTailReq>;

export const DiagnosticsLogTailRes = DiagnosticsLogSummary.extend({
  lines: z.array(z.string()),
  limit: z.number().int().min(10).max(2000),
  available: z.number().int().nonnegative().nullable()
});
export type DiagnosticsLogTailRes = z.infer<typeof DiagnosticsLogTailRes>;


export const AlarmInactiveValues = z.enum(ALARM_INACTIVE_VALUES);

export const CopyDiagnosticsLog = DiagnosticsLogSummary.extend({
  lines: z.array(z.string()),
  available: z.number().int().nonnegative().nullable()
});
export type CopyDiagnosticsLog = z.infer<typeof CopyDiagnosticsLog>;

export const CopyDiagnosticsResult = z.object({
  ok: z.literal(true),
  copiedAt: z.string(),
  bytes: z.number().int().nonnegative(),
  logCount: z.number().int().nonnegative(),
  logs: z.array(CopyDiagnosticsLog),
  snapshot: DiagnosticsSnapshot
});
export type CopyDiagnosticsResult = z.infer<typeof CopyDiagnosticsResult>;



// Live log streaming
export const DiagnosticsLogStreamReq = z.object({ file: z.string() });
export type DiagnosticsLogStreamReq = z.infer<typeof DiagnosticsLogStreamReq>;

export const DiagnosticsLogUpdate = z.object({ file: z.string(), lines: z.array(z.string()) });
export type DiagnosticsLogUpdate = z.infer<typeof DiagnosticsLogUpdate>;

// Cross‑process Logging
export const LogLevel = z.enum(['trace', 'debug', 'info', 'warn', 'error', 'fatal']);
export type LogLevel = z.infer<typeof LogLevel>;

export const LogWriteReq = z.object({
  level: LogLevel.default('info'),
  msg: z.string().min(1),
  context: z.record(z.unknown()).optional()
});
export type LogWriteReq = z.infer<typeof LogWriteReq>;


// CNC Telemetry & Alarms

export const TelemetrySummaryReq = z.object({
  from: z.string().optional(),
  to: z.string().optional(),
  machineIds: z.array(z.number().int()).optional()
});
export type TelemetrySummaryReq = z.infer<typeof TelemetrySummaryReq>;

export const TelemetrySeconds = z.object({
  READY: z.number().int().nonnegative().default(0),
  'B-STOP': z.number().int().nonnegative().default(0),
  BUSY: z.number().int().nonnegative().default(0),
  ALARM: z.number().int().nonnegative().default(0),
  EMG: z.number().int().nonnegative().default(0),
  OTHER: z.number().int().nonnegative().default(0)
});
export type TelemetrySeconds = z.infer<typeof TelemetrySeconds>;

export const TelemetryMachineSummary = z.object({
  machineId: z.number().int().nullable(),
  machineName: z.string().nullable(),
  seconds: TelemetrySeconds
});
export type TelemetryMachineSummary = z.infer<typeof TelemetryMachineSummary>;

export const TelemetrySummaryRes = z.object({ items: z.array(TelemetryMachineSummary) });
export type TelemetrySummaryRes = z.infer<typeof TelemetrySummaryRes>;

export const AlarmsHistoryReq = z.object({
  from: z.string().optional(),
  to: z.string().optional(),
  machineIds: z.array(z.number().int()).optional()
});
export type AlarmsHistoryReq = z.infer<typeof AlarmsHistoryReq>;

export const AlarmIntervalRow = z.object({
  startAt: z.string(),
  endAt: z.string().nullable(),
  durationMinutes: z.number().int().nonnegative(),
  machineId: z.number().int().nullable(),
  machineName: z.string().nullable(),
  alarmId: z.string().nullable(),
  description: z.string()
});
export type AlarmIntervalRow = z.infer<typeof AlarmIntervalRow>;

export const AlarmsHistoryRes = z.object({ items: z.array(AlarmIntervalRow) });
export type AlarmsHistoryRes = z.infer<typeof AlarmsHistoryRes>;

================
File: packages/shared/src/result.ts
================
import { err, ok, type Result as NeverthrowResult } from 'neverthrow';
import type { AppError } from './ipc';

export type ResultEnvelope<T> = { ok: true; value: T } | { ok: false; error: AppError };
export type ResultPayload<T> = ResultEnvelope<T>;

export const makeOk = <T>(value: T): ResultEnvelope<T> => ({ ok: true, value });
export const makeErr = <T>(error: AppError): ResultEnvelope<T> => ({ ok: false, error });

export const toEnvelope = <T>(result: NeverthrowResult<T, AppError>): ResultEnvelope<T> =>
  result.isOk() ? makeOk(result.value) : makeErr(result.error);

export const fromEnvelope = <T>(payload: ResultEnvelope<T>): NeverthrowResult<T, AppError> =>
  payload.ok ? ok(payload.value) : err(payload.error);

export const toPayload = toEnvelope;
export const fromPayload = fromEnvelope;

================
File: packages/shared/tsconfig.json
================
{
  "extends": "../../tsconfig.base.json",
  "compilerOptions": {
    "outDir": "dist",
    "module": "ESNext",
    "declaration": true,
    "emitDeclarationOnly": false
  },
  "include": ["src/**/*.ts"]
}

================
File: playwright.config.ts
================
import { defineConfig } from '@playwright/test';

export default defineConfig({
  testDir: 'tests/e2e',
  timeout: 60_000,
  use: {
    baseURL: 'http://127.0.0.1:5180',
    trace: 'on-first-retry'
  },
  webServer: {
    command: 'pnpm -C packages/renderer dev -- --host 127.0.0.1 --port 5180',
    port: 5180,
    reuseExistingServer: !process.env.CI,
    timeout: 120_000
  }
});

================
File: pnpm-workspace.yaml
================
packages:
  - "packages/*"

================
File: prettier.config.cjs
================
/** @type {import('prettier').Config} */
module.exports = {
  arrowParens: 'always',
  endOfLine: 'lf',
  printWidth: 100,
  singleQuote: true,
  semi: true,
  tabWidth: 2,
  trailingComma: 'none'
};

================
File: settings.json
================
{
  "version": 1,
  "db": {
    "host": "127.0.0.1",
    "port": 5432,
    "database": "woodtron",
    "user": "woodtron_user",
    "password": "woodtron",
    "sslMode": "disable",
    "statementTimeoutMs": 30000
  },
  "paths": {
    "processedJobsRoot": "C:\\Users\\mike2\\Documents\\GitHub\\Test NC Files",
    "autoPacCsvDir": "D:\\SoftwareTesting\\LabelStatus",
    "grundnerFolderPath": "D:\\SoftwareTesting\\Nestpick"
  },
  "test": {
    "testDataFolderPath": "D:\\SoftwareTesting\\Nestpick",
    "useTestDataMode": false,
    "sheetIdMode": "type_data"
  },
  "grundner": {
    "reservedAdjustmentMode": "delta"
  }
}

================
File: simulation/import_cnc_stats.py
================
"""
Import CNC telemetry stats from cnc_data*.json (and CSV) into Postgres.

Behavior
- Watches a folder (or processes a single file) for telemetry exports:
  files matching cnc_data*.json (date-stamped). CSV is also supported.
- Parses JSON (object, array, NDJSON lines, or container objects under
  common keys like data/items/rows/records/telemetry/payloads).
- Maps fields to the public.cncstats table and upserts on key
  (same mapping as the Electron app's test-data path).
- After commit, verifies inserted keys exist in DB; deletes the file
  only when verification succeeds (unless --no-delete is set).

Usage
- Edit HARD_CODED_DIR below or run:
    python simulation/import_cnc_stats.py --dir "C:\\path\\to\\folder"
  First pass behavior: process only the newest file unless you pass --all.
  Single file:
    python simulation/import_cnc_stats.py --file "C:\\path\\to\\cnc_data_20250908_141408.json"
- Keep running (default) or process once and exit with --once.
- Polling interval can be set via --interval (seconds).

Notes
- DB connection is read from repo-root settings.json (same as the app).
- Columns: key, api_ip, currentprogram, mode, status, alarm, emg,
  powerontime, cuttingtime, alarmhistory, vacuumtime, drillheadtime,
  spindletime, conveyortime, greasetime.
"""

from __future__ import annotations

import argparse
import json
import logging
import time
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import psycopg2


# 1) Set this to your folder containing cnc_data*.json files
HARD_CODED_DIR = r"C:\\Users\\mike2\\Documents\\GitHub\\CNCTestData\\cnc_data"  # <-- update me or pass --dir


# ----- DB config helpers -----

@dataclass
class DbConfig:
    host: str
    port: int
    database: str
    user: str
    password: str


def load_db_settings(repo_root: Path) -> DbConfig:
    cfg_path = repo_root / "settings.json"
    with cfg_path.open("r", encoding="utf-8") as f:
        raw = json.load(f)
    db_raw = raw["db"]
    return DbConfig(
        host=db_raw["host"],
        port=int(db_raw["port"]),
        database=db_raw["database"],
        user=db_raw["user"],
        password=str(db_raw.get("password", "")),
    )


def connect_db(cfg: DbConfig):
    return psycopg2.connect(
        host=cfg.host,
        port=cfg.port,
        dbname=cfg.database,
        user=cfg.user,
        password=cfg.password,
    )


# ----- File parsing utilities -----

def infer_timestamp_from_file_name(file_name: str) -> Optional[str]:
    """Infer timestamp in format YYYY.MM.DD HH:MM:SS from names like 2024-09-10_12-34-56.*"""
    import re

    m = re.search(r"(\d{4})[._-]?(\d{2})[._-]?(\d{2})[T_\- ]?(\d{2})[._-]?(\d{2})[._-]?(\d{2})", file_name)
    if not m:
        return None
    return f"{m.group(1)}.{m.group(2)}.{m.group(3)} {m.group(4)}:{m.group(5)}:{m.group(6)}"


def split_csv_line(line: str) -> List[str]:
    out: List[str] = []
    current = ""
    in_quotes = False
    i = 0
    while i < len(line):
        ch = line[i]
        if ch == '"':
            if in_quotes and i + 1 < len(line) and line[i + 1] == '"':
                current += '"'
                i += 1
            else:
                in_quotes = not in_quotes
        elif (ch == ',' or ch == ';') and not in_quotes:
            out.append(current)
            current = ""
        else:
            current += ch
        i += 1
    out.append(current)
    return [c.strip() for c in out]


def strip_csv_cell(value: Optional[str]) -> str:
    if not isinstance(value, str):
        return ""
    return value.strip().strip('"')


def parse_csv_content(text: str) -> List[List[str]]:
    lines = [ln.rstrip() for ln in text.splitlines() if ln.strip()]
    return [split_csv_line(ln) for ln in lines]


def normalize_header_name(name: str, index: int, seen: Dict[str, int]) -> str:
    import re

    base = strip_csv_cell(name).lower()
    base = re.sub(r"[^a-z0-9]+", "_", base).strip("_")
    if not base:
        base = f"column_{index + 1}"
    count = seen.get(base, 0) + 1
    seen[base] = count
    return f"{base}_{count}" if count > 1 else base


def parse_cnc_csv_records(csv_file: Path) -> List[Dict[str, Any]]:
    raw = csv_file.read_text(encoding="utf-8", errors="ignore")
    rows = parse_csv_content(raw)
    if len(rows) <= 1:
        return []
    headers = rows[0]
    seen: Dict[str, int] = {}
    keys = [normalize_header_name(h, idx, seen) for idx, h in enumerate(headers)]
    out: List[Dict[str, Any]] = []
    for r in rows[1:]:
        rec: Dict[str, Any] = {}
        has_val = False
        for i, key in enumerate(keys):
            val = strip_csv_cell(r[i] if i < len(r) else "")
            if val:
                rec[key] = val
                has_val = True
        if has_val:
            out.append(rec)
    return out


def read_json_payloads(file_path: Path) -> List[Dict[str, Any]]:
    """Parse JSON or NDJSON file into a list of dict payloads.

    Accepts:
    - Single object → [obj]
    - Array of objects → [obj, ...]
    - Object with array under common keys (data/items/rows/records/telemetry/payloads) → that array
    - NDJSON lines → one object per line
    """
    text = file_path.read_text(encoding="utf-8", errors="ignore").lstrip("\ufeff").strip()
    if not text:
        return []
    # Try standard JSON (object or array)
    try:
        parsed = json.loads(text)
        if isinstance(parsed, list):
            return [p for p in parsed if isinstance(p, dict)]
        if isinstance(parsed, dict):
            for key in ("data", "items", "rows", "records", "telemetry", "payloads"):
                val = parsed.get(key)
                if isinstance(val, list):
                    return [p for p in val if isinstance(p, dict)]
            return [parsed]
    except Exception:
        pass
    # Try NDJSON (one JSON per line)
    out_list: List[Dict[str, Any]] = []
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue
        try:
            obj = json.loads(line)
            if isinstance(obj, dict):
                out_list.append(obj)
        except Exception:
            continue
    return out_list


# ----- Mapping logic to public.cncstats (mirrors app test-data path) -----

def _to_record(value: Any) -> Optional[Dict[str, Any]]:
    return value if isinstance(value, dict) else None


def _pick_ci(source: Optional[Dict[str, Any]], candidates: List[str]) -> Any:
    if not source:
        return None
    lower_map = {k.lower(): v for k, v in source.items()}
    for cand in candidates:
        v = lower_map.get(cand.lower())
        if v is not None:
            return v
    return None


def _to_str_or_null(value: Any) -> Optional[str]:
    if value is None:
        return None
    if isinstance(value, str):
        s = value.strip()
        return s if s else None
    if isinstance(value, (int, float)):
        try:
            if not (float("-inf") < float(value) < float("inf")):
                return None
        except Exception:
            return None
        return str(value)
    if isinstance(value, bool):
        return "true" if value else "false"
    try:
        return json.dumps(value)
    except Exception:
        return str(value)


def _pick_string(sources: List[Optional[Dict[str, Any]]], candidates: List[str]) -> Optional[str]:
    for src in sources:
        v = _pick_ci(src, candidates)
        s = _to_str_or_null(v)
        if s is not None:
            return s
    return None


def _sanitize(value: Optional[str], limit: int) -> Optional[str]:
    if value is None:
        return None
    s = value.strip()
    if not s:
        return None
    return s if len(s) <= limit else s[:limit]


def build_upsert_from_payload(entry: Any, file_name_for_timestamp: Optional[str]) -> Optional[Dict[str, Optional[str]]]:
    rec = _to_record(entry)
    if rec is None:
        return None

    machine_status = _to_record(_pick_ci(rec, ["MachineStatus", "machineStatus", "machine_status"]))
    timers = _to_record(_pick_ci(rec, ["Timers", "timers", "timer"]))

    # Prefer timestamp from record, else infer from file name, else current time
    timestamp_value = _pick_string([rec], ["timestamp", "time", "ts", "key"]) or (
        infer_timestamp_from_file_name(file_name_for_timestamp or "") if file_name_for_timestamp else None
    )
    if not timestamp_value:
        timestamp_value = datetime.now().strftime("%Y.%m.%d %H:%M:%S")

    api_ip = _pick_string([rec, machine_status], ["CNC_IP", "cnc_ip", "api_ip", "ip"])  # optional

    alarm_history_raw = _pick_ci(rec, ["AlarmHistoryDictionary", "alarmHistory", "AlarmHistory"])
    if isinstance(alarm_history_raw, dict) and alarm_history_raw:
        alarm_history = json.dumps(alarm_history_raw)
    else:
        alarm_history = None

    upsert = {
        "key": timestamp_value,
        "api_ip": api_ip,
        "currentprogram": _pick_string([machine_status, rec], ["CurrentProgram", "currentProgram", "Program", "program", "MainProgram"]),
        "mode": _pick_string([machine_status, rec], ["Mode", "mode", "OperatingMode"]),
        "status": _pick_string([machine_status, rec], ["Status", "status", "MachineStatus", "state"]),
        "alarm": _pick_string([machine_status, rec], ["Alarm", "alarm"]),
        "emg": _pick_string([machine_status, rec], ["EMG", "emg", "Emergency", "emergency"]),
        "powerontime": _pick_string([timers, rec], ["PowerOnTime_sec", "powerOnTime", "power_on", "PowerOn", "powerontime"]),
        "cuttingtime": _pick_string([timers, rec], ["CycleCuttingTime_sec", "cycleCuttingTime", "AccumulatedCuttingTime_sec", "cuttingTime", "cut_time"]),
        "alarmhistory": alarm_history,
        "vacuumtime": _pick_string([timers, rec], ["VacTime_sec", "vacTime", "VacuumTime"]),
        "drillheadtime": _pick_string([timers, rec], ["DrillTime_sec", "drillTime", "DrillHeadTime"]),
        "spindletime": _pick_string([timers, rec], ["SpindleTime_sec", "spindleTime"]),
        "conveyortime": _pick_string([timers, rec], ["ConveyorTime_sec", "conveyorTime"]),
        "greasetime": _pick_string([timers, rec], ["GreaseTime_sec", "greaseTime"]),
    }

    # Sanitize to match app constraints (key/api_ip<=100, others<=50)
    upsert["key"] = _sanitize(upsert["key"], 100)
    upsert["api_ip"] = _sanitize(upsert["api_ip"], 100)
    for col in (
        "currentprogram",
        "mode",
        "status",
        "alarm",
        "emg",
        "powerontime",
        "cuttingtime",
        "alarmhistory",
        "vacuumtime",
        "drillheadtime",
        "spindletime",
        "conveyortime",
        "greasetime",
    ):
        upsert[col] = _sanitize(upsert[col], 50)

    if not upsert["key"]:
        return None
    return upsert


def upsert_cncstats(conn, row: Dict[str, Optional[str]]):
    sql = (
        "INSERT INTO public.cncstats("
        " key, api_ip, currentprogram, mode, status, alarm, emg, powerontime, cuttingtime,"
        " alarmhistory, vacuumtime, drillheadtime, spindletime, conveyortime, greasetime)"
        " VALUES (%(key)s, %(api_ip)s, %(currentprogram)s, %(mode)s, %(status)s, %(alarm)s, %(emg)s, %(powerontime)s, %(cuttingtime)s,"
        " %(alarmhistory)s, %(vacuumtime)s, %(drillheadtime)s, %(spindletime)s, %(conveyortime)s, %(greasetime)s)"
        " ON CONFLICT (key) DO UPDATE SET"
        " api_ip = EXCLUDED.api_ip,"
        " currentprogram = EXCLUDED.currentprogram,"
        " mode = EXCLUDED.mode,"
        " status = EXCLUDED.status,"
        " alarm = EXCLUDED.alarm,"
        " emg = EXCLUDED.emg,"
        " powerontime = EXCLUDED.powerontime,"
        " cuttingtime = EXCLUDED.cuttingtime,"
        " alarmhistory = EXCLUDED.alarmhistory,"
        " vacuumtime = EXCLUDED.vacuumtime,"
        " drillheadtime = EXCLUDED.drillheadtime,"
        " spindletime = EXCLUDED.spindletime,"
        " conveyortime = EXCLUDED.conveyortime,"
        " greasetime = EXCLUDED.greasetime"
    )
    with conn.cursor() as cur:
        cur.execute(sql, row)


def find_cnc_jsons(folder: Path) -> List[Path]:
    return sorted([p for p in folder.glob("cnc_data*.json") if p.is_file()], key=lambda p: p.stat().st_mtime)


def find_cnc_csvs(folder: Path) -> List[Path]:
    return sorted([p for p in folder.glob("cnc_data*.csv") if p.is_file()], key=lambda p: p.stat().st_mtime)


def _is_file_stable(path: Path, attempts: int = 4, delay_s: float = 0.25) -> bool:
    try:
        last = path.stat().st_size
    except FileNotFoundError:
        return False
    for _ in range(max(1, attempts)):
        time.sleep(max(0.01, delay_s))
        try:
            now = path.stat().st_size
        except FileNotFoundError:
            return False
        if now == last:
            return True
        last = now
    return False


def _process_one_file(conn, path: Path):
    logger = logging.getLogger("import_cnc_stats")
    batch = 0
    keys_successful: List[str] = []
    if path.suffix.lower() == ".json":
        records = read_json_payloads(path)
        if not records:
            logger.warning("No JSON objects in %s; skipping", path.name)
            return 0, []
        logger.info("Parsed %d JSON object(s) from %s", len(records), path.name)
        for rec in records:
            upsert = build_upsert_from_payload(rec, path.name)
            if not upsert:
                continue
            key = upsert.get("key")
            try:
                logger.info("Upserting key=%s from %s", key, path.name)
                upsert_cncstats(conn, upsert)
                batch += 1
                if key:
                    keys_successful.append(key)
            except Exception as e:
                logger.error("Upsert failed for key=%s file=%s: %s", key, path.name, e)
    elif path.suffix.lower() == ".csv":
        records = parse_cnc_csv_records(path)
        if not records:
            logger.warning("No data rows in %s; skipping", path.name)
            return 0, []
        logger.info("Parsed %d CSV row(s) from %s", len(records), path.name)
        for rec in records:
            upsert = build_upsert_from_payload(rec, path.name)
            if not upsert:
                continue
            key = upsert.get("key")
            try:
                logger.info("Upserting key=%s from %s", key, path.name)
                upsert_cncstats(conn, upsert)
                batch += 1
                if key:
                    keys_successful.append(key)
            except Exception as e:
                logger.error("Upsert failed for key=%s file=%s: %s", key, path.name, e)
    else:
        logger.warning("Unsupported file type: %s; skipping", path.name)
        return 0, []
    return batch, keys_successful


def _verify_keys(conn, keys: List[str]) -> List[str]:
    """Return the list of keys that are present in DB."""
    if not keys:
        return []
    unique = list({k for k in keys if k})
    with conn.cursor() as cur:
        cur.execute("SELECT key FROM public.cncstats WHERE key = ANY(%s)", (unique,))
        rows = cur.fetchall() or []
    found = [r[0] for r in rows if r and r[0] is not None]
    return found


def main():
    # Configure logging
    logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s %(message)s', datefmt='%H:%M:%S')
    logger = logging.getLogger("import_cnc_stats")

    parser = argparse.ArgumentParser(description="Import CNC telemetry from cnc_data*.json (or .csv) into public.cncstats")
    parser.add_argument("--dir", help="Folder containing cnc_data*.json (or .csv)")
    parser.add_argument("--file", help="Import a single file (json/csv)")
    parser.add_argument("--all", action="store_true", help="Import all matching files on first pass (default: newest only)")
    parser.add_argument("--once", action="store_true", help="Process available files then exit")
    parser.add_argument("--interval", type=float, default=1.0, help="Polling interval in seconds for --dir mode (default: 1.0)")
    parser.add_argument("--no-delete", action="store_true", help="Do not delete files after successful import")
    args = parser.parse_args()

    # Load DB settings from repo root settings.json
    repo_root = Path(__file__).resolve().parents[1]
    db_cfg = load_db_settings(repo_root)

    if args.file:
        file_path = Path(args.file)
        if not file_path.exists() or not file_path.is_file():
            raise SystemExit(f"File not found: {file_path}")
        with connect_db(db_cfg) as conn:
            if not _is_file_stable(file_path):
                logger.info("Waiting for file to stabilize: %s", file_path.name)
            batch, keys = _process_one_file(conn, file_path)
            conn.commit()
            found = _verify_keys(conn, keys)
            ok = len(found) == len(keys)
            logger.info("Imported %d row(s) from %s; verified %d/%d keys", batch, file_path.name, len(found), len(keys))
            if ok and batch > 0 and not args.no_delete:
                try:
                    file_path.unlink()
                    logger.info("Deleted %s", file_path.name)
                except Exception as e:
                    logger.warning("Failed to delete %s: %s", file_path.name, e)
            elif not ok:
                missing = [k for k in keys if k not in set(found)]
                logger.warning("Verification failed for %s; missing keys: %s", file_path.name, ", ".join(missing) if missing else "<none>")
        return

    target_dir = Path(args.dir) if args.dir else Path(HARD_CODED_DIR)
    if not target_dir.exists() or not target_dir.is_dir():
        raise SystemExit(f"Target directory not found: {target_dir}")

    logger.info("Watching for cnc_data*.json/.csv in: %s", target_dir)

    try:
        with connect_db(db_cfg) as conn:
            first_pass = True
            while True:
                # Collect candidates (JSON first, then CSV), oldest→newest
                json_files = find_cnc_jsons(target_dir)
                csv_files = find_cnc_csvs(target_dir)
                candidates: List[Path] = []
                if json_files:
                    candidates.extend(json_files)
                if csv_files:
                    candidates.extend(csv_files)

                if not candidates:
                    if args.once:
                        logger.info("No files to process; exiting (--once)")
                        return
                    time.sleep(max(0.1, args.interval))
                    first_pass = False
                    continue

                if first_pass and not args.all and len(candidates) > 1:
                    # Only process newest on first pass when --all is not set
                    candidates = [candidates[-1]]

                processed_any = False
                for path in candidates:
                    if not _is_file_stable(path):
                        # Skip this cycle; it may still be written
                        continue
                    batch, keys = _process_one_file(conn, path)
                    conn.commit()
                    found = _verify_keys(conn, keys)
                    ok = len(found) == len(keys)
                    if ok and batch > 0:
                        processed_any = True
                        logger.info("Imported %d row(s) from %s; verified %d/%d keys", batch, path.name, len(found), len(keys))
                        if not args.no_delete:
                            try:
                                path.unlink()
                                logger.info("Deleted %s", path.name)
                            except Exception as e:
                                logger.warning("Failed to delete %s: %s", path.name, e)
                    else:
                        if batch == 0:
                            logger.info("No rows imported from %s; leaving file in place", path.name)
                        else:
                            missing = [k for k in keys if k not in set(found)]
                            logger.warning("Verification failed for %s; missing keys: %s", path.name, ", ".join(missing) if missing else "<none>")

                first_pass = False
                if args.once:
                    return
                if not processed_any:
                    time.sleep(max(0.1, args.interval))
    except KeyboardInterrupt:
        logger.info("Stopped by user")


if __name__ == "__main__":
    main()

================
File: simulation/README.md
================
Simulation Test Suite

Purpose
- Simulate an end-to-end job workflow by driving the same file-based watchers the app uses (AutoPAC CSVs and Nestpick folders).
- Useful for smoke testing environments, watcher behavior, and DB lifecycle transitions without manual operator actions.

What it does
- Picks a random job from the `jobs` table.
- Optionally stages it to a target machine (copies NC/CSV/.PTS/.LPT/images into the machine’s `ap_jobfolder`). If the per‑file parts CSV `<base>.csv` is missing, the script synthesizes one using `.pts/.lpt` to estimate part rows.
- Generates AutoPAC CSVs in sequence: `load_finish<machine>.csv`, `label_finish<machine>.csv`, `cnc_finish<machine>.csv`.
- Lets the app forward the parts CSV to Nestpick (watchers write `Nestpick.csv`).
- Reads `Nestpick.csv` (forwarded by the app) to pick a `PalletName` if present, deletes it, then writes an Unstack report (`Report_FullNestpickUnstack.csv`) to complete the lifecycle and set `jobs.pallet`. Falls back to a random pallet if none found.
- Adds a random delay (0–120s) between steps to mimic real timing.

Prerequisites
- The Electron app must be running with watchers enabled.
- `settings.json` must be configured with valid DB and paths (autoPacCsvDir, machines’ ap_jobfolder and nestpick_folder).
- Python 3.9+ and pip.

Install deps
- pip install -r simulation/requirements.txt

Run the simulator
- Repeat forever (prompts for machine):
  - python simulation/simulate_workflow.py
- Repeat forever (explicit machine):
  - python simulation/simulate_workflow.py --machine WT1
- Run once and exit:
  - python simulation/simulate_workflow.py --once --machine WT1

Useful options
- `--machine`  Machine name token (e.g. WT1) or numeric id (e.g. 1). If omitted, prompts.
- `--ask-machine`  Always prompt for the machine, ignoring `--machine`.
- `--min-delay`, `--max-delay`  Seconds between steps inside a cycle. Defaults 0 and 120.
- `--between-min`, `--between-max`  Seconds between cycles. Defaults 3 and 15.
- `--once`  Run one cycle and exit.
- `--dry-run`  Print planned actions without writing files.
- `--no-stage`  Skip staging if you only want to drive AutoPAC/Nestpick for already staged jobs.

Notes on staging
- The script mirrors key parts of `worklist.ts` to stage a job:
  - Derives a destination folder under `ap_jobfolder/<leaf>` where `<leaf>` is taken from job.folder or the NC base name.
  - Copies the `.nc` and, if found, the per-file parts CSV `JobName.csv` (this is forwarded to Nestpick on CNC_FINISH).
  - If the destination exists, a timestamped suffix is appended to avoid collisions.
- We intentionally do not run the app’s IPC to update STAGED; watchers accept `LOAD_FINISH` directly from `PENDING` and will set `staged_at` on the first AutoPAC event.
- Copies `.nc`, `.pts`, `.lpt`, and images matching `<base>*.bmp|jpg|jpeg` from the job source to the staged folder.
- If `<base>.csv` is missing, creates a headered CSV with columns: `X-pos,Y-pos,reserve,ElementID,LengthX,LengthY,Thickness,Destination,SourceMachine,Type,Additional,Category,PalletName,X-posTarget,YposTarget,RposTarget`, and N data rows (N derived from `.pts` or `.lpt`, else 1). The app’s watcher will fill `Destination=99` and `SourceMachine=<id>`.

Unstack (pallet) file format
- Written to `<nestpick_folder>/Report_FullNestpickUnstack.csv`.
- No header required; the script writes rows like: `JobBase,Pallet_A05`.
- The watcher updates `jobs.pallet` and completes the lifecycle to `NESTPICK_COMPLETE`.

Troubleshooting
- Nothing happens: confirm the app is running and `autoPacCsvDir`/Nestpick folders match `settings.json`.
- Job not found by AutoPAC: ensure the first column in the AutoPAC CSV is the NC base name and the CSV contains the machine token (e.g., WT1).
- Not forwarded to Nestpick: ensure the job’s parts CSV `JobBase.csv` exists in the staged folder.

================
File: simulation/requirements.txt
================
psycopg2-binary>=2.9.9

================
File: simulation/simulate_workflow.py
================
import argparse
import json
import os
import random
import shutil
import sys
import time
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Optional, Tuple

import psycopg2


@dataclass
class DbConfig:
    host: str
    port: int
    database: str
    user: str
    password: str


@dataclass
class Settings:
    processed_jobs_root: str
    auto_pac_csv_dir: str


@dataclass
class Machine:
    machine_id: int
    name: str
    ap_jobfolder: str
    nestpick_folder: str
    nestpick_enabled: bool


@dataclass
class Job:
    key: str
    folder: Optional[str]
    ncfile: Optional[str]


def split_csv_line(line: str) -> list[str]:
    out: list[str] = []
    current = ''
    in_quotes = False
    i = 0
    while i < len(line):
        ch = line[i]
        if ch == '"':
            if in_quotes and i + 1 < len(line) and line[i + 1] == '"':
                current += '"'
                i += 1
            else:
                in_quotes = not in_quotes
        elif (ch == ',' or ch == ';') and not in_quotes:
            out.append(current)
            current = ''
        else:
            current += ch
        i += 1
    out.append(current)
    return [c.strip() for c in out]


def parse_csv_content(text: str) -> list[list[str]]:
    lines = [ln.rstrip() for ln in text.splitlines() if ln.strip()]
    return [split_csv_line(ln) for ln in lines]


def count_parts_from_pts(source_root: Path, base_stem: str) -> Optional[int]:
    pts = find_file_by_name(source_root, f"{base_stem}.pts")
    if not pts:
        return None
    try:
        text = pts.read_text(encoding='utf-8', errors='ignore')
    except Exception:
        return None
    rows = parse_csv_content(text)
    if not rows:
        return None
    # Heuristic: if first row has alphabetic header, skip it
    start = 1 if any(any(ch.isalpha() for ch in cell) for cell in rows[0]) else 0
    count = sum(1 for r in rows[start:] if any(cell.strip() for cell in r))
    return count or None


def count_parts_from_lpt(source_root: Path, base_stem: str) -> Optional[int]:
    lpt = find_file_by_name(source_root, f"{base_stem}.lpt")
    if not lpt:
        return None
    try:
        text = lpt.read_text(encoding='utf-8', errors='ignore')
    except Exception:
        return None
    rows = parse_csv_content(text)
    if not rows:
        return None
    # Heuristic: count rows that look like data (3+ columns or first col numeric-like)
    start = 1 if any(any(ch.isalpha() for ch in cell) for cell in rows[0]) else 0
    data_rows = [r for r in rows[start:] if len(r) >= 1 and any(tok for tok in r)]
    return (len(data_rows) or None)


def synthesize_parts_rows(source_root: Path, base_stem: str) -> list[list[str]]:
    count = (
        count_parts_from_pts(source_root, base_stem)
        or count_parts_from_lpt(source_root, base_stem)
        or 1
    )
    rows: list[list[str]] = []
    for i in range(count):
        rows.append([
            "0",            # X-pos
            "0",            # Y-pos
            "",             # reserve
            f"{base_stem}-{i+1}",  # ElementID
            "0",            # LengthX
            "0",            # LengthY
            "0",            # Thickness
            "",             # Destination (filled by watcher)
            "",             # SourceMachine (filled by watcher)
            "",             # Type
            "",             # Additional
            "",             # Category
            "",             # PalletName
            "0",            # X-posTarget
            "0",            # YposTarget
            "0",            # RposTarget
        ])
    return rows


def wait_for_file(path: Path, timeout_s: int = 60) -> bool:
    end = time.time() + timeout_s
    while time.time() < end:
        if path.exists():
            # basic stability check
            size1 = path.stat().st_size
            time.sleep(0.2)
            size2 = path.stat().st_size
            if size1 == size2:
                return True
        time.sleep(0.3)
    return False


def try_extract_pallet_then_clear(nestpick_root: Path) -> Optional[str]:
    nestpick_csv = nestpick_root / "Nestpick.csv"
    if not wait_for_file(nestpick_csv, timeout_s=60):
        return None
    try:
        text = nestpick_csv.read_text(encoding='utf-8', errors='ignore')
        rows = parse_csv_content(text)
        if not rows:
            return None
        header = rows[0]
        is_header = any(any(ch.isalpha() for ch in cell) for cell in header)
        pallet_idx = -1
        data_start = 0
        if is_header:
            data_start = 1
            for idx, cell in enumerate(header):
                if cell.strip().lower() == 'palletname':
                    pallet_idx = idx
                    break
        # pick first non-empty pallet value
        pallet_val: Optional[str] = None
        for r in rows[data_start:]:
            if pallet_idx >= 0 and pallet_idx < len(r):
                val = r[pallet_idx].strip().strip('"')
                if val:
                    pallet_val = val
                    break
        return pallet_val
    finally:
        try:
            nestpick_csv.unlink()
            print(f"[nestpick] Cleared {nestpick_csv}")
        except Exception:
            pass


def write_unstack_unified(nestpick_root: Path, base: str, pallet: str, dry_run=False) -> Path:
    out_path = nestpick_root / "Report_FullNestpickUnstack.csv"
    data = f"{base},{pallet}"
    if dry_run:
        print(f"[unstack] Would write {out_path}\n{data}")
        return out_path
    atomic_write(out_path, data)
    print(f"[unstack] Wrote {out_path}")
    return out_path


def load_settings(repo_root: Path) -> Tuple[DbConfig, Settings]:
    cfg_path = repo_root / "settings.json"
    with cfg_path.open("r", encoding="utf-8") as f:
        raw = json.load(f)
    db_raw = raw["db"]
    db = DbConfig(
        host=db_raw["host"],
        port=int(db_raw["port"]),
        database=db_raw["database"],
        user=db_raw["user"],
        password=str(db_raw.get("password", "")),
    )
    s_raw = raw["paths"]
    s = Settings(
        processed_jobs_root=s_raw.get("processedJobsRoot", ""),
        auto_pac_csv_dir=s_raw.get("autoPacCsvDir", ""),
    )
    return db, s


def connect_db(cfg: DbConfig):
    return psycopg2.connect(
        host=cfg.host,
        port=cfg.port,
        dbname=cfg.database,
        user=cfg.user,
        password=cfg.password,
    )


def list_machines(conn) -> list[Machine]:
    with conn.cursor() as cur:
        cur.execute(
            """
            select machine_id, coalesce(name, ''), ap_jobfolder, nestpick_folder, nestpick_enabled
            from machines
            order by machine_id asc
            """
        )
        rows = cur.fetchall() or []
        out: list[Machine] = []
        for row in rows:
            out.append(
                Machine(
                    machine_id=int(row[0]),
                    name=row[1] or f"Machine {row[0]}",
                    ap_jobfolder=row[2],
                    nestpick_folder=row[3],
                    nestpick_enabled=bool(row[4]),
                )
            )
        return out


def get_machine(conn, selector: str) -> Machine:
    with conn.cursor() as cur:
        if selector.isdigit():
            cur.execute(
                """
                select machine_id, coalesce(name, ''), ap_jobfolder, nestpick_folder, nestpick_enabled
                from machines
                where machine_id = %s
                limit 1
                """,
                (int(selector),),
            )
        else:
            cur.execute(
                """
                select machine_id, coalesce(name, ''), ap_jobfolder, nestpick_folder, nestpick_enabled
                from machines
                where lower(name) = lower(%s)
                order by machine_id asc
                limit 1
                """,
                (selector,),
            )
        row = cur.fetchone()
        if not row:
            raise RuntimeError(f"Machine not found for selector: {selector}")
        return Machine(
            machine_id=int(row[0]),
            name=row[1] or f"Machine {row[0]}",
            ap_jobfolder=row[2],
            nestpick_folder=row[3],
            nestpick_enabled=bool(row[4]),
        )


def choose_machine_interactive(conn) -> Machine:
    machines = list_machines(conn)
    if not machines:
        raise RuntimeError("No machines configured in DB")
    print("Select a machine to simulate:")
    for m in machines:
        print(f"  - {m.machine_id}: {m.name}")
    while True:
        raw = input("Enter machine name or id: ").strip()
        if not raw:
            # default to first
            return machines[0]
        # try id1
        if raw.isdigit():
            for m in machines:
                if m.machine_id == int(raw):
                    return m
        # try name (case-insensitive exact)
        for m in machines:
            if m.name.lower() == raw.lower():
                return m
        print("Not found. Please enter a valid machine name or id.")


def pick_random_job(conn) -> Job:
    with conn.cursor() as cur:
        # Prefer jobs that have an ncfile set; watchers can handle PENDING → LOAD_FINISH directly
        cur.execute(
            """
            select key, folder, ncfile
            from jobs
            where coalesce(ncfile,'') <> ''
            order by random()
            limit 1
            """
        )
        row = cur.fetchone()
        if not row:
            raise RuntimeError("No jobs available (ncfile missing)")
        return Job(key=row[0], folder=row[1], ncfile=row[2])


def derive_job_leaf(folder: Optional[str], ncfile: Optional[str], key: str) -> str:
    if folder:
        parts = [p for p in Path(folder).parts if p not in ("/", "\\") and p]
        if parts:
            return parts[-1]
    if ncfile:
        return str(Path(ncfile).stem)
    return str(Path(key).stem)


def find_file_by_name(root: Path, target_name: str) -> Optional[Path]:
    target_lower = target_name.lower()
    for base, _dirs, files in os.walk(root):
        for name in files:
            if name.lower() == target_lower:
                return Path(base) / name
    return None


def find_source_root(processed_root: Path, job: Job) -> Path:
    # Follow the spirit of worklist.ts: if job.folder is absolute and exists → use it;
    # if it is relative and exists under processed_root → use it; otherwise fall back to processed_root.
    if job.folder:
        try:
            p = Path(job.folder)
            if p.is_absolute() and p.exists():
                return p
            candidate = processed_root / job.folder
            if candidate.exists():
                return candidate
        except Exception:
            pass
    return processed_root


def ensure_unique_dir(base_dir: Path) -> Path:
    if not base_dir.exists():
        return base_dir
    ts = datetime.now().strftime("%Y%m%d-%H%M%S")
    candidate = base_dir.parent / f"{base_dir.name}_{ts}"
    suffix = 1
    while candidate.exists():
        candidate = base_dir.parent / f"{base_dir.name}_{ts}_{suffix}"
        suffix += 1
    return candidate


def stage_job(processed_root: Path, job: Job, machine: Machine, dry_run=False) -> Optional[Path]:
    if not machine.ap_jobfolder:
        print("[stage] Machine ap_jobfolder not set; skipping copy")
        return None

    source_root = find_source_root(processed_root, job)
    leaf = derive_job_leaf(job.folder, job.ncfile, job.key)
    dest_base = Path(machine.ap_jobfolder) / leaf
    dest = ensure_unique_dir(dest_base)

    if dry_run:
        print(f"[stage] Would stage into: {dest}")
        return dest

    dest.mkdir(parents=True, exist_ok=True)

    # Copy the primary NC file and, if present, the exact per-file CSV (<base>.csv)
    if not job.ncfile:
        raise RuntimeError("Job has no ncfile set")
    nc_candidates = [job.ncfile, f"{Path(job.ncfile).stem}.nc"]
    nc_path = None
    for name in nc_candidates:
        nc_path = find_file_by_name(source_root, name)
        if nc_path:
            break
    if not nc_path:
        raise RuntimeError(f"NC file not found under {source_root}: {job.ncfile}")

    shutil.copy2(nc_path, dest / nc_path.name)

    base_stem = Path(job.ncfile).stem
    parts_csv = find_file_by_name(source_root, f"{base_stem}.csv")
    if parts_csv:
        shutil.copy2(parts_csv, dest / parts_csv.name)
    else:
        # Generate a minimal parts CSV compatible with Nestpick expectations
        print(f"[stage] Parts CSV not found for base {base_stem}; generating synthetic parts CSV")
        rows = synthesize_parts_rows(source_root, base_stem)
        header = [
            "X-pos","Y-pos","reserve","ElementID","LengthX","LengthY","Thickness",
            "Destination","SourceMachine","Type","Additional","Category","PalletName",
            "X-posTarget","YposTarget","RposTarget"
        ]
        # Build CSV text (header + synthesized rows)
        lines = [",".join(header)]
        for r in rows:
            lines.append(",".join(r))
        out = "\n".join(lines) + "\n"
        atomic_write(dest / f"{base_stem}.csv", out)

    # Copy associated .lpt/.pts and images (base*.(bmp|jpg|jpeg))
    for ext in (".lpt", ".pts"):
        cand = find_file_by_name(source_root, f"{base_stem}{ext}")
        if cand:
            shutil.copy2(cand, dest / cand.name)

    for base_dir, _dirs, files in os.walk(source_root):
        for name in files:
            name_lower = name.lower()
            if name_lower.endswith((".bmp",".jpg",".jpeg")) and name_lower.startswith(base_stem.lower()):
                src = Path(base_dir) / name
                rel = src.relative_to(source_root)
                (dest / rel.parent).mkdir(parents=True, exist_ok=True)
                shutil.copy2(src, dest / rel)

    print(f"[stage] Staged {job.key} → {dest}")
    return dest


def atomic_write(path: Path, data: str):
    path.parent.mkdir(parents=True, exist_ok=True)
    tmp = Path(f"{path}.tmp-{int(time.time() * 1000)}")
    with tmp.open("w", encoding="utf-8", newline="\n") as f:
        f.write(data)
        if not data.endswith("\n"):
            f.write("\n")
    os.replace(tmp, path)


def write_autopac_csv(auto_pac_dir: Path, machine_token: str, kind: str, bases: list[str], dry_run=False) -> Path:
    # kind ∈ {load_finish, label_finish, cnc_finish}
    filename = f"{kind}{machine_token}.csv"
    content_lines = []
    for b in bases:
        content_lines.append(b)
    content_lines.append(machine_token)
    data = "\n".join(content_lines)
    # Ensure CSV rows are comma-separated as Base,Machine
    rows = [f"{b},{machine_token}" for b in bases]
    data = "\n".join(rows)
    out_path = auto_pac_dir / filename
    if dry_run:
        print(f"[autopac] Would write {out_path}\n{data}")
        return out_path
    atomic_write(out_path, data)
    print(f"[autopac] Wrote {out_path}")
    return out_path


def write_unstack_csv(nestpick_root: Path, base: str, pallet_num: int, dry_run=False) -> Path:
    pallet = f"Pallet_A{pallet_num:02d}"
    out_path = nestpick_root / "Report_FullNestpickUnstack.csv"
    data = f"{base},{pallet}"
    if dry_run:
        print(f"[unstack] Would write {out_path}\n{data}")
        return out_path
    atomic_write(out_path, data)
    print(f"[unstack] Wrote {out_path}")
    return out_path


def sleep_random(min_s: int, max_s: int):
    delay = random.uniform(min_s, max_s)
    print(f"[delay] Sleeping {delay:.1f}s")
    time.sleep(delay)


def main():
    parser = argparse.ArgumentParser(description="Simulate a full job workflow via file watchers")
    parser.add_argument("--machine", help="Machine selector: name token (e.g. WT1) or numeric id. If omitted, prompts interactively.")
    parser.add_argument("--ask-machine", action="store_true", help="Prompt for the machine even if --machine is provided.")
    parser.add_argument("--min-delay", type=int, default=0, help="Minimum seconds between steps within a cycle (default: 0)")
    parser.add_argument("--max-delay", type=int, default=30, help="Maximum seconds between steps within a cycle (default: 30)")
    parser.add_argument("--between-min", type=int, default=3, help="Minimum seconds between cycles (default: 3)")
    parser.add_argument("--between-max", type=int, default=15, help="Maximum seconds between cycles (default: 15)")
    parser.add_argument("--once", action="store_true", help="Run a single simulation cycle and exit")
    parser.add_argument("--no-stage", action="store_true", help="Skip staging step")
    parser.add_argument("--dry-run", action="store_true", help="Print actions without writing files")
    args = parser.parse_args()

    repo_root = Path(__file__).resolve().parents[1]
    db_cfg, app_settings = load_settings(repo_root)

    if not app_settings.auto_pac_csv_dir:
        print("autoPacCsvDir is not configured in settings.json", file=sys.stderr)
        sys.exit(1)

    processed_root = Path(app_settings.processed_jobs_root) if app_settings.processed_jobs_root else None
    if not processed_root and not args.no_stage:
        print("processedJobsRoot is not configured in settings.json; cannot stage", file=sys.stderr)
        sys.exit(1)

    with connect_db(db_cfg) as conn:
        if args.ask_machine or not args.machine:
            machine = choose_machine_interactive(conn)
        else:
            machine = get_machine(conn, args.machine)
        print(f"[machine] Using {machine.name} (#{machine.machine_id})")

        job = pick_random_job(conn)
        base = Path(job.ncfile or job.key).stem
        print(f"[job] Selected {job.key} (base '{base}')")

        # Stage
        if not args.no_stage:
            stage_job(processed_root, job, machine, dry_run=args.dry_run)

        # AutoPAC: LOAD_FINISH → LABEL_FINISH → CNC_FINISH
        auto_pac_dir = Path(app_settings.auto_pac_csv_dir)
        machine_token = machine.name if machine.name else str(machine.machine_id)

        sleep_random(args.min_delay, args.max_delay)
        write_autopac_csv(auto_pac_dir, machine_token, "load_finish", [base], dry_run=args.dry_run)

        sleep_random(args.min_delay, args.max_delay)
        write_autopac_csv(auto_pac_dir, machine_token, "label_finish", [base], dry_run=args.dry_run)

        sleep_random(args.min_delay, args.max_delay)
        write_autopac_csv(auto_pac_dir, machine_token, "cnc_finish", [base], dry_run=args.dry_run)

        # After CNC_FINISH, the app should forward parts CSV to Nestpick (Nestpick.csv).
        # Before writing Unstack, try to read PalletName from Nestpick.csv then delete it.
        if machine.nestpick_enabled and machine.nestpick_folder:
            sleep_random(args.min_delay, args.max_delay)
            pallet = try_extract_pallet_then_clear(Path(machine.nestpick_folder)) or f"Pallet_A{random.randint(0,20):02d}"
            # Write Unstack report using pallet value
            write_unstack_unified(Path(machine.nestpick_folder), base, pallet, dry_run=args.dry_run)
        else:
            print("[nestpick] Machine not configured for Nestpick; skipping unstack")

        print("[done] Simulation complete")


def run_forever():
    parser = argparse.ArgumentParser(description="Simulate a full job workflow via file watchers (repeat)")
    parser.add_argument("--machine", help="Machine selector: name token (e.g. WT1) or numeric id. If omitted, prompts interactively.")
    parser.add_argument("--ask-machine", action="store_true", help="Prompt for the machine even if --machine is provided.")
    parser.add_argument("--min-delay", type=int, default=0, help="Minimum seconds between steps within a cycle (default: 0)")
    parser.add_argument("--max-delay", type=int, default=30, help="Maximum seconds between steps within a cycle (default: 30)")
    parser.add_argument("--between-min", type=int, default=3, help="Minimum seconds between cycles (default: 3)")
    parser.add_argument("--between-max", type=int, default=15, help="Maximum seconds between cycles (default: 15)")
    parser.add_argument("--no-stage", action="store_true", help="Skip staging step")
    parser.add_argument("--dry-run", action="store_true", help="Print actions without writing files")
    args = parser.parse_args()

    repo_root = Path(__file__).resolve().parents[1]
    db_cfg, app_settings = load_settings(repo_root)
    if not app_settings.auto_pac_csv_dir:
        print("autoPacCsvDir is not configured in settings.json", file=sys.stderr)
        sys.exit(1)
    processed_root = Path(app_settings.processed_jobs_root) if app_settings.processed_jobs_root else None
    if not processed_root and not args.no_stage:
        print("processedJobsRoot is not configured in settings.json; cannot stage", file=sys.stderr)
        sys.exit(1)

    with connect_db(db_cfg) as conn:
        if args.ask_machine or not args.machine:
            machine = choose_machine_interactive(conn)
        else:
            machine = get_machine(conn, args.machine)
        print(f"[machine] Using {machine.name} (#{machine.machine_id})")

        cycle = 0
        try:
            while True:
                cycle += 1
                print(f"\n=== Simulation cycle {cycle} ===")
                try:
                    job = pick_random_job(conn)
                except Exception as e:
                    print(f"[warn] Could not pick a job: {e}")
                    time.sleep(max(1, args.between_min))
                    continue

                base = Path(job.ncfile or job.key).stem
                print(f"[job] Selected {job.key} (base '{base}')")

                if not args.no_stage and processed_root:
                    try:
                        stage_job(processed_root, job, machine, dry_run=args.dry_run)
                    except Exception as e:
                        print(f"[warn] Staging failed: {e}")

                auto_pac_dir = Path(app_settings.auto_pac_csv_dir)
                machine_token = machine.name if machine.name else str(machine.machine_id)

                sleep_random(args.min_delay, args.max_delay)
                write_autopac_csv(auto_pac_dir, machine_token, "load_finish", [base], dry_run=args.dry_run)

                sleep_random(args.min_delay, args.max_delay)
                write_autopac_csv(auto_pac_dir, machine_token, "label_finish", [base], dry_run=args.dry_run)

                sleep_random(args.min_delay, args.max_delay)
                write_autopac_csv(auto_pac_dir, machine_token, "cnc_finish", [base], dry_run=args.dry_run)

                if machine.nestpick_enabled and machine.nestpick_folder:
                    sleep_random(args.min_delay, args.max_delay)
                    pallet = try_extract_pallet_then_clear(Path(machine.nestpick_folder)) or f"Pallet_A{random.randint(0,20):02d}"
                    write_unstack_unified(Path(machine.nestpick_folder), base, pallet, dry_run=args.dry_run)
                else:
                    print("[nestpick] Machine not configured for Nestpick; skipping unstack")

                print(f"[done] Cycle {cycle} complete")

                if args.between_max > 0:
                    sleep_random(args.between_min, args.between_max)
        except KeyboardInterrupt:
            print("\n[exit] Stopped by user")


if __name__ == "__main__":
    if "--once" in sys.argv:
        main()
    else:
        run_forever()

================
File: SQL_Schema.sql
================
SET statement_timeout = 0;
SET lock_timeout = 0;
SET idle_in_transaction_session_timeout = 0;
SET transaction_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = on;
SELECT pg_catalog.set_config('search_path', '', false);
SET check_function_bodies = false;
SET xmloption = content;
SET client_min_messages = warning;
SET row_security = off;

CREATE SCHEMA IF NOT EXISTS public;
ALTER SCHEMA public OWNER TO pg_database_owner;
COMMENT ON SCHEMA public IS 'standard public schema';

CREATE TYPE public.job_status AS ENUM (
    'PENDING',
    'STAGED',
    'LOAD_FINISH',
    'LABEL_FINISH',
    'CNC_FINISH',
    'FORWARDED_TO_NESTPICK',
    'NESTPICK_COMPLETE'
);

ALTER TYPE public.job_status OWNER TO postgres;

-- Removed duplicate enum job_status_new

CREATE FUNCTION public.set_updated_at() RETURNS trigger
    LANGUAGE plpgsql
    AS $$
BEGIN
  NEW.updated_at := now();
  RETURN NEW;
END$$;

ALTER FUNCTION public.set_updated_at() OWNER TO postgres;
SET default_tablespace = '';
SET default_table_access_method = heap;

CREATE TABLE public.cncstats (
    key character varying(100) NOT NULL,
    api_ip character varying(100),
    currentprogram character varying(50),
    mode character varying(50),
    status character varying(50),
    alarm character varying(50),
    emg character varying(50),
    powerontime character varying(50),
    cuttingtime character varying(50),
    alarmhistory character varying(50),
    vacuumtime character varying(50),
    drillheadtime character varying(50),
    spindletime character varying(50),
    conveyortime character varying(50),
    greasetime character varying(50)
);

ALTER TABLE public.cncstats OWNER TO woodtron_user;

CREATE TABLE public.grundner (
    id integer NOT NULL,
    type_data integer NOT NULL,
    customer_id character varying(50),
    length_mm integer,
    width_mm integer,
    thickness_mm integer,
    stock integer,
    stock_available integer,
    last_updated character varying(50),
    reserved_stock integer DEFAULT 0
);

ALTER TABLE public.grundner OWNER TO woodtron_user;

CREATE SEQUENCE public.grundner_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;

ALTER SEQUENCE public.grundner_id_seq OWNER TO woodtron_user;
ALTER SEQUENCE public.grundner_id_seq OWNED BY public.grundner.id;

CREATE TABLE public.job_events (
    event_id bigint NOT NULL,
    key character varying(100) NOT NULL,
    machine_id integer,
    event_type text NOT NULL,
    payload jsonb,
    created_at timestamp with time zone DEFAULT now() NOT NULL
);

ALTER TABLE public.job_events OWNER TO postgres;
COMMENT ON TABLE public.job_events IS 'Append-only audit trail of lifecycle/file events (multi-PC safe)';

CREATE SEQUENCE public.job_events_event_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;

ALTER SEQUENCE public.job_events_event_id_seq OWNER TO postgres;
ALTER SEQUENCE public.job_events_event_id_seq OWNED BY public.job_events.event_id;

CREATE TABLE public.jobs (
    key character varying(100) NOT NULL,
    folder character varying(255),
    ncfile character varying(255),
    material character varying(255),
    parts character varying(255),
    size character varying(255),
    thickness character varying(255),
    is_reserved boolean DEFAULT false,
    machine_id integer,
    dateadded timestamp with time zone,
    staged_at timestamp with time zone,
    cut_at timestamp with time zone,
    nestpick_completed_at timestamp with time zone,
    updated_at timestamp with time zone DEFAULT now() NOT NULL,
    pallet character varying(50),
    last_error text,
    status public.job_status DEFAULT 'PENDING'::public.job_status,
    CONSTRAINT jobs_key_not_blank CHECK ((length(btrim((key)::text)) > 0))
);

ALTER TABLE public.jobs OWNER TO postgres;

COMMENT ON TABLE public.jobs IS 'Canonical job lifecycle row (single source of truth; use status + timestamps)';

CREATE VIEW public.jobs_history AS
 SELECT key,
    folder,
    ncfile,
    material,
    parts,
    size,
    thickness,
    is_reserved,
    status,
    machine_id,
    dateadded,
    staged_at,
    cut_at,
    nestpick_completed_at,
    updated_at,
    pallet,
    last_error
   FROM public.jobs
  WHERE (status = 'NESTPICK_COMPLETE'::public.job_status);

ALTER VIEW public.jobs_history OWNER TO postgres;

CREATE VIEW public.jobs_pending AS
 SELECT key,
    folder,
    ncfile,
    material,
    parts,
    size,
    thickness,
    is_reserved,
    status,
    machine_id,
    dateadded,
    staged_at,
    cut_at,
    nestpick_completed_at,
    updated_at,
    pallet,
    last_error
   FROM public.jobs
  WHERE (status = 'PENDING'::public.job_status);

ALTER VIEW public.jobs_pending OWNER TO postgres;

CREATE VIEW public.machine_jobs AS
 SELECT key,
    folder,
    ncfile,
    material,
    parts,
    size,
    thickness,
    is_reserved,
    status,
    machine_id,
    dateadded,
    staged_at,
    cut_at,
    nestpick_completed_at,
    updated_at,
    pallet,
    last_error
   FROM public.jobs
  WHERE (status = ANY (ARRAY['STAGED'::public.job_status, 'CNC_FINISH'::public.job_status, 'FORWARDED_TO_NESTPICK'::public.job_status]));

ALTER VIEW public.machine_jobs OWNER TO postgres;

CREATE TABLE public.machines (
    machine_id integer NOT NULL,
    name text NOT NULL,
    pc_ip inet,
    cnc_ip inet,
    cnc_port integer,
    ap_jobfolder text NOT NULL,
    nestpick_folder text NOT NULL,
    nestpick_enabled boolean DEFAULT true NOT NULL,
    created_at timestamp with time zone DEFAULT now() NOT NULL,
    updated_at timestamp with time zone DEFAULT now() NOT NULL,
    pc_port integer DEFAULT 5000 NOT NULL,
    CONSTRAINT machines_cnc_port_check CHECK (((cnc_port >= 1) AND (cnc_port <= 65535))),
    CONSTRAINT machines_pc_port_check CHECK (((pc_port >= 1) AND (pc_port <= 65535)))
);

ALTER TABLE public.machines OWNER TO postgres;
COMMENT ON TABLE public.machines IS 'Per-CNC config: PC/CNC IPs, AutoPac/Nestpick folders, flags';
COMMENT ON COLUMN public.machines.ap_jobfolder IS 'Ready-To-Run / AutoPac intake (per machine)';
COMMENT ON COLUMN public.machines.nestpick_folder IS 'Where pallet-tagged CSVs are moved for Nestpick ingestion';
CREATE SEQUENCE public.machines_machine_id_seq
    AS integer
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER SEQUENCE public.machines_machine_id_seq OWNER TO postgres;
ALTER SEQUENCE public.machines_machine_id_seq OWNED BY public.machines.machine_id;
ALTER TABLE ONLY public.grundner ALTER COLUMN id SET DEFAULT nextval('public.grundner_id_seq'::regclass);
ALTER TABLE ONLY public.job_events ALTER COLUMN event_id SET DEFAULT nextval('public.job_events_event_id_seq'::regclass);
ALTER TABLE ONLY public.machines ALTER COLUMN machine_id SET DEFAULT nextval('public.machines_machine_id_seq'::regclass);
ALTER TABLE ONLY public.cncstats
    ADD CONSTRAINT cncstats_pkey PRIMARY KEY (key);
ALTER TABLE ONLY public.grundner
    ADD CONSTRAINT grundner_pkey PRIMARY KEY (id);

ALTER TABLE ONLY public.grundner
    ADD CONSTRAINT grundner_type_data_customer_id_key UNIQUE (type_data, customer_id);
ALTER TABLE ONLY public.job_events
    ADD CONSTRAINT job_events_pkey PRIMARY KEY (event_id);
ALTER TABLE ONLY public.jobs
    ADD CONSTRAINT jobs_pkey PRIMARY KEY (key);

ALTER TABLE ONLY public.machines
    ADD CONSTRAINT machines_pkey PRIMARY KEY (machine_id);
CREATE INDEX job_events_created_idx ON public.job_events USING btree (created_at);
CREATE INDEX job_events_key_idx ON public.job_events USING btree (key);
CREATE INDEX job_events_machine_idx ON public.job_events USING btree (machine_id);
CREATE INDEX job_events_type_idx ON public.job_events USING btree (event_type);
CREATE INDEX jobs_dates_idx ON public.jobs USING btree (dateadded, staged_at, cut_at, nestpick_completed_at);
CREATE INDEX machines_cnc_ip_idx ON public.machines USING btree (cnc_ip);
CREATE INDEX machines_name_idx ON public.machines USING btree (name);
CREATE INDEX machines_pc_ip_idx ON public.machines USING btree (pc_ip);
CREATE TRIGGER trg_jobs_updated BEFORE UPDATE ON public.jobs FOR EACH ROW EXECUTE FUNCTION public.set_updated_at();
CREATE TRIGGER trg_machines_updated BEFORE UPDATE ON public.machines FOR EACH ROW EXECUTE FUNCTION public.set_updated_at();
ALTER TABLE ONLY public.job_events
    ADD CONSTRAINT job_events_key_fkey FOREIGN KEY (key) REFERENCES public.jobs(key) ON DELETE CASCADE;
ALTER TABLE ONLY public.job_events
    ADD CONSTRAINT job_events_machine_id_fkey FOREIGN KEY (machine_id) REFERENCES public.machines(machine_id) ON DELETE SET NULL;
ALTER TABLE ONLY public.jobs
    ADD CONSTRAINT jobs_machine_id_fkey FOREIGN KEY (machine_id) REFERENCES public.machines(machine_id) ON DELETE SET NULL;

================
File: test-results/.last-run.json
================
{
  "status": "failed",
  "failedTests": [
    "4219922fea2e2bd3c691-2567ecb3446c83946494",
    "4219922fea2e2bd3c691-0e6d9530b98f02f3cbe3",
    "4219922fea2e2bd3c691-14959726babc18e25576"
  ]
}

================
File: tests/e2e/smoke.spec.ts
================
import { expect, test } from '@playwright/test';
import type { DiagnosticsSnapshot, ReadyListRes, TelemetrySummaryRes } from '../../packages/shared/src';

const diagnosticsSnapshot = {
  dbStatus: { online: true, checkedAt: new Date().toISOString(), latencyMs: 25, error: null },
  watchers: [],
  recentErrors: [],
  lastUpdatedAt: new Date().toISOString()
};

test.beforeEach(async ({ page }) => {
  await page.addInitScript(({ snapshot }) => {
    const now = () => new Date().toISOString();

    const state = {
      settings: {
        version: 1,
        db: {
          host: 'localhost',
          port: 5432,
          database: 'woodtron',
          user: 'woodtron_user',
          password: '',
          sslMode: 'disable',
          statementTimeoutMs: 30000
        },
        paths: { processedJobsRoot: '', autoPacCsvDir: '', grundnerFolderPath: '' },
        test: { testDataFolderPath: '', useTestDataMode: false, sheetIdMode: 'type_data' },
        grundner: { reservedAdjustmentMode: 'delta' }
      },
      machines: [
        {
          machineId: 1,
          name: 'Router A',
          apJobfolder: 'C:/ap/router-a',
          nestpickFolder: 'C:/nest/router-a',
          nestpickEnabled: true,
          pcPort: 5000,
          pcIp: null,
          cncIp: null,
          cncPort: null
        }
      ],
      jobs: [
        {
          key: 'JOB-1',
          folder: 'folder/job-1',
          ncfile: 'job-1',
          material: 'Plywood',
          parts: '10',
          size: '1200x600',
          thickness: '18',
          dateadded: now(),
          reserved: false,
          status: 'PENDING',
          machineId: 1
        }
      ],
      router: [
        {
          key: 'JOB-1',
          folder: null,
          ncfile: 'job-1',
          material: null,
          status: 'STAGED',
          machineId: 1,
          stagedAt: now(),
          cutAt: null,
          nestpickCompletedAt: null,
          updatedAt: now(),
          parts: null,
          size: null,
          thickness: null,
          pallet: null,
          lastError: null
        }
      ]
    };

    const calls = {
      settingsSave: [] as unknown[],
      testConnection: 0,
      reserve: 0,
      unreserve: 0
    };

    function notifyDiagnostics(listener: (snapshot: DiagnosticsSnapshot) => void) {
      listener(snapshot as unknown as DiagnosticsSnapshot);
      return () => {};
    }

    // @ts-expect-error: inject mock state
    window.__mockState = state;
    // @ts-expect-error: inject mock calls
    window.__mockCalls = calls;

    // Inject API stub
    window.api = {
      settings: {
        get: async () => state.settings,
        getPath: async () => '/mock/config/path',
        validatePath: async () => ({ path: '', exists: true, isDirectory: true, isFile: false, error: null }),
        save: async (next: typeof state.settings) => {
          state.settings = next;
          calls.settingsSave.push(JSON.parse(JSON.stringify(next)));
          return next;
        }
      },
      db: {
        testConnection: async () => {
          calls.testConnection += 1;
          return { ok: true } as const;
        },
        getStatus: async () => snapshot.dbStatus,
        subscribeStatus: (listener: (status: typeof snapshot.dbStatus) => void) => {
          listener(snapshot.dbStatus);
          return () => {};
        }
      },
      jobs: {
        list: async () => ({ items: state.jobs, nextCursor: null }),
        filters: async () => ({ options: { materials: ['Plywood'], statuses: ['PENDING', 'STAGED'] } }),
        events: async () => ({ events: [] }),
        reserve: async (key: string) => {
          const job = state.jobs.find((j) => j.key === key);
          if (job) {
            job.reserved = true;
            job.status = 'STAGED';
            calls.reserve += 1;
            return { ok: true } as const;
          }
          return { ok: false } as const;
        },
        unreserve: async (key: string) => {
          const job = state.jobs.find((j) => j.key === key);
          if (job) {
            job.reserved = false;
            job.status = 'PENDING';
            calls.unreserve += 1;
            return { ok: true } as const;
          }
          return { ok: false } as const;
        },
        addToWorklist: async () => ({ ok: true, path: 'C:/ap/router-a' }),
        resync: async () => ({ inserted: 0, updated: 0 })
      },
      machines: {
        list: async () => ({ items: state.machines }),
        save: async (machine: Record<string, unknown>) => ({ ...machine, machineId: Date.now() }),
        delete: async () => null
      },
      router: {
        list: async () => ({ items: state.router })
      },
      grundner: {
        list: async () => ({ items: [] }),
        update: async () => ({ ok: true, updated: 0 }),
        resync: async () => ({ updated: 0 })
      },
      files: {
        listReady: async () => ({ machineId: 1, files: [] }),
        importReady: async () => ({ imported: 0, errors: [] }),
        subscribeReady: (_machineId: number, _listener: (payload: ReadyListRes) => void) => {
          return () => {};
        }
      },
      telemetry: {
        summary: async () => ({ items: [] } as TelemetrySummaryRes),
        subscribe: (
          _req: { from?: string; to?: string; machineIds?: number[] },
          listener: (payload: TelemetrySummaryRes) => void
        ) => {
          listener({ items: [] });
          return () => {};
        }
      },
      dialog: {
        pickFolder: async () => null
      },
      history: {
        list: async () => ({ items: [] }),
        timeline: async () => null
      },
      hypernest: {
        open: async () => ({ ok: true })
      },
      alarms: {
        list: async () => [],
        history: async () => ({ items: [] }),
        subscribe: (listener: (alarms: []) => void) => {
          listener([]);
          return () => {};
        }
      },
      diagnostics: {
        get: async () => snapshot,
        copy: async () => ({ logCount: 5 }),
        listLogs: async () => ({ items: [] }),
        logTail: async () => ({ content: '', limit: 100, size: 0 }),
        subscribe: (listener: (snapshot: DiagnosticsSnapshot) => void) => notifyDiagnostics(listener)
      },
      ui: {
        theme: {
          get: async () => ({ preference: 'system' as const }),
          set: async () => ({ preference: 'system' as const })
        }
      }
    } as const;
  }, { snapshot: diagnosticsSnapshot });
});

test('settings save and test connection', async ({ page }) => {
  await page.goto('/settings');
  await expect(page.getByText('Database')).toBeVisible();
  await page.getByLabel('Host').fill('db.internal');
  await page.getByRole('button', { name: 'Test' }).click();
  await page.getByRole('button', { name: 'Save' }).click();

  const host = await page.evaluate(() => (window as unknown as { __mockState: { settings: { db: { host: string } } } }).__mockState.settings.db.host);
  const calls = await page.evaluate(() => (window as unknown as { __mockCalls: { testConnection: number; settingsSave: unknown[] } }).__mockCalls);
  expect(host).toBe('db.internal');
  expect(calls.testConnection).toBeGreaterThanOrEqual(1);
  expect(calls.settingsSave.length).toBeGreaterThan(0);
});

test('jobs reserve and unreserve flow', async ({ page }) => {
  await page.goto('/jobs');
  await expect(page.getByText('Jobs')).toBeVisible();

  const rowCheckbox = page.locator('tbody tr').first().locator('input[type="checkbox"]');
  await rowCheckbox.check();
  await page.getByRole('button', { name: /^Reserve$/ }).click();

  await page.waitForTimeout(200);
  let state = await page.evaluate(() => (window as unknown as { __mockState: { jobs: Array<{ reserved: boolean }> } }).__mockState);
  expect(state.jobs[0].reserved).toBe(true);

  const rowCheckbox2 = page.locator('tbody tr').first().locator('input[type="checkbox"]');
  await rowCheckbox2.check();
  await page.getByRole('button', { name: /^Unreserve$/ }).click();
  await page.waitForTimeout(200);
  state = await page.evaluate(() => (window as unknown as { __mockState: { jobs: Array<{ reserved: boolean }> } }).__mockState);
  expect(state.jobs[0].reserved).toBe(false);

  const calls = await page.evaluate(() => (window as unknown as { __mockCalls: { reserve: number; unreserve: number } }).__mockCalls);
  expect(calls.reserve).toBe(1);
  expect(calls.unreserve).toBe(1);
});

test('router page renders data', async ({ page }) => {
  await page.goto('/router');
  await expect(page.getByText('Router Jobs')).toBeVisible();
  await expect(page.getByRole('cell', { name: 'JOB-1' })).toBeVisible();
});

================
File: tests/integration/main-ipc.test.ts
================
/* eslint-disable @typescript-eslint/no-explicit-any */
import { beforeAll, describe, expect, it, vi } from 'vitest';

import { EventEmitter } from 'events';

import { newDb } from 'pg-mem';

import type { ResultEnvelope, JobsListReq, JobsListRes, JobStatus, LifecycleRes } from '../../packages/shared/src';






class MockWebContents extends EventEmitter {

  public sent: Array<{ channel: string; payload: unknown }> = [];



  constructor(public readonly id: number) {

    super();

  }



  isDestroyed() {

    return false;

  }



  send(channel: string, payload: unknown) {

    this.sent.push({ channel, payload });

    this.emit(channel, payload);

  }

}

type InvokeEvent = { sender: MockWebContents };
type Handler = (event: InvokeEvent, ...args: unknown[]) => ResultEnvelope<unknown> | Promise<ResultEnvelope<unknown>>;
interface GlobalWithHandlers {
  __IPC_HANDLERS__?: Map<string, Handler>;
}

type PoolClient = { connect: () => Promise<void>; end: () => Promise<void>; query: <T = unknown>(sql: string, params?: unknown[]) => Promise<{ rows: T[] }>; };

type ClientWithRelease = PoolClient & { release?: () => Promise<void> };
type QueryResult<T> = { rows: T[]; rowCount?: number };

type MaterialRow = { material: string | null };
type _JobRowRecord = {
  key: string;
  folder: string | null;
  ncfile: string | null;
  material: string | null;
  parts: string | null;
  size: string | null;
  thickness: string | null;
  dateadded: string | Date | null;
  is_reserved: boolean;
  status: JobStatus;
  machine_id: number | null;
};


const handlers: Map<string, Handler> =
  ((globalThis as GlobalWithHandlers).__IPC_HANDLERS__ as Map<string, Handler> | undefined) ??
  new Map<string, Handler>();
if (!(globalThis as GlobalWithHandlers).__IPC_HANDLERS__) {
  (globalThis as GlobalWithHandlers).__IPC_HANDLERS__ = handlers;
}




let senderCounter = 0;

function createSender() {

  return new MockWebContents(++senderCounter);

}



const db = newDb({ autoCreateForeignKeyIndices: true });

const pgAdapter = db.adapters.createPg();

const clientPrototype = pgAdapter.Client.prototype as {
  getTypeParser: (oid: number, format?: string) => (value: unknown) => unknown;
};
clientPrototype.getTypeParser = () => (val: unknown) => val;

const DB_USER = 'user';

const DB_PASS = 'pass';

const DB_NAME = 'test';





const sanitizeConfig = (config?: Record<string, unknown>) => {

  if (!config) return {};

  const clone = { ...config } as Record<string, unknown>;

  delete clone.password;

  return clone;

};



class FakePool {

  private readonly config: Record<string, unknown>;

  private readonly clients = new Set<ClientWithRelease>();



  constructor(config?: Record<string, unknown>) {

    this.config = sanitizeConfig(config);

  }



  async connect() {

    const client = new pgAdapter.Client(this.config) as unknown as ClientWithRelease;

    await client.connect();

    this.clients.add(client);

    const release = async () => {

      this.clients.delete(client);

      await client.end().catch(() => {});

    };

    client.release = release;

    return client;

  }



  async end() {

    const pending = Array.from(this.clients).map((client) => client.end().catch(() => {}));

    this.clients.clear();

    await Promise.all(pending);

  }



  on() {

    return this;

  }



  getTypeParser(_oid: number, _format?: string) {

    return (value: unknown) => value;

  }

}



vi.mock('pg', () => ({

  ...pgAdapter,

  Pool: FakePool,

  Client: pgAdapter.Client

}));



const testSettings = {

  version: 1,

  db: {

    host: 'localhost',

    port: 5432,

    database: DB_NAME,

    user: DB_USER,

    password: DB_PASS,

    sslMode: 'disable',

    statementTimeoutMs: 30000

  },

  paths: { processedJobsRoot: '', autoPacCsvDir: '', grundnerFolderPath: '' },

  test: { testDataFolderPath: '', useTestDataMode: false, sheetIdMode: 'type_data' },

  grundner: { reservedAdjustmentMode: 'delta' }

};



vi.mock('../../packages/main/src/services/config', () => ({

  loadConfig: () => testSettings,

  saveConfig: vi.fn(),

  redactSettings: vi.fn(),

  validateDbSettings: vi.fn()

}));



vi.mock('../../packages/main/src/services/db', async () => {

  const actual = await vi.importActual('../../packages/main/src/services/db');

  const { drizzle } = await import('drizzle-orm/node-postgres');



  const withClient = async <T>(fn: (client: PoolClient) => Promise<T>): Promise<T> => {

    const client = new pgAdapter.Client(sanitizeConfig(testSettings.db)) as unknown as ClientWithRelease;

    await client.connect();

    try {

      await client.query(`SET statement_timeout TO ${testSettings.db.statementTimeoutMs}`);

      return await fn(client);

    } finally {

      await client.end();

    }

  };



  const withDb = async <T>(fn: (db: unknown, client: PoolClient) => Promise<T>): Promise<T> => {

    return withClient(async (client) => {

      const db = drizzle(client as any);

      return fn(db, client);

    });

  };



  return {

    ...actual,

    getPool: () => null,

    resetPool: async () => {},

    withClient,

    withDb,

    testConnection: async () => ({ ok: true } as const)

  };

});



vi.mock('../../packages/main/src/services/ingest', () => ({

  ingestProcessedJobsRoot: vi.fn(async () => ({ inserted: 0, updated: 0 }))

}));



vi.mock('../../packages/main/src/services/worklist', () => ({

  addJobToWorklist: vi.fn(async () => ({ ok: true, path: 'X' }))

}));



vi.mock('../../packages/main/src/services/grundner', () => ({

  getGrundnerLookupColumn: () => 'material',

  getGrundnerMode: () => 'delta'

}));



vi.mock('../../packages/main/src/repo/jobEventsRepo', () => ({

  appendJobEvent: vi.fn(async () => {}),

  getJobEvents: vi.fn(async () => [])

}));



vi.mock('../../packages/main/src/repo/jobsRepo', () => {

  const ALLOWED_TRANSITIONS = {

    PENDING: ['PENDING'],

    STAGED: ['PENDING', 'STAGED'],

    LOAD_FINISH: ['PENDING', 'STAGED', 'LOAD_FINISH'],

    LABEL_FINISH: ['STAGED', 'LOAD_FINISH', 'LABEL_FINISH'],

    CNC_FINISH: ['STAGED', 'LOAD_FINISH', 'LABEL_FINISH', 'CNC_FINISH'],

    FORWARDED_TO_NESTPICK: ['CNC_FINISH', 'FORWARDED_TO_NESTPICK'],

    NESTPICK_COMPLETE: ['FORWARDED_TO_NESTPICK', 'NESTPICK_COMPLETE']

  } as const;



  const run = async <T extends Record<string, unknown>>(sql: string, params: unknown[] = []): Promise<QueryResult<T>> => {

    const client = new pgAdapter.Client(sanitizeConfig(testSettings.db)) as unknown as ClientWithRelease;

    await client.connect();

    try {

      return client.query<T>(sql, params);

    } finally {

      await client.end();

    }

  };



  const toIso = (value: Date | string | null | undefined) => {

    if (!value) return null;

    const date = value instanceof Date ? value : new Date(value);

    return Number.isNaN(date.getTime()) ? null : date.toISOString();

  };



  return {

    listJobFilters: async () => {

      const materials = await run<MaterialRow>('SELECT DISTINCT material FROM jobs ORDER BY material ASC');

      const materialNames = materials.rows

        .map((row: MaterialRow) => (row.material ? String(row.material).trim() : ''))

        .filter(Boolean);

      return { materials: materialNames, statuses: ['PENDING','STAGED','LOAD_FINISH','LABEL_FINISH','CNC_FINISH','FORWARDED_TO_NESTPICK','NESTPICK_COMPLETE'] };

    },



    listJobs: async (req: JobsListReq) => {

      const limit = req?.limit ?? 50;

      const result = await run(

        'SELECT key, folder, ncfile, material, parts, size, thickness, dateadded, is_reserved, status, machine_id FROM jobs ORDER BY dateadded DESC, key DESC LIMIT $1',

        [limit]

      );

      const items = result.rows.map((row: Record<string, unknown>) => ({

        key: row.key,

        folder: row.folder ?? null,

        ncfile: row.ncfile ?? null,

        material: row.material ?? null,

        parts: row.parts ?? null,

        size: row.size ?? null,

        thickness: row.thickness ?? null,

        dateadded: toIso(row.dateadded as string | Date | null | undefined),

        reserved: !!row.is_reserved,

        status: row.status,

        machineId: row.machine_id ?? null

      }));

      return { items, nextCursor: null };

    },



    reserveJob: async (key: string) => {

      const res = await run('UPDATE jobs SET is_reserved = TRUE, updated_at = NOW() WHERE key = $1 RETURNING key', [key]);

      return (res.rowCount ?? 0) > 0;

    },



    unreserveJob: async (key: string) => {

      const res = await run('UPDATE jobs SET is_reserved = FALSE, updated_at = NOW() WHERE key = $1 RETURNING key', [key]);

      return (res.rowCount ?? 0) > 0;

    },



    updateLifecycle: async (key: string, to: string, options: { machineId?: number | null; source?: string; payload?: unknown } = {}) => {

      const currentResult = await run(

        'SELECT status, machine_id, staged_at, cut_at, nestpick_completed_at, updated_at FROM jobs WHERE key = $1',

        [key]

      );

      if (!currentResult.rowCount) {

        return { ok: false, reason: 'NOT_FOUND' } as const;

      }

      const current = currentResult.rows[0];

      const previousStatus = current.status as keyof typeof ALLOWED_TRANSITIONS;

      const allowedTransitions = ALLOWED_TRANSITIONS[to as keyof typeof ALLOWED_TRANSITIONS] as readonly string[] | undefined;
      if (!allowedTransitions?.includes(previousStatus)) {

        return { ok: false, reason: 'INVALID_TRANSITION', previousStatus } as const;

      }



      const now = new Date();

      let touched = previousStatus !== to;

      const nextStaged = current.staged_at || (['STAGED','LOAD_FINISH','LABEL_FINISH'].includes(to) ? now : null);

      const nextCut = current.cut_at || (to === 'CNC_FINISH' ? now : null);

      const nextNestpick = current.nestpick_completed_at || (to === 'NESTPICK_COMPLETE' ? now : null);



      if (!current.staged_at && nextStaged) touched = true;

      if (!current.cut_at && nextCut) touched = true;

      if (!current.nestpick_completed_at && nextNestpick) touched = true;



      let nextMachineId = current.machine_id ?? null;

      if (Object.prototype.hasOwnProperty.call(options, 'machineId') && options.machineId !== current.machine_id) {

        nextMachineId = options.machineId ?? null;

        touched = true;

      }



      if (!touched) {

        return {

          ok: false,

          reason: 'NO_CHANGE',

          previousStatus,

          stagedAt: toIso(current.staged_at as string | Date | null | undefined),

          cutAt: toIso(current.cut_at as string | Date | null | undefined),

          nestpickCompletedAt: toIso(current.nestpick_completed_at as string | Date | null | undefined),

          updatedAt: toIso(current.updated_at as string | Date | null | undefined)

        } as const;

      }



      const updated = await run(

        'UPDATE jobs SET status = $1, staged_at = $2, cut_at = $3, nestpick_completed_at = $4, machine_id = $5, updated_at = $6 WHERE key = $7 RETURNING status, machine_id, staged_at, cut_at, nestpick_completed_at, updated_at',

        [to, nextStaged, nextCut, nextNestpick, nextMachineId, now, key]

      );



      if (!updated.rowCount) {

        return { ok: false, reason: 'NOT_FOUND' } as const;

      }



      const row = updated.rows[0];

      return {

        ok: true,

        status: row.status,

        previousStatus,

        machineId: row.machine_id ?? null,

        stagedAt: toIso(row.staged_at as string | Date | null | undefined),

        cutAt: toIso(row.cut_at as string | Date | null | undefined),

        nestpickCompletedAt: toIso(row.nestpick_completed_at as string | Date | null | undefined),

        updatedAt: toIso(row.updated_at as string | Date | null | undefined)

      } as const;

    }

  };

});



describe('IPC integration', () => {

  beforeAll(async () => {

    db.public.none(`

      CREATE TYPE job_status AS ENUM (

        'PENDING','STAGED','LOAD_FINISH','LABEL_FINISH','CNC_FINISH','FORWARDED_TO_NESTPICK','NESTPICK_COMPLETE'

      );



      CREATE TABLE public.jobs (

        key TEXT PRIMARY KEY,

        folder TEXT,

        ncfile TEXT,

        material TEXT,

        parts TEXT,

        size TEXT,

        thickness TEXT,

        dateadded TIMESTAMP,

        staged_at TIMESTAMP,

        cut_at TIMESTAMP,

        nestpick_completed_at TIMESTAMP,

        updated_at TIMESTAMP DEFAULT now(),

        is_reserved BOOLEAN DEFAULT FALSE,

        machine_id INTEGER,

        status job_status DEFAULT 'PENDING',

        pallet TEXT,

        last_error TEXT

      );



      CREATE TABLE public.job_events (

        event_id SERIAL PRIMARY KEY,

        key TEXT NOT NULL,

        machine_id INTEGER,

        event_type TEXT NOT NULL,

        payload JSONB,

        created_at TIMESTAMP DEFAULT now()

      );



      CREATE TABLE public.machines (

        machine_id SERIAL PRIMARY KEY,

        name TEXT NOT NULL,

        ap_jobfolder TEXT,

        nestpick_folder TEXT,

        nestpick_enabled BOOLEAN DEFAULT TRUE,

        pc_port INTEGER DEFAULT 5000

      );



      CREATE TABLE public.grundner (

        id SERIAL PRIMARY KEY,

        type_data INTEGER,

        customer_id TEXT,

        reserved_stock INTEGER DEFAULT 0

      );

    `);



    db.public.none(`

      INSERT INTO public.machines (machine_id, name, ap_jobfolder, nestpick_folder, nestpick_enabled, pc_port)

      VALUES (1, 'Router A', 'C:/ap/router-a', 'C:/nest/router-a', TRUE, 5000);



      INSERT INTO public.jobs (key, folder, ncfile, material, parts, size, thickness, dateadded, status, machine_id)

      VALUES ('JOB-1', 'folder/job-1', 'job-1', 'Plywood', '10', '1200x600', '18', now(), 'PENDING', 1);



      INSERT INTO public.grundner (id, type_data, customer_id, reserved_stock)

      VALUES (1, 1, 'Plywood', 0);

    `);



    const { registerDbIpc } = await import('../../packages/main/src/ipc/db');

    const { registerJobsIpc } = await import('../../packages/main/src/ipc/jobs');

    const { registerLifecycleIpc } = await import('../../packages/main/src/ipc/lifecycle');



    const electron = await import('electron');

    if (!electron.ipcMain) {

      throw new Error('ipcMain mock was not applied');

    }



    registerDbIpc();

    registerJobsIpc();

    registerLifecycleIpc();

  });



  async function invoke<T>(channel: string, ...args: unknown[]): Promise<ResultEnvelope<T>> {

    const handler = handlers.get(channel);

    if (!handler) throw new Error(`No handler registered for ${channel}`);

    const sender = createSender();

    const event: InvokeEvent = { sender };

    const outcome = handler(event, ...args);

    return (await Promise.resolve(outcome)) as ResultEnvelope<T>;

  }

  function expectOk<T>(payload: ResultEnvelope<T>): T {
    expect(payload.ok).toBe(true);
    if (!payload.ok) {
      const { code, message } = payload.error;
      throw new Error(`Expected ok result but received ${code}: ${message}`);
    }
    return payload.value;
  }


  it('responds to db:ping', async () => {

    const result = await invoke<null>('db:ping');

    expect(expectOk(result)).toBeNull();

  });



  it('lists jobs and updates lifecycle', async () => {

    const list = expectOk(await invoke<JobsListRes>('jobs:list', { limit: 50, filter: {}, sortBy: 'dateadded', sortDir: 'desc' }));

    expect(list.items).toHaveLength(1);

    expect(list.items[0].key).toBe('JOB-1');

    expectOk(await invoke<null>('jobs:reserve', { key: 'JOB-1' }));

    const lifecycle = expectOk(
      await invoke<LifecycleRes>('jobs:lifecycle', { key: 'JOB-1', to: 'STAGED', machineId: 1 })
    );

    expect(lifecycle.status).toBe('STAGED');

    expectOk(await invoke<null>('jobs:unreserve', { key: 'JOB-1' }));

  });

});










/* eslint-disable @typescript-eslint/no-explicit-any */

================
File: tests/setup/electronMock.ts
================
import { join } from 'path';
import { vi } from 'vitest';
import type { IpcMain } from 'electron';

const handlers = new Map<string, (...args: unknown[]) => unknown>();

const ipcMain = {
  handle: vi.fn((channel: string, handler: (...args: unknown[]) => unknown) => {
    handlers.set(channel, handler);
  }),
  removeHandler: vi.fn((channel: string) => {
    handlers.delete(channel);
  })
};

const resolvedUserData = () => {
  const override = process.env.WOODTRON_USER_DATA_PATH;
  if (override && override.trim()) return override.trim();
  return join(process.cwd(), '.woodtron');
};

const app = {
  getPath: vi.fn((key: string) => (key === 'userData' ? resolvedUserData() : resolvedUserData())),
  isReady: vi.fn(() => true),
  whenReady: vi.fn(() => Promise.resolve()),
  on: vi.fn()
};

const shell = {
  openExternal: vi.fn(async () => undefined)
};

const shared = {
  app,
  ipcMain,
  BrowserWindow: class {},
  shell
};

vi.mock('electron', () => shared);

(async () => {
  const bridgeModule = await import('../../packages/main/src/ipc/ipcBridge');
  const mod = bridgeModule as { __setIpcMain?: (mock: IpcMain) => void };
  if (mod && typeof mod.__setIpcMain === 'function') {
    mod.__setIpcMain(ipcMain as unknown as IpcMain);
  }
})();

(globalThis as unknown as { __IPC_HANDLERS__?: Map<string, (...args: unknown[]) => unknown> }).__IPC_HANDLERS__ = handlers;

================
File: tests/tsconfig.json
================
{
    "extends":  "../tsconfig.base.json",
    "compilerOptions":  {
                            "module":  "CommonJS",
                            "moduleResolution":  "node",
                            "lib":  [
                                        "ES2020",
                                        "DOM"
                                    ],
                            "types":  [
                                          "node",
                                          "vitest/globals",
                                          "@playwright/test"
                                      ],
                            "noEmit":  true
                        },
    "include":  [
                    "../packages/renderer/src/types/global.d.ts",
                    "./**/*.ts",
                    "./**/*.tsx"
                ]
}

================
File: tests/unit/alarmsRepo.test.ts
================
import { beforeEach, describe, expect, it, vi } from 'vitest';

const queryMock = vi.fn();
const errorMock = vi.fn();

vi.mock('../../packages/main/src/services/db', () => ({
  withClient: async (fn: (client: { query: typeof queryMock }) => unknown) => fn({ query: queryMock })
}));

vi.mock('../../packages/main/src/logger', () => ({
  logger: {
    error: errorMock,
    warn: vi.fn(),
    info: vi.fn(),
    debug: vi.fn()
  }
}));

describe('alarms repository', () => {
  beforeEach(() => {
    queryMock.mockReset();
    errorMock.mockReset();
  });

  it('returns only active alarms with derived severity', async () => {
    queryMock.mockResolvedValueOnce({
      rows: [
        {
          key: 'Router-1',
          alarm: 'Emergency stop triggered',
          status: 'ALARM',
          mode: 'AUTO',
          currentprogram: 'JOB1',
          alarmhistory: 'prev'
        },
        {
          key: 'Router-2',
          alarm: 'OK',
          status: 'READY',
          mode: 'MANUAL',
          currentprogram: 'JOB2',
          alarmhistory: 'hist'
        }
      ]
    });

    const { listActiveAlarms } = await import('../../packages/main/src/repo/alarmsRepo');
    const alarms = await listActiveAlarms();
    expect(alarms).toHaveLength(1);
    expect(alarms[0]).toMatchObject({
      key: 'Router-1',
      alarm: 'Emergency stop triggered',
      severity: 'critical'
    });
    expect(typeof alarms[0].lastSeenAt).toBe('string');
  });

  it('logs and returns empty list on failure', async () => {
    queryMock.mockRejectedValueOnce(new Error('boom'));
    const { listActiveAlarms } = await import('../../packages/main/src/repo/alarmsRepo');
    const result = await listActiveAlarms();
    expect(result).toEqual([]);
    expect(errorMock).toHaveBeenCalled();
  });
});

================
File: tests/unit/alarmUtils.test.ts
================
import { describe, expect, it } from 'vitest';
import type { AlarmEntry } from '../../packages/shared/src';
import { selectCurrentAlarms } from '../../packages/renderer/src/shell/alarmUtils';

const createAlarm = (key: string, alarm: string, overrides: Partial<AlarmEntry> = {}): AlarmEntry => ({
  id: `${key}:${alarm}`,
  key,
  alarm,
  status: null,
  mode: null,
  currentProgram: null,
  alarmHistory: null,
  lastSeenAt: '2025-01-01T00:00:00.000Z',
  severity: 'warning',
  ...overrides
});

describe('selectCurrentAlarms', () => {
  it('returns first entry per machine key preserving order', () => {
    const raw: AlarmEntry[] = [
      createAlarm('M1', 'Alarm A'),
      createAlarm('M1', 'Alarm B'),
      createAlarm('M2', 'Alarm X'),
      createAlarm('M2', 'Alarm Y'),
      createAlarm('M3', 'Alarm 1')
    ];

    const current = selectCurrentAlarms(raw);

    expect(current).toHaveLength(3);
    expect(current[0].alarm).toBe('Alarm A');
    expect(current[1].alarm).toBe('Alarm X');
    expect(current[2].alarm).toBe('Alarm 1');
  });

  it('returns empty array when no alarms', () => {
    expect(selectCurrentAlarms([])).toEqual([]);
  });
});

================
File: tests/unit/config.test.ts
================
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
import { mkdtempSync, rmSync, readFileSync, existsSync } from 'fs';
import { join } from 'path';
import { tmpdir } from 'os';

const ENV_KEY = 'WOODTRON_USER_DATA_PATH';

describe('config service', () => {
  let tempDir: string;

  beforeEach(() => {
    tempDir = mkdtempSync(join(tmpdir(), 'woodtron-config-'));
    process.env[ENV_KEY] = tempDir;
    vi.resetModules();
  });

  afterEach(() => {
    delete process.env[ENV_KEY];
    rmSync(tempDir, { recursive: true, force: true });
  });

  async function loadModule() {
    return import('../../packages/main/src/services/config');
  }

  it('creates defaults when config file missing', async () => {
    const { loadConfig } = await loadModule();
    const cfg = loadConfig();
    expect(cfg.db.host).toBe('localhost');
    const file = join(tempDir, 'settings.json');
    expect(existsSync(file)).toBe(true);
    const written = JSON.parse(readFileSync(file, 'utf8'));
    expect(written.db.host).toBe('localhost');
  });

  it('persists overrides and reloads them', async () => {
    const mod = await loadModule();
    const next = mod.loadConfig();
    next.db.host = 'db.internal';
    next.paths.processedJobsRoot = 'C:/jobs';
    next.db.password = 'secret';
    mod.saveConfig(next);

    vi.resetModules();
    process.env[ENV_KEY] = tempDir;
    const reloaded = (await loadModule()).loadConfig();
    expect(reloaded.db.host).toBe('db.internal');
    expect(reloaded.paths.processedJobsRoot).toBe('C:/jobs');
  });

  it('redacts sensitive settings', async () => {
    const { loadConfig, redactSettings } = await loadModule();
    const cfg = loadConfig();
    cfg.db.password = 'secret';
    const sanitized = redactSettings(cfg);
    expect(sanitized.db.password).toBe('********');
  });
});

================
File: tests/unit/diagnostics.test.ts
================
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
import { mkdtempSync, rmSync, writeFileSync, readFileSync } from 'fs';
import { join } from 'path';
import { tmpdir } from 'os';

const dbStatusMock = vi.fn(() => ({
  online: true,
  checkedAt: new Date().toISOString(),
  latencyMs: 12,
  error: null
}));

vi.mock('../../packages/main/src/services/dbWatchdog', () => ({
  getDbStatus: dbStatusMock
}));

vi.mock('../../packages/main/src/logger', () => ({
  logger: {
    warn: vi.fn(),
    info: vi.fn(),
    error: vi.fn(),
    debug: vi.fn()
  }
}));

describe('diagnostics service', () => {
  let tempDir: string;

  beforeEach(() => {
    tempDir = mkdtempSync(join(tmpdir(), 'woodtron-diagnostics-'));
    vi.resetModules();
  });

  afterEach(() => {
    rmSync(tempDir, { recursive: true, force: true });
  });

  async function loadDiagnostics() {
    return import('../../packages/main/src/services/diagnostics');
  }

  it('loads existing error log on initialization', async () => {
    const logPath = join(tempDir, 'worker-errors.jsonl');
    const existing = { id: '1', source: 'worker', message: 'prior error', timestamp: new Date().toISOString() };
    writeFileSync(logPath, JSON.stringify(existing) + '\n');

    const diagnostics = await loadDiagnostics();
    await diagnostics.initializeDiagnostics(tempDir);
    const snapshot = diagnostics.getDiagnosticsSnapshot();
    expect(snapshot.recentErrors).toHaveLength(1);
    expect(snapshot.recentErrors[0].message).toBe('prior error');
  });

  it('records watcher transitions and worker errors', async () => {
    const diagnostics = await loadDiagnostics();
    await diagnostics.initializeDiagnostics(tempDir);

    diagnostics.registerWatcher('watcher:auto', 'Auto Watcher');
    diagnostics.watcherReady('watcher:auto', 'Auto Watcher');

    const snapshots: string[] = [];
    const unsubscribe = diagnostics.subscribeDiagnostics((snapshot) => {
      snapshots.push(snapshot.lastUpdatedAt);
    });

    const entry = diagnostics.recordWorkerError('test-source', new Error('boom'), { job: 'A1' });
    expect(entry.message).toBe('boom');
    expect(entry.source).toBe('test-source');

    const snapshot = diagnostics.getDiagnosticsSnapshot();
    expect(snapshot.watchers[0]).toMatchObject({
      name: 'watcher:auto',
      status: 'watching'
    });
    expect(snapshot.recentErrors[0].message).toBe('boom');
    expect(snapshots.length).toBeGreaterThan(0);

    unsubscribe();

    await new Promise((resolve) => setTimeout(resolve, 20));

    const logPath = join(tempDir, 'worker-errors.jsonl');
    const written = readFileSync(logPath, 'utf8');
    expect(written).toContain('boom');
  });
});

================
File: tests/unit/ipcErrors.test.ts
================
import { describe, expect, it } from 'vitest';
interface DatabaseError extends Error { code?: string; detail?: string; schema?: string; table?: string; constraint?: string; column?: string }

import { createAppError, toAppError } from '../../packages/main/src/ipc/errors';

const makeDbError = (message: string, props: Record<string, unknown>): DatabaseError => {
  return Object.assign(new Error(message), props) as DatabaseError;
};

describe('ipc error mapping', () => {
  it('returns existing AppError instances unchanged', () => {
    const appError = createAppError('custom.error', 'something went wrong', { hint: 'retry' });
    const mapped = toAppError(appError);
    expect(mapped).toBe(appError);
  });

  it('maps known Postgres errors to friendly AppError variants', () => {
    const dbError = makeDbError('duplicate key value violates unique constraint "jobs_pkey"', {
      code: '23505',
      detail: 'Key (id)=(1) already exists.',
      schema: 'public',
      table: 'jobs',
      constraint: 'jobs_pkey',
      column: 'id'
    });

    const mapped = toAppError(dbError);

    expect(mapped.code).toBe('db.uniqueViolation');
    expect(mapped.message).toBe('A record with the same value already exists.');
    expect(mapped.details).toEqual({
      detail: 'Key (id)=(1) already exists.',
      schema: 'public',
      table: 'jobs',
      constraint: 'jobs_pkey',
      column: 'id'
    });
  });

  it('falls back to generic db error for unmapped Postgres codes', () => {
    const dbError = makeDbError('connection reset', {
      code: '99999',
      table: 'jobs'
    });

    const mapped = toAppError(dbError);

    expect(mapped.code).toBe('db.error');
    expect(mapped.message).toBe('connection reset');
    expect(mapped.details).toEqual({ table: 'jobs' });
  });

  it('wraps standard Error instances', () => {
    const error = new Error('explode');

    const mapped = toAppError(error);

    expect(mapped.code).toBe('unknown');
    expect(mapped.message).toBe('explode');
    const details = mapped.details as { stack?: string } | undefined;
    if (details) {
      expect(typeof details.stack).toBe('string');
    }
  });

  it('wraps arbitrary values as unknown errors', () => {
    const raw = { unexpected: true };

    const mapped = toAppError(raw);

    expect(mapped.code).toBe('unknown');
    expect(mapped.message).toBe('An unknown error occurred.');
    expect(mapped.details).toEqual({ raw });
  });
});

================
File: tests/unit/ipcResult.test.ts
================
import { beforeEach, describe, expect, it, vi } from 'vitest';
import { err, ok, type Result } from 'neverthrow';
import { ipcMain } from 'electron';

import type { AppError, ResultEnvelope } from '../../packages/shared/src';
import { createAppError } from '../../packages/main/src/ipc/errors';
import { failure, fromPromise, fromResult, registerResultHandler, success } from '../../packages/main/src/ipc/result';

type StoredHandler = (event: unknown, ...args: unknown[]) => unknown;

const handlers = ((globalThis as unknown as { __IPC_HANDLERS__?: Map<string, StoredHandler> }).__IPC_HANDLERS__ ?? new Map<string, StoredHandler>()) as Map<string, StoredHandler>;

describe('ipc result utilities', () => {
  beforeEach(() => {
    vi.clearAllMocks();
    handlers.clear();
  });

  it('wraps neverthrow results as envelopes', () => {
    const valueEnvelope = fromResult(ok('value'));
    expect(valueEnvelope).toEqual({ ok: true, value: 'value' });

    const appError = createAppError('test.failure', 'nope', { extra: 1 });
    const errorEnvelope = fromResult(err(appError));
    expect(errorEnvelope).toEqual({ ok: false, error: appError });
  });

  it('converts promises into envelopes', async () => {
    const resolver = vi.fn(async () => 42);
    const okEnvelope = await fromPromise(resolver);
    expect(resolver).toHaveBeenCalledOnce();
    expect(okEnvelope).toEqual({ ok: true, value: 42 });

    const appError = createAppError('db.error', 'boom');
    const failureEnvelope = await fromPromise(() => Promise.reject(appError));
    expect(failureEnvelope).toEqual({ ok: false, error: appError });
  });

  it('builds success and failure envelopes directly', () => {
    expect(success('ready')).toEqual({ ok: true, value: 'ready' });

    const appError = createAppError('test.failure', 'kaboom');
    expect(failure(appError)).toEqual({ ok: false, error: appError });
  });

  describe('registerResultHandler', () => {
    it('registers handler and forwards result envelopes', async () => {
      const appError = createAppError('test.failure', 'invalid');
      const okHandler = vi.fn(async () => ok('ok-result'));
      const errHandler = vi.fn(() => err(appError) as Result<string, AppError>);

      registerResultHandler<string>('test:ok', okHandler);
      registerResultHandler<string>('test:err', errHandler);

      expect(ipcMain.handle).toHaveBeenCalledWith('test:ok', expect.any(Function));
      expect(ipcMain.handle).toHaveBeenCalledWith('test:err', expect.any(Function));

      const okRegistered = handlers.get('test:ok');
      expect(typeof okRegistered).toBe('function');
      const okPayload = (await okRegistered!({ sender: { id: 1 } })) as ResultEnvelope<string>;
      expect(okHandler).toHaveBeenCalledWith(expect.objectContaining({ sender: { id: 1 } }));
      expect(okPayload).toEqual({ ok: true, value: 'ok-result' });

      const errRegistered = handlers.get('test:err');
      expect(typeof errRegistered).toBe('function');
      const errPayload = (await errRegistered!({ sender: { id: 2 } })) as ResultEnvelope<string>;
      expect(errHandler).toHaveBeenCalledWith(expect.objectContaining({ sender: { id: 2 } }));
      expect(errPayload).toEqual({ ok: false, error: appError });
    });

    it('maps thrown errors via toAppError', async () => {
      registerResultHandler<string>('test:throw', () => {
        throw new Error('explode');
      });

      const handler = handlers.get('test:throw');
      expect(typeof handler).toBe('function');
      const payload = (await handler!({ sender: {} })) as ResultEnvelope<string>;
      expect(payload.ok).toBe(false);
      if (!payload.ok) {
        expect(payload.error.code).toBe('unknown');
        expect(payload.error.message).toBe('explode');
        expect(payload.error.details).toBeDefined();
      }
    });
  });
});

================
File: tests/unit/telemetryParser.test.ts
================
import { describe, expect, it } from 'vitest';
import { normalizeTelemetryPayload } from '../../packages/main/src/workers/telemetryParser';
import type { Machine } from '../../packages/shared/src';

describe('normalizeTelemetryPayload', () => {
  const baseMachine: Machine = {
    machineId: 7,
    name: 'Router A',
    pcIp: '10.0.0.5',
    cncIp: null,
    cncPort: null,
    apJobfolder: 'c:/jobs',
    nestpickFolder: 'c:/nestpick',
    nestpickEnabled: true,
    pcPort: 5000
  };

  it('maps flat payload fields', () => {
    const payload = {
      status: 'RUN',
      mode: 'AUTO',
      alarm: 'ok',
      currentProgram: 'JOB123',
      powerOnTime: '12:34',
      cuttingTime: '01:20'
    };
    const result = normalizeTelemetryPayload(baseMachine, payload);
    expect(result.key).toBe('Router A');
    expect(result.status).toBe('RUN');
    expect(result.mode).toBe('AUTO');
    expect(result.currentProgram).toBe('JOB123');
    expect(result.powerOnTime).toBe('12:34');
    expect(result.cuttingTime).toBe('01:20');
    expect(result.apiIp).toBe('10.0.0.5');
  });

  it('extracts nested timer fields and payload key override', () => {
    const payload = {
      key: 'Router-Override',
      timers: {
        power_on: '88:00',
        cutting_time: '03:45'
      },
      alarmHistory: 'none'
    };
    const result = normalizeTelemetryPayload(baseMachine, payload);
    expect(result.key).toBe('Router-Override');
    expect(result.powerOnTime).toBe('88:00');
    expect(result.cuttingTime).toBe('03:45');
    expect(result.alarmHistory).toBe('none');
  });

  it('falls back to machine identifier when name missing', () => {
    const unnamed: Machine = { ...baseMachine, name: '', machineId: 42 };
    const result = normalizeTelemetryPayload(unnamed, {});
    expect(result.key).toBe('Machine 42');
  });
});

================
File: tests/unit/watchersService.test.ts
================
import { EventEmitter } from 'events';
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';

class FakeWorker extends EventEmitter {
  public readonly script: string;
  public readonly postMessage = vi.fn();
  public readonly terminate = vi.fn(async () => {});

  constructor(script: string) {
    super();
    this.script = script;
  }
}

const workerState = { instances: [] as FakeWorker[] };
const workerCtor = vi.fn((script: string) => {
  const worker = new FakeWorker(script);
  workerState.instances.push(worker);
  return worker;
});

vi.mock('worker_threads', () => ({
  Worker: workerCtor
}));

const diagnostics = {
  registerWatcher: vi.fn(),
  watcherReady: vi.fn(),
  recordWatcherEvent: vi.fn(),
  recordWatcherError: vi.fn(),
  recordWorkerError: vi.fn(),
  setMachineHealthIssue: vi.fn(),
  clearMachineHealthIssue: vi.fn()
};

vi.mock('../../packages/main/src/services/diagnostics', () => diagnostics);

const logger = {
  info: vi.fn(),
  warn: vi.fn(),
  error: vi.fn(),
  debug: vi.fn()
};

vi.mock('../../packages/main/src/logger', () => ({ logger }));

describe('watchers service', () => {
  let watchers: { initWatchers: () => void; shutdownWatchers: () => Promise<void> };

  beforeEach(async () => {
    vi.resetModules();
    workerState.instances.length = 0;
    workerCtor.mockClear();
    Object.values(diagnostics).forEach((fn) => fn.mockClear?.());
    Object.values(logger).forEach((fn) => fn.mockClear?.());
    process.env.WOODTRON_WATCHERS_WORKER_PATH = 'C:/fake/watchersWorker.js';
    watchers = await import('../../packages/main/src/services/watchers');
  });

  afterEach(async () => {
    const instance = workerState.instances[0];
    if (instance) {
      const shutdown = watchers.shutdownWatchers();
      instance.emit('exit', 0);
      await shutdown;
    } else {
      await watchers.shutdownWatchers();
    }
    delete process.env.WOODTRON_WATCHERS_WORKER_PATH;
  });

  it('spawns worker and relays watcher lifecycle events', () => {
    watchers.initWatchers();
    expect(workerCtor).toHaveBeenCalledWith('C:/fake/watchersWorker.js');

    const instance = workerState.instances[0];
    expect(instance).toBeTruthy();

    instance.emit('message', { type: 'registerWatcher', name: 'watcher:auto', label: 'Auto' });
    expect(diagnostics.registerWatcher).toHaveBeenCalledWith('watcher:auto', 'Auto');

    instance.emit('message', { type: 'watcherReady', name: 'watcher:auto', label: 'Auto' });
    expect(diagnostics.watcherReady).toHaveBeenCalledWith('watcher:auto', 'Auto');

    instance.emit('message', {
      type: 'watcherEvent',
      name: 'watcher:auto',
      label: 'Auto',
      message: 'CSV processed',
      context: { job: 'JOB-1' }
    });
    expect(diagnostics.recordWatcherEvent).toHaveBeenCalledWith('watcher:auto', {
      label: 'Auto',
      message: 'CSV processed',
      context: { job: 'JOB-1' }
    });

    instance.emit('message', {
      type: 'watcherError',
      name: 'watcher:auto',
      label: 'Auto',
      error: { message: 'boom', stack: 'stack-trace' },
      context: { job: 'JOB-1' }
    });
    expect(diagnostics.recordWatcherError).toHaveBeenCalledWith(
      'watcher:auto',
      expect.objectContaining({ message: 'boom' }),
      { job: 'JOB-1', label: 'Auto' }
    );
  });

  it('propagates machine health updates and telemetry worker errors', () => {
    watchers.initWatchers();
    const instance = workerState.instances[0];
    expect(instance).toBeTruthy();

    instance.emit('message', {
      type: 'machineHealthSet',
      payload: { machineId: 7, code: 'NO_PARTS_CSV', message: 'Missing parts CSV' }
    });
    expect(diagnostics.setMachineHealthIssue).toHaveBeenCalledWith({
      machineId: 7,
      code: 'NO_PARTS_CSV',
      message: 'Missing parts CSV'
    });

    instance.emit('message', {
      type: 'machineHealthClear',
      payload: { machineId: 7, code: 'NO_PARTS_CSV' }
    });
    expect(diagnostics.clearMachineHealthIssue).toHaveBeenCalledWith(7, 'NO_PARTS_CSV');

    instance.emit('message', {
      type: 'workerError',
      source: 'telemetry:init',
      error: { message: 'telemetry down', stack: 'stack' },
      context: { host: '127.0.0.1' }
    });
    expect(diagnostics.recordWorkerError).toHaveBeenCalledWith(
      'telemetry:init',
      expect.objectContaining({ message: 'telemetry down' }),
      { host: '127.0.0.1' }
    );
  });

  it('shuts down the worker thread gracefully', async () => {
    watchers.initWatchers();
    const instance = workerState.instances[0];
    expect(instance).toBeTruthy();

    const shutdown = watchers.shutdownWatchers();
    expect(instance.postMessage).toHaveBeenCalledWith({ type: 'shutdown', reason: 'app-quit' });
    instance.emit('exit', 0);
    await shutdown;
    expect(instance.terminate).not.toHaveBeenCalled();
  });
});

================
File: tsconfig.base.json
================
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "CommonJS",
    "moduleResolution": "node",
    "strict": true,
    "skipLibCheck": true,
    "esModuleInterop": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "isolatedModules": false,
    "noEmit": true
  }
}

================
File: vitest.config.ts
================
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    environment: 'node',
    include: ['tests/**/*.test.ts'],
    setupFiles: ['tests/setup/electronMock.ts'],
    coverage: {
      provider: 'v8',
      reporter: ['text', 'html', 'lcov'],
      reportsDirectory: 'coverage',
      include: ['packages/main/src/**/*.ts', 'packages/preload/src/**/*.ts', 'packages/shared/src/**/*.ts'],
      exclude: ['tests/**', 'packages/**/dist/**', 'packages/renderer/**', 'resources/**'],
      thresholds: {
        statements: 10,
        lines: 10,
        functions: 10,
        branches: 5
      }
    }
  }
});
